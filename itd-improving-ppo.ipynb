{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11422967,"sourceType":"datasetVersion","datasetId":7153855},{"sourceId":11424466,"sourceType":"datasetVersion","datasetId":7154956},{"sourceId":11673316,"sourceType":"datasetVersion","datasetId":7326109},{"sourceId":11703407,"sourceType":"datasetVersion","datasetId":7345979}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vaasini889123/itd-improving-ppo?scriptVersionId=239252935\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:43:19.510578Z","iopub.execute_input":"2025-05-05T14:43:19.510802Z","iopub.status.idle":"2025-05-05T14:43:19.526591Z","shell.execute_reply.started":"2025-05-05T14:43:19.510779Z","shell.execute_reply":"2025-05-05T14:43:19.525857Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/reqd-data-lstmrl/merged_df.csv\n/kaggle/input/reqd-data-lstmrl/beh.csv\n/kaggle/input/reqd-data-lstmrl/role_mappings_users.csv\n/kaggle/input/features-extracted/final_features_extracted.csv\n/kaggle/input/lstm-vae/user_day_sequences (3).csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout, RepeatVector, TimeDistributed, Masking, BatchNormalization, Bidirectional\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport tensorflow as tf\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nimport gym\nfrom gym import spaces","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:10.068042Z","iopub.execute_input":"2025-05-07T05:09:10.068652Z","iopub.status.idle":"2025-05-07T05:09:10.073048Z","shell.execute_reply.started":"2025-05-07T05:09:10.068632Z","shell.execute_reply":"2025-05-07T05:09:10.072267Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras.layers import Lambda, TimeDistributed\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:12.421534Z","iopub.execute_input":"2025-05-07T05:09:12.421811Z","iopub.status.idle":"2025-05-07T05:09:12.425611Z","shell.execute_reply.started":"2025-05-07T05:09:12.421792Z","shell.execute_reply":"2025-05-07T05:09:12.424791Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import os\nfrom tensorflow.keras.models import save_model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Layer\nimport ast\nfrom sklearn.preprocessing import OneHotEncoder\nfrom google.colab import files\nimport json\nfrom collections import defaultdict, deque","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:13.603392Z","iopub.execute_input":"2025-05-07T05:09:13.604128Z","iopub.status.idle":"2025-05-07T05:09:13.608088Z","shell.execute_reply.started":"2025-05-07T05:09:13.604103Z","shell.execute_reply":"2025-05-07T05:09:13.607326Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense\nimport random\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:15.8615Z","iopub.execute_input":"2025-05-07T05:09:15.861765Z","iopub.status.idle":"2025-05-07T05:09:15.865458Z","shell.execute_reply.started":"2025-05-07T05:09:15.861746Z","shell.execute_reply":"2025-05-07T05:09:15.864747Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:18.401606Z","iopub.execute_input":"2025-05-07T05:09:18.402178Z","iopub.status.idle":"2025-05-07T05:09:18.406025Z","shell.execute_reply.started":"2025-05-07T05:09:18.402156Z","shell.execute_reply":"2025-05-07T05:09:18.405137Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, TimeDistributed, Dropout, Attention\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:30.896845Z","iopub.execute_input":"2025-05-07T05:09:30.897445Z","iopub.status.idle":"2025-05-07T05:09:30.901187Z","shell.execute_reply.started":"2025-05-07T05:09:30.897422Z","shell.execute_reply":"2025-05-07T05:09:30.900443Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:36.141639Z","iopub.execute_input":"2025-05-07T05:09:36.142333Z","iopub.status.idle":"2025-05-07T05:09:36.14557Z","shell.execute_reply.started":"2025-05-07T05:09:36.142308Z","shell.execute_reply":"2025-05-07T05:09:36.144995Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/lstm-vae/user_day_sequences (3).csv')\ndata = data['activity_sequence']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:04.629519Z","iopub.execute_input":"2025-05-04T14:31:04.630107Z","iopub.status.idle":"2025-05-04T14:31:04.962114Z","shell.execute_reply.started":"2025-05-04T14:31:04.630082Z","shell.execute_reply":"2025-05-04T14:31:04.961514Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def convert_to_int_list(activity_sequence):\n    try:\n        int_list = ast.literal_eval(activity_sequence)\n\n        if all(isinstance(item, int) for item in int_list):\n          return int_list\n        else:\n          return [int(x) for x in int_list]\n    except (SyntaxError, ValueError):\n        print(f\"Invalid activity sequence: {activity_sequence}\")\n        return [] \n\ndata = data.apply(convert_to_int_list) # Corrected line to apply function to the Series directly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:06.284706Z","iopub.execute_input":"2025-05-04T14:31:06.285314Z","iopub.status.idle":"2025-05-04T14:31:12.131852Z","shell.execute_reply.started":"2025-05-04T14:31:06.285287Z","shell.execute_reply":"2025-05-04T14:31:12.131308Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.13282Z","iopub.execute_input":"2025-05-04T14:31:12.133077Z","iopub.status.idle":"2025-05-04T14:31:12.203791Z","shell.execute_reply.started":"2025-05-04T14:31:12.133054Z","shell.execute_reply":"2025-05-04T14:31:12.203205Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"df = data.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.204515Z","iopub.execute_input":"2025-05-04T14:31:12.205007Z","iopub.status.idle":"2025-05-04T14:31:12.283692Z","shell.execute_reply.started":"2025-05-04T14:31:12.204965Z","shell.execute_reply":"2025-05-04T14:31:12.283195Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Parse strings to lists\nsequences = [seq for seq in df]\n\n# Get unique labels\nall_labels = set()\nfor seq in sequences:\n    all_labels.update(seq)\nlabels = sorted(list(all_labels)) \nV = len(labels)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.285188Z","iopub.execute_input":"2025-05-04T14:31:12.285527Z","iopub.status.idle":"2025-05-04T14:31:12.459488Z","shell.execute_reply.started":"2025-05-04T14:31:12.285505Z","shell.execute_reply":"2025-05-04T14:31:12.45871Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"encoder = OneHotEncoder(categories=[labels], handle_unknown='ignore') \nmax_len = 86  #longest sequence\n\n# Converting sequences to one-hot encoded arrays\nX = []\nfor seq in sequences:\n    seq_array = np.array(seq).reshape(-1, 1)\n    one_hot = encoder.fit_transform(seq_array).toarray() \n    # Pad to max_len\n    padded = np.pad(one_hot, ((0, max_len - len(seq)), (0, 0)), mode='constant')  # Shape: (max_len, V)\n    X.append(padded)\nX = np.array(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.460178Z","iopub.execute_input":"2025-05-04T14:31:12.460385Z","iopub.status.idle":"2025-05-04T14:34:01.981615Z","shell.execute_reply.started":"2025-05-04T14:31:12.460369Z","shell.execute_reply":"2025-05-04T14:34:01.981003Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"np.save('X.npy', X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:34:01.983251Z","iopub.execute_input":"2025-05-04T14:34:01.983493Z","iopub.status.idle":"2025-05-04T14:34:03.720854Z","shell.execute_reply.started":"2025-05-04T14:34:01.983476Z","shell.execute_reply":"2025-05-04T14:34:03.72002Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:21:05.60917Z","iopub.execute_input":"2025-05-04T13:21:05.609383Z","iopub.status.idle":"2025-05-04T13:21:05.615395Z","shell.execute_reply.started":"2025-05-04T13:21:05.609366Z","shell.execute_reply":"2025-05-04T13:21:05.61452Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(330452, 86, 12)"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:48:58.559838Z","iopub.execute_input":"2025-05-04T13:48:58.560166Z","iopub.status.idle":"2025-05-04T13:48:58.567966Z","shell.execute_reply.started":"2025-05-04T13:48:58.560106Z","shell.execute_reply":"2025-05-04T13:48:58.567373Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"array([[[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 1., 0.],\n        [0., 0., 1., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 1., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 1., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 1.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 1.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 1., 0.],\n        [0., 0., 0., ..., 0., 0., 1.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"X = np.load('/kaggle/working/X.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:30:31.055242Z","iopub.execute_input":"2025-05-04T14:30:31.055538Z","iopub.status.idle":"2025-05-04T14:30:31.103283Z","shell.execute_reply.started":"2025-05-04T14:30:31.055516Z","shell.execute_reply":"2025-05-04T14:30:31.102539Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/704012822.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/working/X.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/X.npy'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/working/X.npy'","output_type":"error"}],"execution_count":10},{"cell_type":"markdown","source":"viewing and selecting top features","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv('/kaggle/input/features-extracted/final_features_extracted.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:49:02.784123Z","iopub.execute_input":"2025-05-04T13:49:02.784789Z","iopub.status.idle":"2025-05-04T13:49:03.534254Z","shell.execute_reply.started":"2025-05-04T13:49:02.784764Z","shell.execute_reply":"2025-05-04T13:49:03.533609Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:32:27.391777Z","iopub.execute_input":"2025-05-04T13:32:27.392053Z","iopub.status.idle":"2025-05-04T13:32:27.465797Z","shell.execute_reply.started":"2025-05-04T13:32:27.392032Z","shell.execute_reply":"2025-05-04T13:32:27.465036Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                      0.0                   0   \n1       AAE0190  2010-01-05                      0.0                   0   \n2       AAE0190  2010-01-06                      0.0                   0   \n3       AAE0190  2010-01-07                      0.0                   0   \n4       AAE0190  2010-01-08                      0.0                   0   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                      0.0                   0   \n330281  ZSL0305  2011-05-11                      0.0                   0   \n330282  ZSL0305  2011-05-12                      0.0                   0   \n330283  ZSL0305  2011-05-13                      0.0                   0   \n330284  ZSL0305  2011-05-16                      0.0                   0   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                             0                1.0         1.0   \n1                             0                1.0         1.0   \n2                             0                1.0         1.0   \n3                             0                1.0         1.0   \n4                             0                1.0         1.0   \n...                         ...                ...         ...   \n330280                        0                1.0         1.0   \n330281                        0                1.0         1.0   \n330282                        0                1.0         1.0   \n330283                        0                1.0         1.0   \n330284                        0                1.0         1.0   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0                   0.0                   0.0              0.0  ...   \n1                   0.0                   0.0              0.0  ...   \n2                   0.0                   0.0              0.0  ...   \n3                   0.0                   0.0              0.0  ...   \n4                   0.0                   0.0              0.0  ...   \n...                 ...                   ...              ...  ...   \n330280              0.0                   0.0              0.0  ...   \n330281              0.0                   0.0              0.0  ...   \n330282              0.0                   0.0              0.0  ...   \n330283              0.0                   0.0              0.0  ...   \n330284              0.0                   0.0              0.0  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                         0.0                  0.0                0.0   \n1                         0.0                  0.0                0.0   \n2                         0.0                  0.0                0.0   \n3                         0.0                  0.0                0.0   \n4                         0.0                  0.0                0.0   \n...                       ...                  ...                ...   \n330280                    0.0                  0.0                0.0   \n330281                    0.0                  0.0                0.0   \n330282                    0.0                  0.0                0.0   \n330283                    0.0                  0.0                0.0   \n330284                    0.0                  0.0                0.0   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                           0.0                     0.0         14.0   \n1                           0.0                     0.0         13.0   \n2                           0.0                     0.0         14.0   \n3                           0.0                     0.0         14.0   \n4                           0.0                     0.0         13.0   \n...                         ...                     ...          ...   \n330280                      0.0                     0.0          1.0   \n330281                      0.0                     0.0          1.0   \n330282                      0.0                     0.0          1.0   \n330283                      0.0                     0.0          1.0   \n330284                      0.0                     0.0          1.0   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0                   43.0        0.214286             470.0       0.0  \n1                   39.0        0.538462             467.0       0.0  \n2                   40.0        0.642857             741.0       0.0  \n3                   42.0        0.571429             454.0       0.0  \n4                   40.0        0.307692             373.0       0.0  \n...                  ...             ...               ...       ...  \n330280               2.0        0.000000              41.0       0.0  \n330281               4.0        2.000000              49.0       0.0  \n330282               6.0        3.000000              48.0       0.0  \n330283               2.0        1.000000              30.0       0.0  \n330284               2.0        1.000000              67.0       0.0  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:32:30.501588Z","iopub.execute_input":"2025-05-04T13:32:30.502163Z","iopub.status.idle":"2025-05-04T13:32:30.506892Z","shell.execute_reply.started":"2025-05-04T13:32:30.502139Z","shell.execute_reply":"2025-05-04T13:32:30.5063Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'weekend_logon_flag',\n       'peer_machine_logon_flag', 'total_logon_count', 'unique_pcs',\n       'device_connects', 'after_hours_connects', 'device_pc_count',\n       'files_accessed', 'image_files_accessed', 'binary_files_accessed',\n       'text_files_accessed', 'file_type_entropy', 'sensitive_keyword_count',\n       'avg_content_word_count', 'emails_sent', 'total_recipients',\n       'external_ratio', 'keyword_richness', 'bcc_flag'],\n      dtype='object')"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"merged_df_forseq = pd.read_csv('/kaggle/input/reqd-data-lstmrl/merged_df.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:34:03.721737Z","iopub.execute_input":"2025-05-04T14:34:03.721993Z","iopub.status.idle":"2025-05-04T14:34:05.068325Z","shell.execute_reply.started":"2025-05-04T14:34:03.721956Z","shell.execute_reply":"2025-05-04T14:34:05.067458Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"seq_to_encode = merged_df_forseq['aggregated_sequence']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:40:21.925904Z","iopub.execute_input":"2025-05-04T15:40:21.926687Z","iopub.status.idle":"2025-05-04T15:40:21.929956Z","shell.execute_reply.started":"2025-05-04T15:40:21.926661Z","shell.execute_reply":"2025-05-04T15:40:21.929325Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"seq_to_encode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:32:37.161391Z","iopub.execute_input":"2025-05-04T13:32:37.161687Z","iopub.status.idle":"2025-05-04T13:32:37.167406Z","shell.execute_reply.started":"2025-05-04T13:32:37.161662Z","shell.execute_reply":"2025-05-04T13:32:37.16685Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"0                                 [1, 11, 12, 11, 12, 2]\n1         [1, 11, 12, 11, 12, 11, 12, 11, 12, 11, 12, 2]\n2                                 [1, 12, 11, 12, 11, 2]\n3                     [1, 11, 12, 11, 12, 11, 12, 11, 2]\n4                     [1, 11, 12, 11, 12, 11, 12, 11, 2]\n                               ...                      \n330280                                            [1, 2]\n330281                                            [1, 2]\n330282                                            [1, 2]\n330283                                            [1, 2]\n330284                                            [1, 2]\nName: aggregated_sequence, Length: 330285, dtype: object"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"class AttentionLSTMVAE:\n    def __init__(self, vocab_size, max_len, hidden_size=32, latent_dim=8):\n        self.vocab_size = vocab_size\n        self.max_len = max_len\n        self.hidden_size = hidden_size\n        self.latent_dim = latent_dim\n        self.model = self.build_model()\n\n    def sampling(self, args):\n        mu, log_var = args\n        epsilon = K.random_normal(shape=(K.shape(mu)[0], self.latent_dim))\n        return mu + K.exp(0.5 * log_var) * epsilon\n\n    def build_model(self):\n        # Encoder\n        inputs = Input(shape=(self.max_len, self.vocab_size))\n        h = LSTM(self.hidden_size, return_sequences=True)(inputs)\n        h = Attention()([h, h])  # Self-attention\n        h = LSTM(self.hidden_size)(h)  # Aggregate sequence\n        mu = Dense(self.latent_dim, name='mu')(h)\n        log_var = Dense(self.latent_dim, name='log_var')(h)\n        z = Lambda(self.sampling, output_shape=(self.latent_dim,), name='z')([mu, log_var])\n\n        # Decoder\n        z_repeated = RepeatVector(self.max_len)(z)\n        decoder_out = LSTM(self.hidden_size, return_sequences=True)(z_repeated)\n        decoder_out = Attention()([decoder_out, decoder_out])  # Self-attention\n        outputs = TimeDistributed(Dense(self.vocab_size, activation='softmax'))(decoder_out)\n\n        # Custom Loss Layer\n        class VAELossLayer(tf.keras.layers.Layer):\n            def __init__(self, max_len, **kwargs):\n                super(VAELossLayer, self).__init__(**kwargs)\n                self.max_len = max_len\n\n            def call(self, inputs):\n                x, x_decoded, mu, log_var = inputs\n                # Reconstruction loss\n                recon_loss = tf.reduce_mean(\n                    tf.keras.losses.categorical_crossentropy(x, x_decoded)\n                ) * self.max_len\n                # KL divergence\n                kl_loss = -0.5 * tf.reduce_mean(\n                    1 + log_var - tf.square(mu) - tf.exp(log_var)\n                )\n                # Add loss\n                self.add_loss(recon_loss + 0.1 * kl_loss)\n                return x_decoded\n\n        loss_layer = VAELossLayer(self.max_len)\n        outputs = loss_layer([inputs, outputs, mu, log_var])\n\n        vae = Model(inputs, outputs)\n        vae.compile(optimizer='adam')\n        return vae\n\n    def get_encoder(self):\n        encoder = Model(self.model.input, self.model.get_layer('z').output)\n        return encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:42.64595Z","iopub.execute_input":"2025-05-04T14:35:42.646539Z","iopub.status.idle":"2025-05-04T14:35:42.655415Z","shell.execute_reply.started":"2025-05-04T14:35:42.646517Z","shell.execute_reply":"2025-05-04T14:35:42.654659Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"V = 12\nmax_len = 86\nvae = AttentionLSTMVAE(\n        vocab_size=V,\n        max_len=max_len\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:46.665133Z","iopub.execute_input":"2025-05-04T14:35:46.665373Z","iopub.status.idle":"2025-05-04T14:35:46.74908Z","shell.execute_reply.started":"2025-05-04T14:35:46.665357Z","shell.execute_reply":"2025-05-04T14:35:46.748557Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"vae.model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:46.964292Z","iopub.execute_input":"2025-05-04T14:35:46.964826Z","iopub.status.idle":"2025-05-04T14:35:46.985931Z","shell.execute_reply.started":"2025-05-04T14:35:46.964807Z","shell.execute_reply":"2025-05-04T14:35:46.985275Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m12\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m5,760\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_2 (\u001b[38;5;33mAttention\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │          \u001b[38;5;34m8,320\u001b[0m │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ mu (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ log_var (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m264\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ z (\u001b[38;5;33mLambda\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ mu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n│                           │                        │                │ log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ repeat_vector_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │              \u001b[38;5;34m0\u001b[0m │ z[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n│ (\u001b[38;5;33mRepeatVector\u001b[0m)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │          \u001b[38;5;34m5,248\u001b[0m │ repeat_vector_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_3 (\u001b[38;5;33mAttention\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│                           │                        │                │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ time_distributed_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m12\u001b[0m)         │            \u001b[38;5;34m396\u001b[0m │ attention_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ vae_loss_layer_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86\u001b[0m, \u001b[38;5;34m12\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n│ (\u001b[38;5;33mVAELossLayer\u001b[0m)            │                        │                │ time_distributed_1[\u001b[38;5;34m0\u001b[0m]… │\n│                           │                        │                │ mu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],              │\n│                           │                        │                │ log_var[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,760</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ mu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ log_var (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n│                           │                        │                │ log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ repeat_vector_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ z[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │ repeat_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│                           │                        │                │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ time_distributed_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span> │ attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ vae_loss_layer_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">VAELossLayer</span>)            │                        │                │ time_distributed_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                           │                        │                │ mu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],              │\n│                           │                        │                │ log_var[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,252\u001b[0m (79.11 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,252</span> (79.11 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,252\u001b[0m (79.11 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,252</span> (79.11 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train_size = 0.6\nval_size = 0.2\ntest_size = 0.2\n# Split into train+val and test\nX_train_val, X_test = train_test_split(\n            X, test_size=test_size, random_state=42\n        )\n        \n# Split train+val into train and val\nval_size_adjusted = val_size / (train_size + val_size)  # Adjust for train+val proportion\nX_train, X_val = train_test_split(\n            X_train_val, test_size=val_size_adjusted, random_state=42\n        )\n        \nprint(f\"Train samples: {X_train.shape[0]}\")\nprint(f\"Validation samples: {X_val.shape[0]}\")\nprint(f\"Test samples: {X_test.shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:49.979959Z","iopub.execute_input":"2025-05-04T14:35:49.980531Z","iopub.status.idle":"2025-05-04T14:35:51.382254Z","shell.execute_reply.started":"2025-05-04T14:35:49.980505Z","shell.execute_reply":"2025-05-04T14:35:51.381615Z"}},"outputs":[{"name":"stdout","text":"Train samples: 198270\nValidation samples: 66091\nTest samples: 66091\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = vae.model.fit(\n            X_train, X_train,\n            epochs=10,\n            batch_size=32,\n            validation_data=(X_val, None),\n            verbose=1\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:36:02.66568Z","iopub.execute_input":"2025-05-04T14:36:02.665924Z","iopub.status.idle":"2025-05-04T14:57:43.579703Z","shell.execute_reply.started":"2025-05-04T14:36:02.665908Z","shell.execute_reply":"2025-05-04T14:57:43.579036Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1746369377.698220      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 21ms/step - loss: 13.6740 - val_loss: 9.4878\nEpoch 2/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 21ms/step - loss: 9.4053 - val_loss: 9.1039\nEpoch 3/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 21ms/step - loss: 9.1359 - val_loss: 8.5957\nEpoch 4/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 21ms/step - loss: 8.2981 - val_loss: 8.0391\nEpoch 5/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 21ms/step - loss: 7.4593 - val_loss: 6.4423\nEpoch 6/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 21ms/step - loss: 6.4525 - val_loss: 6.1407\nEpoch 7/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 21ms/step - loss: 6.1920 - val_loss: 6.2203\nEpoch 8/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 21ms/step - loss: 5.8696 - val_loss: 5.7878\nEpoch 9/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 21ms/step - loss: 5.7479 - val_loss: 5.5584\nEpoch 10/10\n\u001b[1m6196/6196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 21ms/step - loss: 5.6840 - val_loss: 5.4358\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"def save_vae_model(vae, save_dir=\"/kaggle/working/vae_model\"):\n    \"\"\"Save all components of the VAE\"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Save models\n    save_model(vae.model, os.path.join(save_dir, \"vae.h5\"))\n    save_model(vae.get_encoder(), os.path.join(save_dir, \"encoder.h5\"))\n\n    # Save config\n    config = {\n        'vocab_size': vae.vocab_size,\n        'max_len': vae.max_len,\n        'hidden_size': vae.hidden_size,\n        'latent_dim': vae.latent_dim\n    }\n    with open(os.path.join(save_dir, 'config.json'), 'w') as f:\n        json.dump(config, f)\n    \n    print(f\"Model saved to {save_dir}\")\n\nsave_vae_model(vae, \"attention_lstmvae_1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:57:55.765932Z","iopub.execute_input":"2025-05-04T14:57:55.766674Z","iopub.status.idle":"2025-05-04T14:57:55.844465Z","shell.execute_reply.started":"2025-05-04T14:57:55.766645Z","shell.execute_reply":"2025-05-04T14:57:55.843951Z"}},"outputs":[{"name":"stdout","text":"Model saved to attention_lstmvae_1\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:38:02.978771Z","iopub.execute_input":"2025-05-06T15:38:02.978984Z","iopub.status.idle":"2025-05-06T15:38:02.990457Z","shell.execute_reply.started":"2025-05-06T15:38:02.978967Z","shell.execute_reply":"2025-05-06T15:38:02.989703Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def evaluate_vae(vae, X_test, history, index_to_token=None, batch_size=32):\n    try:\n        # Set matplotlib backend\n        plt.switch_backend('Agg')\n\n        # Define loss functions\n        def compute_recon_loss(x, x_pred):\n            return tf.reduce_mean(\n                tf.keras.losses.categorical_crossentropy(x, x_pred)\n            ) * vae.max_len\n\n        def compute_kl_loss(mu, log_var):\n            return -0.5 * tf.reduce_mean(1 + log_var - tf.square(mu) - tf.exp(log_var))\n\n        # Evaluate\n        encoder = vae.get_encoder()\n        mu_model = Model(vae.model.input, vae.model.get_layer('mu').output)\n        log_var_model = Model(vae.model.input, vae.model.get_layer('log_var').output)\n\n        X_pred = vae.model.predict(X_test, batch_size=batch_size)\n        mu = mu_model.predict(X_test, batch_size=batch_size)\n        log_var = log_var_model.predict(X_test, batch_size=batch_size)\n\n        recon_loss = compute_recon_loss(X_test, X_pred).numpy()\n        kl_loss = compute_kl_loss(mu, log_var).numpy()\n        total_loss = recon_loss + 0.1 * kl_loss\n\n        print(f\"Test Set Metrics:\")\n        print(f\"Reconstruction Loss: {recon_loss:.4f}\")\n        print(f\"KL Divergence: {kl_loss:.4f}\")\n        print(f\"Total Loss: {total_loss:.4f}\")\n\n        # Visualization 1: Loss Curves\n        plt.figure(figsize=(10, 6))\n        plt.plot(history.history['loss'], label='Training Loss')\n        plt.plot(history.history['val_loss'], label='Validation Loss')\n        plt.axhline(y=total_loss, color='r', linestyle='--', label='Test Loss')\n        plt.title('Training, Validation, and Test Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n        # Visualization 2: Latent Space\n        z = encoder.predict(X_test, batch_size=batch_size)\n        if vae.latent_dim > 2:\n            z_embedded = TSNE(n_components=2, random_state=42).fit_transform(z)\n        else:\n            z_embedded = z\n        plt.figure(figsize=(8, 6))\n        plt.scatter(z_embedded[:, 0], z_embedded[:, 1], alpha=0.5, s=10)\n        plt.title('Latent Space Visualization (Test Set)')\n        plt.xlabel('Component 1')\n        plt.ylabel('Component 2')\n        plt.grid(True)\n        plt.show()\n\n        # Visualization 3: Reconstructed Sequences\n        plt.figure(figsize=(12, 10))\n        for i in range(min(5, X_test.shape[0])):\n            orig_seq = np.argmax(X_test[i], axis=-1)\n            pred_seq = np.argmax(X_pred[i], axis=-1)\n            \n            if index_to_token:\n                orig_text = ''.join([index_to_token[idx] for idx in orig_seq])\n                pred_text = ''.join([index_to_token[idx] for idx in pred_seq])\n            else:\n                orig_text = str(orig_seq)\n                pred_text = str(pred_seq)\n            \n            plt.subplot(5, 2, 2 * i + 1)\n            sns.heatmap(X_test[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Original Sequence {i+1}\\n{orig_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n            \n            plt.subplot(5, 2, 2 * i + 2)\n            sns.heatmap(X_pred[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Reconstructed Sequence {i+1}\\n{pred_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n        \n        plt.tight_layout()\n        plt.show()\n\n        return {\n            'recon_loss': recon_loss,\n            'kl_loss': kl_loss,\n            'total_loss': total_loss\n        }\n    \n    except Exception as e:\n        print(f\"Error in evaluate_vae: {str(e)}\")\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:58:20.705604Z","iopub.execute_input":"2025-05-04T14:58:20.706148Z","iopub.status.idle":"2025-05-04T14:58:20.718559Z","shell.execute_reply.started":"2025-05-04T14:58:20.706123Z","shell.execute_reply":"2025-05-04T14:58:20.717745Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:28:17.833513Z","iopub.execute_input":"2025-05-06T07:28:17.834046Z","iopub.status.idle":"2025-05-06T07:28:17.838138Z","shell.execute_reply.started":"2025-05-06T07:28:17.83402Z","shell.execute_reply":"2025-05-06T07:28:17.837336Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"index_to_token = {i: chr(65 + i) for i in range(V)}\nmetrics = evaluate_vae(vae, X_test, history, index_to_token=index_to_token, batch_size=32)\nif metrics is None:\n        print(\"Evaluation failed. Check test data or model predictions.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:11:40.660682Z","iopub.execute_input":"2025-05-04T15:11:40.661756Z","iopub.status.idle":"2025-05-04T15:19:23.907303Z","shell.execute_reply.started":"2025-05-04T15:11:40.661725Z","shell.execute_reply":"2025-05-04T15:19:23.906735Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step\n\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\nTest Set Metrics:\nReconstruction Loss: 5.2869\nKL Divergence: 1.8720\nTotal Loss: 5.4741\n\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"encoder = vae.get_encoder()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:23:46.626119Z","iopub.execute_input":"2025-05-04T15:23:46.626402Z","iopub.status.idle":"2025-05-04T15:23:46.631652Z","shell.execute_reply.started":"2025-05-04T15:23:46.626381Z","shell.execute_reply":"2025-05-04T15:23:46.631125Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"z = encoder.predict(X_test, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:31:28.065872Z","iopub.execute_input":"2025-05-04T15:31:28.066183Z","iopub.status.idle":"2025-05-04T15:31:36.735099Z","shell.execute_reply.started":"2025-05-04T15:31:28.066158Z","shell.execute_reply":"2025-05-04T15:31:36.734395Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"X_pred = vae.model.predict(X_test, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:32:10.776054Z","iopub.execute_input":"2025-05-04T15:32:10.776746Z","iopub.status.idle":"2025-05-04T15:32:25.105814Z","shell.execute_reply.started":"2025-05-04T15:32:10.776721Z","shell.execute_reply":"2025-05-04T15:32:25.105229Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"z_embedded = TSNE(n_components=2, random_state=42).fit_transform(z)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:32:47.231713Z","iopub.execute_input":"2025-05-04T15:32:47.23216Z","iopub.status.idle":"2025-05-04T15:33:21.122691Z","shell.execute_reply.started":"2025-05-04T15:32:47.232136Z","shell.execute_reply":"2025-05-04T15:33:21.121683Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3058596415.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         return self._tsne(\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;31m# higher learning rate controlled via the early exaggeration parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_exaggeration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             print(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compute_error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     error = _barnes_hut_tsne.gradient(\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mval_P\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":44},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(z_embedded[:, 0], z_embedded[:, 1], alpha=0.5, s=10)\nplt.title('Latent Space Visualization (Test Set)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nif vae.latent_dim > 2:\n            \nelse:\n        z_embedded = z\n        plt.figure(figsize=(8, 6))\n        plt.scatter(z_embedded[:, 0], z_embedded[:, 1], alpha=0.5, s=10)\n        plt.title('Latent Space Visualization (Test Set)')\n        plt.xlabel('Component 1')\n        plt.ylabel('Component 2')\n        plt.grid(True)\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:25:23.765844Z","iopub.execute_input":"2025-05-04T15:25:23.76613Z","iopub.status.idle":"2025-05-04T15:31:04.859916Z","shell.execute_reply.started":"2025-05-04T15:25:23.766108Z","shell.execute_reply":"2025-05-04T15:31:04.85888Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m2066/2066\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3441364334.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m             \u001b[0mz_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mz_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params_vs_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mdegrees_of_freedom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         return self._tsne(\n\u001b[0m\u001b[1;32m   1013\u001b[0m             \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0mdegrees_of_freedom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mopt_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_iter_without_progress\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_without_progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopt_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;31m# Save the final number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compute_error\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_convergence\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m         \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0minc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embedded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     error = _barnes_hut_tsne.gradient(\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mval_P\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mX_embedded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":40},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nfor i in range(min(5, X_test.shape[0])):\n            orig_seq = np.argmax(X_test[i], axis=-1)\n            pred_seq = np.argmax(X_pred[i], axis=-1)\n            \n            if index_to_token:\n                orig_text = ''.join([index_to_token[idx] for idx in orig_seq])\n                pred_text = ''.join([index_to_token[idx] for idx in pred_seq])\n            else:\n                orig_text = str(orig_seq)\n                pred_text = str(pred_seq)\n            \n            plt.subplot(5, 2, 2 * i + 1)\n            sns.heatmap(X_test[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Original Sequence {i+1}\\n{orig_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n            \n            plt.subplot(5, 2, 2 * i + 2)\n            sns.heatmap(X_pred[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Reconstructed Sequence {i+1}\\n{pred_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n        \n            plt.tight_layout()\n            plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:31:10.845136Z","iopub.execute_input":"2025-05-04T15:31:10.845398Z","iopub.status.idle":"2025-05-04T15:31:10.868885Z","shell.execute_reply.started":"2025-05-04T15:31:10.845377Z","shell.execute_reply":"2025-05-04T15:31:10.867965Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1433910967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0morig_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mpred_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex_to_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_pred' is not defined"],"ename":"NameError","evalue":"name 'X_pred' is not defined","output_type":"error"}],"execution_count":41},{"cell_type":"code","source":"beh = pd.read_csv('/kaggle/input/reqd-data-lstmrl/beh.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:57.547622Z","iopub.execute_input":"2025-05-06T07:31:57.548191Z","iopub.status.idle":"2025-05-06T07:31:57.609061Z","shell.execute_reply.started":"2025-05-06T07:31:57.548168Z","shell.execute_reply":"2025-05-06T07:31:57.608404Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"info = pd.read_csv('/kaggle/input/reqd-data-lstmrl/merged_df.csv')\ninfo = info.drop(columns={'Unnamed: 0'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:57.827109Z","iopub.execute_input":"2025-05-06T07:31:57.827761Z","iopub.status.idle":"2025-05-06T07:31:58.846659Z","shell.execute_reply.started":"2025-05-06T07:31:57.827736Z","shell.execute_reply":"2025-05-06T07:31:58.845931Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:59.526934Z","iopub.execute_input":"2025-05-06T07:31:59.527584Z","iopub.status.idle":"2025-05-06T07:31:59.648983Z","shell.execute_reply.started":"2025-05-06T07:31:59.527559Z","shell.execute_reply":"2025-05-06T07:31:59.648153Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                      0.0                   0   \n1       AAE0190  2010-01-05                      0.0                   0   \n2       AAE0190  2010-01-06                      0.0                   0   \n3       AAE0190  2010-01-07                      0.0                   0   \n4       AAE0190  2010-01-08                      0.0                   0   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                      0.0                   0   \n330281  ZSL0305  2011-05-11                      0.0                   0   \n330282  ZSL0305  2011-05-12                      0.0                   0   \n330283  ZSL0305  2011-05-13                      0.0                   0   \n330284  ZSL0305  2011-05-16                      0.0                   0   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                             0                1.0         1.0   \n1                             0                1.0         1.0   \n2                             0                1.0         1.0   \n3                             0                1.0         1.0   \n4                             0                1.0         1.0   \n...                         ...                ...         ...   \n330280                        0                1.0         1.0   \n330281                        0                1.0         1.0   \n330282                        0                1.0         1.0   \n330283                        0                1.0         1.0   \n330284                        0                1.0         1.0   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0                   0.0                   0.0              0.0  ...   \n1                   0.0                   0.0              0.0  ...   \n2                   0.0                   0.0              0.0  ...   \n3                   0.0                   0.0              0.0  ...   \n4                   0.0                   0.0              0.0  ...   \n...                 ...                   ...              ...  ...   \n330280              0.0                   0.0              0.0  ...   \n330281              0.0                   0.0              0.0  ...   \n330282              0.0                   0.0              0.0  ...   \n330283              0.0                   0.0              0.0  ...   \n330284              0.0                   0.0              0.0  ...   \n\n        text_files_accessed  file_type_entropy  sensitive_keyword_count  \\\n0                       0.0                0.0                      0.0   \n1                       0.0                0.0                      0.0   \n2                       0.0                0.0                      0.0   \n3                       0.0                0.0                      0.0   \n4                       0.0                0.0                      0.0   \n...                     ...                ...                      ...   \n330280                  0.0                0.0                      0.0   \n330281                  0.0                0.0                      0.0   \n330282                  0.0                0.0                      0.0   \n330283                  0.0                0.0                      0.0   \n330284                  0.0                0.0                      0.0   \n\n        avg_content_word_count  emails_sent  total_recipients  external_ratio  \\\n0                          0.0         14.0              43.0        0.214286   \n1                          0.0         13.0              39.0        0.538462   \n2                          0.0         14.0              40.0        0.642857   \n3                          0.0         14.0              42.0        0.571429   \n4                          0.0         13.0              40.0        0.307692   \n...                        ...          ...               ...             ...   \n330280                     0.0          1.0               2.0        0.000000   \n330281                     0.0          1.0               4.0        2.000000   \n330282                     0.0          1.0               6.0        3.000000   \n330283                     0.0          1.0               2.0        1.000000   \n330284                     0.0          1.0               2.0        1.000000   \n\n        keyword_richness  bcc_flag  \\\n0                  470.0       0.0   \n1                  467.0       0.0   \n2                  741.0       0.0   \n3                  454.0       0.0   \n4                  373.0       0.0   \n...                  ...       ...   \n330280              41.0       0.0   \n330281              49.0       0.0   \n330282              48.0       0.0   \n330283              30.0       0.0   \n330284              67.0       0.0   \n\n                                   aggregated_sequence  \n0                               [1, 11, 12, 11, 12, 2]  \n1       [1, 11, 12, 11, 12, 11, 12, 11, 12, 11, 12, 2]  \n2                               [1, 12, 11, 12, 11, 2]  \n3                   [1, 11, 12, 11, 12, 11, 12, 11, 2]  \n4                   [1, 11, 12, 11, 12, 11, 12, 11, 2]  \n...                                                ...  \n330280                                          [1, 2]  \n330281                                          [1, 2]  \n330282                                          [1, 2]  \n330283                                          [1, 2]  \n330284                                          [1, 2]  \n\n[330285 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n      <th>aggregated_sequence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n      <td>[1, 11, 12, 11, 12, 2]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n      <td>[1, 11, 12, 11, 12, 11, 12, 11, 12, 11, 12, 2]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n      <td>[1, 12, 11, 12, 11, 2]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n      <td>[1, 11, 12, 11, 12, 11, 12, 11, 2]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n      <td>[1, 11, 12, 11, 12, 11, 12, 11, 2]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>[1, 2]</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n      <td>[1, 2]</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n      <td>[1, 2]</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>[1, 2]</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n      <td>[1, 2]</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"info = info.iloc[:,:22]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:03.427421Z","iopub.execute_input":"2025-05-06T07:32:03.428083Z","iopub.status.idle":"2025-05-06T07:32:03.45156Z","shell.execute_reply.started":"2025-05-06T07:32:03.428057Z","shell.execute_reply":"2025-05-06T07:32:03.450851Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:03.786888Z","iopub.execute_input":"2025-05-06T07:32:03.787527Z","iopub.status.idle":"2025-05-06T07:32:03.893276Z","shell.execute_reply.started":"2025-05-06T07:32:03.787504Z","shell.execute_reply":"2025-05-06T07:32:03.892531Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                      0.0                   0   \n1       AAE0190  2010-01-05                      0.0                   0   \n2       AAE0190  2010-01-06                      0.0                   0   \n3       AAE0190  2010-01-07                      0.0                   0   \n4       AAE0190  2010-01-08                      0.0                   0   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                      0.0                   0   \n330281  ZSL0305  2011-05-11                      0.0                   0   \n330282  ZSL0305  2011-05-12                      0.0                   0   \n330283  ZSL0305  2011-05-13                      0.0                   0   \n330284  ZSL0305  2011-05-16                      0.0                   0   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                             0                1.0         1.0   \n1                             0                1.0         1.0   \n2                             0                1.0         1.0   \n3                             0                1.0         1.0   \n4                             0                1.0         1.0   \n...                         ...                ...         ...   \n330280                        0                1.0         1.0   \n330281                        0                1.0         1.0   \n330282                        0                1.0         1.0   \n330283                        0                1.0         1.0   \n330284                        0                1.0         1.0   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0                   0.0                   0.0              0.0  ...   \n1                   0.0                   0.0              0.0  ...   \n2                   0.0                   0.0              0.0  ...   \n3                   0.0                   0.0              0.0  ...   \n4                   0.0                   0.0              0.0  ...   \n...                 ...                   ...              ...  ...   \n330280              0.0                   0.0              0.0  ...   \n330281              0.0                   0.0              0.0  ...   \n330282              0.0                   0.0              0.0  ...   \n330283              0.0                   0.0              0.0  ...   \n330284              0.0                   0.0              0.0  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                         0.0                  0.0                0.0   \n1                         0.0                  0.0                0.0   \n2                         0.0                  0.0                0.0   \n3                         0.0                  0.0                0.0   \n4                         0.0                  0.0                0.0   \n...                       ...                  ...                ...   \n330280                    0.0                  0.0                0.0   \n330281                    0.0                  0.0                0.0   \n330282                    0.0                  0.0                0.0   \n330283                    0.0                  0.0                0.0   \n330284                    0.0                  0.0                0.0   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                           0.0                     0.0         14.0   \n1                           0.0                     0.0         13.0   \n2                           0.0                     0.0         14.0   \n3                           0.0                     0.0         14.0   \n4                           0.0                     0.0         13.0   \n...                         ...                     ...          ...   \n330280                      0.0                     0.0          1.0   \n330281                      0.0                     0.0          1.0   \n330282                      0.0                     0.0          1.0   \n330283                      0.0                     0.0          1.0   \n330284                      0.0                     0.0          1.0   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0                   43.0        0.214286             470.0       0.0  \n1                   39.0        0.538462             467.0       0.0  \n2                   40.0        0.642857             741.0       0.0  \n3                   42.0        0.571429             454.0       0.0  \n4                   40.0        0.307692             373.0       0.0  \n...                  ...             ...               ...       ...  \n330280               2.0        0.000000              41.0       0.0  \n330281               4.0        2.000000              49.0       0.0  \n330282               6.0        3.000000              48.0       0.0  \n330283               2.0        1.000000              30.0       0.0  \n330284               2.0        1.000000              67.0       0.0  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"roles = pd.read_csv('/kaggle/input/reqd-data-lstmrl/role_mappings_users.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:08.012455Z","iopub.execute_input":"2025-05-06T07:32:08.012719Z","iopub.status.idle":"2025-05-06T07:32:08.021841Z","shell.execute_reply.started":"2025-05-06T07:32:08.012699Z","shell.execute_reply":"2025-05-06T07:32:08.021164Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"roles['role'] = (\n    roles['role_0'] * 1 + \n    roles['role_1'] * 2 + \n    roles['role_2'] * 4 + \n    roles['role_3'] * 8\n)\n\n# Create role lookup dictionary\nrole_lookup = dict(zip(roles['user'], roles['role']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:15.12236Z","iopub.execute_input":"2025-05-06T07:32:15.122987Z","iopub.status.idle":"2025-05-06T07:32:15.128733Z","shell.execute_reply.started":"2025-05-06T07:32:15.122965Z","shell.execute_reply":"2025-05-06T07:32:15.128121Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"seq_to_encode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:40:49.75576Z","iopub.execute_input":"2025-05-04T15:40:49.75604Z","iopub.status.idle":"2025-05-04T15:40:49.762132Z","shell.execute_reply.started":"2025-05-04T15:40:49.756022Z","shell.execute_reply":"2025-05-04T15:40:49.761396Z"}},"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"0                                 [1, 11, 12, 11, 12, 2]\n1         [1, 11, 12, 11, 12, 11, 12, 11, 12, 11, 12, 2]\n2                                 [1, 12, 11, 12, 11, 2]\n3                     [1, 11, 12, 11, 12, 11, 12, 11, 2]\n4                     [1, 11, 12, 11, 12, 11, 12, 11, 2]\n                               ...                      \n330280                                            [1, 2]\n330281                                            [1, 2]\n330282                                            [1, 2]\n330283                                            [1, 2]\n330284                                            [1, 2]\nName: aggregated_sequence, Length: 330285, dtype: object"},"metadata":{}}],"execution_count":63},{"cell_type":"code","source":"if isinstance(seq_to_encode, str):\n    seq_to_encode = ast.literal_eval(seq_to_encode)  # Convert to a real list\n\n# If seq_to_encode is a pandas Series or list of lists (non-strings), ensure it's in the right format\nif isinstance(seq_to_encode, list) or isinstance(seq_to_encode, pd.Series):\n    # You might need to process each item in the series individually if they're not already lists\n    seq_to_encode = [ast.literal_eval(str(item)) if isinstance(item, str) else item for item in seq_to_encode]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:43:45.630804Z","iopub.execute_input":"2025-05-04T15:43:45.631153Z","iopub.status.idle":"2025-05-04T15:43:49.742241Z","shell.execute_reply.started":"2025-05-04T15:43:45.631128Z","shell.execute_reply":"2025-05-04T15:43:49.741637Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"type(seq_to_encode[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:43:49.743386Z","iopub.execute_input":"2025-05-04T15:43:49.74368Z","iopub.status.idle":"2025-05-04T15:43:49.748266Z","shell.execute_reply.started":"2025-05-04T15:43:49.743657Z","shell.execute_reply":"2025-05-04T15:43:49.747677Z"}},"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}],"execution_count":73},{"cell_type":"code","source":"encoder = OneHotEncoder(categories=[labels], handle_unknown='ignore') \nmax_len = 86  #longest sequence\n\n# Converting sequences to one-hot encoded arrays\nseqs = []\nfor seq in seq_to_encode:\n    seq_array = np.array(seq).reshape(-1, 1)\n    one_hot = encoder.fit_transform(seq_array).toarray() \n    # Pad to max_len\n    padded = np.pad(one_hot, ((0, max_len - len(seq)), (0, 0)), mode='constant')  # Shape: (max_len, V)\n    seqs.append(padded)\nseqs = np.array(seqs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:43:53.685009Z","iopub.execute_input":"2025-05-04T15:43:53.685361Z","iopub.status.idle":"2025-05-04T15:46:41.625617Z","shell.execute_reply.started":"2025-05-04T15:43:53.685334Z","shell.execute_reply":"2025-05-04T15:46:41.625023Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"seqs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:46:41.627311Z","iopub.execute_input":"2025-05-04T15:46:41.627524Z","iopub.status.idle":"2025-05-04T15:46:41.633919Z","shell.execute_reply.started":"2025-05-04T15:46:41.627509Z","shell.execute_reply":"2025-05-04T15:46:41.633252Z"}},"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"array([[[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 1., 0.],\n        [0., 0., 0., ..., 0., 0., 1.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 1., 0.],\n        [0., 0., 0., ..., 0., 0., 1.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 1.],\n        [0., 0., 0., ..., 0., 1., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       ...,\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]],\n\n       [[1., 0., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.],\n        [0., 0., 0., ..., 0., 0., 0.]]])"},"metadata":{}}],"execution_count":75},{"cell_type":"code","source":"seqs.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:46:41.634532Z","iopub.execute_input":"2025-05-04T15:46:41.634773Z","iopub.status.idle":"2025-05-04T15:46:41.65117Z","shell.execute_reply.started":"2025-05-04T15:46:41.634748Z","shell.execute_reply":"2025-05-04T15:46:41.650491Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"(330285, 86, 12)"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"np.save('seqs.npy', seqs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:47:46.725546Z","iopub.execute_input":"2025-05-04T15:47:46.725818Z","iopub.status.idle":"2025-05-04T15:47:49.339692Z","shell.execute_reply.started":"2025-05-04T15:47:46.725796Z","shell.execute_reply":"2025-05-04T15:47:49.338787Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"type(seq_to_encode)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:36:24.865779Z","iopub.execute_input":"2025-05-04T15:36:24.866421Z","iopub.status.idle":"2025-05-04T15:36:24.870762Z","shell.execute_reply.started":"2025-05-04T15:36:24.866398Z","shell.execute_reply":"2025-05-04T15:36:24.87009Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"list"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"encoder = vae.get_encoder()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:48:18.98605Z","iopub.execute_input":"2025-05-04T15:48:18.986329Z","iopub.status.idle":"2025-05-04T15:48:18.991512Z","shell.execute_reply.started":"2025-05-04T15:48:18.98631Z","shell.execute_reply":"2025-05-04T15:48:18.990811Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"tensor = tf.convert_to_tensor(seqs, dtype=tf.float32)\nmu_all = encoder.predict(tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:48:23.584964Z","iopub.execute_input":"2025-05-04T15:48:23.585256Z","iopub.status.idle":"2025-05-04T15:49:05.762449Z","shell.execute_reply.started":"2025-05-04T15:48:23.585233Z","shell.execute_reply":"2025-05-04T15:49:05.761822Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m10322/10322\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 3ms/step\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:49:05.763646Z","iopub.execute_input":"2025-05-04T15:49:05.763865Z","iopub.status.idle":"2025-05-04T15:49:05.768422Z","shell.execute_reply.started":"2025-05-04T15:49:05.763848Z","shell.execute_reply":"2025-05-04T15:49:05.767881Z"}},"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"(330285, 8)"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"df_latent = pd.DataFrame(index=range(seqs.shape[0]))\n\ndf_latent['latent_vector'] = list(mu_all)\n\n# Verify latent vectors\nprint(\"Latent vector shape:\", mu_all.shape)\nprint(\"Sample latent vector:\", df_latent['latent_vector'].iloc[0])\n\nmu_mean = np.mean(mu_all, axis=0)\nmu_std = np.std(mu_all, axis=0)\nprint(\"Mu mean:\", mu_mean)  \nprint(\"Mu std:\", mu_std)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:49:37.605225Z","iopub.execute_input":"2025-05-04T15:49:37.605482Z","iopub.status.idle":"2025-05-04T15:49:37.726534Z","shell.execute_reply.started":"2025-05-04T15:49:37.605463Z","shell.execute_reply":"2025-05-04T15:49:37.725925Z"}},"outputs":[{"name":"stdout","text":"Latent vector shape: (330285, 8)\nSample latent vector: [ 0.16200998  0.21235588  0.3329291   1.3584232   0.86544913 -0.27206764\n -1.299133    0.1619663 ]\nMu mean: [ 0.07215787  1.3137182   0.5614589   1.284144   -0.456778    0.6895762\n  0.13965617 -0.19740307]\nMu std: [0.9715056  1.4289726  0.51185304 0.61968815 0.71853715 0.79882926\n 0.9994091  0.83030444]\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"df_latent.to_pickle('vae_latent_vectors.pkl')  \nprint(\"Saved DataFrame to 'vae_latent_vectors.pkl'\")\nnp.save('mu_all.npy', mu_all)\nprint(\"Saved latent vectors to 'mu_all.npy'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:49:48.026102Z","iopub.execute_input":"2025-05-04T15:49:48.026369Z","iopub.status.idle":"2025-05-04T15:49:50.548646Z","shell.execute_reply.started":"2025-05-04T15:49:48.026348Z","shell.execute_reply":"2025-05-04T15:49:50.547874Z"}},"outputs":[{"name":"stdout","text":"Saved DataFrame to 'vae_latent_vectors.pkl'\nSaved latent vectors to 'mu_all.npy'\n","output_type":"stream"}],"execution_count":83},{"cell_type":"code","source":"user_ids = info['user']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:06.788268Z","iopub.execute_input":"2025-05-06T07:33:06.788547Z","iopub.status.idle":"2025-05-06T07:33:06.792356Z","shell.execute_reply.started":"2025-05-06T07:33:06.788525Z","shell.execute_reply":"2025-05-06T07:33:06.791585Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:06.665017Z","iopub.execute_input":"2025-05-04T15:57:06.665293Z","iopub.status.idle":"2025-05-04T15:57:06.669693Z","shell.execute_reply.started":"2025-05-04T15:57:06.665274Z","shell.execute_reply":"2025-05-04T15:57:06.669141Z"}},"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"(330285, 8)"},"metadata":{}}],"execution_count":103},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:15.405635Z","iopub.execute_input":"2025-05-04T15:57:15.405902Z","iopub.status.idle":"2025-05-04T15:57:15.475856Z","shell.execute_reply.started":"2025-05-04T15:57:15.405883Z","shell.execute_reply":"2025-05-04T15:57:15.475155Z"}},"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                      0.0                   0   \n1       AAE0190  2010-01-05                      0.0                   0   \n2       AAE0190  2010-01-06                      0.0                   0   \n3       AAE0190  2010-01-07                      0.0                   0   \n4       AAE0190  2010-01-08                      0.0                   0   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                      0.0                   0   \n330281  ZSL0305  2011-05-11                      0.0                   0   \n330282  ZSL0305  2011-05-12                      0.0                   0   \n330283  ZSL0305  2011-05-13                      0.0                   0   \n330284  ZSL0305  2011-05-16                      0.0                   0   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                             0                1.0         1.0   \n1                             0                1.0         1.0   \n2                             0                1.0         1.0   \n3                             0                1.0         1.0   \n4                             0                1.0         1.0   \n...                         ...                ...         ...   \n330280                        0                1.0         1.0   \n330281                        0                1.0         1.0   \n330282                        0                1.0         1.0   \n330283                        0                1.0         1.0   \n330284                        0                1.0         1.0   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0                   0.0                   0.0              0.0  ...   \n1                   0.0                   0.0              0.0  ...   \n2                   0.0                   0.0              0.0  ...   \n3                   0.0                   0.0              0.0  ...   \n4                   0.0                   0.0              0.0  ...   \n...                 ...                   ...              ...  ...   \n330280              0.0                   0.0              0.0  ...   \n330281              0.0                   0.0              0.0  ...   \n330282              0.0                   0.0              0.0  ...   \n330283              0.0                   0.0              0.0  ...   \n330284              0.0                   0.0              0.0  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                         0.0                  0.0                0.0   \n1                         0.0                  0.0                0.0   \n2                         0.0                  0.0                0.0   \n3                         0.0                  0.0                0.0   \n4                         0.0                  0.0                0.0   \n...                       ...                  ...                ...   \n330280                    0.0                  0.0                0.0   \n330281                    0.0                  0.0                0.0   \n330282                    0.0                  0.0                0.0   \n330283                    0.0                  0.0                0.0   \n330284                    0.0                  0.0                0.0   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                           0.0                     0.0         14.0   \n1                           0.0                     0.0         13.0   \n2                           0.0                     0.0         14.0   \n3                           0.0                     0.0         14.0   \n4                           0.0                     0.0         13.0   \n...                         ...                     ...          ...   \n330280                      0.0                     0.0          1.0   \n330281                      0.0                     0.0          1.0   \n330282                      0.0                     0.0          1.0   \n330283                      0.0                     0.0          1.0   \n330284                      0.0                     0.0          1.0   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0                   43.0        0.214286             470.0       0.0  \n1                   39.0        0.538462             467.0       0.0  \n2                   40.0        0.642857             741.0       0.0  \n3                   42.0        0.571429             454.0       0.0  \n4                   40.0        0.307692             373.0       0.0  \n...                  ...             ...               ...       ...  \n330280               2.0        0.000000              41.0       0.0  \n330281               4.0        2.000000              49.0       0.0  \n330282               6.0        3.000000              48.0       0.0  \n330283               2.0        1.000000              30.0       0.0  \n330284               2.0        1.000000              67.0       0.0  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":104},{"cell_type":"code","source":"X_combined = np.column_stack([\n    info,                # Original features (excluding VAE error)\n    np.array([role_lookup[uid] for uid in user_ids]),  # Lookup role for each user-day\n    mu_all                 # VAE reconstruction error\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:29.440557Z","iopub.execute_input":"2025-05-04T15:57:29.441027Z","iopub.status.idle":"2025-05-04T15:57:29.951069Z","shell.execute_reply.started":"2025-05-04T15:57:29.441Z","shell.execute_reply":"2025-05-04T15:57:29.950249Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"X_combined.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:37.984786Z","iopub.execute_input":"2025-05-04T15:57:37.985067Z","iopub.status.idle":"2025-05-04T15:57:37.989669Z","shell.execute_reply.started":"2025-05-04T15:57:37.985047Z","shell.execute_reply":"2025-05-04T15:57:37.989112Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"(330285, 31)"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"X_combined = X_combined[:,2:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:51.946092Z","iopub.execute_input":"2025-05-04T15:57:51.946343Z","iopub.status.idle":"2025-05-04T15:57:51.949695Z","shell.execute_reply.started":"2025-05-04T15:57:51.946325Z","shell.execute_reply":"2025-05-04T15:57:51.949102Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"X_combined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:53.885296Z","iopub.execute_input":"2025-05-04T15:57:53.885532Z","iopub.status.idle":"2025-05-04T15:57:53.890539Z","shell.execute_reply.started":"2025-05-04T15:57:53.885515Z","shell.execute_reply":"2025-05-04T15:57:53.890012Z"}},"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"array([[0.0, 0, 0, ..., -0.2720676362514496, -1.2991329431533813,\n        0.16196629405021667],\n       [0.0, 0, 0, ..., -0.791343629360199, -2.3588831424713135,\n        -1.1802793741226196],\n       [0.0, 0, 0, ..., -0.9547088742256165, -1.4090399742126465,\n        -1.0169450044631958],\n       ...,\n       [0.0, 0, 0, ..., 1.6622734069824219, 0.8997203707695007,\n        -0.5208495259284973],\n       [0.0, 0, 0, ..., 0.7760046124458313, -0.12847267091274261,\n        -1.0735514163970947],\n       [0.0, 0, 0, ..., 0.19119590520858765, -0.2956971824169159,\n        0.31119585037231445]], dtype=object)"},"metadata":{}}],"execution_count":109},{"cell_type":"code","source":"np.save('X_combined', X_combined)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:50:12.265491Z","iopub.execute_input":"2025-05-04T15:50:12.265759Z","iopub.status.idle":"2025-05-04T15:50:12.809682Z","shell.execute_reply.started":"2025-05-04T15:50:12.26574Z","shell.execute_reply":"2025-05-04T15:50:12.808845Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"X_combined.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:58:02.325687Z","iopub.execute_input":"2025-05-04T15:58:02.326365Z","iopub.status.idle":"2025-05-04T15:58:02.3307Z","shell.execute_reply.started":"2025-05-04T15:58:02.326338Z","shell.execute_reply":"2025-05-04T15:58:02.330026Z"}},"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"(330285, 29)"},"metadata":{}}],"execution_count":110},{"cell_type":"code","source":"info.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:17:23.215957Z","iopub.execute_input":"2025-05-04T16:17:23.216242Z","iopub.status.idle":"2025-05-04T16:17:23.221658Z","shell.execute_reply.started":"2025-05-04T16:17:23.216222Z","shell.execute_reply":"2025-05-04T16:17:23.22096Z"}},"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'weekend_logon_flag',\n       'peer_machine_logon_flag', 'total_logon_count', 'unique_pcs',\n       'device_connects', 'after_hours_connects', 'device_pc_count',\n       'files_accessed', 'image_files_accessed', 'binary_files_accessed',\n       'text_files_accessed', 'file_type_entropy', 'sensitive_keyword_count',\n       'avg_content_word_count', 'emails_sent', 'total_recipients',\n       'external_ratio', 'keyword_richness', 'bcc_flag'],\n      dtype='object')"},"metadata":{}}],"execution_count":124},{"cell_type":"code","source":"temporal_features = [\n        'after_hours_logon_count', 'weekend_logon_flag', \n        'total_logon_count', 'after_hours_connects'\n    ]\ndevice_features = [\n        'device_connects', 'device_pc_count'\n    ]\nfile_features = [\n        'binary_files_accessed', 'text_files_accessed',\n        'file_type_entropy', 'sensitive_keyword_count', 'avg_content_word_count'\n    ]\nemail_features = [\n        'emails_sent', 'external_ratio', 'bcc_flag', 'total_recipients'\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:14:31.995888Z","iopub.execute_input":"2025-05-04T16:14:31.996433Z","iopub.status.idle":"2025-05-04T16:14:32.000364Z","shell.execute_reply.started":"2025-05-04T16:14:31.99641Z","shell.execute_reply":"2025-05-04T16:14:31.999807Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:17:41.26585Z","iopub.execute_input":"2025-05-04T16:17:41.266208Z","iopub.status.idle":"2025-05-04T16:17:41.337536Z","shell.execute_reply.started":"2025-05-04T16:17:41.266185Z","shell.execute_reply":"2025-05-04T16:17:41.336817Z"}},"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                      0.0                   0   \n1       AAE0190  2010-01-05                      0.0                   0   \n2       AAE0190  2010-01-06                      0.0                   0   \n3       AAE0190  2010-01-07                      0.0                   0   \n4       AAE0190  2010-01-08                      0.0                   0   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                      0.0                   0   \n330281  ZSL0305  2011-05-11                      0.0                   0   \n330282  ZSL0305  2011-05-12                      0.0                   0   \n330283  ZSL0305  2011-05-13                      0.0                   0   \n330284  ZSL0305  2011-05-16                      0.0                   0   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                             0                1.0         1.0   \n1                             0                1.0         1.0   \n2                             0                1.0         1.0   \n3                             0                1.0         1.0   \n4                             0                1.0         1.0   \n...                         ...                ...         ...   \n330280                        0                1.0         1.0   \n330281                        0                1.0         1.0   \n330282                        0                1.0         1.0   \n330283                        0                1.0         1.0   \n330284                        0                1.0         1.0   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0                   0.0                   0.0              0.0  ...   \n1                   0.0                   0.0              0.0  ...   \n2                   0.0                   0.0              0.0  ...   \n3                   0.0                   0.0              0.0  ...   \n4                   0.0                   0.0              0.0  ...   \n...                 ...                   ...              ...  ...   \n330280              0.0                   0.0              0.0  ...   \n330281              0.0                   0.0              0.0  ...   \n330282              0.0                   0.0              0.0  ...   \n330283              0.0                   0.0              0.0  ...   \n330284              0.0                   0.0              0.0  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                         0.0                  0.0                0.0   \n1                         0.0                  0.0                0.0   \n2                         0.0                  0.0                0.0   \n3                         0.0                  0.0                0.0   \n4                         0.0                  0.0                0.0   \n...                       ...                  ...                ...   \n330280                    0.0                  0.0                0.0   \n330281                    0.0                  0.0                0.0   \n330282                    0.0                  0.0                0.0   \n330283                    0.0                  0.0                0.0   \n330284                    0.0                  0.0                0.0   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                           0.0                     0.0         14.0   \n1                           0.0                     0.0         13.0   \n2                           0.0                     0.0         14.0   \n3                           0.0                     0.0         14.0   \n4                           0.0                     0.0         13.0   \n...                         ...                     ...          ...   \n330280                      0.0                     0.0          1.0   \n330281                      0.0                     0.0          1.0   \n330282                      0.0                     0.0          1.0   \n330283                      0.0                     0.0          1.0   \n330284                      0.0                     0.0          1.0   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0                   43.0        0.214286             470.0       0.0  \n1                   39.0        0.538462             467.0       0.0  \n2                   40.0        0.642857             741.0       0.0  \n3                   42.0        0.571429             454.0       0.0  \n4                   40.0        0.307692             373.0       0.0  \n...                  ...             ...               ...       ...  \n330280               2.0        0.000000              41.0       0.0  \n330281               4.0        2.000000              49.0       0.0  \n330282               6.0        3.000000              48.0       0.0  \n330283               2.0        1.000000              30.0       0.0  \n330284               2.0        1.000000              67.0       0.0  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":125},{"cell_type":"code","source":"info.iloc[:,2:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:18:00.465421Z","iopub.execute_input":"2025-05-04T16:18:00.466025Z","iopub.status.idle":"2025-05-04T16:18:00.498583Z","shell.execute_reply.started":"2025-05-04T16:18:00.465976Z","shell.execute_reply":"2025-05-04T16:18:00.497969Z"}},"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"        after_hours_logon_count  weekend_logon_flag  peer_machine_logon_flag  \\\n0                           0.0                   0                        0   \n1                           0.0                   0                        0   \n2                           0.0                   0                        0   \n3                           0.0                   0                        0   \n4                           0.0                   0                        0   \n...                         ...                 ...                      ...   \n330280                      0.0                   0                        0   \n330281                      0.0                   0                        0   \n330282                      0.0                   0                        0   \n330283                      0.0                   0                        0   \n330284                      0.0                   0                        0   \n\n        total_logon_count  unique_pcs  device_connects  after_hours_connects  \\\n0                     1.0         1.0              0.0                   0.0   \n1                     1.0         1.0              0.0                   0.0   \n2                     1.0         1.0              0.0                   0.0   \n3                     1.0         1.0              0.0                   0.0   \n4                     1.0         1.0              0.0                   0.0   \n...                   ...         ...              ...                   ...   \n330280                1.0         1.0              0.0                   0.0   \n330281                1.0         1.0              0.0                   0.0   \n330282                1.0         1.0              0.0                   0.0   \n330283                1.0         1.0              0.0                   0.0   \n330284                1.0         1.0              0.0                   0.0   \n\n        device_pc_count  files_accessed  image_files_accessed  \\\n0                   0.0             0.0                   0.0   \n1                   0.0             0.0                   0.0   \n2                   0.0             0.0                   0.0   \n3                   0.0             0.0                   0.0   \n4                   0.0             0.0                   0.0   \n...                 ...             ...                   ...   \n330280              0.0             0.0                   0.0   \n330281              0.0             0.0                   0.0   \n330282              0.0             0.0                   0.0   \n330283              0.0             0.0                   0.0   \n330284              0.0             0.0                   0.0   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                         0.0                  0.0                0.0   \n1                         0.0                  0.0                0.0   \n2                         0.0                  0.0                0.0   \n3                         0.0                  0.0                0.0   \n4                         0.0                  0.0                0.0   \n...                       ...                  ...                ...   \n330280                    0.0                  0.0                0.0   \n330281                    0.0                  0.0                0.0   \n330282                    0.0                  0.0                0.0   \n330283                    0.0                  0.0                0.0   \n330284                    0.0                  0.0                0.0   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                           0.0                     0.0         14.0   \n1                           0.0                     0.0         13.0   \n2                           0.0                     0.0         14.0   \n3                           0.0                     0.0         14.0   \n4                           0.0                     0.0         13.0   \n...                         ...                     ...          ...   \n330280                      0.0                     0.0          1.0   \n330281                      0.0                     0.0          1.0   \n330282                      0.0                     0.0          1.0   \n330283                      0.0                     0.0          1.0   \n330284                      0.0                     0.0          1.0   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0                   43.0        0.214286             470.0       0.0  \n1                   39.0        0.538462             467.0       0.0  \n2                   40.0        0.642857             741.0       0.0  \n3                   42.0        0.571429             454.0       0.0  \n4                   40.0        0.307692             373.0       0.0  \n...                  ...             ...               ...       ...  \n330280               2.0        0.000000              41.0       0.0  \n330281               4.0        2.000000              49.0       0.0  \n330282               6.0        3.000000              48.0       0.0  \n330283               2.0        1.000000              30.0       0.0  \n330284               2.0        1.000000              67.0       0.0  \n\n[330285 rows x 20 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>files_accessed</th>\n      <th>image_files_accessed</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 20 columns</p>\n</div>"},"metadata":{}}],"execution_count":127},{"cell_type":"code","source":"scaler = StandardScaler()\ninfo.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:42.987403Z","iopub.execute_input":"2025-05-06T07:33:42.987667Z","iopub.status.idle":"2025-05-06T07:33:43.17762Z","shell.execute_reply.started":"2025-05-06T07:33:42.987648Z","shell.execute_reply":"2025-05-06T07:33:43.176777Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/tmp/ipykernel_31/1535646499.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.14474679 -0.14474679 -0.14474679 ... -0.14474679 -0.14474679\n -0.14474679]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  info.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])\n/tmp/ipykernel_31/1535646499.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.29726833 -0.29726833 -0.29726833 ... -0.29726833 -0.29726833\n -0.29726833]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  info.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:46.528652Z","iopub.execute_input":"2025-05-06T07:33:46.528945Z","iopub.status.idle":"2025-05-06T07:33:46.667077Z","shell.execute_reply.started":"2025-05-06T07:33:46.528922Z","shell.execute_reply":"2025-05-06T07:33:46.666339Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                -0.737332           -0.144747   \n1       AAE0190  2010-01-05                -0.737332           -0.144747   \n2       AAE0190  2010-01-06                -0.737332           -0.144747   \n3       AAE0190  2010-01-07                -0.737332           -0.144747   \n4       AAE0190  2010-01-08                -0.737332           -0.144747   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.144747   \n330281  ZSL0305  2011-05-11                -0.737332           -0.144747   \n330282  ZSL0305  2011-05-12                -0.737332           -0.144747   \n330283  ZSL0305  2011-05-13                -0.737332           -0.144747   \n330284  ZSL0305  2011-05-16                -0.737332           -0.144747   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                     -0.297268           -0.53406   -0.236389   \n1                     -0.297268           -0.53406   -0.236389   \n2                     -0.297268           -0.53406   -0.236389   \n3                     -0.297268           -0.53406   -0.236389   \n4                     -0.297268           -0.53406   -0.236389   \n...                         ...                ...         ...   \n330280                -0.297268           -0.53406   -0.236389   \n330281                -0.297268           -0.53406   -0.236389   \n330282                -0.297268           -0.53406   -0.236389   \n330283                -0.297268           -0.53406   -0.236389   \n330284                -0.297268           -0.53406   -0.236389   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0             -0.331274             -0.143634        -0.381313  ...   \n1             -0.331274             -0.143634        -0.381313  ...   \n2             -0.331274             -0.143634        -0.381313  ...   \n3             -0.331274             -0.143634        -0.381313  ...   \n4             -0.331274             -0.143634        -0.381313  ...   \n...                 ...                   ...              ...  ...   \n330280        -0.331274             -0.143634        -0.381313  ...   \n330281        -0.331274             -0.143634        -0.381313  ...   \n330282        -0.331274             -0.143634        -0.381313  ...   \n330283        -0.331274             -0.143634        -0.381313  ...   \n330284        -0.331274             -0.143634        -0.381313  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                   -0.205347            -0.285834          -0.358449   \n1                   -0.205347            -0.285834          -0.358449   \n2                   -0.205347            -0.285834          -0.358449   \n3                   -0.205347            -0.285834          -0.358449   \n4                   -0.205347            -0.285834          -0.358449   \n...                       ...                  ...                ...   \n330280              -0.205347            -0.285834          -0.358449   \n330281              -0.205347            -0.285834          -0.358449   \n330282              -0.205347            -0.285834          -0.358449   \n330283              -0.205347            -0.285834          -0.358449   \n330284              -0.205347            -0.285834          -0.358449   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                     -0.088544               -0.396378     1.141349   \n1                     -0.088544               -0.396378     0.952298   \n2                     -0.088544               -0.396378     1.141349   \n3                     -0.088544               -0.396378     1.141349   \n4                     -0.088544               -0.396378     0.952298   \n...                         ...                     ...          ...   \n330280                -0.088544               -0.396378    -1.316319   \n330281                -0.088544               -0.396378    -1.316319   \n330282                -0.088544               -0.396378    -1.316319   \n330283                -0.088544               -0.396378    -1.316319   \n330284                -0.088544               -0.396378    -1.316319   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0               0.930009       -0.759447          0.386906 -0.583959  \n1               0.711501       -0.233484          0.374986 -0.583959  \n2               0.766128       -0.064106          1.463670 -0.583959  \n3               0.875382       -0.179997          0.323333 -0.583959  \n4               0.766128       -0.607898          0.001496 -0.583959  \n...                  ...             ...               ...       ...  \n330280         -1.309699       -1.107117         -1.317639 -0.583959  \n330281         -1.200445        2.137805         -1.285853 -0.583959  \n330282         -1.091191        3.760267         -1.289826 -0.583959  \n330283         -1.309699        0.515344         -1.361345 -0.583959  \n330284         -1.309699        0.515344         -1.214333 -0.583959  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>1.141349</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>0.386906</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>0.952298</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.374986</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>1.141349</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.463670</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>1.141349</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>0.323333</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>0.952298</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.001496</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.317639</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.285853</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.289826</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.361345</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.214333</td>\n      <td>-0.583959</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"beh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:50.677579Z","iopub.execute_input":"2025-05-06T07:33:50.678276Z","iopub.status.idle":"2025-05-06T07:33:50.691734Z","shell.execute_reply.started":"2025-05-06T07:33:50.678251Z","shell.execute_reply":"2025-05-06T07:33:50.691055Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"    Unnamed: 0  2010-01-02  2010-01-03  2010-01-04  2010-01-05  2010-01-06  \\\n0      AAE0190           0           0           0           0           0   \n1      AAF0535           0           0           0           0           0   \n2      AAF0791           0           0           0           0           0   \n3      AAL0706           0           0           0           0           0   \n4      AAM0658           0           0           0           0           0   \n..         ...         ...         ...         ...         ...         ...   \n995    ZKS0899           0           0           0           0           0   \n996    ZMC0284           0           0           0           0           0   \n997    ZSB0649           0           0           0           0           0   \n998    ZSK0258           0           0           0           0           0   \n999    ZSL0305           0           0           0           0           0   \n\n     2010-01-07  2010-01-08  2010-01-09  2010-01-10  ...  2011-05-08  \\\n0             0           0           0           0  ...           0   \n1             0           0           0           0  ...           0   \n2             0           0           0           0  ...           0   \n3             0           0           0           0  ...           0   \n4             0           0           0           0  ...           0   \n..          ...         ...         ...         ...  ...         ...   \n995           0           0           0           0  ...           0   \n996           0           0           0           0  ...           0   \n997           0           0           0           0  ...           0   \n998           0           0           0           0  ...           0   \n999           0           0           0           0  ...           0   \n\n     2011-05-09  2011-05-10  2011-05-11  2011-05-12  2011-05-13  2011-05-14  \\\n0             0           0           0           0           0           0   \n1             0           0           0           0           0           0   \n2             0           0           0           0           0           0   \n3             0           0           0           0           0           0   \n4             0           0           0           0           0           0   \n..          ...         ...         ...         ...         ...         ...   \n995           0           0           0           0           0           0   \n996           0           0           0           0           0           0   \n997           0           0           0           0           0           0   \n998           0           0           0           0           0           0   \n999           0           0           0           0           0           0   \n\n     2011-05-15  2011-05-16  2011-05-17  \n0             0           0           0  \n1             0           0           0  \n2             0           0           0  \n3             0           0           0  \n4             0           0           0  \n..          ...         ...         ...  \n995           0           0           0  \n996           0           0           0  \n997           0           0           0  \n998           0           0           0  \n999           0           0           0  \n\n[1000 rows x 502 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>2010-01-02</th>\n      <th>2010-01-03</th>\n      <th>2010-01-04</th>\n      <th>2010-01-05</th>\n      <th>2010-01-06</th>\n      <th>2010-01-07</th>\n      <th>2010-01-08</th>\n      <th>2010-01-09</th>\n      <th>2010-01-10</th>\n      <th>...</th>\n      <th>2011-05-08</th>\n      <th>2011-05-09</th>\n      <th>2011-05-10</th>\n      <th>2011-05-11</th>\n      <th>2011-05-12</th>\n      <th>2011-05-13</th>\n      <th>2011-05-14</th>\n      <th>2011-05-15</th>\n      <th>2011-05-16</th>\n      <th>2011-05-17</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAF0535</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAF0791</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAL0706</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAM0658</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>ZKS0899</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>ZMC0284</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>ZSB0649</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>ZSK0258</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>ZSL0305</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 502 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"beh.rename(columns={'Unnamed: 0': 'user'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:53.34731Z","iopub.execute_input":"2025-05-06T07:33:53.347572Z","iopub.status.idle":"2025-05-06T07:33:53.351949Z","shell.execute_reply.started":"2025-05-06T07:33:53.347551Z","shell.execute_reply":"2025-05-06T07:33:53.351185Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"labels_df = beh.melt(\n    id_vars=['user'], \n    var_name='date', \n    value_name='is_anomaly'\n)\n\n# Convert to datetime and sort\nlabels_df['date'] = pd.to_datetime(labels_df['date'])\nlabels_df = labels_df.sort_values(['user', 'date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:53.867283Z","iopub.execute_input":"2025-05-06T07:33:53.867551Z","iopub.status.idle":"2025-05-06T07:33:54.00768Z","shell.execute_reply.started":"2025-05-06T07:33:53.86753Z","shell.execute_reply":"2025-05-06T07:33:54.00713Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"merged_df = pd.read_csv('/kaggle/input/reqd-data-lstmrl/merged_df.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:57.38725Z","iopub.execute_input":"2025-05-06T07:33:57.387528Z","iopub.status.idle":"2025-05-06T07:33:58.042513Z","shell.execute_reply.started":"2025-05-06T07:33:57.387506Z","shell.execute_reply":"2025-05-06T07:33:58.041705Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"merged_df = merged_df.rename(columns = {'date_only':'date'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:58.043662Z","iopub.execute_input":"2025-05-06T07:33:58.043946Z","iopub.status.idle":"2025-05-06T07:33:58.075953Z","shell.execute_reply.started":"2025-05-06T07:33:58.043918Z","shell.execute_reply":"2025-05-06T07:33:58.075368Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"merged_df['date'] = pd.to_datetime(merged_df['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:58.147054Z","iopub.execute_input":"2025-05-06T07:33:58.147299Z","iopub.status.idle":"2025-05-06T07:33:58.184421Z","shell.execute_reply.started":"2025-05-06T07:33:58.147279Z","shell.execute_reply":"2025-05-06T07:33:58.183913Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"aligned_df = pd.merge(\n    merged_df,\n    labels_df,\n    on=['user', 'date'],\n    how='inner'  # Only keep rows present in both\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:00.392393Z","iopub.execute_input":"2025-05-06T07:34:00.392657Z","iopub.status.idle":"2025-05-06T07:34:00.552556Z","shell.execute_reply.started":"2025-05-06T07:34:00.392637Z","shell.execute_reply":"2025-05-06T07:34:00.551965Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"aligned_df = aligned_df.drop(columns='Unnamed: 0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:00.667085Z","iopub.execute_input":"2025-05-06T07:34:00.667353Z","iopub.status.idle":"2025-05-06T07:34:00.695643Z","shell.execute_reply.started":"2025-05-06T07:34:00.667334Z","shell.execute_reply":"2025-05-06T07:34:00.695099Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"is_anomaly = aligned_df[['is_anomaly']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:02.727221Z","iopub.execute_input":"2025-05-06T07:34:02.727489Z","iopub.status.idle":"2025-05-06T07:34:02.732353Z","shell.execute_reply.started":"2025-05-06T07:34:02.727469Z","shell.execute_reply":"2025-05-06T07:34:02.731763Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"is_anomaly = is_anomaly.to_numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:03.066969Z","iopub.execute_input":"2025-05-06T07:34:03.067688Z","iopub.status.idle":"2025-05-06T07:34:03.070917Z","shell.execute_reply.started":"2025-05-06T07:34:03.067661Z","shell.execute_reply":"2025-05-06T07:34:03.070109Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"is_anomaly=is_anomaly.reshape(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:12.427434Z","iopub.execute_input":"2025-05-06T07:34:12.427938Z","iopub.status.idle":"2025-05-06T07:34:12.431267Z","shell.execute_reply.started":"2025-05-06T07:34:12.427912Z","shell.execute_reply":"2025-05-06T07:34:12.430568Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"is_anomaly.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:18.272651Z","iopub.execute_input":"2025-05-06T07:34:18.273304Z","iopub.status.idle":"2025-05-06T07:34:18.277915Z","shell.execute_reply.started":"2025-05-06T07:34:18.273276Z","shell.execute_reply":"2025-05-06T07:34:18.277303Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"(330285,)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"x = info.drop(columns=['user', 'date_only'])\ny = is_anomaly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:28:34.921188Z","iopub.execute_input":"2025-05-04T16:28:34.921444Z","iopub.status.idle":"2025-05-04T16:28:34.936691Z","shell.execute_reply.started":"2025-05-04T16:28:34.921425Z","shell.execute_reply":"2025-05-04T16:28:34.935816Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"x.shape, y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:28:37.261223Z","iopub.execute_input":"2025-05-04T16:28:37.261886Z","iopub.status.idle":"2025-05-04T16:28:37.266225Z","shell.execute_reply.started":"2025-05-04T16:28:37.261864Z","shell.execute_reply":"2025-05-04T16:28:37.26563Z"}},"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"((330285, 20), (330285, 1))"},"metadata":{}}],"execution_count":154},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:29:28.06131Z","iopub.execute_input":"2025-05-04T16:29:28.061596Z","iopub.status.idle":"2025-05-04T16:29:28.065345Z","shell.execute_reply.started":"2025-05-04T16:29:28.061576Z","shell.execute_reply":"2025-05-04T16:29:28.064565Z"}},"outputs":[],"execution_count":157},{"cell_type":"code","source":"\nmi_selector = SelectKBest(mutual_info_classif, k=10)  # Change k as needed (top 10 features here)\nX_mi = mi_selector.fit_transform(x, y)\n\n# Get the selected feature names\nselected_mi_features = x.columns[mi_selector.get_support()]\nprint(\"Selected features by Mutual Information:\")\nprint(selected_mi_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:29:48.101928Z","iopub.execute_input":"2025-05-04T16:29:48.102627Z","iopub.status.idle":"2025-05-04T16:30:25.358015Z","shell.execute_reply.started":"2025-05-04T16:29:48.102604Z","shell.execute_reply":"2025-05-04T16:30:25.357149Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  y = column_or_1d(y, warn=True)\n","output_type":"stream"},{"name":"stdout","text":"Selected features by Mutual Information:\nIndex(['after_hours_logon_count', 'peer_machine_logon_flag',\n       'total_logon_count', 'device_connects', 'device_pc_count',\n       'files_accessed', 'text_files_accessed', 'file_type_entropy',\n       'avg_content_word_count', 'bcc_flag'],\n      dtype='object')\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"}],"execution_count":159},{"cell_type":"code","source":"correlation_matrix = x.corr()\n\n# Plotting the correlation matrix\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\nplt.title(\"Correlation Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:34:18.502936Z","iopub.execute_input":"2025-05-04T16:34:18.503713Z","iopub.status.idle":"2025-05-04T16:34:19.337069Z","shell.execute_reply.started":"2025-05-04T16:34:18.503683Z","shell.execute_reply":"2025-05-04T16:34:19.336266Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"# Fit a Random Forest Classifier to assess feature importances\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(x, y)\n\n# Get feature importances\nimportances = rf.feature_importances_\n\n# Sort features by importance\nindices = np.argsort(importances)[::-1]  # Sorting in descending order of importance\n\n# Get top K features (e.g., top 5)\ntop_k = 10\ntop_k_indices = indices[:top_k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:35:02.275913Z","iopub.execute_input":"2025-05-04T16:35:02.276202Z","iopub.status.idle":"2025-05-04T16:35:24.859712Z","shell.execute_reply.started":"2025-05-04T16:35:02.276181Z","shell.execute_reply":"2025-05-04T16:35:24.858754Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/tmp/ipykernel_31/2010346285.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  rf.fit(x, y)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2010346285.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# List top K feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtop_k_feature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_k_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Top {top_k} important features: {top_k_feature_names}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"],"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'columns'","output_type":"error"}],"execution_count":162},{"cell_type":"code","source":"# List top K feature names\ntop_k_feature_names = x.columns[top_k_indices]\nprint(f\"Top {top_k} important features: {top_k_feature_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:38:01.849761Z","iopub.execute_input":"2025-05-04T16:38:01.850474Z","iopub.status.idle":"2025-05-04T16:38:01.854715Z","shell.execute_reply.started":"2025-05-04T16:38:01.85045Z","shell.execute_reply":"2025-05-04T16:38:01.853954Z"}},"outputs":[{"name":"stdout","text":"Top 10 important features: Index(['keyword_richness', 'total_recipients', 'external_ratio',\n       'avg_content_word_count', 'device_connects', 'emails_sent',\n       'text_files_accessed', 'files_accessed', 'total_logon_count',\n       'after_hours_logon_count'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":163},{"cell_type":"code","source":"feature_cols = ['after_hours_logon_count', 'total_logon_count','device_connects','avg_content_word_count', 'text_files_accessed', 'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag','keyword_richness' ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:28.228395Z","iopub.execute_input":"2025-05-06T07:34:28.229101Z","iopub.status.idle":"2025-05-06T07:34:28.233238Z","shell.execute_reply.started":"2025-05-06T07:34:28.229068Z","shell.execute_reply":"2025-05-06T07:34:28.23242Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"len(feature_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:31.787889Z","iopub.execute_input":"2025-05-06T07:31:31.788151Z","iopub.status.idle":"2025-05-06T07:31:31.79361Z","shell.execute_reply.started":"2025-05-06T07:31:31.788132Z","shell.execute_reply":"2025-05-06T07:31:31.793005Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"11"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:46:35.165884Z","iopub.execute_input":"2025-05-04T16:46:35.166165Z","iopub.status.idle":"2025-05-04T16:46:35.29577Z","shell.execute_reply.started":"2025-05-04T16:46:35.166145Z","shell.execute_reply":"2025-05-04T16:46:35.29509Z"}},"outputs":[{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                -0.737332           -0.144747   \n1       AAE0190  2010-01-05                -0.737332           -0.144747   \n2       AAE0190  2010-01-06                -0.737332           -0.144747   \n3       AAE0190  2010-01-07                -0.737332           -0.144747   \n4       AAE0190  2010-01-08                -0.737332           -0.144747   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.144747   \n330281  ZSL0305  2011-05-11                -0.737332           -0.144747   \n330282  ZSL0305  2011-05-12                -0.737332           -0.144747   \n330283  ZSL0305  2011-05-13                -0.737332           -0.144747   \n330284  ZSL0305  2011-05-16                -0.737332           -0.144747   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                     -0.297268           -0.53406   -0.236389   \n1                     -0.297268           -0.53406   -0.236389   \n2                     -0.297268           -0.53406   -0.236389   \n3                     -0.297268           -0.53406   -0.236389   \n4                     -0.297268           -0.53406   -0.236389   \n...                         ...                ...         ...   \n330280                -0.297268           -0.53406   -0.236389   \n330281                -0.297268           -0.53406   -0.236389   \n330282                -0.297268           -0.53406   -0.236389   \n330283                -0.297268           -0.53406   -0.236389   \n330284                -0.297268           -0.53406   -0.236389   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0             -0.331274             -0.143634        -0.381313  ...   \n1             -0.331274             -0.143634        -0.381313  ...   \n2             -0.331274             -0.143634        -0.381313  ...   \n3             -0.331274             -0.143634        -0.381313  ...   \n4             -0.331274             -0.143634        -0.381313  ...   \n...                 ...                   ...              ...  ...   \n330280        -0.331274             -0.143634        -0.381313  ...   \n330281        -0.331274             -0.143634        -0.381313  ...   \n330282        -0.331274             -0.143634        -0.381313  ...   \n330283        -0.331274             -0.143634        -0.381313  ...   \n330284        -0.331274             -0.143634        -0.381313  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                   -0.205347            -0.285834          -0.358449   \n1                   -0.205347            -0.285834          -0.358449   \n2                   -0.205347            -0.285834          -0.358449   \n3                   -0.205347            -0.285834          -0.358449   \n4                   -0.205347            -0.285834          -0.358449   \n...                       ...                  ...                ...   \n330280              -0.205347            -0.285834          -0.358449   \n330281              -0.205347            -0.285834          -0.358449   \n330282              -0.205347            -0.285834          -0.358449   \n330283              -0.205347            -0.285834          -0.358449   \n330284              -0.205347            -0.285834          -0.358449   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                     -0.088544               -0.396378     1.141349   \n1                     -0.088544               -0.396378     0.952298   \n2                     -0.088544               -0.396378     1.141349   \n3                     -0.088544               -0.396378     1.141349   \n4                     -0.088544               -0.396378     0.952298   \n...                         ...                     ...          ...   \n330280                -0.088544               -0.396378    -1.316319   \n330281                -0.088544               -0.396378    -1.316319   \n330282                -0.088544               -0.396378    -1.316319   \n330283                -0.088544               -0.396378    -1.316319   \n330284                -0.088544               -0.396378    -1.316319   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0               0.930009       -0.759447          0.386906 -0.583959  \n1               0.711501       -0.233484          0.374986 -0.583959  \n2               0.766128       -0.064106          1.463670 -0.583959  \n3               0.875382       -0.179997          0.323333 -0.583959  \n4               0.766128       -0.607898          0.001496 -0.583959  \n...                  ...             ...               ...       ...  \n330280         -1.309699       -1.107117         -1.317639 -0.583959  \n330281         -1.200445        2.137805         -1.285853 -0.583959  \n330282         -1.091191        3.760267         -1.289826 -0.583959  \n330283         -1.309699        0.515344         -1.361345 -0.583959  \n330284         -1.309699        0.515344         -1.214333 -0.583959  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>1.141349</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>0.386906</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>0.952298</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.374986</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>1.141349</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.463670</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>1.141349</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>0.323333</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>0.952298</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.001496</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.317639</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.285853</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.289826</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.361345</td>\n      <td>-0.583959</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.144747</td>\n      <td>-0.297268</td>\n      <td>-0.53406</td>\n      <td>-0.236389</td>\n      <td>-0.331274</td>\n      <td>-0.143634</td>\n      <td>-0.381313</td>\n      <td>...</td>\n      <td>-0.205347</td>\n      <td>-0.285834</td>\n      <td>-0.358449</td>\n      <td>-0.088544</td>\n      <td>-0.396378</td>\n      <td>-1.316319</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.214333</td>\n      <td>-0.583959</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":169},{"cell_type":"code","source":"a = info[ ['user','date_only'] + feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:32.447062Z","iopub.execute_input":"2025-05-06T07:34:32.44732Z","iopub.status.idle":"2025-05-06T07:34:32.464659Z","shell.execute_reply.started":"2025-05-06T07:34:32.447301Z","shell.execute_reply":"2025-05-06T07:34:32.464003Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:32.72734Z","iopub.execute_input":"2025-05-06T07:34:32.727914Z","iopub.status.idle":"2025-05-06T07:34:32.741366Z","shell.execute_reply.started":"2025-05-06T07:34:32.727893Z","shell.execute_reply":"2025-05-06T07:34:32.74062Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n330280 -0.583959         -1.317639  \n330281 -0.583959         -1.285853  \n330282 -0.583959         -1.289826  \n330283 -0.583959         -1.361345  \n330284 -0.583959         -1.214333  \n\n[330285 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"role_data = np.array([role_lookup[uid] for uid in user_ids])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:40.848131Z","iopub.execute_input":"2025-05-06T07:34:40.848816Z","iopub.status.idle":"2025-05-06T07:34:40.901116Z","shell.execute_reply.started":"2025-05-06T07:34:40.848773Z","shell.execute_reply":"2025-05-06T07:34:40.900381Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"role_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:49:09.385758Z","iopub.execute_input":"2025-05-04T16:49:09.386047Z","iopub.status.idle":"2025-05-04T16:49:09.390903Z","shell.execute_reply.started":"2025-05-04T16:49:09.386025Z","shell.execute_reply":"2025-05-04T16:49:09.390171Z"}},"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"array([8, 8, 8, ..., 2, 2, 2])"},"metadata":{}}],"execution_count":178},{"cell_type":"code","source":"role_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:57.542746Z","iopub.execute_input":"2025-05-06T07:34:57.543458Z","iopub.status.idle":"2025-05-06T07:34:57.547746Z","shell.execute_reply.started":"2025-05-06T07:34:57.543434Z","shell.execute_reply":"2025-05-06T07:34:57.547137Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"(330285,)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"np.unique(role_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:35:36.647215Z","iopub.execute_input":"2025-05-06T07:35:36.647726Z","iopub.status.idle":"2025-05-06T07:35:36.659208Z","shell.execute_reply.started":"2025-05-06T07:35:36.647701Z","shell.execute_reply":"2025-05-06T07:35:36.658489Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"array([ 1,  2,  4,  5,  6,  8,  9, 10, 12, 14])"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"s = pd.Series(role_data, name='role')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:50:17.517337Z","iopub.execute_input":"2025-05-04T16:50:17.51762Z","iopub.status.idle":"2025-05-04T16:50:17.521664Z","shell.execute_reply.started":"2025-05-04T16:50:17.5176Z","shell.execute_reply":"2025-05-04T16:50:17.520964Z"}},"outputs":[],"execution_count":179},{"cell_type":"code","source":"a = pd.concat([a, s], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:50:36.146165Z","iopub.execute_input":"2025-05-04T16:50:36.146708Z","iopub.status.idle":"2025-05-04T16:50:36.166817Z","shell.execute_reply.started":"2025-05-04T16:50:36.146673Z","shell.execute_reply":"2025-05-04T16:50:36.166132Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:50:37.445761Z","iopub.execute_input":"2025-05-04T16:50:37.446397Z","iopub.status.idle":"2025-05-04T16:50:37.459714Z","shell.execute_reply.started":"2025-05-04T16:50:37.446375Z","shell.execute_reply":"2025-05-04T16:50:37.459099Z"}},"outputs":[{"execution_count":181,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  role  \n0      -0.583959          0.386906     8  \n1      -0.583959          0.374986     8  \n2      -0.583959          1.463670     8  \n3      -0.583959          0.323333     8  \n4      -0.583959          0.001496     8  \n...          ...               ...   ...  \n330280 -0.583959         -1.317639     2  \n330281 -0.583959         -1.285853     2  \n330282 -0.583959         -1.289826     2  \n330283 -0.583959         -1.361345     2  \n330284 -0.583959         -1.214333     2  \n\n[330285 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n      <th>role</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 14 columns</p>\n</div>"},"metadata":{}}],"execution_count":181},{"cell_type":"code","source":"is_an = aligned_df[['is_anomaly']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:53:24.445576Z","iopub.execute_input":"2025-05-04T16:53:24.446253Z","iopub.status.idle":"2025-05-04T16:53:24.452911Z","shell.execute_reply.started":"2025-05-04T16:53:24.446226Z","shell.execute_reply":"2025-05-04T16:53:24.452118Z"}},"outputs":[],"execution_count":187},{"cell_type":"code","source":"a = pd.concat([a,is_an],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:53:55.780683Z","iopub.execute_input":"2025-05-04T16:53:55.78122Z","iopub.status.idle":"2025-05-04T16:53:55.806547Z","shell.execute_reply.started":"2025-05-04T16:53:55.781197Z","shell.execute_reply":"2025-05-04T16:53:55.806019Z"}},"outputs":[],"execution_count":191},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:53:59.165606Z","iopub.execute_input":"2025-05-04T16:53:59.166242Z","iopub.status.idle":"2025-05-04T16:53:59.179676Z","shell.execute_reply.started":"2025-05-04T16:53:59.16622Z","shell.execute_reply":"2025-05-04T16:53:59.179157Z"}},"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  role  is_anomaly  \n0      -0.583959          0.386906     8           0  \n1      -0.583959          0.374986     8           0  \n2      -0.583959          1.463670     8           0  \n3      -0.583959          0.323333     8           0  \n4      -0.583959          0.001496     8           0  \n...          ...               ...   ...         ...  \n330280 -0.583959         -1.317639     2           0  \n330281 -0.583959         -1.285853     2           0  \n330282 -0.583959         -1.289826     2           0  \n330283 -0.583959         -1.361345     2           0  \n330284 -0.583959         -1.214333     2           0  \n\n[330285 rows x 15 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n      <th>role</th>\n      <th>is_anomaly</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n      <td>8</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 15 columns</p>\n</div>"},"metadata":{}}],"execution_count":192},{"cell_type":"code","source":"a['user_anomaly_rate'] = a.groupby('user')['is_anomaly'].transform(\n        lambda x: x.ewm(span=30).mean().shift(1).fillna(0.001))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:54:38.985711Z","iopub.execute_input":"2025-05-04T16:54:38.986135Z","iopub.status.idle":"2025-05-04T16:54:39.326164Z","shell.execute_reply.started":"2025-05-04T16:54:38.986113Z","shell.execute_reply":"2025-05-04T16:54:39.325291Z"}},"outputs":[],"execution_count":195},{"cell_type":"code","source":"len(a['user_anomaly_rate'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:55:01.886441Z","iopub.execute_input":"2025-05-04T16:55:01.886685Z","iopub.status.idle":"2025-05-04T16:55:01.893473Z","shell.execute_reply.started":"2025-05-04T16:55:01.886668Z","shell.execute_reply":"2025-05-04T16:55:01.892867Z"}},"outputs":[{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"1531"},"metadata":{}}],"execution_count":198},{"cell_type":"code","source":"a['role_anomaly_rate'] = a.groupby('role')['is_anomaly'].transform(\n        lambda x: x.rolling(100, min_periods=1).mean().shift(1).fillna(0.005))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:55:18.007748Z","iopub.execute_input":"2025-05-04T16:55:18.008025Z","iopub.status.idle":"2025-05-04T16:55:18.069442Z","shell.execute_reply.started":"2025-05-04T16:55:18.008004Z","shell.execute_reply":"2025-05-04T16:55:18.06887Z"}},"outputs":[],"execution_count":199},{"cell_type":"code","source":"a['role_anomaly_rate'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:55:45.707034Z","iopub.execute_input":"2025-05-04T16:55:45.707701Z","iopub.status.idle":"2025-05-04T16:55:45.714402Z","shell.execute_reply.started":"2025-05-04T16:55:45.707677Z","shell.execute_reply":"2025-05-04T16:55:45.713856Z"}},"outputs":[{"execution_count":203,"output_type":"execute_result","data":{"text/plain":"array([0.005, 0.   , 0.01 , 0.02 , 0.03 , 0.04 , 0.05 , 0.06 , 0.07 ,\n       0.08 , 0.09 , 0.1  , 0.11 , 0.12 , 0.13 , 0.14 , 0.15 , 0.16 ,\n       0.17 , 0.18 , 0.19 , 0.2  , 0.21 , 0.22 , 0.23 , 0.24 , 0.25 ,\n       0.26 , 0.27 , 0.28 , 0.29 , 0.3  , 0.31 , 0.32 , 0.33 , 0.34 ,\n       0.35 , 0.36 , 0.37 , 0.38 , 0.39 , 0.4  , 0.41 , 0.42 , 0.43 ,\n       0.44 , 0.45 , 0.46 , 0.47 ])"},"metadata":{}}],"execution_count":203},{"cell_type":"code","source":"class AdaptiveDQNAgent:\n    def __init__(self, state_dim):\n        self.state_dim = state_dim\n        self.model = self._build_model()\n        self.user_thresholds = defaultdict(lambda: 0.65)  # Default thresholds\n        self.role_thresholds = defaultdict(lambda: 0.55)\n        self.user_counts = defaultdict(int)\n        \n    def _build_model(self):\n        \"\"\"Build and compile the DQN model\"\"\"\n        model = tf.keras.Sequential([\n            tf.keras.layers.Dense(64, activation='relu', input_shape=(self.state_dim,)),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(1, activation='sigmoid')  # Outputs anomaly probability\n        ])\n        model.compile(optimizer='adam', loss='binary_crossentropy')\n        return model\n    \n    def predict(self, state, user, role):\n        if not isinstance(state, np.ndarray):\n            state = np.array(state, dtype=np.float32)\n        \n        # Ensure correct shape (batch_size, state_dim)\n        if len(state.shape) == 1:\n            state = state[np.newaxis, :]\n        \n        prob = self.model.predict(state, verbose=0)[0][0]\n        \n        # Update user count\n        self.user_counts[user] += 1\n        \n        # Get thresholds\n        user_thresh = self.user_thresholds[user]\n        role_thresh = self.role_thresholds[role]\n        \n        # Weighted threshold (more user-specific with more data)\n        user_weight = min(0.7, 0.4 + 0.01 * self.user_counts[user])\n        combined_thresh = user_weight * user_thresh + (1-user_weight) * role_thresh\n        \n        return 1 if prob > combined_thresh else 0, prob\n\n    def update_thresholds(self, user, role, reward):\n        \"\"\"Adjust thresholds based on performance\"\"\"\n        # User thresholds adapt faster\n        adj = 0.02 if reward > 0 else -0.03\n        self.user_thresholds[user] = np.clip(\n            self.user_thresholds[user] + adj, 0.4, 0.8)\n        \n        # Role thresholds adapt slower\n        adj = 0.01 if reward > 0 else -0.02\n        self.role_thresholds[role] = np.clip(\n            self.role_thresholds[role] + adj, 0.5, 0.7)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:01:18.521256Z","iopub.execute_input":"2025-05-04T17:01:18.52195Z","iopub.status.idle":"2025-05-04T17:01:18.52973Z","shell.execute_reply.started":"2025-05-04T17:01:18.521926Z","shell.execute_reply":"2025-05-04T17:01:18.52903Z"}},"outputs":[],"execution_count":215},{"cell_type":"code","source":"class InsiderThreatEnv:\n    def __init__(self, df):\n        self.df = df\n        self.current_idx = 0\n        self.state_columns = [col for col in df.columns \n                            if col not in ['user', 'date_only', 'is_anomaly', 'role']]\n        \n    def reset(self):\n        self.current_idx = np.random.randint(0, len(self.df))\n        return self._get_state()\n    \n    def _get_state(self):\n        return self.df.iloc[self.current_idx][self.state_columns].values.astype(np.float32)\n    \n    def step(self, action):\n        row = self.df.iloc[self.current_idx]\n        true_label = row['is_anomaly']\n        user = row['user']\n        role = row['role']\n        \n        # Calculate reward\n        if action == true_label:\n            reward = 10.0 if action == 1 else 1.0\n        else:\n            reward = -5.0 if action == 1 else -15.0\n        \n        # Move to next state\n        self.current_idx = (self.current_idx + 1) % len(self.df)\n        done = self.current_idx == 0\n        \n        return self._get_state(), reward, done, {'user': user, 'role': role}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:01:29.546328Z","iopub.execute_input":"2025-05-04T17:01:29.546594Z","iopub.status.idle":"2025-05-04T17:01:29.552741Z","shell.execute_reply.started":"2025-05-04T17:01:29.546573Z","shell.execute_reply":"2025-05-04T17:01:29.552123Z"}},"outputs":[],"execution_count":216},{"cell_type":"code","source":"def train_adaptive_dqn(df, epochs=10):\n    env = InsiderThreatEnv(df)\n    agent = AdaptiveDQNAgent(state_dim=len(env.state_columns))\n    \n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        \n        while not done:\n            user = env.df.iloc[env.current_idx]['user']\n            role = env.df.iloc[env.current_idx]['role']\n            \n            # Get action\n            action, _ = agent.predict(state, user, role)\n            \n            # Take step\n            next_state, reward, done, info = env.step(action)\n            \n            # Convert to proper format\n            state_array = np.array(state, dtype=np.float32).reshape(1, -1)\n            next_state_array = np.array(next_state, dtype=np.float32).reshape(1, -1)\n            target = np.array([[1 if action == 1 else 0]], dtype=np.float32)\n            \n            # Train model\n            agent.model.train_on_batch(state_array, target)\n            \n            # Update thresholds\n            agent.update_thresholds(info['user'], info['role'], reward)\n            \n            state = next_state\n            total_reward += reward\n        \n        print(f\"Epoch {epoch+1}, Total Reward: {total_reward:.1f}\")\n    \n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:01:37.645615Z","iopub.execute_input":"2025-05-04T17:01:37.646198Z","iopub.status.idle":"2025-05-04T17:01:37.652543Z","shell.execute_reply.started":"2025-05-04T17:01:37.646173Z","shell.execute_reply":"2025-05-04T17:01:37.651743Z"}},"outputs":[],"execution_count":217},{"cell_type":"code","source":"agent = train_adaptive_dqn(a, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:06:04.585815Z","iopub.execute_input":"2025-05-04T17:06:04.586187Z","iopub.status.idle":"2025-05-04T17:06:07.953682Z","shell.execute_reply.started":"2025-05-04T17:06:04.586164Z","shell.execute_reply":"2025-05-04T17:06:07.952484Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/1314463013.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_adaptive_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/1035432830.py\u001b[0m in \u001b[0;36mtrain_adaptive_dqn\u001b[0;34m(df, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Get action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;31m# Take step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2408882101.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, state, user, role)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Update user count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    448\u001b[0m     ):\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m# Create an iterator that yields batches of input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    451\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2387\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mflat_map_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;31m# pylint: enable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_flat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-private-name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;34m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_FlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/flat_map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m     34\u001b[0m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;31m# Implements PolymorphicFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# Note: wrapper_helper will apply autograph based on context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \"\"\"\n\u001b[1;32m    159\u001b[0m             \u001b[0mnum_in_full_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_full_batches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfirst_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_in_full_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             first_k_indices = tf.reshape(\n\u001b[1;32m    162\u001b[0m                 \u001b[0mfirst_k_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_full_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(input_, begin, size, name)\u001b[0m\n\u001b[1;32m    989\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m   \"\"\"\n\u001b[0;32m--> 991\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_slice\u001b[0;34m(input, begin, size, name)\u001b[0m\n\u001b[1;32m   9899\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9900\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9901\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   9902\u001b[0m         \"Slice\", input=input, begin=begin, size=size, name=name)\n\u001b[1;32m   9903\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    774\u001b[0m   \u001b[0;31m# Requires that op_def has passed validation (using the C++\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m   \u001b[0;31m# ValidateOpDef() from ../framework/op_def_util.h).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m       _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mas_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mouter_cm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0;34m\"\"\"Context manager for copying distribute.Strategy scope information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/tf_contextlib.py\u001b[0m in \u001b[0;36mcontextmanager\u001b[0;34m(target)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \"\"\"\n\u001b[1;32m     38\u001b[0m   \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_contextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'contextmanager'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdecorator_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mdecorator_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mco_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m   decorator = TFDecorator(decorator_name, target, decorator_doc,\n\u001b[0m\u001b[1;32m    137\u001b[0m                           decorator_argspec)\n\u001b[1;32m    138\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecorator_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tf_decorator'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/tf_decorator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__signature__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;31m# Certain callables such as builtins can not be inspected for signature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m     return Signature.from_callable(obj, follow_wrapped=follow_wrapped,\n\u001b[0m\u001b[1;32m   3264\u001b[0m                                    globals=globals, locals=locals, eval_str=eval_str)\n\u001b[1;32m   3265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3009\u001b[0m                       follow_wrapped=True, globals=None, locals=None, eval_str=False):\n\u001b[1;32m   3010\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0m\u001b[1;32m   3012\u001b[0m                                         \u001b[0mfollow_wrapper_chains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2521\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2522\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2523\u001b[0;31m         return _signature_from_function(sigcls, obj,\n\u001b[0m\u001b[1;32m   2524\u001b[0m                                         \u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_bound_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m                                         globals=globals, locals=locals, eval_str=eval_str)\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func, skip_bound_arg, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0;31m# Is 'func' is a pure Python function - don't validate the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;31m# parameters list (for correct order and defaults), it should be OK.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2421\u001b[0;31m     return cls(parameters,\n\u001b[0m\u001b[1;32m   2422\u001b[0m                \u001b[0mreturn_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2423\u001b[0m                __validate_parameters__=is_duck_function)\n","\u001b[0;32m/usr/lib/python3.11/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   3000\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3001\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3002\u001b[0;31m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3004\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMappingProxyType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":222},{"cell_type":"code","source":"a.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:06:15.170793Z","iopub.execute_input":"2025-05-04T17:06:15.171529Z","iopub.status.idle":"2025-05-04T17:06:15.176511Z","shell.execute_reply.started":"2025-05-04T17:06:15.171498Z","shell.execute_reply":"2025-05-04T17:06:15.175835Z"}},"outputs":[{"execution_count":223,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'role', 'is_anomaly',\n       'user_anomaly_rate', 'role_anomaly_rate'],\n      dtype='object')"},"metadata":{}}],"execution_count":223},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:06:29.72977Z","iopub.execute_input":"2025-05-04T17:06:29.730356Z","iopub.status.idle":"2025-05-04T17:06:29.747236Z","shell.execute_reply.started":"2025-05-04T17:06:29.730335Z","shell.execute_reply":"2025-05-04T17:06:29.746543Z"}},"outputs":[{"execution_count":224,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  role  is_anomaly  user_anomaly_rate  \\\n0      -0.583959          0.386906     8           0              0.001   \n1      -0.583959          0.374986     8           0              0.000   \n2      -0.583959          1.463670     8           0              0.000   \n3      -0.583959          0.323333     8           0              0.000   \n4      -0.583959          0.001496     8           0              0.000   \n...          ...               ...   ...         ...                ...   \n330280 -0.583959         -1.317639     2           0              0.000   \n330281 -0.583959         -1.285853     2           0              0.000   \n330282 -0.583959         -1.289826     2           0              0.000   \n330283 -0.583959         -1.361345     2           0              0.000   \n330284 -0.583959         -1.214333     2           0              0.000   \n\n        role_anomaly_rate  \n0                   0.005  \n1                   0.000  \n2                   0.000  \n3                   0.000  \n4                   0.000  \n...                   ...  \n330280              0.000  \n330281              0.000  \n330282              0.000  \n330283              0.000  \n330284              0.000  \n\n[330285 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n      <th>role</th>\n      <th>is_anomaly</th>\n      <th>user_anomaly_rate</th>\n      <th>role_anomaly_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.001</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 17 columns</p>\n</div>"},"metadata":{}}],"execution_count":224},{"cell_type":"code","source":"agent.model.save('adaptive_dqn.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"logcal attempt","metadata":{}},{"cell_type":"code","source":"class InsiderThreatEnv:\n    def __init__(self, df, window_size=5):\n        self.df = df.sort_values(['user', 'date_only']).reset_index(drop=True)\n        self.window_size = window_size\n        self.state_columns = [col for col in df.columns if col not in ['user', 'date_only', 'is_anomaly', 'role']]\n        self.users = df['user'].unique()\n        self.user_data = {user: df[df['user'] == user].reset_index(drop=True) for user in self.users}\n        self.state_buffer = deque(maxlen=window_size)\n        self.current_user = None\n        self.current_idx = 0\n\n    def reset(self):\n        self.current_user = np.random.choice(self.users)\n        self.current_idx = 0\n        self.state_buffer.clear()\n        user_df = self.user_data[self.current_user]\n        \n        for i in range(min(self.window_size, len(user_df))):\n            self.state_buffer.append(user_df.iloc[i][self.state_columns].values.astype(np.float32))\n\n        return self._get_state()\n\n    def _get_state(self):\n        while len(self.state_buffer) < self.window_size:\n            self.state_buffer.appendleft(np.zeros(len(self.state_columns), dtype=np.float32))\n\n        user_df = self.user_data[self.current_user]\n        state = np.concatenate([x for x in self.state_buffer])\n        if self.current_idx < len(user_df):\n            user_rate = user_df.iloc[self.current_idx]['user_anomaly_rate']\n            role_rate = user_df.iloc[self.current_idx]['role_anomaly_rate']\n        else:\n            user_rate = role_rate = 0.0\n        return np.append(state, [user_rate, role_rate]).astype(np.float32)\n\n    def step(self, action):\n        user_df = self.user_data[self.current_user]\n        if self.current_idx >= len(user_df):\n            return self._get_state(), 0.0, True, {'user': self.current_user, 'role': 0}\n\n        row = user_df.iloc[self.current_idx]\n        user, role, true_label = row['user'], row['role'], row['is_anomaly']\n        \n        thresholds = [0.4, 0.6, 0.8]\n        threshold = thresholds[action]\n        prob = np.mean(row[self.state_columns])\n        prediction = 1 if prob > threshold else 0\n\n        if prediction == true_label:\n            reward = 10.0 if prediction == 1 else 1.0\n        else:\n            reward = -15.0 if true_label == 1 else -5.0\n\n        self.current_idx += 1\n        if self.current_idx < len(user_df):\n            self.state_buffer.append(user_df.iloc[self.current_idx][self.state_columns].values.astype(np.float32))\n        \n        done = self.current_idx >= len(user_df)\n        return self._get_state(), reward, done, {'user': user, 'role': role}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:12:57.787079Z","iopub.execute_input":"2025-05-04T17:12:57.787344Z","iopub.status.idle":"2025-05-04T17:12:57.798157Z","shell.execute_reply.started":"2025-05-04T17:12:57.787324Z","shell.execute_reply":"2025-05-04T17:12:57.797445Z"}},"outputs":[],"execution_count":225},{"cell_type":"code","source":"class AdaptiveDQNAgent:\n    def __init__(self, state_dim, action_dim=3, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.gamma = 0.95\n        self.memory = deque(maxlen=2000)\n        self.model = self._build_model()\n        self.target_model = self._build_model()\n        self.update_target_model()\n\n    def _build_model(self):\n        model = tf.keras.Sequential([\n            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_dim,)),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(self.action_dim, activation='linear')\n        ])\n        model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')\n        return model\n\n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n\n    def act(self, state):\n        if np.random.rand() < self.epsilon:\n            return np.random.randint(self.action_dim)\n        q_values = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n        return np.argmax(q_values)\n\n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n\n    def replay(self, batch_size=32):\n        if len(self.memory) < batch_size:\n            return\n        minibatch = np.random.choice(len(self.memory), batch_size, replace=False)\n        minibatch = [self.memory[i] for i in minibatch]\n        states = np.array([s[0] for s in minibatch])\n        actions = np.array([s[1] for s in minibatch])\n        rewards = np.array([s[2] for s in minibatch])\n        next_states = np.array([s[3] for s in minibatch])\n        dones = np.array([s[4] for s in minibatch])\n\n        targets = self.model.predict(states, verbose=0)\n        next_targets = self.target_model.predict(next_states, verbose=0)\n\n        for i in range(batch_size):\n            targets[i][actions[i]] = rewards[i] if dones[i] else rewards[i] + self.gamma * np.max(next_targets[i])\n\n        self.model.fit(states, targets, epochs=1, verbose=0)\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:13:16.122176Z","iopub.execute_input":"2025-05-04T17:13:16.122441Z","iopub.status.idle":"2025-05-04T17:13:16.132239Z","shell.execute_reply.started":"2025-05-04T17:13:16.122419Z","shell.execute_reply":"2025-05-04T17:13:16.13155Z"}},"outputs":[],"execution_count":226},{"cell_type":"code","source":"def train_adaptive_dqn(df, epochs=10, batch_size=32):\n    env = InsiderThreatEnv(df, window_size=5)\n    state_dim = len(env.state_columns) * env.window_size + 2\n    agent = AdaptiveDQNAgent(state_dim=state_dim)\n\n    reward_history = []\n    \n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        total_correct = 0\n        total_anomalies = 0\n        steps = 0\n        done = False\n\n        with trange(1_000, desc=f\"Epoch {epoch+1}\", leave=False) as t:\n            for _ in t:\n                action = agent.act(state)\n                next_state, reward, done, info = env.step(action)\n\n                # For tracking\n                user = info.get(\"user\")\n                true_label = env.user_data[user].iloc[env.current_idx - 1][\"is_anomaly\"] if env.current_idx > 0 else 0\n                pred_label = 1 if action == 2 else 0  # assume action 2 = high threshold = anomaly\n                if pred_label == true_label:\n                    total_correct += 1\n                if true_label == 1:\n                    total_anomalies += 1\n\n                agent.remember(state, action, reward, next_state, done)\n                agent.replay(batch_size)\n                state = next_state\n                total_reward += reward\n                steps += 1\n\n                if steps % 100 == 0:\n                    agent.update_target_model()\n                \n                if done:\n                    break\n\n                # Update tqdm description\n                t.set_postfix({\n                    'Reward': f\"{total_reward:.1f}\",\n                    'Steps': steps,\n                    'Epsilon': f\"{agent.epsilon:.3f}\"\n                })\n\n        reward_history.append(total_reward)\n        avg_reward = np.mean(reward_history[-5:])\n\n        print(f\"[Epoch {epoch+1}] Total Reward: {total_reward:.1f} | \"\n              f\"Avg Reward (last 5): {avg_reward:.1f} | \"\n              f\"Accuracy: {total_correct}/{steps} | \"\n              f\"Anomalies Seen: {total_anomalies} | Epsilon: {agent.epsilon:.3f}\")\n\n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:14:33.966643Z","iopub.execute_input":"2025-05-04T17:14:33.96692Z","iopub.status.idle":"2025-05-04T17:14:33.974669Z","shell.execute_reply.started":"2025-05-04T17:14:33.966899Z","shell.execute_reply":"2025-05-04T17:14:33.97392Z"}},"outputs":[],"execution_count":229},{"cell_type":"code","source":"from tqdm import trange","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:10.877557Z","iopub.execute_input":"2025-05-06T07:31:10.878325Z","iopub.status.idle":"2025-05-06T07:31:10.882033Z","shell.execute_reply.started":"2025-05-06T07:31:10.878298Z","shell.execute_reply":"2025-05-06T07:31:10.881017Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"agent = train_adaptive_dqn(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:19:03.13057Z","iopub.execute_input":"2025-05-04T17:19:03.130827Z","iopub.status.idle":"2025-05-04T17:31:11.455639Z","shell.execute_reply.started":"2025-05-04T17:19:03.130806Z","shell.execute_reply":"2025-05-04T17:31:11.454885Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Total Reward: 346.0 | Avg Reward (last 5): 346.0 | Accuracy: 256/346 | Anomalies Seen: 0 | Epsilon: 0.206\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Total Reward: -122.0 | Avg Reward (last 5): 112.0 | Accuracy: 19/346 | Anomalies Seen: 0 | Epsilon: 0.036\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Total Reward: 53.0 | Avg Reward (last 5): 92.3 | Accuracy: 106/197 | Anomalies Seen: 9 | Epsilon: 0.014\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                  \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Total Reward: 83.0 | Avg Reward (last 5): 90.0 | Accuracy: 13/353 | Anomalies Seen: 0 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Total Reward: 346.0 | Avg Reward (last 5): 141.2 | Accuracy: 213/346 | Anomalies Seen: 0 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Total Reward: 346.0 | Avg Reward (last 5): 141.2 | Accuracy: 247/346 | Anomalies Seen: 0 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Total Reward: 238.0 | Avg Reward (last 5): 213.2 | Accuracy: 213/238 | Anomalies Seen: 0 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Total Reward: 414.0 | Avg Reward (last 5): 285.4 | Accuracy: 58/438 | Anomalies Seen: 0 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                   \r","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Total Reward: 154.0 | Avg Reward (last 5): 299.6 | Accuracy: 29/346 | Anomalies Seen: 0 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    ","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Total Reward: 201.0 | Avg Reward (last 5): 270.6 | Accuracy: 202/229 | Anomalies Seen: 1 | Epsilon: 0.010\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":232},{"cell_type":"code","source":"agent.model.save('dqn_rolebased_1.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:35:11.485254Z","iopub.execute_input":"2025-05-04T17:35:11.485911Z","iopub.status.idle":"2025-05-04T17:35:11.508368Z","shell.execute_reply.started":"2025-05-04T17:35:11.485888Z","shell.execute_reply":"2025-05-04T17:35:11.507852Z"}},"outputs":[],"execution_count":234},{"cell_type":"markdown","source":"better reward and anomaly weighting","metadata":{}},{"cell_type":"code","source":"class InsiderThreatEnv:\n    def __init__(self, df, window_size=5):\n        # Preprocess data\n        self.df = self._preprocess_data(df)\n        self.window_size = window_size\n        \n        # Define features and targets\n        self.state_columns = [col for col in df.columns \n                            if col not in ['user', 'date_only', 'is_anomaly', 'role']]\n        self.scaler = StandardScaler()\n        self.scaler.fit(self.df[self.state_columns])\n        \n        # Group by user\n        self.users = self.df['user'].unique()\n        self.user_data = {user: self.df[self.df['user'] == user] \n                         for user in self.users}\n        \n        # Track episode stats\n        self.current_user = None\n        self.current_idx = 0\n        self.state_buffer = deque(maxlen=window_size)\n        self.anomaly_weight = len(self.df[self.df['is_anomaly']==0])/len(self.df[self.df['is_anomaly']==1])\n    \n    def _preprocess_data(self, df):\n        # Fill missing dates with zero activity\n        all_dates = pd.date_range(df['date_only'].min(), df['date_only'].max())\n        full_data = []\n        \n        for user in df['user'].unique():\n            user_df = df[df['user'] == user]\n            user_role = user_df['role'].iloc[0]\n            \n            for date in all_dates:\n                date_str = date.strftime('%Y-%m-%d')\n                if date_str in user_df['date_only'].values:\n                    row = user_df[user_df['date_only'] == date_str].iloc[0]\n                else:\n                    # Impute zeros for missing days\n                    row = pd.Series({\n                        'user': user, 'date_only': date_str, 'role': user_role,\n                        'is_anomaly': 0, 'user_anomaly_rate': user_df['user_anomaly_rate'].mean(),\n                        'role_anomaly_rate': user_df['role_anomaly_rate'].mean(),\n                        **{col: 0 for col in df.columns if col not in ['user', 'date_only', 'role', \n                                                                       'is_anomaly', 'user_anomaly_rate', \n                                                                       'role_anomaly_rate']}\n                    })\n                full_data.append(row)\n        \n        return pd.DataFrame(full_data).sort_values(['user', 'date_only'])\n    \n    def _get_state(self):\n        # Pad with zeros if needed\n        while len(self.state_buffer) < self.window_size:\n            self.state_buffer.appendleft(np.zeros(len(self.state_columns)))\n        \n        # Create stacked state with temporal features\n        window = np.stack(self.state_buffer)\n        recent = window.flatten()\n        stats = np.concatenate([\n            window.mean(axis=0),  # Mean\n            window.std(axis=0),   # Std dev\n            window[-1] - window[0]  # Trend\n        ])\n        \n        # Get user/role context\n        user_df = self.user_data[self.current_user]\n        if self.current_idx < len(user_df):\n            user_rate = user_df.iloc[self.current_idx]['user_anomaly_rate']\n            role_rate = user_df.iloc[self.current_idx]['role_anomaly_rate']\n        else:\n            user_rate, role_rate = 0.0, 0.0\n        \n        # Combine all features\n        state = np.concatenate([\n            self.scaler.transform([recent])[0],\n            stats,\n            [user_rate, role_rate]\n        ])\n        \n        return state.astype(np.float32)\n    \n    def reset(self):\n        self.current_user = np.random.choice(self.users)\n        user_df = self.user_data[self.current_user]\n        self.current_idx = 0\n        self.state_buffer.clear()\n        \n        # Initialize with first window_size states\n        for i in range(min(self.window_size, len(user_df))):\n            self.state_buffer.append(user_df.iloc[i][self.state_columns].values)\n        \n        return self._get_state()\n    \n    def step(self, action):\n        user_df = self.user_data[self.current_user]\n        if self.current_idx >= len(user_df):\n            return self._get_state(), 0.0, True, {}\n        \n        row = user_df.iloc[self.current_idx]\n        true_label = row['is_anomaly']\n        \n        # Threshold options (low, medium, high)\n        threshold = [0.4, 0.6, 0.8][action]\n        \n        # Simulate anomaly prediction\n        prob = np.mean(row[self.state_columns])  # Replace with actual model\n        prediction = 1 if prob > threshold else 0\n        \n        # Enhanced reward calculation\n        if prediction == true_label:\n            if true_label == 1:  # True positive\n                reward = 20.0 * (1 + threshold) * self.anomaly_weight\n            else:  # True negative\n                reward = 1.0\n        else:\n            if true_label == 1:  # False negative\n                reward = -30.0 * (2 - threshold) * self.anomaly_weight\n            else:  # False positive\n                reward = -10.0\n        \n        # Update position\n        self.current_idx += 1\n        if self.current_idx < len(user_df):\n            self.state_buffer.append(user_df.iloc[self.current_idx][self.state_columns].values)\n        \n        done = self.current_idx >= len(user_df)\n        info = {\n            'true_label': true_label,\n            'prediction': prediction,\n            'threshold': threshold\n        }\n        \n        return self._get_state(), reward, done, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:43:44.386939Z","iopub.execute_input":"2025-05-04T17:43:44.387646Z","iopub.status.idle":"2025-05-04T17:43:44.40399Z","shell.execute_reply.started":"2025-05-04T17:43:44.387622Z","shell.execute_reply":"2025-05-04T17:43:44.403252Z"}},"outputs":[],"execution_count":235},{"cell_type":"code","source":"class AdaptiveDQNAgent:\n    def __init__(self, state_dim, action_dim=3, epsilon=1.0, epsilon_min=0.1, \n                 epsilon_decay=0.98, gamma=0.95):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.gamma = gamma\n        self.memory = deque(maxlen=10000)\n        self.model = self._build_model()\n        self.target_model = self._build_model()\n        self.update_target_model()\n    \n    def _build_model(self):\n        model = tf.keras.Sequential([\n            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_dim,)),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(self.action_dim, activation='linear')\n        ])\n        model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')\n        return model\n    \n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n    \n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n    \n    def act(self, state):\n        if np.random.rand() < self.epsilon:\n            return np.random.randint(self.action_dim)\n        q_values = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n        return np.argmax(q_values)\n    \n    def replay(self, batch_size=32):\n        if len(self.memory) < batch_size:\n            return\n        \n        minibatch = np.random.choice(len(self.memory), batch_size, replace=False)\n        states, actions, rewards, next_states, dones = zip(*[self.memory[i] for i in minibatch])\n        \n        states = np.array(states)\n        next_states = np.array(next_states)\n        \n        targets = self.model.predict(states, verbose=0)\n        target_next = self.target_model.predict(next_states, verbose=0)\n        \n        for i in range(batch_size):\n            if dones[i]:\n                targets[i][actions[i]] = rewards[i]\n            else:\n                targets[i][actions[i]] = rewards[i] + self.gamma * np.max(target_next[i])\n        \n        self.model.fit(states, targets, batch_size=batch_size, verbose=0)\n        \n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:43:54.641175Z","iopub.execute_input":"2025-05-04T17:43:54.641413Z","iopub.status.idle":"2025-05-04T17:43:54.651911Z","shell.execute_reply.started":"2025-05-04T17:43:54.641395Z","shell.execute_reply":"2025-05-04T17:43:54.651278Z"}},"outputs":[],"execution_count":236},{"cell_type":"code","source":"def train_agent(df, epochs=20, batch_size=64):\n    env = InsiderThreatEnv(df)\n    state_dim = (len(env.state_columns) * env.window_size) + (len(env.state_columns) * 3) + 2\n    agent = AdaptiveDQNAgent(state_dim)\n    \n    metrics = {\n        'epoch': [],\n        'total_reward': [],\n        'true_positives': [],\n        'false_negatives': [],\n        'precision': [],\n        'recall': [],\n        'f1': []\n    }\n    \n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        stats = defaultdict(int)\n        \n        while not done:\n            action = agent.act(state)\n            next_state, reward, done, info = env.step(action)\n            \n            agent.remember(state, action, reward, next_state, done)\n            agent.replay(batch_size)\n            \n            # Track predictions\n            if 'true_label' in info:\n                stats['total'] += 1\n                if info['true_label'] == 1:\n                    stats['actual_anomalies'] += 1\n                    if info['prediction'] == 1:\n                        stats['tp'] += 1\n                    else:\n                        stats['fn'] += 1\n                elif info['prediction'] == 1:\n                    stats['fp'] += 1\n            \n            state = next_state\n            total_reward += reward\n        \n        # Calculate metrics\n        precision = stats['tp'] / (stats['tp'] + stats['fp'] + 1e-10)\n        recall = stats['tp'] / (stats['tp'] + stats['fn'] + 1e-10)\n        f1 = 2 * precision * recall / (precision + recall + 1e-10)\n        \n        # Update metrics\n        metrics['epoch'].append(epoch+1)\n        metrics['total_reward'].append(total_reward)\n        metrics['true_positives'].append(stats['tp'])\n        metrics['false_negatives'].append(stats['fn'])\n        metrics['precision'].append(precision)\n        metrics['recall'].append(recall)\n        metrics['f1'].append(f1)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"  Reward: {total_reward:.1f} | ε: {agent.epsilon:.3f}\")\n        print(f\"  TP: {stats['tp']} | FN: {stats['fn']} | FP: {stats.get('fp',0)}\")\n        print(f\"  Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f}\")\n        \n        # Update target network every 5 epochs\n        if epoch % 5 == 0:\n            agent.update_target_model()\n    \n    return agent, pd.DataFrame(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:44:11.861111Z","iopub.execute_input":"2025-05-04T17:44:11.861704Z","iopub.status.idle":"2025-05-04T17:44:11.871157Z","shell.execute_reply.started":"2025-05-04T17:44:11.861682Z","shell.execute_reply":"2025-05-04T17:44:11.870468Z"}},"outputs":[],"execution_count":237},{"cell_type":"code","source":"trained_agent, metrics = train_agent(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:44:22.425644Z","iopub.execute_input":"2025-05-04T17:44:22.426219Z","iopub.status.idle":"2025-05-04T17:45:00.108414Z","shell.execute_reply.started":"2025-05-04T17:44:22.426196Z","shell.execute_reply":"2025-05-04T17:45:00.107313Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2522495878.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/3413841295.py\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(df, epochs, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInsiderThreatEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mstate_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_columns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaptiveDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2974654084.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, window_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2974654084.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mdate_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdate_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_only'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_only'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdate_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0;31m# Impute zeros for missing days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3994\u001b[0m         \u001b[0;31m# irow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3995\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3996\u001b[0;31m             \u001b[0mnew_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3998\u001b[0m             \u001b[0;31m# if we are a copy, mark as such\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterleaved_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36minterleaved_dtype\u001b[0;34m(dtypes)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1482\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp_find_common_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mnp_find_common_type\u001b[0;34m(*dtypes)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \"\"\"\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m         \u001b[0mcommon_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcommon_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"mMSU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m             \u001b[0;31m# NumPy promotion currently (1.25) misbehaves for for times and strings,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":238},{"cell_type":"markdown","source":"isolation forest + rl","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nfrom typing import Dict, Tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:47:04.007453Z","iopub.execute_input":"2025-05-05T14:47:04.007778Z","iopub.status.idle":"2025-05-05T14:47:04.344705Z","shell.execute_reply.started":"2025-05-05T14:47:04.007757Z","shell.execute_reply":"2025-05-05T14:47:04.344136Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:04:22.118936Z","iopub.execute_input":"2025-05-04T18:04:22.119248Z","iopub.status.idle":"2025-05-04T18:04:22.139206Z","shell.execute_reply.started":"2025-05-04T18:04:22.119224Z","shell.execute_reply":"2025-05-04T18:04:22.138488Z"}},"outputs":[{"execution_count":240,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  role  is_anomaly  user_anomaly_rate  \\\n0      -0.583959          0.386906     8           0              0.001   \n1      -0.583959          0.374986     8           0              0.000   \n2      -0.583959          1.463670     8           0              0.000   \n3      -0.583959          0.323333     8           0              0.000   \n4      -0.583959          0.001496     8           0              0.000   \n...          ...               ...   ...         ...                ...   \n330280 -0.583959         -1.317639     2           0              0.000   \n330281 -0.583959         -1.285853     2           0              0.000   \n330282 -0.583959         -1.289826     2           0              0.000   \n330283 -0.583959         -1.361345     2           0              0.000   \n330284 -0.583959         -1.214333     2           0              0.000   \n\n        role_anomaly_rate  \n0                   0.005  \n1                   0.000  \n2                   0.000  \n3                   0.000  \n4                   0.000  \n...                   ...  \n330280              0.000  \n330281              0.000  \n330282              0.000  \n330283              0.000  \n330284              0.000  \n\n[330285 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n      <th>role</th>\n      <th>is_anomaly</th>\n      <th>user_anomaly_rate</th>\n      <th>role_anomaly_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.001</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 17 columns</p>\n</div>"},"metadata":{}}],"execution_count":240},{"cell_type":"code","source":"class DataHandler:\n    def __init__(self):\n        self.feature_cols = [\n            'after_hours_logon_count', 'total_logon_count', 'device_connects',\n            'avg_content_word_count', 'text_files_accessed', 'files_accessed',\n            'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag',\n            'keyword_richness'\n        ]\n        self.context_cols = ['user_anomaly_rate', 'role_anomaly_rate', 'role']\n        \n    def preprocess(self, df: pd.DataFrame) -> Tuple[dict, dict]:\n        \"\"\"Returns: \n        - user_sequences: {user_id: (features, labels, contexts)}\n        - global_stats: (mean_anomaly_rate, role_weights)\n        \"\"\"\n        user_sequences = {}\n        \n        # Calculate global anomaly stats\n        global_anomaly_rate = df['is_anomaly'].mean()\n        role_weights = df.groupby('role')['is_anomaly'].mean().to_dict()\n        \n        for user, group in df.groupby('user'):\n            features = group[self.feature_cols].values\n            labels = group['is_anomaly'].values\n            contexts = group[self.context_cols].values\n            user_sequences[user] = (features, labels, contexts)\n            \n        return user_sequences, (global_anomaly_rate, role_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:14:56.252818Z","iopub.execute_input":"2025-05-04T18:14:56.253177Z","iopub.status.idle":"2025-05-04T18:14:56.259073Z","shell.execute_reply.started":"2025-05-04T18:14:56.253152Z","shell.execute_reply":"2025-05-04T18:14:56.258455Z"}},"outputs":[],"execution_count":258},{"cell_type":"code","source":"class IForestRLEnv:\n    def __init__(self, user_sequences: dict, global_stats: tuple, window_size: int = 5):\n        self.user_sequences = user_sequences\n        self.users = list(user_sequences.keys())\n        self.window_size = window_size\n        \n        # Isolation Forest model\n        self.iforest = IsolationForest(n_estimators=150, contamination='auto')\n        \n        # Class imbalance handling\n        self.global_anomaly_rate, self.role_weights = global_stats\n        self.anomaly_weight = 1 / (self.global_anomaly_rate + 1e-6)\n        \n        # State tracking\n        self.current_user = None\n        self.current_idx = 0\n        self.score_buffer = deque(maxlen=window_size)\n    \n    def reset(self) -> np.ndarray:\n        self.current_user = np.random.choice(self.users)\n        features, _, contexts = self.user_sequences[self.current_user]\n        self.current_idx = 0\n        \n        # Initialize buffer with IF scores\n        self.score_buffer.clear()\n        for i in range(min(self.window_size, len(features))):\n            score = self.iforest.decision_function([features[i]])[0]\n            self.score_buffer.append(score)\n            \n        return self._get_state(contexts[0])\n    \n    def _get_state(self, context: np.ndarray) -> np.ndarray:\n        \"\"\"State includes:\n        - Recent anomaly scores (window_size)\n        - User anomaly rate\n        - Role anomaly rate\n        - Role (one-hot encoded)\n        - Temporal stats of scores\n        \"\"\"\n        # Pad if needed\n        while len(self.score_buffer) < self.window_size:\n            self.score_buffer.appendleft(0.0)\n            \n        # One-hot encode role (assuming 12 roles based on your data)\n        role = int(context[2])  # role is at index 2\n        role_onehot = np.zeros(12)\n        role_onehot[role-1] = 1  # Assuming roles are 1-12\n        \n        state = np.concatenate([\n            np.array(self.score_buffer),               # Recent scores\n            [context[0]],                              # user_anomaly_rate\n            [context[1]],                              # role_anomaly_rate\n            role_onehot,                               # role encoding\n            [np.mean(self.score_buffer)],              # mean score\n            [np.std(self.score_buffer)],               # std score\n            [self.score_buffer[-1] - self.score_buffer[0]]  # trend\n        ])\n        \n        return state.astype(np.float32)\n    \n    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n        \"\"\"Action space:\n        0: Decrease threshold (more sensitive)\n        1: Maintain threshold\n        2: Increase threshold (more strict)\n        \"\"\"\n        features, labels, contexts = self.user_sequences[self.current_user]\n        if self.current_idx >= len(features):\n            return self._get_state(contexts[-1]), 0.0, True, {}\n        \n        # Get current observation\n        x = features[self.current_idx]\n        true_label = labels[self.current_idx]\n        context = contexts[self.current_idx]\n        role = int(context[2])\n        \n        # Adjust threshold based on action and role weight\n        threshold_adjustments = {0: -0.3, 1: 0.0, 2: 0.3}\n        role_weight = self.role_weights.get(role, 1.0)\n        adjusted_threshold = self.iforest.offset_ + (threshold_adjustments[action] * role_weight)\n        \n        # Make prediction\n        score = self.iforest.decision_function([x])[0]\n        pred_label = int(score < adjusted_threshold)\n        \n        # Reward calculation with class balancing\n        if pred_label == true_label:\n            reward = 15.0 if pred_label == 1 else 1.0\n            reward *= self.anomaly_weight if pred_label == 1 else 1.0\n        else:\n            reward = -25.0 if true_label == 1 else -3.0\n            reward *= self.anomaly_weight if true_label == 1 else 1.0\n        \n        # Update position\n        self.current_idx += 1\n        if self.current_idx < len(features):\n            new_score = self.iforest.decision_function([features[self.current_idx]])[0]\n            self.score_buffer.append(new_score)\n        \n        done = self.current_idx >= len(features)\n        info = {\n            'user': self.current_user,\n            'true': true_label,\n            'predicted': pred_label,\n            'threshold': adjusted_threshold,\n            'score': score\n        }\n        \n        return self._get_state(context), reward, done, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:01.066143Z","iopub.execute_input":"2025-05-04T18:16:01.066393Z","iopub.status.idle":"2025-05-04T18:16:01.079658Z","shell.execute_reply.started":"2025-05-04T18:16:01.066377Z","shell.execute_reply":"2025-05-04T18:16:01.07888Z"}},"outputs":[],"execution_count":259},{"cell_type":"code","source":"class DQNAgent:\n    def __init__(self, state_dim: int):\n        self.state_dim = state_dim\n        self.action_dim = 3  # Decrease, Maintain, Increase threshold\n        self.memory = deque(maxlen=100000)\n        \n        # Hyperparameters\n        self.gamma = 0.95\n        self.epsilon = 1.0\n        self.epsilon_min = 0.1\n        self.epsilon_decay = 0.998\n        self.batch_size = 64\n        \n        # Model with dueling architecture\n        self.model = self._build_dueling_dqn()\n        self.target_model = self._build_dueling_dqn()\n        self.update_target_model()\n    \n    def _build_dueling_dqn(self) -> tf.keras.Model:\n        inputs = tf.keras.Input(shape=(self.state_dim,))\n        \n        # Shared feature layer\n        x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n        x = tf.keras.layers.LayerNormalization()(x)\n        x = tf.keras.layers.Dropout(0.3)(x)\n        \n        # Value stream\n        value = tf.keras.layers.Dense(64, activation='relu')(x)\n        value = tf.keras.layers.Dense(1)(value)\n        \n        # Advantage stream\n        advantage = tf.keras.layers.Dense(64, activation='relu')(x)\n        advantage = tf.keras.layers.Dense(self.action_dim)(advantage)\n        \n        # Combine streams\n        q_values = value + (advantage - tf.reduce_mean(advantage, axis=1, keepdims=True))\n        \n        return tf.keras.Model(inputs=inputs, outputs=q_values)\n    \n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n    \n    def remember(self, state, action, reward, next_state, done):\n        # Prioritize anomaly-related experiences\n        if abs(reward) > 20 or (reward < 0 and abs(reward) > 10):\n            self.memory.appendleft((state, action, reward, next_state, done))\n        else:\n            self.memory.append((state, action, reward, next_state, done))\n    \n    def act(self, state: np.ndarray) -> int:\n        if np.random.rand() <= self.epsilon:\n            return np.random.randint(self.action_dim)\n        q_values = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n        return np.argmax(q_values)\n    \n    def replay(self):\n        if len(self.memory) < self.batch_size:\n            return\n        \n        # Create balanced batch\n        batch = []\n        anomaly_indices = [i for i, x in enumerate(self.memory) if x[2] > 15 or x[2] < -15]\n        \n        if len(anomaly_indices) > self.batch_size//3:\n            batch += np.random.choice(anomaly_indices, self.batch_size//3, replace=False).tolist()\n            remaining = np.random.choice(len(self.memory), self.batch_size - len(batch), replace=False)\n            batch += remaining.tolist()\n        else:\n            batch = np.random.choice(len(self.memory), self.batch_size, replace=False).tolist()\n        \n        states, actions, rewards, next_states, dones = zip(*[self.memory[i] for i in batch])\n        \n        # Convert to tensors\n        states = tf.convert_to_tensor(states, dtype=tf.float32)\n        next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n        \n        # Compute target Q-values\n        target_q = rewards + (1 - np.array(dones)) * self.gamma * \\\n                  np.amax(self.target_model.predict(next_states, verbose=0), axis=1)\n        \n        # Train model\n        with tf.GradientTape() as tape:\n            q_values = tf.reduce_sum(\n                self.model(states) * tf.one_hot(actions, self.action_dim),\n                axis=1\n            )\n            loss = tf.keras.losses.Huber()(target_q, q_values)\n        \n        grads = tape.gradient(loss, self.model.trainable_variables)\n        tf.keras.optimizers.Adam(0.001).apply_gradients(zip(grads, self.model.trainable_variables))\n        \n        # Decay epsilon\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:17.14666Z","iopub.execute_input":"2025-05-04T18:16:17.146944Z","iopub.status.idle":"2025-05-04T18:16:17.161827Z","shell.execute_reply.started":"2025-05-04T18:16:17.146923Z","shell.execute_reply":"2025-05-04T18:16:17.161115Z"}},"outputs":[],"execution_count":260},{"cell_type":"code","source":"def train_iforest_rl(df: pd.DataFrame, epochs: int = 30):\n    # 1. Prepare data\n    handler = DataHandler()\n    user_sequences, global_stats = handler.preprocess(df)\n    \n    # 2. Initialize environment\n    env = IForestRLEnv(user_sequences, global_stats)\n    \n    # 3. Train Isolation Forest on normal users\n    normal_users = [u for u in user_sequences if user_sequences[u][1].mean() < 0.05]\n    normal_data = np.concatenate([user_sequences[u][0] for u in normal_users])\n    env.iforest.fit(normal_data)\n    \n    # 4. Initialize agent\n    agent = DQNAgent(state_dim=env._get_state(user_sequences[env.users[0]][2][0]).shape[0])\n    \n    # 5. Training loop\n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        metrics = {'tp':0, 'fp':0, 'tn':0, 'fn':0}\n        \n        while not done:\n            action = agent.act(state)\n            next_state, reward, done, info = env.step(action)\n            \n            agent.remember(state, action, reward, next_state, done)\n            agent.replay()\n            \n            # Track performance\n            if 'true' in info:\n                true, pred = info['true'], info['predicted']\n                if true == 1 and pred == 1: metrics['tp'] += 1\n                elif true == 0 and pred == 1: metrics['fp'] += 1\n                elif true == 1 and pred == 0: metrics['fn'] += 1\n                else: metrics['tn'] += 1\n            \n            state = next_state\n            total_reward += reward\n        \n        # Calculate metrics\n        precision = metrics['tp'] / (metrics['tp'] + metrics['fp'] + 1e-10)\n        recall = metrics['tp'] / (metrics['tp'] + metrics['fn'] + 1e-10)\n        f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"  Reward: {total_reward:.1f} | ε: {agent.epsilon:.3f}\")\n        print(f\"  Anomalies: {metrics['tp'] + metrics['fn']} -> Detected: {metrics['tp']}\")\n        print(f\"  Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f}\")\n        \n        if (epoch + 1) % 10 == 0:\n            agent.update_target_model()\n    \n    return agent, env.iforest\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:32.643598Z","iopub.execute_input":"2025-05-04T18:16:32.644346Z","iopub.status.idle":"2025-05-04T18:16:32.653945Z","shell.execute_reply.started":"2025-05-04T18:16:32.644313Z","shell.execute_reply":"2025-05-04T18:16:32.653265Z"}},"outputs":[],"execution_count":261},{"cell_type":"code","source":"agent, iforest = train_iforest_rl(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:41.950833Z","iopub.execute_input":"2025-05-04T18:16:41.951124Z","iopub.status.idle":"2025-05-04T18:16:43.637639Z","shell.execute_reply.started":"2025-05-04T18:16:41.951102Z","shell.execute_reply":"2025-05-04T18:16:43.636621Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/521937240.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miforest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iforest_rl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/2278423425.py\u001b[0m in \u001b[0;36mtrain_iforest_rl\u001b[0;34m(df, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 4. Initialize agent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 5. Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2856762591.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, state_dim)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Model with dueling architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_dueling_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_dueling_dqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2856762591.py\u001b[0m in \u001b[0;36m_build_dueling_dqn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Combine streams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0madvantage\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"],"ename":"ValueError","evalue":"A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n","output_type":"error"}],"execution_count":262},{"cell_type":"markdown","source":"rl alone","metadata":{}},{"cell_type":"code","source":"class DataHandler:\n    def __init__(self, min_sequence_length: int = 3):\n        self.scaler = StandardScaler()\n        self.min_sequence_length = min_sequence_length\n        \n    def preprocess(self, ais: pd.DataFrame, mu_all: np.ndarray, user_col: str = 'user', \n                   feature_cols: list = None, date_col: str = 'date_only') -> Tuple[dict, dict]:\n        \"\"\"Returns: \n        - user_sequences: {user_id: (features, labels)}\n        - user_stats: {user_id: (mean_anomaly_rate, role)}\n        \"\"\"\n        # Validate inputs\n        if len(ais) != mu_all.shape[0]:\n            raise ValueError(f\"mu_all must have {len(ais)} rows, got {mu_all.shape[0]}\")\n        if mu_all.shape[1] != 8:\n            raise ValueError(f\"mu_all must have 8 columns, got {mu_all.shape[1]}\")\n        \n        # Create a copy of ais to avoid modifying the original\n        df = ais.copy()\n        \n        # Add latent vector columns from mu_all\n        latent_cols = [f'latent_{i}' for i in range(mu_all.shape[1])]\n        df[latent_cols] = mu_all\n        \n        # Combine feature columns\n        all_feature_cols = feature_cols + latent_cols\n        \n        # Handle missing values in feature columns\n        df[all_feature_cols] = df[all_feature_cols].fillna(0)\n        \n        # Normalize features\n        df[all_feature_cols] = self.scaler.fit_transform(df[all_feature_cols])\n        \n        # Ensure is_anomaly column exists\n        if 'is_anomaly' not in df.columns:\n            raise ValueError(\"Dataframe must contain 'is_anomaly' column\")\n        \n        # Group by user with temporal ordering\n        user_sequences = {}\n        user_stats = {}\n        \n        for user, group in df.groupby(user_col):\n            # Sort by date to maintain temporal order\n            group = group.sort_values(date_col)\n            if len(group) < self.min_sequence_length:\n                continue  # Skip users with too few observations\n            features = group[all_feature_cols].values\n            labels = group['is_anomaly'].values\n            user_sequences[user] = (features, labels)\n            \n            # Calculate user-level stats\n            anomaly_rate = labels.mean()\n            role = group['role'].mode()[0]\n            user_stats[user] = (anomaly_rate, role)\n            \n        if not user_sequences:\n            raise ValueError(\"No users have sufficient sequence length\")\n            \n        return user_sequences, user_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:58:17.926907Z","iopub.execute_input":"2025-05-04T18:58:17.927663Z","iopub.status.idle":"2025-05-04T18:58:17.936485Z","shell.execute_reply.started":"2025-05-04T18:58:17.927639Z","shell.execute_reply":"2025-05-04T18:58:17.935712Z"}},"outputs":[],"execution_count":274},{"cell_type":"code","source":"class AnomalyRLEnv:\n    def __init__(self, user_sequences: dict, user_stats: dict, window_size: int = 3):\n        self.user_sequences = user_sequences\n        self.user_stats = user_stats\n        self.users = list(user_sequences.keys())\n        if not self.users:\n            raise ValueError(\"No valid users in user_sequences\")\n        self.window_size = window_size\n        \n        # Class imbalance handling\n        self.anomaly_weight = self._calculate_anomaly_weight()\n        \n        # State tracking\n        self.current_user = None\n        self.current_idx = 0\n        self.feature_dim = len(next(iter(user_sequences.values()))[0][0])  # 19 (11 + 8)\n        self.state_buffer = deque(maxlen=window_size)\n        \n        # Initialize state\n        self.reset()\n    \n    def _calculate_anomaly_weight(self) -> float:\n        \"\"\"Calculate weight for anomaly class\"\"\"\n        total_anomalies = sum(labels.sum() for _, labels in self.user_sequences.values())\n        total_normal = sum(len(labels) - labels.sum() for _, labels in self.user_sequences.values())\n        return total_normal / (total_anomalies + 1e-6)\n    \n    def reset(self) -> np.ndarray:\n        \"\"\"Returns initial state\"\"\"\n        self.current_user = np.random.choice(self.users)\n        features, _ = self.user_sequences[self.current_user]\n        if len(features) == 0:\n            raise ValueError(f\"Empty feature sequence for user {self.current_user}\")\n        self.current_idx = 0\n        self.state_buffer.clear()\n        \n        # Initialize buffer with zeros or available features\n        for i in range(min(self.window_size, len(features))):\n            self.state_buffer.append(features[i])\n        while len(self.state_buffer) < self.window_size:\n            self.state_buffer.appendleft(np.zeros(self.feature_dim))\n            \n        return self._get_state()\n    \n    def _get_state(self) -> np.ndarray:\n        \"\"\"Create state vector:\n        - Window of recent feature vectors (including latent components)\n        - User anomaly rate\n        - Role\n        \"\"\"\n        user_rate, role = self.user_stats[self.current_user]\n        features, _ = self.user_sequences[self.current_user]\n        \n        # Flatten the window of features\n        window_features = np.array(self.state_buffer).flatten()\n        \n        state = np.concatenate([\n            window_features,\n            [user_rate],\n            [role]\n        ])\n        \n        return state.astype(np.float32)\n    \n    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n        \"\"\"Action: 0 (normal), 1 (anomaly)\"\"\"\n        features, labels = self.user_sequences[self.current_user]\n        \n        # Check if sequence is exhausted\n        if self.current_idx >= len(features):\n            return self._get_state(), 0.0, True, {}\n        \n        # Get current observation\n        true_label = labels[self.current_idx]\n        \n        # Calculate reward\n        if action == true_label:\n            reward = 10.0 if action == 1 else 1.0\n            reward *= self.anomaly_weight if action == 1 else 1.0\n        else:\n            reward = -20.0 if true_label == 1 else -5.0\n            reward *= self.anomaly_weight if true_label == 1 else 1.0\n        \n        # Update position and buffer\n        self.current_idx += 1\n        if self.current_idx < len(features):\n            self.state_buffer.append(features[self.current_idx])\n        else:\n            self.state_buffer.append(np.zeros(self.feature_dim))\n        \n        done = self.current_idx >= len(features)\n        info = {\n            'user': self.current_user,\n            'true': true_label,\n            'predicted': action\n        }\n        \n        return self._get_state(), reward, done, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:58:46.887208Z","iopub.execute_input":"2025-05-04T18:58:46.887486Z","iopub.status.idle":"2025-05-04T18:58:46.900572Z","shell.execute_reply.started":"2025-05-04T18:58:46.887464Z","shell.execute_reply":"2025-05-04T18:58:46.899881Z"}},"outputs":[],"execution_count":275},{"cell_type":"code","source":"class DQNAgent:\n    def __init__(self, state_dim: int, action_dim: int = 2):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.memory = deque(maxlen=100000)\n        \n        # Hyperparameters\n        self.gamma = 0.95\n        self.epsilon = 1.0\n        self.epsilon_min = 0.1\n        self.epsilon_decay = 0.995\n        self.batch_size = 64\n        \n        # Model\n        self.model = self._build_model()\n        self.target_model = self._build_model()\n        self.update_target_model()\n    \n    def _build_model(self) -> tf.keras.Model:\n        inputs = Input(shape=(self.state_dim,))\n        x = Dense(96, activation='relu')(inputs)\n        x = Dropout(0.2)(x)\n        x = Dense(48, activation='relu')(x)\n        outputs = Dense(self.action_dim, activation='linear')(x)\n        \n        model = Model(inputs, outputs)\n        model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='huber')\n        return model\n    \n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n    \n    def remember(self, state, action, reward, next_state, done):\n        if abs(reward) > 15:  # Prioritize anomaly-related experiences\n            self.memory.appendleft((state, action, reward, next_state, done))\n        else:\n            self.memory.append((state, action, reward, next_state, done))\n    \n    def act(self, state: np.ndarray) -> int:\n        if np.random.rand() <= self.epsilon:\n            return np.random.randint(self.action_dim)\n        act_values = self.model.predict(state[np.newaxis, :], verbose=0)\n        return np.argmax(act_values[0])\n    \n    def replay(self):\n        if len(self.memory) < self.batch_size:\n            return\n        \n        # Oversample anomaly-related experiences\n        minibatch = []\n        high_impact_indices = [i for i, x in enumerate(self.memory) if abs(x[2]) > 15]\n        \n        if len(high_impact_indices) > self.batch_size//3:\n            minibatch += np.random.choice(high_impact_indices, self.batch_size//3, replace=False).tolist()\n            remaining = np.random.choice(len(self.memory), self.batch_size - len(minibatch), replace=False)\n            minibatch += remaining.tolist()\n        else:\n            minibatch = np.random.choice(len(self.memory), self.batch_size, replace=False).tolist()\n        \n        states, actions, rewards, next_states, dones = zip(*[self.memory[i] for i in minibatch])\n        \n        states = np.array(states)\n        next_states = np.array(next_states)\n        \n        targets = self.model.predict(states, verbose=0)\n        target_next = self.target_model.predict(next_states, verbose=0)\n        \n        for i in range(len(minibatch)):\n            if dones[i]:\n                targets[i][actions[i]] = rewards[i]\n            else:\n                targets[i][actions[i]] = rewards[i] + self.gamma * np.amax(target_next[i])\n        \n        self.model.fit(states, targets, batch_size=self.batch_size, verbose=0)\n        \n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:59:07.726771Z","iopub.execute_input":"2025-05-04T18:59:07.72753Z","iopub.status.idle":"2025-05-04T18:59:07.741174Z","shell.execute_reply.started":"2025-05-04T18:59:07.727497Z","shell.execute_reply":"2025-05-04T18:59:07.740479Z"}},"outputs":[],"execution_count":276},{"cell_type":"code","source":"def train_rl_anomaly_detector(ais: pd.DataFrame, mu_all: np.ndarray, \n                             epochs: int = 50, window_size: int = 3):\n    # 1. Prepare data\n    feature_cols = [\n        'after_hours_logon_count',\n        'total_logon_count',\n        'device_connects',\n        'avg_content_word_count',\n        'text_files_accessed',\n        'files_accessed',\n        'total_recipients',\n        'external_ratio',\n        'emails_sent',\n        'bcc_flag',\n        'keyword_richness'\n    ]\n    handler = DataHandler(min_sequence_length=window_size)\n    sequences, stats = handler.preprocess(ais, mu_all, feature_cols=feature_cols, \n                                        date_col='date_only')\n    \n    # 2. Initialize environment and agent\n    env = AnomalyRLEnv(sequences, stats, window_size=window_size)\n    agent = DQNAgent(state_dim=env._get_state().shape[0], action_dim=2)\n    \n    # 3. RL Training\n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        metrics = {'tp':0, 'fp':0, 'tn':0, 'fn':0}\n        \n        while not done:\n            action = agent.act(state)\n            result = env.step(action)\n            if result is None:\n                print(f\"Warning: step returned None for user {env.current_user}, idx {env.current_idx}\")\n                break\n            next_state, reward, done, info = result\n            \n            agent.remember(state, action, reward, next_state, done)\n            agent.replay()\n            \n            # Track performance\n            if 'true' in info:\n                true, pred = info['true'], info['predicted']\n                if true == 1 and pred == 1: metrics['tp'] += 1\n                elif true == 0 and pred == 1: metrics['fp'] += 1\n                elif true == 1 and pred == 0: metrics['fn'] += 1\n                else: metrics['tn'] += 1\n            \n            state = next_state\n            total_reward += reward\n        \n        # Calculate metrics\n        precision = metrics['tp'] / (metrics['tp'] + metrics['fp'] + 1e-10)\n        recall = metrics['tp'] / (metrics['tp'] + metrics['fn'] + 1e-10)\n        f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"  Reward: {total_reward:.1f} | ε: {agent.epsilon:.3f}\")\n        print(f\"  TP: {metrics['tp']} | FP: {metrics['fp']} | FN: {metrics['fn']}\")\n        print(f\"  Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f}\")\n        \n        if epoch % 5 == 0:\n            agent.update_target_model()\n    \n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:59:21.707085Z","iopub.execute_input":"2025-05-04T18:59:21.707361Z","iopub.status.idle":"2025-05-04T18:59:21.717085Z","shell.execute_reply.started":"2025-05-04T18:59:21.707339Z","shell.execute_reply":"2025-05-04T18:59:21.716319Z"}},"outputs":[],"execution_count":277},{"cell_type":"code","source":"agent = train_rl_anomaly_detector(a, mu_all, epochs=20, window_size=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:59:42.246773Z","iopub.execute_input":"2025-05-04T18:59:42.247378Z","iopub.status.idle":"2025-05-04T19:10:08.641593Z","shell.execute_reply.started":"2025-05-04T18:59:42.247354Z","shell.execute_reply":"2025-05-04T19:10:08.640562Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n  Reward: -326.0 | ε: 0.242\n  TP: 0 | FP: 112 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 2/20\n  Reward: -28796.3 | ε: 0.100\n  TP: 0 | FP: 13 | FN: 6\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 3/20\n  Reward: 142.0 | ε: 0.100\n  TP: 0 | FP: 34 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 4/20\n  Reward: 280.0 | ε: 0.100\n  TP: 0 | FP: 11 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 5/20\n  Reward: 196.0 | ε: 0.100\n  TP: 0 | FP: 25 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 6/20\n  Reward: 196.0 | ε: 0.100\n  TP: 0 | FP: 25 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 7/20\n  Reward: 124.0 | ε: 0.100\n  TP: 0 | FP: 37 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\nEpoch 8/20\n  Reward: 250.0 | ε: 0.100\n  TP: 0 | FP: 16 | FN: 0\n  Precision: 0.00 | Recall: 0.00 | F1: 0.00\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/478131548.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_rl_anomaly_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/3817345279.py\u001b[0m in \u001b[0;36mtrain_rl_anomaly_detector\u001b[0;34m(ais, mu_all, epochs, window_size)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Track performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/805032325.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mtarget_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36menumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 for step in range(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":278},{"cell_type":"markdown","source":"ppo","metadata":{}},{"cell_type":"code","source":"a['role'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T19:44:13.926183Z","iopub.execute_input":"2025-05-04T19:44:13.926754Z","iopub.status.idle":"2025-05-04T19:44:13.934441Z","shell.execute_reply.started":"2025-05-04T19:44:13.926731Z","shell.execute_reply":"2025-05-04T19:44:13.933673Z"}},"outputs":[{"execution_count":308,"output_type":"execute_result","data":{"text/plain":"array([ 8,  4, 12,  2, 10,  6, 14,  1,  9,  5])"},"metadata":{}}],"execution_count":308},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom typing import Dict, Any","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gym\nimport numpy as np\nimport pandas as pd\nimport torch\n\n\n# ----------------------------\n# 1. Custom RL Environment\n# ----------------------------\nclass AdaptiveThresholdEnv(gym.Env):\n    def __init__(self, \n                 anomaly_scores: np.ndarray,  # Precomputed anomaly scores (user-day)\n                 role_bits: np.ndarray,       # Role-bit vectors (user-day, 4 bits)\n                 features: np.ndarray,        # 11 features (user-day)\n                 labels: np.ndarray = None,   # Ground truth (1=anomaly, 0=normal)\n                 window_size: int = 7         # Rolling window for stats\n                ):\n        super(AdaptiveThresholdEnv, self).__init__()\n        \n        self.anomaly_scores = anomaly_scores\n        self.role_bits = role_bits\n        self.features = features\n        self.labels = labels\n        self.window_size = window_size\n        \n        # Action space: [0=decrease, 1=keep, 2=increase]\n        self.action_space = gym.spaces.Discrete(3)\n        \n        # State space: [score, rolling_mean, rolling_std, role_bits (4), features (2 key)]\n        self.observation_space = gym.spaces.Box(\n            low=0, high=1, shape=(9,), dtype=np.float32\n        )\n        \n        self.current_step = 0\n        self.threshold = 0.5  # Initial threshold\n        self.n_users = anomaly_scores.shape[0]\n        \n    def _get_state(self, user_idx: int) -> np.ndarray:\n        \"\"\"Build state vector for the current user-day.\"\"\"\n        # Get rolling stats of anomaly scores\n        start_idx = max(0, self.current_step - self.window_size)\n        rolling_mean = np.mean(self.anomaly_scores[user_idx, start_idx:self.current_step])\n        rolling_std = np.std(self.anomaly_scores[user_idx, start_idx:self.current_step])\n        \n        # Normalize to [0,1]\n        rolling_mean_norm = (rolling_mean - np.min(self.anomaly_scores)) / (\n            np.max(self.anomaly_scores) - np.min(self.anomaly_scores) + 1e-8\n        )\n        rolling_std_norm = rolling_std / (np.max(self.anomaly_scores) + 1e-8)\n        \n        # Get role bits and key features (e.g., first 2 features)\n        role = self.role_bits[user_idx, self.current_step]\n        features = self.features[user_idx, self.current_step, :2]  # Example: 2 key features\n        \n        # Concatenate into state vector\n        state = np.concatenate([\n            [self.anomaly_scores[user_idx, self.current_step]],\n            [rolling_mean_norm, rolling_std_norm],\n            role,\n            features\n        ]).astype(np.float32)\n        \n        return state\n    \n    def step(self, action: int) -> tuple:\n        user_idx = self.current_step % self.n_users  # Simulate user rotation\n        \n        # Adjust threshold based on action\n        delta = 0.05 * (action - 1)  # [-0.05, 0, +0.05]\n        self.threshold = np.clip(self.threshold + delta, 0.1, 0.9)\n        \n        # Get predicted anomaly (0/1)\n        pred = 1 if self.anomaly_scores[user_idx, self.current_step] > self.threshold else 0\n        \n        # Compute reward (use pseudo-labels if no ground truth)\n        if self.labels is not None:\n            true_label = self.labels[user_idx, self.current_step]\n        else:\n            # Fallback: Use static threshold baseline as pseudo-label\n            true_label = 1 if self.anomaly_scores[user_idx, self.current_step] > 0.5 else 0\n        \n        # Reward function (tune weights as needed)\n        reward = 0\n        if pred == true_label:\n            reward += 1.0  # Correct prediction\n        else:\n            if pred == 1:  # False positive\n                reward -= 0.5\n            else:          # False negative\n                reward -= 1.5  # Higher penalty for missing threats\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= self.anomaly_scores.shape[1]  # End of episode\n        \n        return self._get_state(user_idx), reward, done, {}\n    \n    def reset(self) -> np.ndarray:\n        self.current_step = 0\n        self.threshold = 0.5  # Reset to initial threshold\n        return self._get_state(0)  # Return initial state\n\n\n# Dummy data (replace with your arrays)\nanomaly_scores = np.random.rand(n_users, n_days)  # Shape: (users, days)\nrole_bits = np.random.randint(0, 2, (n_users, n_days, 4))  # Shape: (users, days, 4)\nfeatures = np.random.rand(n_users, n_days, 11)    # Shape: (users, days, 11)\n\n# ----------------------------\n# 3. Train PPO Agent\n# ----------------------------\nenv = DummyVecEnv([lambda: AdaptiveThresholdEnv(\n    anomaly_scores, role_bits, features\n)])\n\nmodel = PPO(\n    \"MlpPolicy\", \n    env, \n    verbose=1,\n    policy_kwargs=dict(net_arch=[64, 64]),  # Neural network architecture\n    learning_rate=3e-4,\n    gamma=0.99,\n    ent_coef=0.01,\n    n_steps=1024,\n    batch_size=64,\n)\n\nmodel.learn(total_timesteps=50_000)\n\n# ----------------------------\n# 4. Evaluate Adaptive Thresholds\n# ----------------------------\n# Compare F1-score with static threshold\nfrom sklearn.metrics import f1_score\n\n# Static threshold baseline\nstatic_preds = (anomaly_scores > 0.5).astype(int)\nstatic_f1 = f1_score(labels.flatten(), static_preds.flatten())  # Replace `labels`\n\n# RL adaptive threshold\nadaptive_preds = []\nfor user_idx in range(n_users):\n    obs = env.reset()\n    for day in range(n_days):\n        action, _ = model.predict(obs)\n        obs, _, done, _ = env.step(action)\n        adaptive_preds.append(1 if anomaly_scores[user_idx, day] > env.envs[0].threshold else 0)\n\nadaptive_f1 = f1_score(labels.flatten(), adaptive_preds)  # Replace `labels`\n\nprint(f\"Static F1: {static_f1:.3f}, Adaptive F1: {adaptive_f1:.3f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#features\ninfo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:03:56.305726Z","iopub.execute_input":"2025-05-05T15:03:56.30639Z","iopub.status.idle":"2025-05-05T15:03:56.439904Z","shell.execute_reply.started":"2025-05-05T15:03:56.306364Z","shell.execute_reply":"2025-05-05T15:03:56.439203Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  weekend_logon_flag  \\\n0       AAE0190  2010-01-04                      0.0                   0   \n1       AAE0190  2010-01-05                      0.0                   0   \n2       AAE0190  2010-01-06                      0.0                   0   \n3       AAE0190  2010-01-07                      0.0                   0   \n4       AAE0190  2010-01-08                      0.0                   0   \n...         ...         ...                      ...                 ...   \n330280  ZSL0305  2011-05-10                      0.0                   0   \n330281  ZSL0305  2011-05-11                      0.0                   0   \n330282  ZSL0305  2011-05-12                      0.0                   0   \n330283  ZSL0305  2011-05-13                      0.0                   0   \n330284  ZSL0305  2011-05-16                      0.0                   0   \n\n        peer_machine_logon_flag  total_logon_count  unique_pcs  \\\n0                             0                1.0         1.0   \n1                             0                1.0         1.0   \n2                             0                1.0         1.0   \n3                             0                1.0         1.0   \n4                             0                1.0         1.0   \n...                         ...                ...         ...   \n330280                        0                1.0         1.0   \n330281                        0                1.0         1.0   \n330282                        0                1.0         1.0   \n330283                        0                1.0         1.0   \n330284                        0                1.0         1.0   \n\n        device_connects  after_hours_connects  device_pc_count  ...  \\\n0                   0.0                   0.0              0.0  ...   \n1                   0.0                   0.0              0.0  ...   \n2                   0.0                   0.0              0.0  ...   \n3                   0.0                   0.0              0.0  ...   \n4                   0.0                   0.0              0.0  ...   \n...                 ...                   ...              ...  ...   \n330280              0.0                   0.0              0.0  ...   \n330281              0.0                   0.0              0.0  ...   \n330282              0.0                   0.0              0.0  ...   \n330283              0.0                   0.0              0.0  ...   \n330284              0.0                   0.0              0.0  ...   \n\n        binary_files_accessed  text_files_accessed  file_type_entropy  \\\n0                         0.0                  0.0                0.0   \n1                         0.0                  0.0                0.0   \n2                         0.0                  0.0                0.0   \n3                         0.0                  0.0                0.0   \n4                         0.0                  0.0                0.0   \n...                       ...                  ...                ...   \n330280                    0.0                  0.0                0.0   \n330281                    0.0                  0.0                0.0   \n330282                    0.0                  0.0                0.0   \n330283                    0.0                  0.0                0.0   \n330284                    0.0                  0.0                0.0   \n\n        sensitive_keyword_count  avg_content_word_count  emails_sent  \\\n0                           0.0                     0.0         14.0   \n1                           0.0                     0.0         13.0   \n2                           0.0                     0.0         14.0   \n3                           0.0                     0.0         14.0   \n4                           0.0                     0.0         13.0   \n...                         ...                     ...          ...   \n330280                      0.0                     0.0          1.0   \n330281                      0.0                     0.0          1.0   \n330282                      0.0                     0.0          1.0   \n330283                      0.0                     0.0          1.0   \n330284                      0.0                     0.0          1.0   \n\n        total_recipients  external_ratio  keyword_richness  bcc_flag  \n0                   43.0        0.214286             470.0       0.0  \n1                   39.0        0.538462             467.0       0.0  \n2                   40.0        0.642857             741.0       0.0  \n3                   42.0        0.571429             454.0       0.0  \n4                   40.0        0.307692             373.0       0.0  \n...                  ...             ...               ...       ...  \n330280               2.0        0.000000              41.0       0.0  \n330281               4.0        2.000000              49.0       0.0  \n330282               6.0        3.000000              48.0       0.0  \n330283               2.0        1.000000              30.0       0.0  \n330284               2.0        1.000000              67.0       0.0  \n\n[330285 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>weekend_logon_flag</th>\n      <th>peer_machine_logon_flag</th>\n      <th>total_logon_count</th>\n      <th>unique_pcs</th>\n      <th>device_connects</th>\n      <th>after_hours_connects</th>\n      <th>device_pc_count</th>\n      <th>...</th>\n      <th>binary_files_accessed</th>\n      <th>text_files_accessed</th>\n      <th>file_type_entropy</th>\n      <th>sensitive_keyword_count</th>\n      <th>avg_content_word_count</th>\n      <th>emails_sent</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>keyword_richness</th>\n      <th>bcc_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>43.0</td>\n      <td>0.214286</td>\n      <td>470.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>39.0</td>\n      <td>0.538462</td>\n      <td>467.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>40.0</td>\n      <td>0.642857</td>\n      <td>741.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>42.0</td>\n      <td>0.571429</td>\n      <td>454.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>13.0</td>\n      <td>40.0</td>\n      <td>0.307692</td>\n      <td>373.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.000000</td>\n      <td>49.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>48.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>30.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>67.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 22 columns</p>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"scaler = StandardScaler()\ninfo.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:13.361877Z","iopub.execute_input":"2025-05-05T15:08:13.362189Z","iopub.status.idle":"2025-05-05T15:08:13.656607Z","shell.execute_reply.started":"2025-05-05T15:08:13.362165Z","shell.execute_reply":"2025-05-05T15:08:13.655851Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/tmp/ipykernel_30/1535646499.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.14474679 -0.14474679 -0.14474679 ... -0.14474679 -0.14474679\n -0.14474679]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  info.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])\n/tmp/ipykernel_30/1535646499.py:2: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.29726833 -0.29726833 -0.29726833 ... -0.29726833 -0.29726833\n -0.29726833]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n  info.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"feature_cols = ['after_hours_logon_count', 'total_logon_count','device_connects','avg_content_word_count', 'text_files_accessed', 'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag','keyword_richness' ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:17.519534Z","iopub.execute_input":"2025-05-05T15:08:17.520011Z","iopub.status.idle":"2025-05-05T15:08:17.523525Z","shell.execute_reply.started":"2025-05-05T15:08:17.519991Z","shell.execute_reply":"2025-05-05T15:08:17.522807Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"a = info[ ['user','date_only'] + feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:19.019324Z","iopub.execute_input":"2025-05-05T15:08:19.019792Z","iopub.status.idle":"2025-05-05T15:08:19.038868Z","shell.execute_reply.started":"2025-05-05T15:08:19.019769Z","shell.execute_reply":"2025-05-05T15:08:19.038003Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:20.839443Z","iopub.execute_input":"2025-05-05T15:08:20.839717Z","iopub.status.idle":"2025-05-05T15:08:20.85334Z","shell.execute_reply.started":"2025-05-05T15:08:20.839696Z","shell.execute_reply":"2025-05-05T15:08:20.852752Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n330280 -0.583959         -1.317639  \n330281 -0.583959         -1.285853  \n330282 -0.583959         -1.289826  \n330283 -0.583959         -1.361345  \n330284 -0.583959         -1.214333  \n\n[330285 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"a.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:32.479733Z","iopub.execute_input":"2025-05-05T15:08:32.480406Z","iopub.status.idle":"2025-05-05T15:08:32.485019Z","shell.execute_reply.started":"2025-05-05T15:08:32.480376Z","shell.execute_reply":"2025-05-05T15:08:32.484524Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness'],\n      dtype='object')"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"a.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:35.599544Z","iopub.execute_input":"2025-05-05T15:08:35.600075Z","iopub.status.idle":"2025-05-05T15:08:35.604326Z","shell.execute_reply.started":"2025-05-05T15:08:35.600047Z","shell.execute_reply":"2025-05-05T15:08:35.603723Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(330285, 13)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"roles","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:09:10.859616Z","iopub.execute_input":"2025-05-05T15:09:10.86014Z","iopub.status.idle":"2025-05-05T15:09:10.868413Z","shell.execute_reply.started":"2025-05-05T15:09:10.860117Z","shell.execute_reply":"2025-05-05T15:09:10.867822Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"        user  role_0  role_1  role_2  role_3\n0    AAE0190       0       0       0       1\n1    AAF0535       0       0       1       0\n2    AAF0791       0       0       1       1\n3    AAL0706       0       1       0       0\n4    AAM0658       0       0       1       0\n..       ...     ...     ...     ...     ...\n995  ZKS0899       0       0       1       0\n996  ZMC0284       0       1       1       0\n997  ZSB0649       0       0       1       0\n998  ZSK0258       0       1       1       0\n999  ZSL0305       0       1       0       0\n\n[1000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>role_0</th>\n      <th>role_1</th>\n      <th>role_2</th>\n      <th>role_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAF0535</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAF0791</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAL0706</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAM0658</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>ZKS0899</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>ZMC0284</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>ZSB0649</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>ZSK0258</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>ZSL0305</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"mu_all = np.load('/kaggle/working/mu_all.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:11:43.520201Z","iopub.execute_input":"2025-05-05T15:11:43.520486Z","iopub.status.idle":"2025-05-05T15:11:43.607203Z","shell.execute_reply.started":"2025-05-05T15:11:43.520466Z","shell.execute_reply":"2025-05-05T15:11:43.606304Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"mu_all","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:11:46.659541Z","iopub.execute_input":"2025-05-05T15:11:46.659795Z","iopub.status.idle":"2025-05-05T15:11:46.664995Z","shell.execute_reply.started":"2025-05-05T15:11:46.659775Z","shell.execute_reply":"2025-05-05T15:11:46.664484Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"array([[ 0.16200998,  0.21235588,  0.3329291 , ..., -0.27206764,\n        -1.299133  ,  0.1619663 ],\n       [-0.58693236, -1.6931403 ,  0.743226  , ..., -0.7913436 ,\n        -2.3588831 , -1.1802794 ],\n       [ 0.00956355,  0.17650022,  0.36193565, ..., -0.9547089 ,\n        -1.40904   , -1.016945  ],\n       ...,\n       [ 0.524928  ,  2.767483  ,  0.34948137, ...,  1.6622734 ,\n         0.8997204 , -0.5208495 ],\n       [ 0.7939594 ,  2.3120005 ,  1.0622065 , ...,  0.7760046 ,\n        -0.12847267, -1.0735514 ],\n       [ 1.6584828 ,  1.9417888 ,  0.5367259 , ...,  0.1911959 ,\n        -0.29569718,  0.31119585]], dtype=float32)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:11:50.744626Z","iopub.execute_input":"2025-05-05T15:11:50.744892Z","iopub.status.idle":"2025-05-05T15:11:50.749733Z","shell.execute_reply.started":"2025-05-05T15:11:50.744872Z","shell.execute_reply":"2025-05-05T15:11:50.749065Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(330285, 8)"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"df_features = a\nroles_df = roles","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:37:21.449556Z","iopub.execute_input":"2025-05-06T07:37:21.450334Z","iopub.status.idle":"2025-05-06T07:37:21.453519Z","shell.execute_reply.started":"2025-05-06T07:37:21.450301Z","shell.execute_reply":"2025-05-06T07:37:21.452787Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"roles_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:37:45.232473Z","iopub.execute_input":"2025-05-06T07:37:45.232708Z","iopub.status.idle":"2025-05-06T07:37:45.242134Z","shell.execute_reply.started":"2025-05-06T07:37:45.232693Z","shell.execute_reply":"2025-05-06T07:37:45.241371Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"        user  role_0  role_1  role_2  role_3  role\n0    AAE0190       0       0       0       1     8\n1    AAF0535       0       0       1       0     4\n2    AAF0791       0       0       1       1    12\n3    AAL0706       0       1       0       0     2\n4    AAM0658       0       0       1       0     4\n..       ...     ...     ...     ...     ...   ...\n995  ZKS0899       0       0       1       0     4\n996  ZMC0284       0       1       1       0     6\n997  ZSB0649       0       0       1       0     4\n998  ZSK0258       0       1       1       0     6\n999  ZSL0305       0       1       0       0     2\n\n[1000 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>role_0</th>\n      <th>role_1</th>\n      <th>role_2</th>\n      <th>role_3</th>\n      <th>role</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAF0535</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAF0791</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAL0706</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAM0658</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>ZKS0899</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>ZMC0284</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>ZSB0649</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>ZSK0258</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>ZSL0305</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"df = df_features.merge(roles_df, on=\"user\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:19.599757Z","iopub.execute_input":"2025-05-05T15:22:19.600315Z","iopub.status.idle":"2025-05-05T15:22:19.692241Z","shell.execute_reply.started":"2025-05-05T15:22:19.600293Z","shell.execute_reply":"2025-05-05T15:22:19.691443Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:26.182676Z","iopub.execute_input":"2025-05-05T15:22:26.183177Z","iopub.status.idle":"2025-05-05T15:22:26.198439Z","shell.execute_reply.started":"2025-05-05T15:22:26.183153Z","shell.execute_reply":"2025-05-05T15:22:26.197703Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  role_0  role_1  role_2  role_3  \n0      -0.583959          0.386906       0       0       0       1  \n1      -0.583959          0.374986       0       0       0       1  \n2      -0.583959          1.463670       0       0       0       1  \n3      -0.583959          0.323333       0       0       0       1  \n4      -0.583959          0.001496       0       0       0       1  \n...          ...               ...     ...     ...     ...     ...  \n330280 -0.583959         -1.317639       0       1       0       0  \n330281 -0.583959         -1.285853       0       1       0       0  \n330282 -0.583959         -1.289826       0       1       0       0  \n330283 -0.583959         -1.361345       0       1       0       0  \n330284 -0.583959         -1.214333       0       1       0       0  \n\n[330285 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n      <th>role_0</th>\n      <th>role_1</th>\n      <th>role_2</th>\n      <th>role_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 17 columns</p>\n</div>"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"X = np.concatenate([\n    df.drop([\"user\", \"date_only\"], axis=1).values,\n    mu_all\n], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:30.159868Z","iopub.execute_input":"2025-05-05T15:22:30.160172Z","iopub.status.idle":"2025-05-05T15:22:30.219069Z","shell.execute_reply.started":"2025-05-05T15:22:30.160149Z","shell.execute_reply":"2025-05-05T15:22:30.218283Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:31.459706Z","iopub.execute_input":"2025-05-05T15:22:31.459969Z","iopub.status.idle":"2025-05-05T15:22:31.464742Z","shell.execute_reply.started":"2025-05-05T15:22:31.45995Z","shell.execute_reply":"2025-05-05T15:22:31.464074Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"(330285, 23)"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"clf = IsolationForest(contamination=0.01, random_state=42)  # Adjust contamination\nclf.fit(X)\nanomaly_scores = -clf.decision_function(X)  # Higher = more anomalous\nanomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())  # [0, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:43.639916Z","iopub.execute_input":"2025-05-05T15:22:43.640558Z","iopub.status.idle":"2025-05-05T15:22:58.391278Z","shell.execute_reply.started":"2025-05-05T15:22:43.640533Z","shell.execute_reply":"2025-05-05T15:22:58.390649Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# 1. Histogram of Anomaly Scores (Check Separation)\nplt.hist(anomaly_scores, bins=50)\nplt.xlabel(\"Anomaly Score\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Anomaly Scores\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:23:54.319985Z","iopub.execute_input":"2025-05-05T15:23:54.320294Z","iopub.status.idle":"2025-05-05T15:23:54.583257Z","shell.execute_reply.started":"2025-05-05T15:23:54.320273Z","shell.execute_reply":"2025-05-05T15:23:54.582548Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"is_anomaly.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:24:26.082405Z","iopub.execute_input":"2025-05-05T15:24:26.082932Z","iopub.status.idle":"2025-05-05T15:24:26.087391Z","shell.execute_reply.started":"2025-05-05T15:24:26.082909Z","shell.execute_reply":"2025-05-05T15:24:26.086629Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"(330285, 1)"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:25:09.659908Z","iopub.execute_input":"2025-05-05T15:25:09.660501Z","iopub.status.idle":"2025-05-05T15:25:09.663788Z","shell.execute_reply.started":"2025-05-05T15:25:09.660476Z","shell.execute_reply":"2025-05-05T15:25:09.663014Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"# 2. \"Pseudo-ROC\" (if you had labels, replace pseudo_labels with real ones)\nlabels = is_anomaly  # Top 1% as anomalies\nfpr, tpr, _ = roc_curve(labels, anomaly_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:25:18.460088Z","iopub.execute_input":"2025-05-05T15:25:18.460365Z","iopub.status.idle":"2025-05-05T15:25:18.658924Z","shell.execute_reply.started":"2025-05-05T15:25:18.460346Z","shell.execute_reply":"2025-05-05T15:25:18.658075Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":69},{"cell_type":"markdown","source":"IF with rolling_mean and avg","metadata":{}},{"cell_type":"code","source":"df_features['date_only'] = pd.to_datetime(df_features['date_only'])\ndf_features = df_features.sort_values(['user', 'date_only'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:26:52.93962Z","iopub.execute_input":"2025-05-05T15:26:52.939892Z","iopub.status.idle":"2025-05-05T15:26:53.018454Z","shell.execute_reply.started":"2025-05-05T15:26:52.939872Z","shell.execute_reply":"2025-05-05T15:26:53.017689Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/160185058.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_features['date_only'] = pd.to_datetime(df_features['date_only'])\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:27:06.645515Z","iopub.execute_input":"2025-05-05T15:27:06.646229Z","iopub.status.idle":"2025-05-05T15:27:06.661295Z","shell.execute_reply.started":"2025-05-05T15:27:06.646207Z","shell.execute_reply":"2025-05-05T15:27:06.66055Z"}},"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"           user  date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190 2010-01-04                -0.737332           -0.53406   \n1       AAE0190 2010-01-05                -0.737332           -0.53406   \n2       AAE0190 2010-01-06                -0.737332           -0.53406   \n3       AAE0190 2010-01-07                -0.737332           -0.53406   \n4       AAE0190 2010-01-08                -0.737332           -0.53406   \n...         ...        ...                      ...                ...   \n330280  ZSL0305 2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305 2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305 2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305 2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305 2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n330280 -0.583959         -1.317639  \n330281 -0.583959         -1.285853  \n330282 -0.583959         -1.289826  \n330283 -0.583959         -1.361345  \n330284 -0.583959         -1.214333  \n\n[330285 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":72},{"cell_type":"code","source":"rolling_features = []\nfor feature in df_features.columns[2:13]:  # Assuming columns 2-12 are your 11 features\n    df_features[f'{feature}_rolling_mean'] = df_features.groupby('user')[feature].transform(\n        lambda x: x.rolling(7, min_periods=1).mean()\n    )\n    df_features[f'{feature}_rolling_std'] = df_features.groupby('user')[feature].transform(\n        lambda x: x.rolling(7, min_periods=1).std().fillna(0)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:27:46.159416Z","iopub.execute_input":"2025-05-05T15:27:46.160079Z","iopub.status.idle":"2025-05-05T15:27:52.248103Z","shell.execute_reply.started":"2025-05-05T15:27:46.160045Z","shell.execute_reply":"2025-05-05T15:27:52.247525Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:28:47.341047Z","iopub.execute_input":"2025-05-05T15:28:47.341598Z","iopub.status.idle":"2025-05-05T15:28:47.559792Z","shell.execute_reply.started":"2025-05-05T15:28:47.341577Z","shell.execute_reply":"2025-05-05T15:28:47.559081Z"}},"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"           user  date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190 2010-01-04                -0.737332           -0.53406   \n1       AAE0190 2010-01-05                -0.737332           -0.53406   \n2       AAE0190 2010-01-06                -0.737332           -0.53406   \n3       AAE0190 2010-01-07                -0.737332           -0.53406   \n4       AAE0190 2010-01-08                -0.737332           -0.53406   \n...         ...        ...                      ...                ...   \n330280  ZSL0305 2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305 2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305 2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305 2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305 2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  \\\n0            -0.287121          0.930009       -0.759447  ...   \n1            -0.287121          0.711501       -0.233484  ...   \n2            -0.287121          0.766128       -0.064106  ...   \n3            -0.287121          0.875382       -0.179997  ...   \n4            -0.287121          0.766128       -0.607898  ...   \n...                ...               ...             ...  ...   \n330280       -0.287121         -1.309699       -1.107117  ...   \n330281       -0.287121         -1.200445        2.137805  ...   \n330282       -0.287121         -1.091191        3.760267  ...   \n330283       -0.287121         -1.309699        0.515344  ...   \n330284       -0.287121         -1.309699        0.515344  ...   \n\n        total_recipients_rolling_mean  total_recipients_rolling_std  \\\n0                            0.930009                      0.000000   \n1                            0.820755                      0.154509   \n2                            0.802546                      0.113715   \n3                            0.820755                      0.099735   \n4                            0.809830                      0.089761   \n...                               ...                           ...   \n330280                      -1.278483                      0.029199   \n330281                      -1.262876                      0.037696   \n330282                      -1.239464                      0.075392   \n330283                      -1.247268                      0.079966   \n330284                      -1.255072                      0.083444   \n\n        external_ratio_rolling_mean  external_ratio_rolling_std  \\\n0                         -0.759447                    0.000000   \n1                         -0.496466                    0.371912   \n2                         -0.352346                    0.362589   \n3                         -0.309259                    0.308339   \n4                         -0.368987                    0.298567   \n...                             ...                         ...   \n330280                     0.515344                    1.324734   \n330281                     0.747124                    1.459786   \n330282                     0.978904                    1.805308   \n330283                     0.978904                    1.805308   \n330284                     0.747124                    1.734484   \n\n        emails_sent_rolling_mean  emails_sent_rolling_std  \\\n0                       1.141349                 0.000000   \n1                       1.046823                 0.133679   \n2                       1.078332                 0.109149   \n3                       1.094086                 0.094526   \n4                       1.065729                 0.103548   \n...                          ...                      ...   \n330280                 -1.316319                 0.000000   \n330281                 -1.316319                 0.000000   \n330282                 -1.316319                 0.000000   \n330283                 -1.316319                 0.000000   \n330284                 -1.316319                 0.000000   \n\n        bcc_flag_rolling_mean  bcc_flag_rolling_std  \\\n0                   -0.583959                   0.0   \n1                   -0.583959                   0.0   \n2                   -0.583959                   0.0   \n3                   -0.583959                   0.0   \n4                   -0.583959                   0.0   \n...                       ...                   ...   \n330280              -0.583959                   0.0   \n330281              -0.583959                   0.0   \n330282              -0.583959                   0.0   \n330283              -0.583959                   0.0   \n330284              -0.583959                   0.0   \n\n        keyword_richness_rolling_mean  keyword_richness_rolling_std  \n0                            0.386906                      0.000000  \n1                            0.380946                      0.008429  \n2                            0.741854                      0.625139  \n3                            0.637224                      0.551655  \n4                            0.510078                      0.555942  \n...                               ...                           ...  \n330280                      -1.314233                      0.033981  \n330281                      -1.304584                      0.030408  \n330282                      -1.303449                      0.030850  \n330283                      -1.312531                      0.037534  \n330284                      -1.304584                      0.051383  \n\n[330285 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>total_recipients_rolling_mean</th>\n      <th>total_recipients_rolling_std</th>\n      <th>external_ratio_rolling_mean</th>\n      <th>external_ratio_rolling_std</th>\n      <th>emails_sent_rolling_mean</th>\n      <th>emails_sent_rolling_std</th>\n      <th>bcc_flag_rolling_mean</th>\n      <th>bcc_flag_rolling_std</th>\n      <th>keyword_richness_rolling_mean</th>\n      <th>keyword_richness_rolling_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>0.930009</td>\n      <td>0.000000</td>\n      <td>-0.759447</td>\n      <td>0.000000</td>\n      <td>1.141349</td>\n      <td>0.000000</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>0.386906</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>0.820755</td>\n      <td>0.154509</td>\n      <td>-0.496466</td>\n      <td>0.371912</td>\n      <td>1.046823</td>\n      <td>0.133679</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>0.380946</td>\n      <td>0.008429</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>0.802546</td>\n      <td>0.113715</td>\n      <td>-0.352346</td>\n      <td>0.362589</td>\n      <td>1.078332</td>\n      <td>0.109149</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>0.741854</td>\n      <td>0.625139</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>0.820755</td>\n      <td>0.099735</td>\n      <td>-0.309259</td>\n      <td>0.308339</td>\n      <td>1.094086</td>\n      <td>0.094526</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>0.637224</td>\n      <td>0.551655</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>0.809830</td>\n      <td>0.089761</td>\n      <td>-0.368987</td>\n      <td>0.298567</td>\n      <td>1.065729</td>\n      <td>0.103548</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>0.510078</td>\n      <td>0.555942</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-1.278483</td>\n      <td>0.029199</td>\n      <td>0.515344</td>\n      <td>1.324734</td>\n      <td>-1.316319</td>\n      <td>0.000000</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>-1.314233</td>\n      <td>0.033981</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>-1.262876</td>\n      <td>0.037696</td>\n      <td>0.747124</td>\n      <td>1.459786</td>\n      <td>-1.316319</td>\n      <td>0.000000</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>-1.304584</td>\n      <td>0.030408</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-1.239464</td>\n      <td>0.075392</td>\n      <td>0.978904</td>\n      <td>1.805308</td>\n      <td>-1.316319</td>\n      <td>0.000000</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>-1.303449</td>\n      <td>0.030850</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-1.247268</td>\n      <td>0.079966</td>\n      <td>0.978904</td>\n      <td>1.805308</td>\n      <td>-1.316319</td>\n      <td>0.000000</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>-1.312531</td>\n      <td>0.037534</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-1.255072</td>\n      <td>0.083444</td>\n      <td>0.747124</td>\n      <td>1.734484</td>\n      <td>-1.316319</td>\n      <td>0.000000</td>\n      <td>-0.583959</td>\n      <td>0.0</td>\n      <td>-1.304584</td>\n      <td>0.051383</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 35 columns</p>\n</div>"},"metadata":{}}],"execution_count":78},{"cell_type":"code","source":"X_static = df_features.drop(['user', 'date_only'], axis=1).values  # Original 11 + 14 rolling = 25 features\nX_static.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:36:37.970554Z","iopub.execute_input":"2025-05-05T15:36:37.970825Z","iopub.status.idle":"2025-05-05T15:36:38.080993Z","shell.execute_reply.started":"2025-05-05T15:36:37.970805Z","shell.execute_reply":"2025-05-05T15:36:38.080239Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"(330285, 33)"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"X_combined = np.concatenate([X_static, mu_all], axis=1)  # +8 latent = 33 total features\nX_combined.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:37:31.911483Z","iopub.execute_input":"2025-05-05T15:37:31.911754Z","iopub.status.idle":"2025-05-05T15:37:31.985285Z","shell.execute_reply.started":"2025-05-05T15:37:31.911735Z","shell.execute_reply":"2025-05-05T15:37:31.984624Z"}},"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"(330285, 41)"},"metadata":{}}],"execution_count":82},{"cell_type":"code","source":"# Train IF (now with temporal context)\nclf = IsolationForest(\n    contamination=0.01,  # Adjust based on expected anomaly rate\n    random_state=42,\n    n_jobs=-1\n)\nclf.fit(X_combined)\nanomaly_scores = -clf.decision_function(X_combined)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:38:27.735989Z","iopub.execute_input":"2025-05-05T15:38:27.736305Z","iopub.status.idle":"2025-05-05T15:38:44.178205Z","shell.execute_reply.started":"2025-05-05T15:38:27.736283Z","shell.execute_reply":"2025-05-05T15:38:44.177427Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"plt.hist(anomaly_scores, bins=50)\nplt.xlabel(\"Anomaly Score\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Anomaly Scores\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:42:36.170379Z","iopub.execute_input":"2025-05-05T15:42:36.171149Z","iopub.status.idle":"2025-05-05T15:42:36.378734Z","shell.execute_reply.started":"2025-05-05T15:42:36.17112Z","shell.execute_reply":"2025-05-05T15:42:36.377948Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(labels, anomaly_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:42:49.239553Z","iopub.execute_input":"2025-05-05T15:42:49.239819Z","iopub.status.idle":"2025-05-05T15:42:49.455952Z","shell.execute_reply.started":"2025-05-05T15:42:49.239799Z","shell.execute_reply":"2025-05-05T15:42:49.455216Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"import gym\nfrom gym import spaces","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:08:12.071232Z","iopub.execute_input":"2025-05-06T12:08:12.071946Z","iopub.status.idle":"2025-05-06T12:08:12.075338Z","shell.execute_reply.started":"2025-05-06T12:08:12.07192Z","shell.execute_reply":"2025-05-06T12:08:12.074546Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class AdaptiveThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles, users, window_size=7):\n        super().__init__()\n        self.anomaly_scores = anomaly_scores  # Shape: (n_samples,)\n        self.roles = roles                    # Shape: (n_samples, 4)\n        self.users = users                    # Array of user IDs\n        self.window_size = window_size\n        \n        # Action space: 0=decrease, 1=keep, 2=increase\n        self.action_space = spaces.Discrete(3)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_0, ..., role_3]\n        self.observation_space = spaces.Box(low=0, high=1, shape=(7,), dtype=np.float32)\n        \n        # Trackers\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_steps = {user: 0 for user in np.unique(users)}  # Per-user step counter\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        user_mask = (self.users == user)\n        user_scores = self.anomaly_scores[user_mask]\n        \n        # Rolling stats for the current user\n        start_idx = max(0, self.user_steps[user] - self.window_size)\n        rolling_scores = user_scores[start_idx:self.user_steps[user]]\n        rolling_mean = np.mean(rolling_scores) if len(rolling_scores) > 0 else 0\n        rolling_std = np.std(rolling_scores) if len(rolling_scores) > 0 else 0\n        \n        # Current role bits\n        role = self.roles[self.current_step]\n        \n        return np.array([\n            self.anomaly_scores[self.current_step],\n            rolling_mean,\n            rolling_std,\n            *role\n        ], dtype=np.float32)\n\n    def step(self, action):\n        # Adjust threshold\n        delta = 0.05 * (action - 1)  # [-0.05, 0, +0.05]\n        self.threshold = np.clip(self.threshold + delta, 0.1, 0.9)\n        \n        # Pseudo-label (1 if anomaly, 0 otherwise)\n        pseudo_label = 1 if self.anomaly_scores[self.current_step] > 0.5 else 0  # Static baseline\n        \n        # Cost-sensitive reward (adjust weights based on imbalance)\n        true_positive_reward = 1.0\n        false_negative_penalty = -5.0  # Heavy penalty for missing anomalies\n        false_positive_penalty = -0.5\n        true_negative_reward = 0.1\n        \n        pred = 1 if self.anomaly_scores[self.current_step] > self.threshold else 0\n        \n        if pred == pseudo_label:\n            reward = true_positive_reward if pred == 1 else true_negative_reward\n        else:\n            reward = false_negative_penalty if pred == 0 else false_positive_penalty\n        \n        # Update trackers\n        self.user_steps[self.users[self.current_step]] += 1\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {}\n\n    def reset(self):\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_steps = {user: 0 for user in np.unique(self.users)}\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:46:49.819093Z","iopub.execute_input":"2025-05-05T15:46:49.819683Z","iopub.status.idle":"2025-05-05T15:46:49.829767Z","shell.execute_reply.started":"2025-05-05T15:46:49.819663Z","shell.execute_reply":"2025-05-05T15:46:49.828967Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\n\n# Create environment\nenv = make_vec_env(\n    lambda: AdaptiveThresholdEnv(anomaly_scores, roles_df[[\"role_0\", \"role_1\", \"role_2\", \"role_3\"]].values, df[\"user\"].values),\n    n_envs=4\n)\n\n# Train PPO with class-weighted rewards\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(net_arch=[64, 64]),\n    learning_rate=3e-4,\n    gamma=0.99,\n    ent_coef=0.01,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:46:59.459254Z","iopub.execute_input":"2025-05-05T15:46:59.45952Z","iopub.status.idle":"2025-05-05T15:47:29.746949Z","shell.execute_reply.started":"2025-05-05T15:46:59.459502Z","shell.execute_reply":"2025-05-05T15:47:29.745968Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using cuda device\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n  deprecation(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/3236215615.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m )\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 308\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mclipped_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclipped_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \"\"\"\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mstep_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Avoid circular imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/monitor.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_reset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to step environment that needs reset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shimmy/openai_gym_compatibility.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \"\"\"\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_30/2898027931.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manomaly_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_30/2898027931.py\u001b[0m in \u001b[0;36m_get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Current role bits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mrole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         return np.array([\n","\u001b[0;31mIndexError\u001b[0m: index 1000 is out of bounds for axis 0 with size 1000"],"ename":"IndexError","evalue":"index 1000 is out of bounds for axis 0 with size 1000","output_type":"error"}],"execution_count":90},{"cell_type":"code","source":"df_features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:49:09.750246Z","iopub.execute_input":"2025-05-05T15:49:09.750926Z","iopub.status.idle":"2025-05-05T15:49:09.75532Z","shell.execute_reply.started":"2025-05-05T15:49:09.750907Z","shell.execute_reply":"2025-05-05T15:49:09.754717Z"}},"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'after_hours_logon_count_rolling_mean',\n       'after_hours_logon_count_rolling_std', 'total_logon_count_rolling_mean',\n       'total_logon_count_rolling_std', 'device_connects_rolling_mean',\n       'device_connects_rolling_std', 'avg_content_word_count_rolling_mean',\n       'avg_content_word_count_rolling_std',\n       'text_files_accessed_rolling_mean', 'text_files_accessed_rolling_std',\n       'files_accessed_rolling_mean', 'files_accessed_rolling_std',\n       'total_recipients_rolling_mean', 'total_recipients_rolling_std',\n       'external_ratio_rolling_mean', 'external_ratio_rolling_std',\n       'emails_sent_rolling_mean', 'emails_sent_rolling_std',\n       'bcc_flag_rolling_mean', 'bcc_flag_rolling_std',\n       'keyword_richness_rolling_mean', 'keyword_richness_rolling_std'],\n      dtype='object')"},"metadata":{}}],"execution_count":92},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:49:32.060122Z","iopub.execute_input":"2025-05-05T15:49:32.060402Z","iopub.status.idle":"2025-05-05T15:49:32.0656Z","shell.execute_reply.started":"2025-05-05T15:49:32.060382Z","shell.execute_reply":"2025-05-05T15:49:32.064893Z"}},"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"array([[-0.73733158, -0.53406024, -0.33127354, ...,  0.        ,\n         0.386906  ,  0.        ],\n       [-0.73733158, -0.53406024, -0.33127354, ...,  0.        ,\n         0.38094605,  0.00842864],\n       [-0.73733158, -0.53406024, -0.33127354, ...,  0.        ,\n         0.74185402,  0.62513934],\n       ...,\n       [-0.73733158, -0.53406024, -0.33127354, ...,  0.        ,\n        -1.30344879,  0.03085023],\n       [-0.73733158, -0.53406024, -0.33127354, ...,  0.        ,\n        -1.31253061,  0.03753413],\n       [-0.73733158, -0.53406024, -0.33127354, ...,  0.        ,\n        -1.30458401,  0.05138292]])"},"metadata":{}}],"execution_count":94},{"cell_type":"code","source":"df_merged = df_features.merge(roles_df, on='user', how='left')\n\n# Now roles are aligned with user-days\nroles_expanded = df_merged[['role_0', 'role_1', 'role_2', 'role_3']].values  # Shape: (330285, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:38:19.31061Z","iopub.execute_input":"2025-05-06T07:38:19.311115Z","iopub.status.idle":"2025-05-06T07:38:19.412339Z","shell.execute_reply.started":"2025-05-06T07:38:19.311091Z","shell.execute_reply":"2025-05-06T07:38:19.411734Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"roles_expanded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:38:20.667202Z","iopub.execute_input":"2025-05-06T07:38:20.667668Z","iopub.status.idle":"2025-05-06T07:38:20.672379Z","shell.execute_reply.started":"2025-05-06T07:38:20.667644Z","shell.execute_reply":"2025-05-06T07:38:20.671852Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"array([[0, 0, 0, 1],\n       [0, 0, 0, 1],\n       [0, 0, 0, 1],\n       ...,\n       [0, 1, 0, 0],\n       [0, 1, 0, 0],\n       [0, 1, 0, 0]])"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"unique_rows = np.unique(roles_expanded, axis=0)\nprint(unique_rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:39:01.287429Z","iopub.execute_input":"2025-05-06T07:39:01.288074Z","iopub.status.idle":"2025-05-06T07:39:01.827146Z","shell.execute_reply.started":"2025-05-06T07:39:01.288047Z","shell.execute_reply":"2025-05-06T07:39:01.826477Z"}},"outputs":[{"name":"stdout","text":"[[0 0 0 1]\n [0 0 1 0]\n [0 0 1 1]\n [0 1 0 0]\n [0 1 0 1]\n [0 1 1 0]\n [0 1 1 1]\n [1 0 0 0]\n [1 0 0 1]\n [1 0 1 0]]\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"unique_rows, inverse_indices = np.unique(roles_expanded, axis=0, return_inverse=True)\n\n# Map each row to an integer label starting from 1\nroles_labeled = inverse_indices + 1\n\nprint(\"Transformed roles_expanded:\")\nprint(roles_labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:40:17.452397Z","iopub.execute_input":"2025-05-06T07:40:17.452655Z","iopub.status.idle":"2025-05-06T07:40:18.010118Z","shell.execute_reply.started":"2025-05-06T07:40:17.452637Z","shell.execute_reply":"2025-05-06T07:40:18.009365Z"}},"outputs":[{"name":"stdout","text":"Transformed roles_expanded:\n[1 1 1 ... 4 4 4]\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"roles_labeled.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:41:13.133231Z","iopub.execute_input":"2025-05-06T07:41:13.133931Z","iopub.status.idle":"2025-05-06T07:41:13.138589Z","shell.execute_reply.started":"2025-05-06T07:41:13.133904Z","shell.execute_reply":"2025-05-06T07:41:13.137854Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(330285,)"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"np.unique(roles_labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:40:44.007984Z","iopub.execute_input":"2025-05-06T07:40:44.008267Z","iopub.status.idle":"2025-05-06T07:40:44.016929Z","shell.execute_reply.started":"2025-05-06T07:40:44.008247Z","shell.execute_reply":"2025-05-06T07:40:44.016175Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"class AdaptiveThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, window_size=7):\n        self.anomaly_scores = anomaly_scores  # Shape: (330285,)\n        self.roles = roles_expanded          # Shape: (330285, 4)\n        self.users = users                  # Shape: (330285,) user IDs\n        self.window_size = window_size\n        \n        # Action space: 0=decrease, 1=keep, 2=increase\n        self.action_space = spaces.Discrete(3)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_0, ..., role_3]\n        self.observation_space = spaces.Box(low=0, high=1, shape=(7,), dtype=np.float32)\n        \n        # Trackers\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_history = {}  # Track rolling stats per user\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        \n        # Initialize user history if not exists\n        if user not in self.user_history:\n            self.user_history[user] = {'scores': []}\n        \n        # Update rolling window\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > self.window_size:\n            self.user_history[user]['scores'].pop(0)\n        \n        # Compute stats\n        scores = self.user_history[user]['scores']\n        rolling_mean = np.mean(scores) if scores else 0\n        rolling_std = np.std(scores) if scores else 0\n        \n        # Get role for current step\n        role = self.roles[self.current_step]  # Now safe (roles_expanded matches anomaly_scores)\n        \n        return np.array([\n            self.anomaly_scores[self.current_step],\n            rolling_mean,\n            rolling_std,\n            *role\n        ], dtype=np.float32)\n\n    def step(self, action):\n        # Adjust threshold\n        delta = 0.05 * (action - 1)  # [-0.05, 0, +0.05]\n        self.threshold = np.clip(self.threshold + delta, 0.1, 0.9)\n        \n        # Pseudo-reward (replace with your actual labels if available)\n        pred_anomaly = self.anomaly_scores[self.current_step] > self.threshold\n        reward = 1.0 if pred_anomaly else 0.1  # Simplified example\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {}\n\n    def reset(self):\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_history = {}\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:51:23.359623Z","iopub.execute_input":"2025-05-05T15:51:23.360123Z","iopub.status.idle":"2025-05-05T15:51:23.371205Z","shell.execute_reply.started":"2025-05-05T15:51:23.360098Z","shell.execute_reply":"2025-05-05T15:51:23.370281Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"# Create environment\nenv = DummyVecEnv([\n    lambda: AdaptiveThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_expanded=roles_expanded,\n        users=df_merged['user'].values\n    )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:51:54.240475Z","iopub.execute_input":"2025-05-05T15:51:54.241007Z","iopub.status.idle":"2025-05-05T15:51:54.24583Z","shell.execute_reply.started":"2025-05-05T15:51:54.240984Z","shell.execute_reply":"2025-05-05T15:51:54.245056Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":98},{"cell_type":"code","source":"# Train PPO\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(net_arch=[64, 64]),\n    learning_rate=3e-4,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:52:01.004827Z","iopub.execute_input":"2025-05-05T15:52:01.005157Z","iopub.status.idle":"2025-05-05T15:55:22.095286Z","shell.execute_reply.started":"2025-05-05T15:52:01.005131Z","shell.execute_reply":"2025-05-05T15:55:22.094571Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n-----------------------------\n| time/              |      |\n|    fps             | 751  |\n|    iterations      | 1    |\n|    time_elapsed    | 2    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 559         |\n|    iterations           | 2           |\n|    time_elapsed         | 7           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.013844848 |\n|    clip_fraction        | 0.0875      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.658       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0115      |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.00522    |\n|    value_loss           | 0.235       |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 539         |\n|    iterations           | 3           |\n|    time_elapsed         | 11          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.016210144 |\n|    clip_fraction        | 0.095       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | 0.807       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0301     |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00587    |\n|    value_loss           | 0.0971      |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 527         |\n|    iterations           | 4           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.019748362 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | 0.8         |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0259     |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00765    |\n|    value_loss           | 0.0543      |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 522         |\n|    iterations           | 5           |\n|    time_elapsed         | 19          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009366392 |\n|    clip_fraction        | 0.00718     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.07       |\n|    explained_variance   | 0.693       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00706     |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.00142    |\n|    value_loss           | 0.0332      |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 6            |\n|    time_elapsed         | 23           |\n|    total_timesteps      | 12288        |\n| train/                  |              |\n|    approx_kl            | 0.0061051645 |\n|    clip_fraction        | 0.0126       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.806        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.0113       |\n|    n_updates            | 50           |\n|    policy_gradient_loss | -0.000614    |\n|    value_loss           | 0.0253       |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 516         |\n|    iterations           | 7           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 14336       |\n| train/                  |             |\n|    approx_kl            | 0.010811161 |\n|    clip_fraction        | 0.0529      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.05       |\n|    explained_variance   | 0.836       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0166      |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.00389    |\n|    value_loss           | 0.0205      |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 513         |\n|    iterations           | 8           |\n|    time_elapsed         | 31          |\n|    total_timesteps      | 16384       |\n| train/                  |             |\n|    approx_kl            | 0.007818099 |\n|    clip_fraction        | 0.0113      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.04       |\n|    explained_variance   | 0.387       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0231     |\n|    n_updates            | 70          |\n|    policy_gradient_loss | -0.000647   |\n|    value_loss           | 0.00922     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 511         |\n|    iterations           | 9           |\n|    time_elapsed         | 36          |\n|    total_timesteps      | 18432       |\n| train/                  |             |\n|    approx_kl            | 0.016432121 |\n|    clip_fraction        | 0.148       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.02       |\n|    explained_variance   | 0.879       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0231      |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.0101     |\n|    value_loss           | 0.00777     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 511         |\n|    iterations           | 10          |\n|    time_elapsed         | 40          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.016657047 |\n|    clip_fraction        | 0.0601      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.872      |\n|    explained_variance   | 0.694       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0127     |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.00295    |\n|    value_loss           | 0.00646     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 510         |\n|    iterations           | 11          |\n|    time_elapsed         | 44          |\n|    total_timesteps      | 22528       |\n| train/                  |             |\n|    approx_kl            | 0.027748121 |\n|    clip_fraction        | 0.0937      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.941      |\n|    explained_variance   | 0.842       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0413     |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.00938    |\n|    value_loss           | 0.0108      |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 508         |\n|    iterations           | 12          |\n|    time_elapsed         | 48          |\n|    total_timesteps      | 24576       |\n| train/                  |             |\n|    approx_kl            | 0.011413364 |\n|    clip_fraction        | 0.0489      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.888      |\n|    explained_variance   | 0.847       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00716    |\n|    n_updates            | 110         |\n|    policy_gradient_loss | -0.00753    |\n|    value_loss           | 0.00321     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 508         |\n|    iterations           | 13          |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 26624       |\n| train/                  |             |\n|    approx_kl            | 0.012428674 |\n|    clip_fraction        | 0.0835      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.93       |\n|    explained_variance   | 0.874       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00403    |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.00173    |\n|    value_loss           | 0.00404     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 508         |\n|    iterations           | 14          |\n|    time_elapsed         | 56          |\n|    total_timesteps      | 28672       |\n| train/                  |             |\n|    approx_kl            | 0.008680668 |\n|    clip_fraction        | 0.073       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.884      |\n|    explained_variance   | 0.918       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.01        |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.00333    |\n|    value_loss           | 0.00239     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 507         |\n|    iterations           | 15          |\n|    time_elapsed         | 60          |\n|    total_timesteps      | 30720       |\n| train/                  |             |\n|    approx_kl            | 0.024185259 |\n|    clip_fraction        | 0.172       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.859      |\n|    explained_variance   | 0.842       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0199      |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.0126     |\n|    value_loss           | 0.00348     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 506         |\n|    iterations           | 16          |\n|    time_elapsed         | 64          |\n|    total_timesteps      | 32768       |\n| train/                  |             |\n|    approx_kl            | 0.010344492 |\n|    clip_fraction        | 0.161       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.872      |\n|    explained_variance   | 0.53        |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0061     |\n|    n_updates            | 150         |\n|    policy_gradient_loss | -0.0062     |\n|    value_loss           | 0.0045      |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 506         |\n|    iterations           | 17          |\n|    time_elapsed         | 68          |\n|    total_timesteps      | 34816       |\n| train/                  |             |\n|    approx_kl            | 0.009610346 |\n|    clip_fraction        | 0.0979      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.917      |\n|    explained_variance   | 0.727       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0302     |\n|    n_updates            | 160         |\n|    policy_gradient_loss | -0.00395    |\n|    value_loss           | 0.000512    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 506         |\n|    iterations           | 18          |\n|    time_elapsed         | 72          |\n|    total_timesteps      | 36864       |\n| train/                  |             |\n|    approx_kl            | 0.008705219 |\n|    clip_fraction        | 0.0884      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.841      |\n|    explained_variance   | 0.825       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0271      |\n|    n_updates            | 170         |\n|    policy_gradient_loss | -0.00449    |\n|    value_loss           | 0.00037     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 506         |\n|    iterations           | 19          |\n|    time_elapsed         | 76          |\n|    total_timesteps      | 38912       |\n| train/                  |             |\n|    approx_kl            | 0.019628577 |\n|    clip_fraction        | 0.162       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.904      |\n|    explained_variance   | 0.863       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0319     |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.00524    |\n|    value_loss           | 0.000583    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 506         |\n|    iterations           | 20          |\n|    time_elapsed         | 80          |\n|    total_timesteps      | 40960       |\n| train/                  |             |\n|    approx_kl            | 0.014374753 |\n|    clip_fraction        | 0.0486      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.824      |\n|    explained_variance   | 0.855       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0126     |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.00322    |\n|    value_loss           | 0.000521    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 505         |\n|    iterations           | 21          |\n|    time_elapsed         | 84          |\n|    total_timesteps      | 43008       |\n| train/                  |             |\n|    approx_kl            | 0.018421862 |\n|    clip_fraction        | 0.141       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.652      |\n|    explained_variance   | 0.839       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00276     |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.00538    |\n|    value_loss           | 0.000119    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 506         |\n|    iterations           | 22          |\n|    time_elapsed         | 89          |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.013208177 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.891      |\n|    explained_variance   | 0.681       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0121     |\n|    n_updates            | 210         |\n|    policy_gradient_loss | -0.00633    |\n|    value_loss           | 0.000108    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 505         |\n|    iterations           | 23          |\n|    time_elapsed         | 93          |\n|    total_timesteps      | 47104       |\n| train/                  |             |\n|    approx_kl            | 0.033693172 |\n|    clip_fraction        | 0.122       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.81       |\n|    explained_variance   | 0.758       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0238     |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.0105     |\n|    value_loss           | 9.95e-05    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 505          |\n|    iterations           | 24           |\n|    time_elapsed         | 97           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0035292003 |\n|    clip_fraction        | 0.0162       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.48        |\n|    explained_variance   | 0.892        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00763      |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00094     |\n|    value_loss           | 0.000483     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 505          |\n|    iterations           | 25           |\n|    time_elapsed         | 101          |\n|    total_timesteps      | 51200        |\n| train/                  |              |\n|    approx_kl            | 0.0070538414 |\n|    clip_fraction        | 0.0712       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.674       |\n|    explained_variance   | 0.876        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00231     |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.0036      |\n|    value_loss           | 0.000697     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 505          |\n|    iterations           | 26           |\n|    time_elapsed         | 105          |\n|    total_timesteps      | 53248        |\n| train/                  |              |\n|    approx_kl            | 0.0042192494 |\n|    clip_fraction        | 0.0598       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.596       |\n|    explained_variance   | 0.716        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00658      |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.0052      |\n|    value_loss           | 3.62e-05     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 504          |\n|    iterations           | 27           |\n|    time_elapsed         | 109          |\n|    total_timesteps      | 55296        |\n| train/                  |              |\n|    approx_kl            | 0.0024847111 |\n|    clip_fraction        | 0.0182       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.656       |\n|    explained_variance   | 0.783        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00874     |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.000857    |\n|    value_loss           | 2.33e-05     |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 504         |\n|    iterations           | 28          |\n|    time_elapsed         | 113         |\n|    total_timesteps      | 57344       |\n| train/                  |             |\n|    approx_kl            | 0.009545762 |\n|    clip_fraction        | 0.043       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.736      |\n|    explained_variance   | 0.91        |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0136     |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.00169    |\n|    value_loss           | 9.26e-05    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 504         |\n|    iterations           | 29          |\n|    time_elapsed         | 117         |\n|    total_timesteps      | 59392       |\n| train/                  |             |\n|    approx_kl            | 0.016035277 |\n|    clip_fraction        | 0.0816      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.786      |\n|    explained_variance   | 0.844       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.019      |\n|    n_updates            | 280         |\n|    policy_gradient_loss | -0.00399    |\n|    value_loss           | 0.000281    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 504         |\n|    iterations           | 30          |\n|    time_elapsed         | 121         |\n|    total_timesteps      | 61440       |\n| train/                  |             |\n|    approx_kl            | 0.004825362 |\n|    clip_fraction        | 0.0228      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.664      |\n|    explained_variance   | 0.872       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0337     |\n|    n_updates            | 290         |\n|    policy_gradient_loss | -0.00337    |\n|    value_loss           | 4.85e-05    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 31          |\n|    time_elapsed         | 126         |\n|    total_timesteps      | 63488       |\n| train/                  |             |\n|    approx_kl            | 0.012210544 |\n|    clip_fraction        | 0.049       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.627      |\n|    explained_variance   | 0.9         |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0184     |\n|    n_updates            | 300         |\n|    policy_gradient_loss | -0.00362    |\n|    value_loss           | 2e-05       |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 32          |\n|    time_elapsed         | 130         |\n|    total_timesteps      | 65536       |\n| train/                  |             |\n|    approx_kl            | 0.012039311 |\n|    clip_fraction        | 0.112       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.739      |\n|    explained_variance   | 0.75        |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0117     |\n|    n_updates            | 310         |\n|    policy_gradient_loss | -0.0107     |\n|    value_loss           | 5.82e-06    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 33          |\n|    time_elapsed         | 134         |\n|    total_timesteps      | 67584       |\n| train/                  |             |\n|    approx_kl            | 0.003941495 |\n|    clip_fraction        | 0.0304      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.737      |\n|    explained_variance   | 0.92        |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.019      |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.00113    |\n|    value_loss           | 8.96e-06    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 34          |\n|    time_elapsed         | 138         |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.014511216 |\n|    clip_fraction        | 0.117       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.828      |\n|    explained_variance   | 0.859       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00244    |\n|    n_updates            | 330         |\n|    policy_gradient_loss | -0.00286    |\n|    value_loss           | 5.06e-05    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 35          |\n|    time_elapsed         | 142         |\n|    total_timesteps      | 71680       |\n| train/                  |             |\n|    approx_kl            | 0.004070745 |\n|    clip_fraction        | 0.0341      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.625      |\n|    explained_variance   | 0.776       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00385     |\n|    n_updates            | 340         |\n|    policy_gradient_loss | -0.00173    |\n|    value_loss           | 1.85e-05    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 36          |\n|    time_elapsed         | 146         |\n|    total_timesteps      | 73728       |\n| train/                  |             |\n|    approx_kl            | 0.012203092 |\n|    clip_fraction        | 0.14        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.794      |\n|    explained_variance   | 0.797       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0161     |\n|    n_updates            | 350         |\n|    policy_gradient_loss | -0.00736    |\n|    value_loss           | 2.1e-05     |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 37          |\n|    time_elapsed         | 150         |\n|    total_timesteps      | 75776       |\n| train/                  |             |\n|    approx_kl            | 0.007688082 |\n|    clip_fraction        | 0.0479      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.747      |\n|    explained_variance   | 0.879       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00988    |\n|    n_updates            | 360         |\n|    policy_gradient_loss | -0.0019     |\n|    value_loss           | 8.32e-06    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 503          |\n|    iterations           | 38           |\n|    time_elapsed         | 154          |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0031441976 |\n|    clip_fraction        | 0.0213       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.734       |\n|    explained_variance   | 0.846        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00861      |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.000388    |\n|    value_loss           | 4.74e-06     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 503          |\n|    iterations           | 39           |\n|    time_elapsed         | 158          |\n|    total_timesteps      | 79872        |\n| train/                  |              |\n|    approx_kl            | 0.0033940943 |\n|    clip_fraction        | 0.0187       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.425       |\n|    explained_variance   | 0.857        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00303      |\n|    n_updates            | 380          |\n|    policy_gradient_loss | -0.002       |\n|    value_loss           | 4.31e-06     |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 40          |\n|    time_elapsed         | 162         |\n|    total_timesteps      | 81920       |\n| train/                  |             |\n|    approx_kl            | 0.004966978 |\n|    clip_fraction        | 0.0301      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.577      |\n|    explained_variance   | 0.863       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00922    |\n|    n_updates            | 390         |\n|    policy_gradient_loss | -0.00283    |\n|    value_loss           | 3.97e-05    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 503          |\n|    iterations           | 41           |\n|    time_elapsed         | 166          |\n|    total_timesteps      | 83968        |\n| train/                  |              |\n|    approx_kl            | 0.0035691666 |\n|    clip_fraction        | 0.0312       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.588       |\n|    explained_variance   | 0.6          |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00341     |\n|    n_updates            | 400          |\n|    policy_gradient_loss | -0.00201     |\n|    value_loss           | 4.44e-06     |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 42          |\n|    time_elapsed         | 170         |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.013717865 |\n|    clip_fraction        | 0.0604      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.767      |\n|    explained_variance   | 0.873       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0414     |\n|    n_updates            | 410         |\n|    policy_gradient_loss | -0.00493    |\n|    value_loss           | 2.74e-06    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 43          |\n|    time_elapsed         | 174         |\n|    total_timesteps      | 88064       |\n| train/                  |             |\n|    approx_kl            | 0.022536675 |\n|    clip_fraction        | 0.103       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.422      |\n|    explained_variance   | 0.896       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0531      |\n|    n_updates            | 420         |\n|    policy_gradient_loss | -0.00557    |\n|    value_loss           | 5.45e-05    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 503          |\n|    iterations           | 44           |\n|    time_elapsed         | 179          |\n|    total_timesteps      | 90112        |\n| train/                  |              |\n|    approx_kl            | 0.0075902236 |\n|    clip_fraction        | 0.0987       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.569       |\n|    explained_variance   | 0.879        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.0046      |\n|    n_updates            | 430          |\n|    policy_gradient_loss | -0.00283     |\n|    value_loss           | 9.22e-05     |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 503         |\n|    iterations           | 45          |\n|    time_elapsed         | 183         |\n|    total_timesteps      | 92160       |\n| train/                  |             |\n|    approx_kl            | 0.012825174 |\n|    clip_fraction        | 0.128       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.495      |\n|    explained_variance   | 0.853       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.036      |\n|    n_updates            | 440         |\n|    policy_gradient_loss | -0.00911    |\n|    value_loss           | 6.65e-06    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 502         |\n|    iterations           | 46          |\n|    time_elapsed         | 187         |\n|    total_timesteps      | 94208       |\n| train/                  |             |\n|    approx_kl            | 0.010902178 |\n|    clip_fraction        | 0.0266      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.754      |\n|    explained_variance   | 0.832       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00648     |\n|    n_updates            | 450         |\n|    policy_gradient_loss | -0.00224    |\n|    value_loss           | 4.83e-06    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 502         |\n|    iterations           | 47          |\n|    time_elapsed         | 191         |\n|    total_timesteps      | 96256       |\n| train/                  |             |\n|    approx_kl            | 0.011839375 |\n|    clip_fraction        | 0.136       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.455      |\n|    explained_variance   | 0.557       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0303     |\n|    n_updates            | 460         |\n|    policy_gradient_loss | -0.00295    |\n|    value_loss           | 1.25e-05    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 502         |\n|    iterations           | 48          |\n|    time_elapsed         | 195         |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.014956467 |\n|    clip_fraction        | 0.129       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.543      |\n|    explained_variance   | 0.718       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0311      |\n|    n_updates            | 470         |\n|    policy_gradient_loss | -0.00604    |\n|    value_loss           | 3.11e-06    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 502          |\n|    iterations           | 49           |\n|    time_elapsed         | 199          |\n|    total_timesteps      | 100352       |\n| train/                  |              |\n|    approx_kl            | 0.0033014202 |\n|    clip_fraction        | 0.0307       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.496       |\n|    explained_variance   | 0.781        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.0151      |\n|    n_updates            | 480          |\n|    policy_gradient_loss | -0.0025      |\n|    value_loss           | 3.5e-06      |\n------------------------------------------\n","output_type":"stream"},{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7ec745e75f10>"},"metadata":{}}],"execution_count":99},{"cell_type":"code","source":"def evaluate_global_model(model, anomaly_scores, roles_expanded, users, true_labels):\n    \"\"\"Index-safe evaluation with proper step handling.\"\"\"\n    # Validate inputs\n    assert isinstance(users, np.ndarray), \"Users must be a NumPy array\"\n    assert len(anomaly_scores) == len(roles_expanded) == len(users), \\\n        \"Input arrays must have the same length\"\n    \n    env = AdaptiveThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_expanded=roles_expanded,\n        users=users\n    )\n    obs = env.reset()\n    preds, scores = [], []\n    \n    # Process all steps\n    while env.current_step < len(anomaly_scores):\n        # Get current score and threshold before stepping\n        current_score = anomaly_scores[env.current_step]\n        current_threshold = env.threshold\n        \n        # Store prediction (score > threshold)\n        preds.append(1 if current_score > current_threshold else 0)\n        scores.append(current_score)\n        \n        # Predict action and step (only if not at the end)\n        if env.current_step < len(anomaly_scores) - 1:\n            action, _ = model.predict(obs, deterministic=True)\n            obs, _, done, _ = env.step(action)\n            if done:\n                break\n        else:\n            # At the final step, don't step further\n            break\n    \n    # Ensure preds and true_labels align\n    preds = np.array(preds)\n    # Flatten true_labels if 2D (shape (n, 1) -> (n,))\n    true_labels = true_labels.flatten() if true_labels.ndim > 1 else true_labels\n    true_labels = true_labels[:len(preds)]  # Truncate to match preds length\n    \n    # Calculate metrics\n    metrics = {\n        \"precision\": precision_score(true_labels, preds, zero_division=0),\n        \"recall\": recall_score(true_labels, preds, zero_division=0),\n        \"f1\": f1_score(true_labels, preds, zero_division=0),\n        \"auc_roc\": roc_auc_score(true_labels, preds) if len(np.unique(true_labels)) > 1 else 0,\n        \"final_threshold\": env.threshold\n    }\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:59:49.786463Z","iopub.execute_input":"2025-05-05T16:59:49.786735Z","iopub.status.idle":"2025-05-05T16:59:49.794003Z","shell.execute_reply.started":"2025-05-05T16:59:49.786715Z","shell.execute_reply":"2025-05-05T16:59:49.79322Z"}},"outputs":[],"execution_count":147},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n    cm = confusion_matrix(y_true, y_pred)\n    labels = [\"Normal\", \"Anomaly\"]\n\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:59:51.823534Z","iopub.execute_input":"2025-05-05T16:59:51.823765Z","iopub.status.idle":"2025-05-05T16:59:51.828686Z","shell.execute_reply.started":"2025-05-05T16:59:51.82375Z","shell.execute_reply":"2025-05-05T16:59:51.827874Z"}},"outputs":[],"execution_count":148},{"cell_type":"code","source":"users=df_merged['user'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:58:13.724318Z","iopub.execute_input":"2025-05-05T16:58:13.724979Z","iopub.status.idle":"2025-05-05T16:58:13.728194Z","shell.execute_reply.started":"2025-05-05T16:58:13.724958Z","shell.execute_reply":"2025-05-05T16:58:13.727469Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"anomaly_scores.shape, roles_expanded.shape, is_anomaly.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:54:09.288987Z","iopub.execute_input":"2025-05-05T16:54:09.289475Z","iopub.status.idle":"2025-05-05T16:54:09.294114Z","shell.execute_reply.started":"2025-05-05T16:54:09.289452Z","shell.execute_reply":"2025-05-05T16:54:09.293424Z"}},"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"((330285,), (330285, 4), (330285, 1))"},"metadata":{}}],"execution_count":129},{"cell_type":"code","source":"users","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:57:50.882992Z","iopub.execute_input":"2025-05-05T16:57:50.883873Z","iopub.status.idle":"2025-05-05T16:57:50.888305Z","shell.execute_reply.started":"2025-05-05T16:57:50.883846Z","shell.execute_reply":"2025-05-05T16:57:50.887735Z"}},"outputs":[{"execution_count":140,"output_type":"execute_result","data":{"text/plain":"array(['AAE0190', 'AAE0190', 'AAE0190', ..., 'ZSL0305', 'ZSL0305',\n       'ZSL0305'], dtype=object)"},"metadata":{}}],"execution_count":140},{"cell_type":"code","source":"users","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:58:05.983882Z","iopub.execute_input":"2025-05-05T16:58:05.984192Z","iopub.status.idle":"2025-05-05T16:58:05.988828Z","shell.execute_reply.started":"2025-05-05T16:58:05.984168Z","shell.execute_reply":"2025-05-05T16:58:05.988299Z"}},"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"'AAE0190'"},"metadata":{}}],"execution_count":143},{"cell_type":"code","source":"# Test with a small subset\nsmall_scores = anomaly_scores[:100]\nsmall_roles = roles_expanded[:100]\nsmall_users = users[:100]\nsmall_labels = is_anomaly[:100]\n\nmetrics = evaluate_global_model(model, small_scores, small_roles, small_users, small_labels)\nprint(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:59:54.782995Z","iopub.execute_input":"2025-05-05T16:59:54.783585Z","iopub.status.idle":"2025-05-05T16:59:54.873292Z","shell.execute_reply.started":"2025-05-05T16:59:54.783562Z","shell.execute_reply":"2025-05-05T16:59:54.872533Z"}},"outputs":[{"name":"stdout","text":"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc_roc': 0, 'final_threshold': 0.5}\n","output_type":"stream"}],"execution_count":149},{"cell_type":"code","source":"# After training:\nresults = evaluate_global_model(\n    model=model,\n    anomaly_scores=anomaly_scores,      \n    roles_expanded=roles_expanded,     \n    users=users,    \n    true_labels=is_anomaly             \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:00:24.724466Z","iopub.execute_input":"2025-05-05T17:00:24.725246Z","iopub.status.idle":"2025-05-05T17:04:46.01114Z","shell.execute_reply.started":"2025-05-05T17:00:24.725221Z","shell.execute_reply":"2025-05-05T17:04:46.010186Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/3647569197.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m print(f\"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0mFinal\u001b[0m \u001b[0mThreshold\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'final_threshold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mPrecision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mRecall\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mScore\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'metrics'"],"ename":"KeyError","evalue":"'metrics'","output_type":"error"}],"execution_count":150},{"cell_type":"code","source":"print(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:06:16.463966Z","iopub.execute_input":"2025-05-05T17:06:16.464515Z","iopub.status.idle":"2025-05-05T17:06:16.468417Z","shell.execute_reply.started":"2025-05-05T17:06:16.464492Z","shell.execute_reply":"2025-05-05T17:06:16.467674Z"}},"outputs":[{"name":"stdout","text":"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc_roc': 0.49999847987814705, 'final_threshold': 0.1}\n","output_type":"stream"}],"execution_count":152},{"cell_type":"code","source":"print(f\"\"\"\nFinal Threshold: {results['final_threshold']:.3f}\nPrecision: {results['metrics']['precision']:.3f}\nRecall: {results['metrics']['recall']:.3f}\nF1-Score: {results['metrics']['f1']:.3f}\nAUC-ROC: {results['metrics']['auc_roc']:.3f}\nMCC: {results['metrics']['mcc']:.3f}\n\"\"\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('ppo_globalthres.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:06:39.468286Z","iopub.execute_input":"2025-05-05T17:06:39.468576Z","iopub.status.idle":"2025-05-05T17:06:39.48263Z","shell.execute_reply.started":"2025-05-05T17:06:39.468555Z","shell.execute_reply":"2025-05-05T17:06:39.482076Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"plot_confusion_matrix(is_anomaly, results[\"predictions\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_global_model(model, anomaly_scores, roles_expanded, users, true_labels):\n    \"\"\"Index-safe evaluation with proper step handling.\"\"\"\n    # Validate inputs\n    assert isinstance(users, np.ndarray), \"Users must be a NumPy array\"\n    assert len(anomaly_scores) == len(roles_expanded) == len(users), \\\n        \"Input arrays must have the same length\"\n    \n    env = AdaptiveThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_expanded=roles_expanded,\n        users=users\n    )\n    obs = env.reset()\n    preds, scores = [], []\n    \n    # Process all steps\n    while env.current_step < len(anomaly_scores):\n        current_score = anomaly_scores[env.current_step]\n        current_threshold = env.threshold\n        preds.append(1 if current_score > current_threshold else 0)\n        scores.append(current_score)\n        \n        if env.current_step < len(anomaly_scores) - 1:\n            action, _ = model.predict(obs, deterministic=True)\n            obs, _, done, _ = env.step(action)\n            if done:\n                break\n        else:\n            break\n    \n    # Ensure preds and true_labels align\n    preds = np.array(preds)\n    true_labels = true_labels.flatten() if true_labels.ndim > 1 else true_labels\n    true_labels = true_labels[:len(preds)]  # Truncate to match preds length\n    \n    # Calculate metrics\n    metrics = {\n        \"precision\": precision_score(true_labels, preds, zero_division=0),\n        \"recall\": recall_score(true_labels, preds, zero_division=0),\n        \"f1\": f1_score(true_labels, preds, zero_division=0),\n        \"auc_roc\": roc_auc_score(true_labels, preds) if len(np.unique(true_labels)) > 1 else 0,\n        \"final_threshold\": env.threshold\n    }\n    \n    return metrics, preds, true_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:08:47.759223Z","iopub.execute_input":"2025-05-05T17:08:47.759517Z","iopub.status.idle":"2025-05-05T17:08:47.766981Z","shell.execute_reply.started":"2025-05-05T17:08:47.759499Z","shell.execute_reply":"2025-05-05T17:08:47.766264Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"# Test with a small subset\nsmall_scores = anomaly_scores[:100]\nsmall_roles = roles_expanded[:100]\nsmall_users = users[:100]\nsmall_labels = is_anomaly[:100]\n\nmetrics = evaluate_global_model(model, small_scores, small_roles, small_users, small_labels)\nprint(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:09:41.550794Z","iopub.execute_input":"2025-05-05T17:09:41.55108Z","iopub.status.idle":"2025-05-05T17:09:41.640708Z","shell.execute_reply.started":"2025-05-05T17:09:41.551059Z","shell.execute_reply":"2025-05-05T17:09:41.640189Z"}},"outputs":[{"name":"stdout","text":"({'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc_roc': 0, 'final_threshold': 0.5}, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n","output_type":"stream"}],"execution_count":156},{"cell_type":"code","source":"metrics, preds, true_labels = evaluate_global_model(\n    model, anomaly_scores, roles_expanded, users, is_anomaly\n)\nprint(\"Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:12:20.548965Z","iopub.execute_input":"2025-05-05T17:12:20.549543Z","iopub.status.idle":"2025-05-05T17:16:39.72598Z","shell.execute_reply.started":"2025-05-05T17:12:20.54952Z","shell.execute_reply":"2025-05-05T17:16:39.724968Z"}},"outputs":[{"name":"stdout","text":"Metrics: {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'auc_roc': 0.49999847987814705, 'final_threshold': 0.1}\n","output_type":"stream"}],"execution_count":158},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:16:45.689853Z","iopub.execute_input":"2025-05-05T17:16:45.690551Z","iopub.status.idle":"2025-05-05T17:16:45.693804Z","shell.execute_reply.started":"2025-05-05T17:16:45.690528Z","shell.execute_reply":"2025-05-05T17:16:45.693058Z"}},"outputs":[],"execution_count":159},{"cell_type":"code","source":"cm = confusion_matrix(true_labels, preds)\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal (0)', 'Anomaly (1)'],\n            yticklabels=['Normal (0)', 'Anomaly (1)'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:16:46.969258Z","iopub.execute_input":"2025-05-05T17:16:46.969734Z","iopub.status.idle":"2025-05-05T17:16:47.214149Z","shell.execute_reply.started":"2025-05-05T17:16:46.969712Z","shell.execute_reply":"2025-05-05T17:16:47.213461Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":160},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class RoleAdaptiveThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, n_roles=10):\n        self.anomaly_scores = anomaly_scores  # Shape: (330285,)\n        self.role_ids = np.argmax(roles_expanded, axis=1) \n        self.users = users                    \n        self.n_roles = n_roles\n        \n        # Initialize separate thresholds per role\n        self.role_thresholds = np.linspace(0.3, 0.7, n_roles)\n        \n        # Action: Delta to adjust threshold ∈ [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # State: [current_score, rolling_mean, rolling_std, one_hot_role]\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,)),\n            \"role\": spaces.Discrete(n_roles)\n        })\n        \n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_id\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role_id] = np.clip(\n            self.role_thresholds[role_id] + action[0], \n            0.1, 0.9  # Hard bounds\n        )\n        \n        # Get prediction\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_id])\n        \n        # Reward (heavier penalties for high-risk roles)\n        reward = self._calculate_reward(pred, role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_id]\n        }\n\n    def _calculate_reward(self, pred, role_id):\n        # Define risk weights per role (e.g., role_0=highest risk)\n        role_weights = [2.0, 1.8, 1.5, 1.2, 1.0]  # Extend to n_roles\n        weight = role_weights[role_id % len(role_weights)]\n        \n        # Simplified reward (replace with your actual labels if available)\n        return weight * (10 if pred else -1)  # Customize based on FP/FN costs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert role bits to IDs (0-9)\nrole_ids = np.argmax(roles_expanded, axis=1)\n\n# Calculate anomaly frequency per role\nrole_anomaly_rates = pd.DataFrame({\n    'role_id': role_ids,\n    'is_anomaly': is_anomaly\n}).groupby('role_id')['is_anomaly'].mean()\n\nprint(\"Anomaly Rates per Role:\")\nprint(role_anomaly_rates.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:29:35.545092Z","iopub.execute_input":"2025-05-05T17:29:35.546Z","iopub.status.idle":"2025-05-05T17:29:35.589073Z","shell.execute_reply.started":"2025-05-05T17:29:35.545965Z","shell.execute_reply":"2025-05-05T17:29:35.588087Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/419953156.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate anomaly frequency per role\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m role_anomaly_rates = pd.DataFrame({\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m'role_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrole_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'is_anomaly'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mis_anomaly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0mraw_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Per-column arrays must each be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"],"ename":"ValueError","evalue":"Per-column arrays must each be 1-dimensional","output_type":"error"}],"execution_count":161},{"cell_type":"code","source":"# Assuming roles_expanded is a (330285, 4) numpy array\nrole_ids = np.zeros(len(roles_expanded), dtype=int)\nfor i in range(4):  # For each bit\n    role_ids += (roles_expanded[:, i] * (2 ** i)).astype(int)\n\n# Verify unique roles\nprint(\"Unique Role IDs:\", np.unique(role_ids)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:32:27.059317Z","iopub.execute_input":"2025-05-05T17:32:27.059786Z","iopub.status.idle":"2025-05-05T17:32:27.074258Z","shell.execute_reply.started":"2025-05-05T17:32:27.059765Z","shell.execute_reply":"2025-05-05T17:32:27.073677Z"}},"outputs":[{"name":"stdout","text":"Unique Role IDs: [ 1  2  4  5  6  8  9 10 12 14]\n","output_type":"stream"}],"execution_count":163},{"cell_type":"code","source":"is_anomaly = is_anomaly.reshape(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:34:07.148827Z","iopub.execute_input":"2025-05-05T17:34:07.149528Z","iopub.status.idle":"2025-05-05T17:34:07.152828Z","shell.execute_reply.started":"2025-05-05T17:34:07.149502Z","shell.execute_reply":"2025-05-05T17:34:07.152008Z"}},"outputs":[],"execution_count":168},{"cell_type":"code","source":"\nrole_df = pd.DataFrame({\n    'role_id': role_ids,\n    'is_anomaly': is_anomaly  # Your anomaly labels (330285,)\n})\n\n# Calculate anomaly frequency per role\nrole_anomaly_rates = role_df.groupby('role_id')['is_anomaly'].mean()\nprint(\"Anomaly Rates per Role:\")\nprint(role_anomaly_rates.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:34:11.057946Z","iopub.execute_input":"2025-05-05T17:34:11.05849Z","iopub.status.idle":"2025-05-05T17:34:11.077484Z","shell.execute_reply.started":"2025-05-05T17:34:11.058467Z","shell.execute_reply":"2025-05-05T17:34:11.076746Z"}},"outputs":[{"name":"stdout","text":"Anomaly Rates per Role:\nrole_id\n14    0.008380\n2     0.005605\n6     0.005437\n10    0.004072\n4     0.003720\n12    0.001840\n9     0.001605\n1     0.000931\n8     0.000000\n5     0.000000\nName: is_anomaly, dtype: float64\n","output_type":"stream"}],"execution_count":169},{"cell_type":"code","source":"# Normalize weights between [0.5, 2.0] based on anomaly rates\nmin_rate = role_anomaly_rates.min()\nmax_rate = role_anomaly_rates.max()\nrole_weights = (role_anomaly_rates - min_rate) / (max_rate - min_rate + 1e-8) * 1.5 + 0.5\nrole_weights = role_weights.to_dict()  # {role_id: weight}\n\nprint(\"Role Weights:\")\nprint(role_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:34:24.26999Z","iopub.execute_input":"2025-05-05T17:34:24.270696Z","iopub.status.idle":"2025-05-05T17:34:24.275799Z","shell.execute_reply.started":"2025-05-05T17:34:24.270672Z","shell.execute_reply":"2025-05-05T17:34:24.275223Z"}},"outputs":[{"name":"stdout","text":"Role Weights:\n{1: 0.6666364519334633, 2: 1.503301351626301, 4: 1.1658889718506966, 5: 0.5, 6: 1.4732138828974453, 8: 0.5, 9: 0.7872542782243186, 10: 1.2289515996962965, 12: 0.8293045582720272, 14: 1.9999982100467788}\n","output_type":"stream"}],"execution_count":170},{"cell_type":"code","source":"class RoleWeightedThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, is_anomaly):\n        # Convert bit-encoded roles to IDs\n        self.role_ids = np.sum(roles_expanded * (2 ** np.arange(4)), axis=1)  # Shape: (330285,)\n        \n        # Calculate role weights\n        self.role_weights = self._calculate_role_weights(self.role_ids, is_anomaly)\n        \n        # Initialize thresholds per role\n        self.role_thresholds = np.ones(len(role_weights)) * 0.5  # Default threshold=0.5\n        \n        # Action space: threshold delta ∈ [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_id_one_hot]\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,)),\n            \"role\": spaces.Discrete(len(role_weights))\n        })\n        \n        # Trackers\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _calculate_role_weights(self, role_ids, is_anomaly):\n        \"\"\"Compute weights based on anomaly frequency per role.\"\"\"\n        df = pd.DataFrame({'role': role_ids, 'is_anomaly': is_anomaly})\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        return (anomaly_rates / anomaly_rates.max() * 2.0).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_id\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role_id] = np.clip(\n            self.role_thresholds[role_id] + action[0], \n            0.1, 0.9\n        )\n        \n        # Get prediction and reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_id])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_id]\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        \"\"\"Weighted reward based on role risk.\"\"\"\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label == 1:  # Anomaly\n            return 50.0 * weight if pred == 1 else -100.0 * weight  # Heavy FN penalty\n        else:                # Normal\n            return 0.1 if pred == 0 else -2.0 / weight  # Smaller FP penalty","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:39:06.469959Z","iopub.execute_input":"2025-05-05T17:39:06.470537Z","iopub.status.idle":"2025-05-05T17:39:06.481741Z","shell.execute_reply.started":"2025-05-05T17:39:06.470512Z","shell.execute_reply":"2025-05-05T17:39:06.481213Z"}},"outputs":[],"execution_count":174},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.policies import MultiInputPolicy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:48:41.767763Z","iopub.execute_input":"2025-05-05T17:48:41.768084Z","iopub.status.idle":"2025-05-05T17:48:41.787049Z","shell.execute_reply.started":"2025-05-05T17:48:41.768062Z","shell.execute_reply":"2025-05-05T17:48:41.786138Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/2390098406.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiInputPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'MultiInputPolicy' from 'stable_baselines3.common.policies' (/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py)"],"ename":"ImportError","evalue":"cannot import name 'MultiInputPolicy' from 'stable_baselines3.common.policies' (/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py)","output_type":"error"}],"execution_count":183},{"cell_type":"code","source":"model = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(\n        net_arch=[dict(pi=[64, 64], vf=[64, 64])]  # Separate policy/value networks\n    ),\n    learning_rate=3e-4,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:47:08.728303Z","iopub.execute_input":"2025-05-05T17:47:08.728946Z","iopub.status.idle":"2025-05-05T17:47:08.751828Z","shell.execute_reply.started":"2025-05-05T17:47:08.728922Z","shell.execute_reply":"2025-05-05T17:47:08.750796Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/1005972069.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = PPO(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     policy_kwargs=dict(\n\u001b[1;32m      5\u001b[0m         \u001b[0mnet_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Separate policy/value networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     ):\n\u001b[0;32m--> 104\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     ):\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;31m# Catch common mistake: using MlpPolicy/CnnPolicy instead of MultiInputPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CnnPolicy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You must use `MultiInputPolicy` when working with dict observation space, not {policy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sde\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: You must use `MultiInputPolicy` when working with dict observation space, not MlpPolicy"],"ename":"ValueError","evalue":"You must use `MultiInputPolicy` when working with dict observation space, not MlpPolicy","output_type":"error"}],"execution_count":181},{"cell_type":"code","source":"model.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:42:02.829472Z","iopub.execute_input":"2025-05-05T17:42:02.830316Z","iopub.status.idle":"2025-05-05T17:42:02.851508Z","shell.execute_reply.started":"2025-05-05T17:42:02.830287Z","shell.execute_reply":"2025-05-05T17:42:02.850501Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/3384957020.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 308\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         total_timesteps, callback = self._setup_learn(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# pytype: disable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;31m# pytype: enable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Seeds are only used once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}],"execution_count":180},{"cell_type":"code","source":"from stable_baselines3.common.env_util import make_vec_env\n\n# Create and vectorize the environment\nenv = make_vec_env(\n    lambda: RoleWeightedThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly),\n    n_envs=1\n)\n\n# Train PPO with MultiInputPolicy\nmodel = PPO(\n    \"MultiInputPolicy\",\n    env,\n    policy_kwargs=dict(\n        net_arch=[dict(pi=[64, 64], vf=[64, 64])]  # Separate policy/value networks\n    ),\n    learning_rate=3e-4,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:51:08.088294Z","iopub.execute_input":"2025-05-05T17:51:08.088835Z","iopub.status.idle":"2025-05-05T17:51:08.133104Z","shell.execute_reply.started":"2025-05-05T17:51:08.088816Z","shell.execute_reply":"2025-05-05T17:51:08.131947Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/4215729627.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 308\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         total_timesteps, callback = self._setup_learn(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# pytype: disable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;31m# pytype: enable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Seeds are only used once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}],"execution_count":185},{"cell_type":"code","source":"class VecEnvResetWrapper(gym.Wrapper):\n    def __init__(self, env):\n        super().__init__(env)\n        self.info_buffer = [{}] * self.env.num_envs if hasattr(self.env, \"num_envs\") else [{}]\n\n    def reset(self, **kwargs):\n        obs, info = self.env.reset(**kwargs)\n        self.info_buffer = info if isinstance(info, list) else [info]\n        return obs\n\n    def step(self, action):\n        obs, reward, done, info = self.env.step(action)\n        self.info_buffer = info if isinstance(info, list) else [info]\n        return obs, reward, done, info\n\nclass RoleWeightedThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, is_anomaly):\n        # Normalize anomaly scores to [0, 1]\n        anomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())\n        self.anomaly_scores = anomaly_scores  # Shape: (330285,)\n        self.users = users                    # Shape: (330285,)\n        self.is_anomaly = is_anomaly.flatten()  # Shape: (330285,)\n        self.roles_expanded = roles_expanded  # Shape: (330285, 4)\n        \n        # Convert bit-encoded roles to IDs\n        self.role_ids = np.sum(roles_expanded * (2 ** np.arange(4)), axis=1)  # Shape: (330285,)\n        \n        # Calculate role weights\n        self.role_weights = self._calculate_role_weights(self.role_ids, self.is_anomaly)\n        \n        # Initialize thresholds per role\n        self.role_thresholds = np.ones(len(self.role_weights)) * 0.5  # Default threshold=0.5\n        \n        # Action space: threshold delta ∈ [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_id]\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32),\n            \"role\": spaces.Discrete(len(self.role_weights))\n        })\n        \n        # Trackers\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _calculate_role_weights(self, role_ids, is_anomaly):\n        \"\"\"Compute weights based on anomaly frequency per role.\"\"\"\n        df = pd.DataFrame({'role': role_ids, 'is_anomaly': is_anomaly})\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        return (anomaly_rates / anomaly_rates.max() * 2.0).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"scores\": np.zeros(3, dtype=np.float32),\n                \"role\": 0\n            }\n        \n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_id\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role_id] = np.clip(\n            self.role_thresholds[role_id] + action[0], \n            0.1, 0.9\n        )\n        \n        # Get prediction and reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_id])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_id]\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        \"\"\"Weighted reward based on role risk.\"\"\"\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label == 1:  # Anomaly\n            return 50.0 * weight if pred == 1 else -100.0 * weight  # Heavy FN penalty\n        else:                # Normal\n            return 0.1 if pred == 0 else -2.0 / weight  # Smaller FP penalty\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n        self.role_thresholds = np.ones(len(self.role_weights)) * 0.5  # Reset thresholds\n        return self._get_state(), {}  # Return observation and info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:54:06.969014Z","iopub.execute_input":"2025-05-05T17:54:06.969368Z","iopub.status.idle":"2025-05-05T17:54:06.983759Z","shell.execute_reply.started":"2025-05-05T17:54:06.969345Z","shell.execute_reply":"2025-05-05T17:54:06.982931Z"}},"outputs":[],"execution_count":189},{"cell_type":"code","source":"env = make_vec_env(\n    lambda: RoleWeightedThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly),\n    n_envs=1\n)\nenv = VecEnvResetWrapper(env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:54:26.608397Z","iopub.execute_input":"2025-05-05T17:54:26.608655Z","iopub.status.idle":"2025-05-05T17:54:26.636245Z","shell.execute_reply.started":"2025-05-05T17:54:26.608635Z","shell.execute_reply":"2025-05-05T17:54:26.635502Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n  deprecation(\n","output_type":"stream"}],"execution_count":191},{"cell_type":"code","source":"model = PPO(\n    \"MultiInputPolicy\",\n    env,\n    policy_kwargs=dict(\n        net_arch=dict(pi=[64, 64], vf=[64, 64])\n    ),\n    learning_rate=3e-4,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:54:35.269129Z","iopub.execute_input":"2025-05-05T17:54:35.269761Z","iopub.status.idle":"2025-05-05T17:54:35.295729Z","shell.execute_reply.started":"2025-05-05T17:54:35.26974Z","shell.execute_reply":"2025-05-05T17:54:35.294801Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/3191854771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = PPO(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"MultiInputPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     policy_kwargs=dict(\n\u001b[1;32m      5\u001b[0m         \u001b[0mnet_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     ):\n\u001b[0;32m--> 104\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0msupported_action_spaces\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpace\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     ):\n\u001b[0;32m---> 81\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_make_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_wrap_env\u001b[0;34m(env, verbose, monitor_wrapper)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVecEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Patch to support gym 0.21/0.26 and gymnasium\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_patch_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmonitor_wrapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py\u001b[0m in \u001b[0;36m_patch_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mshimmy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGymV26CompatibilityV0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Gym 0.21 env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mshimmy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGymV21CompatibilityV0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shimmy/openai_gym_compatibility.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env_id, make_kwargs, env, render_mode)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;34m\"Either env_id or env must be provided to create a legacy gym environment.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             )\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/shimmy/openai_gym_compatibility.py\u001b[0m in \u001b[0;36m_convert_space\u001b[0;34m(space)\u001b[0m\n\u001b[1;32m    331\u001b[0m         )\n\u001b[1;32m    332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         raise NotImplementedError(\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0;34mf\"Cannot convert space of type {space}. Please upgrade your code to gymnasium.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         )\n","\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert space of type Dict('role': Discrete(10), 'scores': Box(0.0, 1.0, (3,), float32)). Please upgrade your code to gymnasium."],"ename":"NotImplementedError","evalue":"Cannot convert space of type Dict('role': Discrete(10), 'scores': Box(0.0, 1.0, (3,), float32)). Please upgrade your code to gymnasium.","output_type":"error"}],"execution_count":192},{"cell_type":"code","source":"class SimpleRoleThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, n_roles=10):\n        self.anomaly_scores = anomaly_scores\n        self.roles = np.argmax(roles_expanded, axis=1)  # Convert to role IDs 0-9\n        self.users = users\n        self.n_roles = n_roles\n        \n        # Initialize thresholds per role\n        self.role_thresholds = np.ones(n_roles) * 0.5\n        \n        # Action space: threshold adjustment [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # Simplified observation: [current_score, rolling_mean, rolling_std, role_id_normalized]\n        self.observation_space = spaces.Box(\n            low=np.array([0, 0, 0, 0]),\n            high=np.array([1, 1, 1, 1]),\n            dtype=np.float32\n        )\n        \n        self.current_step = 0\n        self.user_history = {}\n\n    def _get_rolling_stats(self, user):\n        if user not in self.user_history:\n            self.user_history[user] = []\n        \n        scores = self.user_history[user]\n        if len(scores) > 7:\n            scores.pop(0)\n        \n        mean = np.mean(scores) if scores else 0\n        std = np.std(scores) if scores else 0\n        return mean, std\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = {}\n        return self._get_state()\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        role = self.roles[self.current_step]\n        \n        # Update rolling stats\n        current_score = self.anomaly_scores[self.current_step]\n        if user in self.user_history:\n            self.user_history[user].append(current_score)\n        else:\n            self.user_history[user] = [current_score]\n        \n        mean, std = self._get_rolling_stats(user)\n        \n        # Normalize role ID to [0,1]\n        normalized_role = role / (self.n_roles - 1)\n        \n        return np.array([\n            current_score,\n            mean,\n            std,\n            normalized_role\n        ], dtype=np.float32)\n\n    def step(self, action):\n        role = self.roles[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role] = np.clip(\n            self.role_thresholds[role] + action[0],\n            0.1, 0.9\n        )\n        \n        # Get prediction\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role])\n        \n        # Simple reward\n        reward = 10 if pred else -1\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {}\n\n# Initialize and train\nenv = SimpleRoleThresholdEnv(\n    anomaly_scores=anomaly_scores,\n    roles_expanded=roles_expanded,\n    users=users\n)\n\n# Wrap for Stable Baselines3\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nenv = DummyVecEnv([lambda: env])\n\n# Train with MlpPolicy (now compatible)\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(net_arch=[64, 64]),\n    verbose=1\n)\nmodel.learn(total_timesteps=100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:00:01.868997Z","iopub.execute_input":"2025-05-05T18:00:01.869763Z","iopub.status.idle":"2025-05-05T18:03:02.26707Z","shell.execute_reply.started":"2025-05-05T18:00:01.869737Z","shell.execute_reply":"2025-05-05T18:03:02.266349Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gym/spaces/box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n","output_type":"stream"},{"name":"stdout","text":"Using cuda device\n-----------------------------\n| time/              |      |\n|    fps             | 834  |\n|    iterations      | 1    |\n|    time_elapsed    | 2    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 661         |\n|    iterations           | 2           |\n|    time_elapsed         | 6           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.010689353 |\n|    clip_fraction        | 0.0543      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.42       |\n|    explained_variance   | 0.000554    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 16.9        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.00295    |\n|    std                  | 0.996       |\n|    value_loss           | 161         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 624          |\n|    iterations           | 3            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 6144         |\n| train/                  |              |\n|    approx_kl            | 0.0013777821 |\n|    clip_fraction        | 0.000439     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.207        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 13.4         |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.000423    |\n|    std                  | 0.977        |\n|    value_loss           | 100          |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 604         |\n|    iterations           | 4           |\n|    time_elapsed         | 13          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.001969167 |\n|    clip_fraction        | 0.00161     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | -0.00943    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 18.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.000598   |\n|    std                  | 0.986       |\n|    value_loss           | 96.4        |\n-----------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 595           |\n|    iterations           | 5             |\n|    time_elapsed         | 17            |\n|    total_timesteps      | 10240         |\n| train/                  |               |\n|    approx_kl            | 0.00095104345 |\n|    clip_fraction        | 0.000781      |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.41         |\n|    explained_variance   | 0.0658        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 14.7          |\n|    n_updates            | 40            |\n|    policy_gradient_loss | -0.000386     |\n|    std                  | 1             |\n|    value_loss           | 79.4          |\n-------------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 587        |\n|    iterations           | 6          |\n|    time_elapsed         | 20         |\n|    total_timesteps      | 12288      |\n| train/                  |            |\n|    approx_kl            | 0.00577779 |\n|    clip_fraction        | 0.0178     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.42      |\n|    explained_variance   | -0.0165    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 9.76       |\n|    n_updates            | 50         |\n|    policy_gradient_loss | -0.00216   |\n|    std                  | 0.993      |\n|    value_loss           | 62.4       |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 583         |\n|    iterations           | 7           |\n|    time_elapsed         | 24          |\n|    total_timesteps      | 14336       |\n| train/                  |             |\n|    approx_kl            | 0.005690049 |\n|    clip_fraction        | 0.01        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.0172      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 5.99        |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.00155    |\n|    std                  | 0.997       |\n|    value_loss           | 47.6        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 581          |\n|    iterations           | 8            |\n|    time_elapsed         | 28           |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0023576533 |\n|    clip_fraction        | 0.000635     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.42        |\n|    explained_variance   | -0.00484     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 3.1          |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.000413    |\n|    std                  | 0.995        |\n|    value_loss           | 34.9         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 577         |\n|    iterations           | 9           |\n|    time_elapsed         | 31          |\n|    total_timesteps      | 18432       |\n| train/                  |             |\n|    approx_kl            | 0.002112843 |\n|    clip_fraction        | 0.00244     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.42       |\n|    explained_variance   | -0.00117    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.09        |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.000598   |\n|    std                  | 0.991       |\n|    value_loss           | 24.3        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 574          |\n|    iterations           | 10           |\n|    time_elapsed         | 35           |\n|    total_timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0037013157 |\n|    clip_fraction        | 0.0185       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | -0.000782    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.312        |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.000979    |\n|    std                  | 0.983        |\n|    value_loss           | 15.8         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 573          |\n|    iterations           | 11           |\n|    time_elapsed         | 39           |\n|    total_timesteps      | 22528        |\n| train/                  |              |\n|    approx_kl            | 0.0068305833 |\n|    clip_fraction        | 0.0388       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.39        |\n|    explained_variance   | -0.00447     |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00509     |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00379     |\n|    std                  | 0.947        |\n|    value_loss           | 9.48         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 572          |\n|    iterations           | 12           |\n|    time_elapsed         | 42           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0038105743 |\n|    clip_fraction        | 0.00625      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.36        |\n|    explained_variance   | -0.00471     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.245        |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.000267    |\n|    std                  | 0.938        |\n|    value_loss           | 5.85         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 570         |\n|    iterations           | 13          |\n|    time_elapsed         | 46          |\n|    total_timesteps      | 26624       |\n| train/                  |             |\n|    approx_kl            | 0.007087893 |\n|    clip_fraction        | 0.00996     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | -0.00262    |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0032     |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.000675   |\n|    std                  | 0.922       |\n|    value_loss           | 3.59        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 570          |\n|    iterations           | 14           |\n|    time_elapsed         | 50           |\n|    total_timesteps      | 28672        |\n| train/                  |              |\n|    approx_kl            | 0.0077462215 |\n|    clip_fraction        | 0.0438       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.34        |\n|    explained_variance   | 0.00627      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00101      |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.0025      |\n|    std                  | 0.915        |\n|    value_loss           | 1.99         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 569         |\n|    iterations           | 15          |\n|    time_elapsed         | 53          |\n|    total_timesteps      | 30720       |\n| train/                  |             |\n|    approx_kl            | 0.004374181 |\n|    clip_fraction        | 0.00801     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.0666      |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00331    |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.000523   |\n|    std                  | 0.904       |\n|    value_loss           | 1.16        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 16           |\n|    time_elapsed         | 57           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0061481483 |\n|    clip_fraction        | 0.0243       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.32        |\n|    explained_variance   | 0.0103       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.0144       |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.00066     |\n|    std                  | 0.909        |\n|    value_loss           | 0.658        |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 567           |\n|    iterations           | 17            |\n|    time_elapsed         | 61            |\n|    total_timesteps      | 34816         |\n| train/                  |               |\n|    approx_kl            | 0.00042263363 |\n|    clip_fraction        | 0.00894       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.33         |\n|    explained_variance   | -0.00952      |\n|    learning_rate        | 0.0003        |\n|    loss                 | 0.00268       |\n|    n_updates            | 160           |\n|    policy_gradient_loss | 1.94e-05      |\n|    std                  | 0.922         |\n|    value_loss           | 0.38          |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 565          |\n|    iterations           | 18           |\n|    time_elapsed         | 65           |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0067680604 |\n|    clip_fraction        | 0.0662       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.34        |\n|    explained_variance   | -0.00348     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.92e-05     |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.00238     |\n|    std                  | 0.915        |\n|    value_loss           | 0.228        |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 565         |\n|    iterations           | 19          |\n|    time_elapsed         | 68          |\n|    total_timesteps      | 38912       |\n| train/                  |             |\n|    approx_kl            | 0.001499886 |\n|    clip_fraction        | 0.00396     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.015      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00198     |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.000505   |\n|    std                  | 0.898       |\n|    value_loss           | 0.129       |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 565         |\n|    iterations           | 20          |\n|    time_elapsed         | 72          |\n|    total_timesteps      | 40960       |\n| train/                  |             |\n|    approx_kl            | 0.005870703 |\n|    clip_fraction        | 0.0295      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | 0.013       |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00211    |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.00183    |\n|    std                  | 0.895       |\n|    value_loss           | 0.0749      |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 564          |\n|    iterations           | 21           |\n|    time_elapsed         | 76           |\n|    total_timesteps      | 43008        |\n| train/                  |              |\n|    approx_kl            | 0.0053785406 |\n|    clip_fraction        | 0.022        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.3         |\n|    explained_variance   | -0.00237     |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00679     |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00061     |\n|    std                  | 0.882        |\n|    value_loss           | 0.045        |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 564          |\n|    iterations           | 22           |\n|    time_elapsed         | 79           |\n|    total_timesteps      | 45056        |\n| train/                  |              |\n|    approx_kl            | 0.0039923564 |\n|    clip_fraction        | 0.0233       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | -0.0163      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00598      |\n|    n_updates            | 210          |\n|    policy_gradient_loss | -0.00183     |\n|    std                  | 0.862        |\n|    value_loss           | 0.0263       |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 564         |\n|    iterations           | 23          |\n|    time_elapsed         | 83          |\n|    total_timesteps      | 47104       |\n| train/                  |             |\n|    approx_kl            | 0.001186524 |\n|    clip_fraction        | 0.000928    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | -0.00144    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00105     |\n|    n_updates            | 220         |\n|    policy_gradient_loss | 0.000132    |\n|    std                  | 0.863       |\n|    value_loss           | 0.0161      |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 564          |\n|    iterations           | 24           |\n|    time_elapsed         | 87           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0032586483 |\n|    clip_fraction        | 0.00474      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | -0.0118      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00586      |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00023     |\n|    std                  | 0.854        |\n|    value_loss           | 0.00946      |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 564          |\n|    iterations           | 25           |\n|    time_elapsed         | 90           |\n|    total_timesteps      | 51200        |\n| train/                  |              |\n|    approx_kl            | 0.0073491083 |\n|    clip_fraction        | 0.0571       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | 0.0525       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.0163       |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.0018      |\n|    std                  | 0.855        |\n|    value_loss           | 0.00594      |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 563          |\n|    iterations           | 26           |\n|    time_elapsed         | 94           |\n|    total_timesteps      | 53248        |\n| train/                  |              |\n|    approx_kl            | 0.0020276727 |\n|    clip_fraction        | 0.00317      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | 0.01         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00507      |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -8.86e-05    |\n|    std                  | 0.849        |\n|    value_loss           | 0.00366      |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 563          |\n|    iterations           | 27           |\n|    time_elapsed         | 98           |\n|    total_timesteps      | 55296        |\n| train/                  |              |\n|    approx_kl            | 0.0038360301 |\n|    clip_fraction        | 0.0156       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | -0.00367     |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00357     |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.000979    |\n|    std                  | 0.849        |\n|    value_loss           | 0.00237      |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 563         |\n|    iterations           | 28          |\n|    time_elapsed         | 101         |\n|    total_timesteps      | 57344       |\n| train/                  |             |\n|    approx_kl            | 0.005599533 |\n|    clip_fraction        | 0.0541      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.0213     |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.00753    |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.00268    |\n|    std                  | 0.84        |\n|    value_loss           | 0.00153     |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 563          |\n|    iterations           | 29           |\n|    time_elapsed         | 105          |\n|    total_timesteps      | 59392        |\n| train/                  |              |\n|    approx_kl            | 0.0049522473 |\n|    clip_fraction        | 0.0345       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | 0.0221       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00365      |\n|    n_updates            | 280          |\n|    policy_gradient_loss | -0.00252     |\n|    std                  | 0.826        |\n|    value_loss           | 0.00101      |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 563           |\n|    iterations           | 30            |\n|    time_elapsed         | 109           |\n|    total_timesteps      | 61440         |\n| train/                  |               |\n|    approx_kl            | 0.00040063917 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.23         |\n|    explained_variance   | 0.00208       |\n|    learning_rate        | 0.0003        |\n|    loss                 | 0.00162       |\n|    n_updates            | 290           |\n|    policy_gradient_loss | -0.000106     |\n|    std                  | 0.824         |\n|    value_loss           | 0.000646      |\n-------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 563         |\n|    iterations           | 31          |\n|    time_elapsed         | 112         |\n|    total_timesteps      | 63488       |\n| train/                  |             |\n|    approx_kl            | 0.006263599 |\n|    clip_fraction        | 0.0149      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.000193   |\n|    learning_rate        | 0.0003      |\n|    loss                 | -0.0172     |\n|    n_updates            | 300         |\n|    policy_gradient_loss | -0.000984   |\n|    std                  | 0.807       |\n|    value_loss           | 0.000452    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 562          |\n|    iterations           | 32           |\n|    time_elapsed         | 116          |\n|    total_timesteps      | 65536        |\n| train/                  |              |\n|    approx_kl            | 0.0052199233 |\n|    clip_fraction        | 0.0233       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | -0.00269     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.0034       |\n|    n_updates            | 310          |\n|    policy_gradient_loss | -0.000472    |\n|    std                  | 0.806        |\n|    value_loss           | 0.000304     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 562          |\n|    iterations           | 33           |\n|    time_elapsed         | 120          |\n|    total_timesteps      | 67584        |\n| train/                  |              |\n|    approx_kl            | 0.0025628307 |\n|    clip_fraction        | 0.0157       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.19        |\n|    explained_variance   | 0.016        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00623     |\n|    n_updates            | 320          |\n|    policy_gradient_loss | -0.00121     |\n|    std                  | 0.793        |\n|    value_loss           | 0.000206     |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 562         |\n|    iterations           | 34          |\n|    time_elapsed         | 123         |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.001426686 |\n|    clip_fraction        | 0.0064      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.19       |\n|    explained_variance   | 0.00741     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.00301     |\n|    n_updates            | 330         |\n|    policy_gradient_loss | 5.27e-05    |\n|    std                  | 0.793       |\n|    value_loss           | 0.000147    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 561         |\n|    iterations           | 35          |\n|    time_elapsed         | 127         |\n|    total_timesteps      | 71680       |\n| train/                  |             |\n|    approx_kl            | 0.008168194 |\n|    clip_fraction        | 0.0725      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.18       |\n|    explained_variance   | 0.0247      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.000734    |\n|    n_updates            | 340         |\n|    policy_gradient_loss | -0.00242    |\n|    std                  | 0.778       |\n|    value_loss           | 9.81e-05    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 562          |\n|    iterations           | 36           |\n|    time_elapsed         | 131          |\n|    total_timesteps      | 73728        |\n| train/                  |              |\n|    approx_kl            | 0.0050990833 |\n|    clip_fraction        | 0.0492       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.16        |\n|    explained_variance   | 0.0114       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00136      |\n|    n_updates            | 350          |\n|    policy_gradient_loss | -0.00189     |\n|    std                  | 0.775        |\n|    value_loss           | 7.08e-05     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 37           |\n|    time_elapsed         | 134          |\n|    total_timesteps      | 75776        |\n| train/                  |              |\n|    approx_kl            | 0.0055448236 |\n|    clip_fraction        | 0.0368       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.16        |\n|    explained_variance   | -0.0387      |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00538     |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.00192     |\n|    std                  | 0.762        |\n|    value_loss           | 4.88e-05     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 38           |\n|    time_elapsed         | 138          |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0058573866 |\n|    clip_fraction        | 0.0265       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 0.563        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00136      |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.00134     |\n|    std                  | 0.754        |\n|    value_loss           | 3.84e-05     |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 561           |\n|    iterations           | 39            |\n|    time_elapsed         | 142           |\n|    total_timesteps      | 79872         |\n| train/                  |               |\n|    approx_kl            | 0.00031095382 |\n|    clip_fraction        | 9.77e-05      |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.14         |\n|    explained_variance   | 0.152         |\n|    learning_rate        | 0.0003        |\n|    loss                 | -0.000947     |\n|    n_updates            | 380           |\n|    policy_gradient_loss | -0.000167     |\n|    std                  | 0.754         |\n|    value_loss           | 2.3e-05       |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 40           |\n|    time_elapsed         | 145          |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0058421222 |\n|    clip_fraction        | 0.0247       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.12        |\n|    explained_variance   | 0.375        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00645      |\n|    n_updates            | 390          |\n|    policy_gradient_loss | -0.00169     |\n|    std                  | 0.734        |\n|    value_loss           | 1.78e-05     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 41           |\n|    time_elapsed         | 149          |\n|    total_timesteps      | 83968        |\n| train/                  |              |\n|    approx_kl            | 0.0010856797 |\n|    clip_fraction        | 0.00884      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.1         |\n|    explained_variance   | 0.308        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00271     |\n|    n_updates            | 400          |\n|    policy_gradient_loss | -0.000867    |\n|    std                  | 0.727        |\n|    value_loss           | 1.19e-05     |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 561         |\n|    iterations           | 42          |\n|    time_elapsed         | 153         |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.005208211 |\n|    clip_fraction        | 0.0315      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.235       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.0015      |\n|    n_updates            | 410         |\n|    policy_gradient_loss | -0.002      |\n|    std                  | 0.712       |\n|    value_loss           | 7.97e-06    |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 43           |\n|    time_elapsed         | 156          |\n|    total_timesteps      | 88064        |\n| train/                  |              |\n|    approx_kl            | 0.0016996387 |\n|    clip_fraction        | 0.0106       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.07        |\n|    explained_variance   | 0.182        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00209     |\n|    n_updates            | 420          |\n|    policy_gradient_loss | -0.000683    |\n|    std                  | 0.702        |\n|    value_loss           | 5.5e-06      |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 44           |\n|    time_elapsed         | 160          |\n|    total_timesteps      | 90112        |\n| train/                  |              |\n|    approx_kl            | 0.0021794692 |\n|    clip_fraction        | 0.0221       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.403        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00489     |\n|    n_updates            | 430          |\n|    policy_gradient_loss | -0.00118     |\n|    std                  | 0.697        |\n|    value_loss           | 4.9e-06      |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 560          |\n|    iterations           | 45           |\n|    time_elapsed         | 164          |\n|    total_timesteps      | 92160        |\n| train/                  |              |\n|    approx_kl            | 0.0015045059 |\n|    clip_fraction        | 0.0062       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.06        |\n|    explained_variance   | 0.448        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00402     |\n|    n_updates            | 440          |\n|    policy_gradient_loss | -0.000809    |\n|    std                  | 0.704        |\n|    value_loss           | 3.31e-06     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 560          |\n|    iterations           | 46           |\n|    time_elapsed         | 167          |\n|    total_timesteps      | 94208        |\n| train/                  |              |\n|    approx_kl            | 0.0029814523 |\n|    clip_fraction        | 0.011        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.07        |\n|    explained_variance   | -0.0813      |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.000758    |\n|    n_updates            | 450          |\n|    policy_gradient_loss | -0.000596    |\n|    std                  | 0.703        |\n|    value_loss           | 1.93e-06     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 560          |\n|    iterations           | 47           |\n|    time_elapsed         | 171          |\n|    total_timesteps      | 96256        |\n| train/                  |              |\n|    approx_kl            | 0.0032139607 |\n|    clip_fraction        | 0.0292       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.07        |\n|    explained_variance   | -0.302       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.00208      |\n|    n_updates            | 460          |\n|    policy_gradient_loss | -0.00111     |\n|    std                  | 0.706        |\n|    value_loss           | 2.71e-06     |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 560           |\n|    iterations           | 48            |\n|    time_elapsed         | 175           |\n|    total_timesteps      | 98304         |\n| train/                  |               |\n|    approx_kl            | 0.00021938875 |\n|    clip_fraction        | 0.000342      |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.08         |\n|    explained_variance   | 0.305         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 0.000598      |\n|    n_updates            | 470           |\n|    policy_gradient_loss | 0.000106      |\n|    std                  | 0.712         |\n|    value_loss           | 1.14e-06      |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 560          |\n|    iterations           | 49           |\n|    time_elapsed         | 179          |\n|    total_timesteps      | 100352       |\n| train/                  |              |\n|    approx_kl            | 0.0027057966 |\n|    clip_fraction        | 0.00669      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.08        |\n|    explained_variance   | 0.673        |\n|    learning_rate        | 0.0003       |\n|    loss                 | -0.00444     |\n|    n_updates            | 480          |\n|    policy_gradient_loss | -0.00084     |\n|    std                  | 0.72         |\n|    value_loss           | 2.73e-06     |\n------------------------------------------\n","output_type":"stream"},{"execution_count":193,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7ec73c5a6750>"},"metadata":{}}],"execution_count":193},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(env.envs[0].role_thresholds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:03:18.44807Z","iopub.execute_input":"2025-05-05T18:03:18.448347Z","iopub.status.idle":"2025-05-05T18:03:18.452796Z","shell.execute_reply.started":"2025-05-05T18:03:18.448326Z","shell.execute_reply":"2025-05-05T18:03:18.451971Z"}},"outputs":[{"name":"stdout","text":"[0.1        0.8        0.9        0.14621422 0.5        0.5\n 0.5        0.5        0.5        0.5       ]\n","output_type":"stream"}],"execution_count":194},{"cell_type":"code","source":"print(env.envs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:22:45.928759Z","iopub.execute_input":"2025-05-05T18:22:45.929167Z","iopub.status.idle":"2025-05-05T18:22:45.933954Z","shell.execute_reply.started":"2025-05-05T18:22:45.929138Z","shell.execute_reply":"2025-05-05T18:22:45.93305Z"}},"outputs":[{"name":"stdout","text":"[<GymV21CompatibilityV0<SimpleRoleThresholdEnv instance>>]\n","output_type":"stream"}],"execution_count":199},{"cell_type":"code","source":"print(env.envs[0].unwrapped)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:24:04.288749Z","iopub.execute_input":"2025-05-05T18:24:04.289092Z","iopub.status.idle":"2025-05-05T18:24:04.293706Z","shell.execute_reply.started":"2025-05-05T18:24:04.289016Z","shell.execute_reply":"2025-05-05T18:24:04.292883Z"}},"outputs":[{"name":"stdout","text":"<GymV21CompatibilityV0<SimpleRoleThresholdEnv instance>>\n","output_type":"stream"}],"execution_count":202},{"cell_type":"code","source":"print(env.envs[0].unwrapped.__dict__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:24:50.953409Z","iopub.execute_input":"2025-05-05T18:24:50.953678Z","iopub.status.idle":"2025-05-05T18:24:50.957934Z","shell.execute_reply.started":"2025-05-05T18:24:50.953658Z","shell.execute_reply":"2025-05-05T18:24:50.957167Z"}},"outputs":[{"name":"stdout","text":"{'observation_space': Box(0.0, 1.0, (4,), float32), 'action_space': Box(-0.1, 0.1, (1,), float32), 'metadata': {'render_modes': []}, 'render_mode': None, 'reward_range': (-inf, inf), 'spec': None, 'gym_env': <__main__.SimpleRoleThresholdEnv object at 0x7ec73c5a63d0>}\n","output_type":"stream"}],"execution_count":203},{"cell_type":"markdown","source":"ppo ","metadata":{}},{"cell_type":"code","source":"class RoleWeightedThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, is_anomaly):\n        # Normalize and store data\n        self.anomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())\n        self.users = users\n        self.is_anomaly = is_anomaly.flatten()\n        self.roles_expanded = roles_expanded\n\n        # Convert roles to integer IDs\n        self.role_ids = np.sum(roles_expanded * (2 ** np.arange(4)), axis=1)\n        unique_roles = np.unique(self.role_ids)\n        self.num_roles = len(unique_roles)\n        self.role_to_idx = {role: idx for idx, role in enumerate(unique_roles)}\n        \n        # Calculate role weights\n        self.role_weights = self._calculate_role_weights()\n        \n        # Initialize thresholds\n        self.role_thresholds = np.ones(self.num_roles) * 0.5\n        \n        # Action space\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # Observation space\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32),\n            \"role\": spaces.Box(low=0, high=1, shape=(self.num_roles,), dtype=np.float32)\n        })\n        \n        # Trackers\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _calculate_role_weights(self):\n        df = pd.DataFrame({'role': self.role_ids, 'is_anomaly': self.is_anomaly})\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        return (anomaly_rates / anomaly_rates.max() * 2.0).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"scores\": np.zeros(3, dtype=np.float32),\n                \"role\": np.zeros(self.num_roles, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        \n        # One-hot encode role\n        role_one_hot = np.zeros(self.num_roles, dtype=np.float32)\n        role_one_hot[self.role_to_idx[role_id]] = 1.0\n        \n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_one_hot\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        role_idx = self.role_to_idx[role_id]\n        \n        # Update threshold\n        self.role_thresholds[role_idx] = np.clip(\n            self.role_thresholds[role_idx] + action[0], \n            0.1, 0.9\n        )\n        \n        # Get prediction and reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_idx])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_idx]\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label == 1:  # Anomaly\n            return 50.0 * weight if pred == 1 else -100.0 * weight\n        else:                # Normal\n            return 0.1 if pred == 0 else -2.0 / weight\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n        self.role_thresholds = np.ones(self.num_roles) * 0.5\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:49:54.289906Z","iopub.execute_input":"2025-05-05T18:49:54.290271Z","iopub.status.idle":"2025-05-05T18:49:54.413083Z","shell.execute_reply.started":"2025-05-05T18:49:54.290246Z","shell.execute_reply":"2025-05-05T18:49:54.412272Z"}},"outputs":[],"execution_count":219},{"cell_type":"code","source":"env = RoleWeightedThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly)\nenv = make_vec_env(lambda: env, n_envs=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:50:06.191167Z","iopub.execute_input":"2025-05-05T18:50:06.191738Z","iopub.status.idle":"2025-05-05T18:50:06.220633Z","shell.execute_reply.started":"2025-05-05T18:50:06.191715Z","shell.execute_reply":"2025-05-05T18:50:06.219858Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":220},{"cell_type":"code","source":"model = PPO(\n    \"MultiInputPolicy\",\n    env,\n    verbose=1,\n    learning_rate=3e-4,\n    n_steps=1024,\n    batch_size=64,\n    n_epochs=10,\n    gamma=0.99,\n    policy_kwargs={\n        \"net_arch\": {\n            \"pi\": [64, 64],\n            \"vf\": [64, 64]\n        }\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:50:17.014575Z","iopub.execute_input":"2025-05-05T18:50:17.015175Z","iopub.status.idle":"2025-05-05T18:50:17.024433Z","shell.execute_reply.started":"2025-05-05T18:50:17.015154Z","shell.execute_reply":"2025-05-05T18:50:17.023773Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}],"execution_count":221},{"cell_type":"code","source":"model.learn(total_timesteps=10_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:50:30.32979Z","iopub.execute_input":"2025-05-05T18:50:30.33053Z","iopub.status.idle":"2025-05-05T18:50:49.634111Z","shell.execute_reply.started":"2025-05-05T18:50:30.330505Z","shell.execute_reply":"2025-05-05T18:50:49.633519Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/gym/core.py:256: DeprecationWarning: \u001b[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001b[0m\n  deprecation(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 788  |\n|    iterations      | 1    |\n|    time_elapsed    | 1    |\n|    total_timesteps | 1024 |\n-----------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 631          |\n|    iterations           | 2            |\n|    time_elapsed         | 3            |\n|    total_timesteps      | 2048         |\n| train/                  |              |\n|    approx_kl            | 0.0028274548 |\n|    clip_fraction        | 0.0213       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | -0.00226     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 987          |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.0069      |\n|    std                  | 0.984        |\n|    value_loss           | 2.87e+03     |\n------------------------------------------\n---------------------------------------\n| time/                   |           |\n|    fps                  | 589       |\n|    iterations           | 3         |\n|    time_elapsed         | 5         |\n|    total_timesteps      | 3072      |\n| train/                  |           |\n|    approx_kl            | 0.0138543 |\n|    clip_fraction        | 0.058     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.4      |\n|    explained_variance   | -0.01     |\n|    learning_rate        | 0.0003    |\n|    loss                 | 31.3      |\n|    n_updates            | 20        |\n|    policy_gradient_loss | -0.00168  |\n|    std                  | 0.984     |\n|    value_loss           | 1.27e+03  |\n---------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 573           |\n|    iterations           | 4             |\n|    time_elapsed         | 7             |\n|    total_timesteps      | 4096          |\n| train/                  |               |\n|    approx_kl            | 0.00015656679 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.4          |\n|    explained_variance   | -0.00144      |\n|    learning_rate        | 0.0003        |\n|    loss                 | 1.5e+04       |\n|    n_updates            | 30            |\n|    policy_gradient_loss | -0.000893     |\n|    std                  | 0.985         |\n|    value_loss           | 4.54e+04      |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 564          |\n|    iterations           | 5            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 5120         |\n| train/                  |              |\n|    approx_kl            | 0.0074024005 |\n|    clip_fraction        | 0.086        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.103        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 6.43         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0104      |\n|    std                  | 1            |\n|    value_loss           | 12.6         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 559          |\n|    iterations           | 6            |\n|    time_elapsed         | 10           |\n|    total_timesteps      | 6144         |\n| train/                  |              |\n|    approx_kl            | 0.0059320424 |\n|    clip_fraction        | 0.0176       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.42        |\n|    explained_variance   | 0.226        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 59.1         |\n|    n_updates            | 50           |\n|    policy_gradient_loss | -0.00548     |\n|    std                  | 1            |\n|    value_loss           | 140          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 556          |\n|    iterations           | 7            |\n|    time_elapsed         | 12           |\n|    total_timesteps      | 7168         |\n| train/                  |              |\n|    approx_kl            | 0.0027624548 |\n|    clip_fraction        | 0.0143       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.43        |\n|    explained_variance   | 0.776        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.841        |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.00122     |\n|    std                  | 1.02         |\n|    value_loss           | 3.14         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 553         |\n|    iterations           | 8           |\n|    time_elapsed         | 14          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.007998321 |\n|    clip_fraction        | 0.0408      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.43       |\n|    explained_variance   | 0.853       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.29        |\n|    n_updates            | 70          |\n|    policy_gradient_loss | -0.00364    |\n|    std                  | 0.995       |\n|    value_loss           | 2.84        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 550         |\n|    iterations           | 9           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 9216        |\n| train/                  |             |\n|    approx_kl            | 0.012122726 |\n|    clip_fraction        | 0.13        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.452       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.86        |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.0125     |\n|    std                  | 0.992       |\n|    value_loss           | 5.73        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 549         |\n|    iterations           | 10          |\n|    time_elapsed         | 18          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.007890549 |\n|    clip_fraction        | 0.0558      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.424       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 3.56        |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.00416    |\n|    std                  | 0.977       |\n|    value_loss           | 7.79        |\n-----------------------------------------\n","output_type":"stream"},{"execution_count":222,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7ec73c5c8bd0>"},"metadata":{}}],"execution_count":222},{"cell_type":"code","source":"model.save('ppo_rolebased.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:03:18.34666Z","iopub.execute_input":"2025-05-05T19:03:18.347259Z","iopub.status.idle":"2025-05-05T19:03:18.359493Z","shell.execute_reply.started":"2025-05-05T19:03:18.347237Z","shell.execute_reply":"2025-05-05T19:03:18.358928Z"}},"outputs":[],"execution_count":227},{"cell_type":"code","source":"obs = env.reset()\nfor _ in range(1000):\n    action, _ = model.predict(obs, deterministic=True)\n    obs, reward, done, info = env.step(action)\n    print(f\"Step {_}: Role={info[0]['role']}, Threshold={info[0]['threshold']:.3f}, Reward={reward[0]:.1f}\")\n    if done:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:54:07.979673Z","iopub.execute_input":"2025-05-05T18:54:07.979937Z","iopub.status.idle":"2025-05-05T18:54:08.869619Z","shell.execute_reply.started":"2025-05-05T18:54:07.979921Z","shell.execute_reply":"2025-05-05T18:54:08.869037Z"}},"outputs":[{"name":"stdout","text":"Step None: Role=8, Threshold=0.600, Reward=0.1\nStep None: Role=8, Threshold=0.700, Reward=0.1\nStep None: Role=8, Threshold=0.800, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=8, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.600, Reward=0.1\nStep None: Role=4, Threshold=0.700, Reward=0.1\nStep None: Role=4, Threshold=0.800, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=-88.8\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=4, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.600, Reward=0.1\nStep None: Role=12, Threshold=0.700, Reward=0.1\nStep None: Role=12, Threshold=0.800, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=12, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.600, Reward=0.1\nStep None: Role=2, Threshold=0.700, Reward=0.1\nStep None: Role=2, Threshold=0.800, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\nStep None: Role=2, Threshold=0.900, Reward=0.1\n","output_type":"stream"}],"execution_count":226},{"cell_type":"markdown","source":"improved trial","metadata":{}},{"cell_type":"code","source":"class BitRoleThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_bit_encoded, users, is_anomaly):\n        # Data normalization with epsilon handling\n        self.anomaly_scores = self._normalize_scores(anomaly_scores)\n        self.users = users\n        self.is_anomaly = is_anomaly.flatten()\n        \n        # Store original 4-bit role encoding\n        self.roles_bit_encoded = roles_bit_encoded.astype(np.float32)  # (n_samples, 4)\n        \n        # Convert 4-bit roles to integer IDs (your exact method)\n        self.role_ids = np.sum(roles_bit_encoded * (2 ** np.arange(4)), axis=1)\n        self.unique_roles = np.unique(self.role_ids)\n        self.num_roles = len(self.unique_roles)\n        self.role_to_idx = {role: idx for idx, role in enumerate(self.unique_roles)}\n        \n        # Enhanced role weighting\n        self.role_weights = self._calculate_role_weights()\n        \n        # Initialize thresholds with role-wise variation\n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles)\n        \n        # Action space with smaller steps\n        self.action_space = spaces.Box(low=-0.05, high=0.05, shape=(1,), dtype=np.float32)\n        \n        # Observation space using raw bits\n        self.observation_space = spaces.Dict({\n            \"current_score\": spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n            \"user_stats\": spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32),\n            \"role_bits\": spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)  # Raw 4 bits\n        })\n        \n        # Tracking\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n\n    def _normalize_scores(self, scores):\n        \"\"\"Robust normalization handling edge cases\"\"\"\n        min_score, max_score = scores.min(), scores.max()\n        range_score = max_score - min_score\n        if range_score < 1e-6:  # Handle constant scores\n            return np.zeros_like(scores)\n        return (scores - min_score) / range_score\n\n    def _calculate_role_weights(self):\n        \"\"\"Enhanced weight calculation considering both anomaly rate and population size\"\"\"\n        df = pd.DataFrame({\n            'role': self.role_ids,\n            'is_anomaly': self.is_anomaly,\n            'user': self.users\n        })\n        \n        # Calculate anomaly prevalence and user count per role\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        user_counts = df.groupby('role')['user'].nunique()\n        \n        # Combine factors with logarithmic scaling\n        weights = anomaly_rates * np.log(user_counts + 1)\n        return (weights / weights.max()).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"current_score\": np.array([0], dtype=np.float32),\n                \"user_stats\": np.array([0, 0], dtype=np.float32),\n                \"role_bits\": np.zeros(4, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        current_score = self.anomaly_scores[self.current_step]\n        \n        # Update user history\n        hist = self.user_history[user]\n        hist['scores'].append(current_score)\n        if len(hist['scores']) > 7:  # 1-week window\n            hist['scores'].pop(0)\n        \n        # Track anomalies\n        if self.is_anomaly[self.current_step]:\n            hist['last_anomaly'] = self.current_step\n            self.global_last_anomaly = self.current_step\n        \n        # Get the 4 role bits exactly as they were input\n        role_bits = self.roles_bit_encoded[self.current_step]\n        \n        return {\n            \"current_score\": np.array([current_score], dtype=np.float32),\n            \"user_stats\": np.array([\n                np.mean(hist['scores']) if hist['scores'] else 0,\n                np.std(hist['scores']) if len(hist['scores']) > 1 else 0\n            ], dtype=np.float32),\n            \"role_bits\": role_bits\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        role_idx = self.role_to_idx[role_id]\n        \n        # Role-weighted threshold adjustment\n        learning_rate = 0.05 * self.role_weights.get(role_id, 1.0)\n        self.role_thresholds[role_idx] = np.clip(\n            self.role_thresholds[role_idx] + action[0] * learning_rate,\n            0.1, 0.9\n        )\n        \n        # Get prediction and balanced reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_idx])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_idx],\n            \"true_label\": self.is_anomaly[self.current_step - 1],\n            \"prediction\": pred\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        \"\"\"Balanced reward function optimized for F1 score\"\"\"\n        weight = self.role_weights.get(role_id, 1.0)\n        \n        if true_label and pred:   # True positive\n            return 15.0 * weight\n        elif true_label and not pred:  # False negative\n            return -20.0 * weight\n        elif not true_label and pred:  # False positive\n            return -3.0 / weight\n        else:  # True negative\n            return 1.0 / weight\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n        # Initialize thresholds with small random variation\n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles) * np.random.uniform(0.95, 1.05, self.num_roles)\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:31:00.305707Z","iopub.execute_input":"2025-05-05T19:31:00.306349Z","iopub.status.idle":"2025-05-05T19:31:00.321762Z","shell.execute_reply.started":"2025-05-05T19:31:00.306322Z","shell.execute_reply":"2025-05-05T19:31:00.321079Z"}},"outputs":[],"execution_count":246},{"cell_type":"code","source":"env = BitRoleThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_bit_encoded=roles_expanded,\n        users=users,\n        is_anomaly=is_anomaly\n    )\n    \n    # Wrap for vectorization (single env)\nenv = DummyVecEnv([lambda: env])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:34:56.425468Z","iopub.execute_input":"2025-05-05T19:34:56.426156Z","iopub.status.idle":"2025-05-05T19:34:56.50638Z","shell.execute_reply.started":"2025-05-05T19:34:56.426132Z","shell.execute_reply":"2025-05-05T19:34:56.505584Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":253},{"cell_type":"code","source":"model = PPO(\n        \"MultiInputPolicy\",  # Changed from \"MlpPolicy\"\n        env,\n        learning_rate=3e-4,\n        n_steps=1024,\n        batch_size=64,\n        n_epochs=10,\n        gamma=0.95,\n        verbose=1,\n        policy_kwargs={\n            \"net_arch\": [dict(pi=[64, 64], vf=[64, 64])]  # Optional custom network\n        }\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:36:13.665746Z","iopub.execute_input":"2025-05-05T19:36:13.666431Z","iopub.status.idle":"2025-05-05T19:36:13.71074Z","shell.execute_reply.started":"2025-05-05T19:36:13.666409Z","shell.execute_reply":"2025-05-05T19:36:13.710057Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n  warnings.warn(\n","output_type":"stream"}],"execution_count":256},{"cell_type":"code","source":"model.learn(total_timesteps=50_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:36:35.390591Z","iopub.execute_input":"2025-05-05T19:36:35.391099Z","iopub.status.idle":"2025-05-05T19:38:12.961419Z","shell.execute_reply.started":"2025-05-05T19:36:35.391069Z","shell.execute_reply":"2025-05-05T19:38:12.960763Z"}},"outputs":[{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 755  |\n|    iterations      | 1    |\n|    time_elapsed    | 1    |\n|    total_timesteps | 1024 |\n-----------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 611           |\n|    iterations           | 2             |\n|    time_elapsed         | 3             |\n|    total_timesteps      | 2048          |\n| train/                  |               |\n|    approx_kl            | 0.00066911784 |\n|    clip_fraction        | 0.000293      |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.41         |\n|    explained_variance   | 0.00897       |\n|    learning_rate        | 0.0003        |\n|    loss                 | 159           |\n|    n_updates            | 10            |\n|    policy_gradient_loss | -0.00106      |\n|    std                  | 0.991         |\n|    value_loss           | 355           |\n-------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 572         |\n|    iterations           | 3           |\n|    time_elapsed         | 5           |\n|    total_timesteps      | 3072        |\n| train/                  |             |\n|    approx_kl            | 0.005377024 |\n|    clip_fraction        | 0.0155      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | -0.0135     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.8        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00111    |\n|    std                  | 0.996       |\n|    value_loss           | 64.6        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 561          |\n|    iterations           | 4            |\n|    time_elapsed         | 7            |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0057085077 |\n|    clip_fraction        | 0.047        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.42        |\n|    explained_variance   | -0.0505      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 92.6         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.00476     |\n|    std                  | 1.01         |\n|    value_loss           | 216          |\n------------------------------------------\n---------------------------------------\n| time/                   |           |\n|    fps                  | 550       |\n|    iterations           | 5         |\n|    time_elapsed         | 9         |\n|    total_timesteps      | 5120      |\n| train/                  |           |\n|    approx_kl            | 0.0041138 |\n|    clip_fraction        | 0.0111    |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.43     |\n|    explained_variance   | -0.0058   |\n|    learning_rate        | 0.0003    |\n|    loss                 | 22        |\n|    n_updates            | 40        |\n|    policy_gradient_loss | -0.00347  |\n|    std                  | 1         |\n|    value_loss           | 50.6      |\n---------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 541          |\n|    iterations           | 6            |\n|    time_elapsed         | 11           |\n|    total_timesteps      | 6144         |\n| train/                  |              |\n|    approx_kl            | 0.0019419647 |\n|    clip_fraction        | 0.00332      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.42        |\n|    explained_variance   | -0.00309     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 95.4         |\n|    n_updates            | 50           |\n|    policy_gradient_loss | -0.000311    |\n|    std                  | 1.01         |\n|    value_loss           | 185          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 537          |\n|    iterations           | 7            |\n|    time_elapsed         | 13           |\n|    total_timesteps      | 7168         |\n| train/                  |              |\n|    approx_kl            | 0.0023777424 |\n|    clip_fraction        | 0.0085       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.44        |\n|    explained_variance   | 0.333        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.0963       |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.00117     |\n|    std                  | 1.06         |\n|    value_loss           | 1.96         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 534          |\n|    iterations           | 8            |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0009458625 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.48        |\n|    explained_variance   | -3.02        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.09         |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.000653    |\n|    std                  | 1.06         |\n|    value_loss           | 11.5         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 528          |\n|    iterations           | 9            |\n|    time_elapsed         | 17           |\n|    total_timesteps      | 9216         |\n| train/                  |              |\n|    approx_kl            | 0.0022026147 |\n|    clip_fraction        | 0.00527      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.48        |\n|    explained_variance   | -0.053       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.5          |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.000119    |\n|    std                  | 1.05         |\n|    value_loss           | 7.34         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 526          |\n|    iterations           | 10           |\n|    time_elapsed         | 19           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 9.837432e-05 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.47        |\n|    explained_variance   | 0.0246       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 64.5         |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.000336    |\n|    std                  | 1.05         |\n|    value_loss           | 397          |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 525           |\n|    iterations           | 11            |\n|    time_elapsed         | 21            |\n|    total_timesteps      | 11264         |\n| train/                  |               |\n|    approx_kl            | 0.00016730494 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.47         |\n|    explained_variance   | 0.188         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 75.8          |\n|    n_updates            | 100           |\n|    policy_gradient_loss | -0.000289     |\n|    std                  | 1.05          |\n|    value_loss           | 280           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 524           |\n|    iterations           | 12            |\n|    time_elapsed         | 23            |\n|    total_timesteps      | 12288         |\n| train/                  |               |\n|    approx_kl            | 0.00035341288 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.47         |\n|    explained_variance   | 0.474         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 85.2          |\n|    n_updates            | 110           |\n|    policy_gradient_loss | -0.000608     |\n|    std                  | 1.05          |\n|    value_loss           | 248           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 524           |\n|    iterations           | 13            |\n|    time_elapsed         | 25            |\n|    total_timesteps      | 13312         |\n| train/                  |               |\n|    approx_kl            | 2.9187824e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.47         |\n|    explained_variance   | 0.558         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 90.6          |\n|    n_updates            | 120           |\n|    policy_gradient_loss | -5.5e-05      |\n|    std                  | 1.05          |\n|    value_loss           | 237           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 523          |\n|    iterations           | 14           |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0035052048 |\n|    clip_fraction        | 0.00723      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.47        |\n|    explained_variance   | 0.75         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 10           |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.00112     |\n|    std                  | 1.05         |\n|    value_loss           | 33           |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 523          |\n|    iterations           | 15           |\n|    time_elapsed         | 29           |\n|    total_timesteps      | 15360        |\n| train/                  |              |\n|    approx_kl            | 0.0017367576 |\n|    clip_fraction        | 0.00117      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.47        |\n|    explained_variance   | 0.486        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 5.29         |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.000604    |\n|    std                  | 1.05         |\n|    value_loss           | 17.8         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 523          |\n|    iterations           | 16           |\n|    time_elapsed         | 31           |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 6.871001e-05 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.47        |\n|    explained_variance   | 0.0204       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 395          |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.000155    |\n|    std                  | 1.05         |\n|    value_loss           | 815          |\n------------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 522        |\n|    iterations           | 17         |\n|    time_elapsed         | 33         |\n|    total_timesteps      | 17408      |\n| train/                  |            |\n|    approx_kl            | 2.9488e-07 |\n|    clip_fraction        | 0          |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.47      |\n|    explained_variance   | 0.309      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 115        |\n|    n_updates            | 160        |\n|    policy_gradient_loss | 1.43e-06   |\n|    std                  | 1.05       |\n|    value_loss           | 409        |\n----------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 522           |\n|    iterations           | 18            |\n|    time_elapsed         | 35            |\n|    total_timesteps      | 18432         |\n| train/                  |               |\n|    approx_kl            | 0.00018171262 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.47         |\n|    explained_variance   | 0.627         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 4.97          |\n|    n_updates            | 170           |\n|    policy_gradient_loss | -0.000172     |\n|    std                  | 1.05          |\n|    value_loss           | 61.4          |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 522          |\n|    iterations           | 19           |\n|    time_elapsed         | 37           |\n|    total_timesteps      | 19456        |\n| train/                  |              |\n|    approx_kl            | 0.0050764857 |\n|    clip_fraction        | 0.0182       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.47        |\n|    explained_variance   | 0.858        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.26         |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00199     |\n|    std                  | 1.06         |\n|    value_loss           | 19.2         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 521         |\n|    iterations           | 20          |\n|    time_elapsed         | 39          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.005976772 |\n|    clip_fraction        | 0.0167      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.48       |\n|    explained_variance   | 0.672       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.03        |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.00157    |\n|    std                  | 1.08        |\n|    value_loss           | 10.9        |\n-----------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 521           |\n|    iterations           | 21            |\n|    time_elapsed         | 41            |\n|    total_timesteps      | 21504         |\n| train/                  |               |\n|    approx_kl            | 4.8516085e-06 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | -0.0463       |\n|    learning_rate        | 0.0003        |\n|    loss                 | 114           |\n|    n_updates            | 200           |\n|    policy_gradient_loss | 8.62e-05      |\n|    std                  | 1.08          |\n|    value_loss           | 840           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 521          |\n|    iterations           | 22           |\n|    time_elapsed         | 43           |\n|    total_timesteps      | 22528        |\n| train/                  |              |\n|    approx_kl            | 0.0051109833 |\n|    clip_fraction        | 0.0161       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.537        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 11           |\n|    n_updates            | 210          |\n|    policy_gradient_loss | -0.00203     |\n|    std                  | 1.08         |\n|    value_loss           | 48.1         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 521          |\n|    iterations           | 23           |\n|    time_elapsed         | 45           |\n|    total_timesteps      | 23552        |\n| train/                  |              |\n|    approx_kl            | 0.0033507473 |\n|    clip_fraction        | 0.0218       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.5         |\n|    explained_variance   | -0.162       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 27.1         |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.00223     |\n|    std                  | 1.09         |\n|    value_loss           | 45.3         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 521          |\n|    iterations           | 24           |\n|    time_elapsed         | 47           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0045716483 |\n|    clip_fraction        | 0.0274       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.5         |\n|    explained_variance   | -0.00198     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 26.9         |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00345     |\n|    std                  | 1.08         |\n|    value_loss           | 77.3         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 25           |\n|    time_elapsed         | 49           |\n|    total_timesteps      | 25600        |\n| train/                  |              |\n|    approx_kl            | 0.0021538604 |\n|    clip_fraction        | 0.00654      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.5         |\n|    explained_variance   | 0.616        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 34.2         |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.00116     |\n|    std                  | 1.08         |\n|    value_loss           | 55.8         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 26           |\n|    time_elapsed         | 51           |\n|    total_timesteps      | 26624        |\n| train/                  |              |\n|    approx_kl            | 0.0017556123 |\n|    clip_fraction        | 0.00127      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.438        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 15.7         |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.000761    |\n|    std                  | 1.08         |\n|    value_loss           | 34.3         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 27           |\n|    time_elapsed         | 53           |\n|    total_timesteps      | 27648        |\n| train/                  |              |\n|    approx_kl            | 0.0017254069 |\n|    clip_fraction        | 0.000684     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.25         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 65.7         |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.000788    |\n|    std                  | 1.08         |\n|    value_loss           | 164          |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 519           |\n|    iterations           | 28            |\n|    time_elapsed         | 55            |\n|    total_timesteps      | 28672         |\n| train/                  |               |\n|    approx_kl            | 0.00024902774 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.666         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 51.4          |\n|    n_updates            | 270           |\n|    policy_gradient_loss | -0.000328     |\n|    std                  | 1.08          |\n|    value_loss           | 240           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 519           |\n|    iterations           | 29            |\n|    time_elapsed         | 57            |\n|    total_timesteps      | 29696         |\n| train/                  |               |\n|    approx_kl            | 1.4905527e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.578         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 223           |\n|    n_updates            | 280           |\n|    policy_gradient_loss | 5.14e-05      |\n|    std                  | 1.08          |\n|    value_loss           | 629           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 30           |\n|    time_elapsed         | 59           |\n|    total_timesteps      | 30720        |\n| train/                  |              |\n|    approx_kl            | 0.0024771735 |\n|    clip_fraction        | 0.00234      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.51         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 100          |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.00294     |\n|    std                  | 1.07         |\n|    value_loss           | 339          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 31           |\n|    time_elapsed         | 61           |\n|    total_timesteps      | 31744        |\n| train/                  |              |\n|    approx_kl            | 6.656849e-05 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.871        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 168          |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.00015     |\n|    std                  | 1.08         |\n|    value_loss           | 386          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 32           |\n|    time_elapsed         | 63           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0021662456 |\n|    clip_fraction        | 0.00117      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.391        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 44.3         |\n|    n_updates            | 310          |\n|    policy_gradient_loss | -0.00135     |\n|    std                  | 1.08         |\n|    value_loss           | 157          |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 33            |\n|    time_elapsed         | 65            |\n|    total_timesteps      | 33792         |\n| train/                  |               |\n|    approx_kl            | 0.00078816694 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.0713        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 211           |\n|    n_updates            | 320           |\n|    policy_gradient_loss | -0.00182      |\n|    std                  | 1.08          |\n|    value_loss           | 664           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 34            |\n|    time_elapsed         | 67            |\n|    total_timesteps      | 34816         |\n| train/                  |               |\n|    approx_kl            | 0.00018081791 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.677         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 98.1          |\n|    n_updates            | 330           |\n|    policy_gradient_loss | -0.000118     |\n|    std                  | 1.08          |\n|    value_loss           | 220           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 518          |\n|    iterations           | 35           |\n|    time_elapsed         | 69           |\n|    total_timesteps      | 35840        |\n| train/                  |              |\n|    approx_kl            | 0.0011702098 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.854        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 209          |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.000894    |\n|    std                  | 1.07         |\n|    value_loss           | 316          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 518          |\n|    iterations           | 36           |\n|    time_elapsed         | 71           |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0020317957 |\n|    clip_fraction        | 0.000879     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | -0.511       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 44           |\n|    n_updates            | 350          |\n|    policy_gradient_loss | -0.000542    |\n|    std                  | 1.07         |\n|    value_loss           | 176          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 518          |\n|    iterations           | 37           |\n|    time_elapsed         | 73           |\n|    total_timesteps      | 37888        |\n| train/                  |              |\n|    approx_kl            | 0.0022050026 |\n|    clip_fraction        | 0.00146      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.771        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 45.7         |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.000805    |\n|    std                  | 1.07         |\n|    value_loss           | 114          |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 38            |\n|    time_elapsed         | 75            |\n|    total_timesteps      | 38912         |\n| train/                  |               |\n|    approx_kl            | 0.00011664332 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.773         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 56.1          |\n|    n_updates            | 370           |\n|    policy_gradient_loss | -0.000175     |\n|    std                  | 1.07          |\n|    value_loss           | 239           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 39            |\n|    time_elapsed         | 77            |\n|    total_timesteps      | 39936         |\n| train/                  |               |\n|    approx_kl            | 0.00018870016 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.768         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 74.9          |\n|    n_updates            | 380           |\n|    policy_gradient_loss | -5.15e-05     |\n|    std                  | 1.07          |\n|    value_loss           | 197           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 517           |\n|    iterations           | 40            |\n|    time_elapsed         | 79            |\n|    total_timesteps      | 40960         |\n| train/                  |               |\n|    approx_kl            | 0.00014622748 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.49         |\n|    explained_variance   | 0.315         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 82.3          |\n|    n_updates            | 390           |\n|    policy_gradient_loss | -0.00018      |\n|    std                  | 1.07          |\n|    value_loss           | 212           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 41           |\n|    time_elapsed         | 81           |\n|    total_timesteps      | 41984        |\n| train/                  |              |\n|    approx_kl            | 0.0007248934 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.722        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 209          |\n|    n_updates            | 400          |\n|    policy_gradient_loss | -0.000321    |\n|    std                  | 1.07         |\n|    value_loss           | 421          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 42           |\n|    time_elapsed         | 83           |\n|    total_timesteps      | 43008        |\n| train/                  |              |\n|    approx_kl            | 0.0064243777 |\n|    clip_fraction        | 0.0334       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.94         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 18.2         |\n|    n_updates            | 410          |\n|    policy_gradient_loss | -0.00409     |\n|    std                  | 1.08         |\n|    value_loss           | 106          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 43           |\n|    time_elapsed         | 85           |\n|    total_timesteps      | 44032        |\n| train/                  |              |\n|    approx_kl            | 0.0026516963 |\n|    clip_fraction        | 0.000879     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.439        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 12.1         |\n|    n_updates            | 420          |\n|    policy_gradient_loss | 0.000181     |\n|    std                  | 1.07         |\n|    value_loss           | 181          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 44           |\n|    time_elapsed         | 86           |\n|    total_timesteps      | 45056        |\n| train/                  |              |\n|    approx_kl            | 0.0017704954 |\n|    clip_fraction        | 0.0112       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.49        |\n|    explained_variance   | 0.79         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 32.2         |\n|    n_updates            | 430          |\n|    policy_gradient_loss | 0.000316     |\n|    std                  | 1.07         |\n|    value_loss           | 48.1         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 517         |\n|    iterations           | 45          |\n|    time_elapsed         | 88          |\n|    total_timesteps      | 46080       |\n| train/                  |             |\n|    approx_kl            | 0.001970835 |\n|    clip_fraction        | 0.00234     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.48       |\n|    explained_variance   | 0.859       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 135         |\n|    n_updates            | 440         |\n|    policy_gradient_loss | -0.00113    |\n|    std                  | 1.06        |\n|    value_loss           | 251         |\n-----------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 517           |\n|    iterations           | 46            |\n|    time_elapsed         | 90            |\n|    total_timesteps      | 47104         |\n| train/                  |               |\n|    approx_kl            | 0.00045944238 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.48         |\n|    explained_variance   | 0.856         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 107           |\n|    n_updates            | 450           |\n|    policy_gradient_loss | -0.000994     |\n|    std                  | 1.06          |\n|    value_loss           | 380           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 517           |\n|    iterations           | 47            |\n|    time_elapsed         | 92            |\n|    total_timesteps      | 48128         |\n| train/                  |               |\n|    approx_kl            | 3.5768026e-06 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.48         |\n|    explained_variance   | -0.289        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 199           |\n|    n_updates            | 460           |\n|    policy_gradient_loss | -1.55e-05     |\n|    std                  | 1.06          |\n|    value_loss           | 734           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 517           |\n|    iterations           | 48            |\n|    time_elapsed         | 94            |\n|    total_timesteps      | 49152         |\n| train/                  |               |\n|    approx_kl            | 0.00043689756 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.48         |\n|    explained_variance   | -4.17         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 89.9          |\n|    n_updates            | 470           |\n|    policy_gradient_loss | -0.000244     |\n|    std                  | 1.06          |\n|    value_loss           | 589           |\n-------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 517         |\n|    iterations           | 49          |\n|    time_elapsed         | 96          |\n|    total_timesteps      | 50176       |\n| train/                  |             |\n|    approx_kl            | 0.003446505 |\n|    clip_fraction        | 0.00586     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.48       |\n|    explained_variance   | 0.773       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 84.8        |\n|    n_updates            | 480         |\n|    policy_gradient_loss | -0.00146    |\n|    std                  | 1.06        |\n|    value_loss           | 149         |\n-----------------------------------------\n","output_type":"stream"},{"execution_count":257,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7ec6f7e56a50>"},"metadata":{}}],"execution_count":257},{"cell_type":"code","source":"model.save(\"ppo_role2.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:39:18.777019Z","iopub.execute_input":"2025-05-05T19:39:18.777348Z","iopub.status.idle":"2025-05-05T19:39:18.790993Z","shell.execute_reply.started":"2025-05-05T19:39:18.777326Z","shell.execute_reply":"2025-05-05T19:39:18.79024Z"}},"outputs":[],"execution_count":259},{"cell_type":"code","source":"def evaluate_model(model, env, n_eval_episodes=1):\n    \"\"\"\n    Evaluate the trained model with proper observation handling\n    \"\"\"\n    all_predictions = []\n    all_labels = []\n    all_scores = []\n    \n    for _ in range(n_eval_episodes):\n        obs = env.reset()\n        done = [False]\n        while not all(done):\n            action, _ = model.predict(obs, deterministic=True)\n            obs, _, done, info = env.step(action)\n            \n            # Properly handle vectorized env observations\n            if isinstance(obs, dict):\n                # Single environment case\n                current_score = obs['current_score'][0][0]\n                pred = info[0]['prediction']\n                true_label = info[0]['true_label']\n            else:\n                # Vectorized environment case\n                current_score = obs[0]['current_score'][0][0]\n                pred = info[0]['prediction']\n                true_label = info[0]['true_label']\n            \n            all_predictions.append(pred)\n            all_labels.append(true_label)\n            all_scores.append(current_score)\n    \n    y_true = np.array(all_labels)\n    y_pred = np.array(all_predictions)\n    y_scores = np.array(all_scores)\n    \n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, zero_division=0),\n        'recall': recall_score(y_true, y_pred, zero_division=0),\n        'f1': f1_score(y_true, y_pred, zero_division=0),\n        'roc_auc': roc_auc_score(y_true, y_scores) if len(np.unique(y_true)) > 1 else 0.5,\n        'pr_auc': average_precision_score(y_true, y_scores),\n        'confusion_matrix': confusion_matrix(y_true, y_pred)\n    }\n    \n    return metrics, y_pred, y_true","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:40:35.865899Z","iopub.execute_input":"2025-05-05T19:40:35.866521Z","iopub.status.idle":"2025-05-05T19:40:35.873836Z","shell.execute_reply.started":"2025-05-05T19:40:35.866496Z","shell.execute_reply":"2025-05-05T19:40:35.873096Z"}},"outputs":[],"execution_count":263},{"cell_type":"code","source":"env = BitRoleThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly)\nenv = DummyVecEnv([lambda: env])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n                            f1_score, roc_auc_score, confusion_matrix, \n                            precision_recall_curve, average_precision_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:46:41.890388Z","iopub.execute_input":"2025-05-05T19:46:41.890666Z","iopub.status.idle":"2025-05-05T19:46:41.894501Z","shell.execute_reply.started":"2025-05-05T19:46:41.890645Z","shell.execute_reply":"2025-05-05T19:46:41.89373Z"}},"outputs":[],"execution_count":265},{"cell_type":"code","source":"\nmetrics, predictions, labels = evaluate_model(model, env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:46:45.349462Z","iopub.execute_input":"2025-05-05T19:46:45.350174Z","iopub.status.idle":"2025-05-05T19:51:41.359473Z","shell.execute_reply.started":"2025-05-05T19:46:45.350149Z","shell.execute_reply":"2025-05-05T19:51:41.358858Z"}},"outputs":[],"execution_count":266},{"cell_type":"code","source":"# Print results\nprint(f\"Accuracy: {metrics['accuracy']:.4f}\")\nprint(f\"Precision: {metrics['precision']:.4f}\")\nprint(f\"Recall: {metrics['recall']:.4f}\")\nprint(f\"F1 Score: {metrics['f1']:.4f}\")\nprint(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(metrics['confusion_matrix'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:52:50.529759Z","iopub.execute_input":"2025-05-05T19:52:50.530467Z","iopub.status.idle":"2025-05-05T19:52:50.53526Z","shell.execute_reply.started":"2025-05-05T19:52:50.530441Z","shell.execute_reply":"2025-05-05T19:52:50.53451Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9236\nPrecision: 0.0034\nRecall: 0.0601\nF1 Score: 0.0065\nROC AUC: 0.8587\nConfusion Matrix:\n[[304954  23967]\n [  1282     82]]\n","output_type":"stream"}],"execution_count":267},{"cell_type":"markdown","source":"improved attempt","metadata":{}},{"cell_type":"code","source":"class BitRoleThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_bit_encoded, users, is_anomaly):\n\n        self.anomaly_scores = self._normalize_scores(anomaly_scores)\n        self.users = users\n        self.is_anomaly = is_anomaly.flatten()\n        \n        self.roles_bit_encoded = roles_bit_encoded.astype(np.float32)  # (n_samples, 4)\n        \n        self.role_ids = np.sum(roles_bit_encoded * (2 ** np.arange(4)), axis=1)\n        self.unique_roles = np.unique(self.role_ids)\n        self.num_roles = len(self.unique_roles)\n        self.role_to_idx = {role: idx for idx, role in enumerate(self.unique_roles)}\n        \n        self.role_weights = self._calculate_role_weights()\n        \n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles)\n        \n        self.action_space = spaces.Box(low=-0.05, high=0.05, shape=(1,), dtype=np.float32)\n        \n        self.observation_space = spaces.Dict({\n            \"current_score\": spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n            \"user_stats\": spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32),\n            \"role_bits\": spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)  # Raw 4 bits\n        })\n       \n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n\n    def _normalize_scores(self, scores):\n        min_score, max_score = scores.min(), scores.max()\n        range_score = max_score - min_score\n        if range_score < 1e-6:  # Handle constant scores\n            return np.zeros_like(scores)\n        return (scores - min_score) / range_score\n\n    def _calculate_role_weights(self):\n        df = pd.DataFrame({\n            'role': self.role_ids,\n            'is_anomaly': self.is_anomaly,\n            'user': self.users\n        })\n        \n        # Calculate anomaly prevalence and user count per role\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        user_counts = df.groupby('role')['user'].nunique()\n        \n        # Combine factors with logarithmic scaling\n        weights = anomaly_rates * np.log(user_counts + 1)\n        return (weights / weights.max()).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"current_score\": np.array([0], dtype=np.float32),\n                \"user_stats\": np.array([0, 0], dtype=np.float32),\n                \"role_bits\": np.zeros(4, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        current_score = self.anomaly_scores[self.current_step]\n        \n        hist = self.user_history[user]\n        hist['scores'].append(current_score)\n        if len(hist['scores']) > 7:  # 1-week window\n            hist['scores'].pop(0)\n        \n        # Track anomalies\n        if self.is_anomaly[self.current_step]:\n            hist['last_anomaly'] = self.current_step\n            self.global_last_anomaly = self.current_step\n        \n        role_bits = self.roles_bit_encoded[self.current_step]\n        \n        return {\n            \"current_score\": np.array([current_score], dtype=np.float32),\n            \"user_stats\": np.array([\n                np.mean(hist['scores']) if hist['scores'] else 0,\n                np.std(hist['scores']) if len(hist['scores']) > 1 else 0\n            ], dtype=np.float32),\n            \"role_bits\": role_bits\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        role_idx = self.role_to_idx[role_id]\n        \n        # Role-weighted threshold adjustment\n        learning_rate = 0.05 * self.role_weights.get(role_id, 1.0)\n        self.role_thresholds[role_idx] = np.clip(\n            self.role_thresholds[role_idx] + action[0] * learning_rate,\n            0.1, 0.9\n        )\n        \n        # Get prediction and balanced reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_idx])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_idx],\n            \"true_label\": self.is_anomaly[self.current_step - 1],\n            \"prediction\": pred\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label and pred:   # True positive\n            return 25.0 * weight  # Increased from 15\n        elif true_label and not pred:  # False negative\n            return -30.0 * weight  # Increased penalty\n        elif not true_label and pred:  # False positive\n            return -5.0 / weight  # Reduced penalty\n        else:  # True negative\n            return 0.5 / weight\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n        # Initialize thresholds with small random variation\n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles) * np.random.uniform(0.95, 1.05, self.num_roles)\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:57:25.828848Z","iopub.execute_input":"2025-05-05T19:57:25.829721Z","iopub.status.idle":"2025-05-05T19:57:25.844837Z","shell.execute_reply.started":"2025-05-05T19:57:25.829695Z","shell.execute_reply":"2025-05-05T19:57:25.844167Z"}},"outputs":[],"execution_count":271},{"cell_type":"code","source":"env = BitRoleThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_bit_encoded=roles_expanded,\n        users=users,\n        is_anomaly=is_anomaly\n    )\n    \n    # Wrap for vectorization (single env)\nenv = DummyVecEnv([lambda: env])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:58:32.269668Z","iopub.execute_input":"2025-05-05T19:58:32.270253Z","iopub.status.idle":"2025-05-05T19:58:32.327742Z","shell.execute_reply.started":"2025-05-05T19:58:32.270231Z","shell.execute_reply":"2025-05-05T19:58:32.326861Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":273},{"cell_type":"code","source":"model = PPO(\n        \"MultiInputPolicy\",  # Changed from \"MlpPolicy\"\n        env,\n        learning_rate=3e-4,\n        n_steps=1024,\n        batch_size=64,\n        n_epochs=10,\n        gamma=0.95,\n        verbose=1\n    )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:58:41.968438Z","iopub.execute_input":"2025-05-05T19:58:41.96891Z","iopub.status.idle":"2025-05-05T19:58:41.979137Z","shell.execute_reply.started":"2025-05-05T19:58:41.968889Z","shell.execute_reply":"2025-05-05T19:58:41.978396Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"}],"execution_count":274},{"cell_type":"code","source":"model.learn(total_timesteps=50_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:58:47.21265Z","iopub.execute_input":"2025-05-05T19:58:47.213399Z","iopub.status.idle":"2025-05-05T20:00:25.105381Z","shell.execute_reply.started":"2025-05-05T19:58:47.213376Z","shell.execute_reply":"2025-05-05T20:00:25.104724Z"}},"outputs":[{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 785  |\n|    iterations      | 1    |\n|    time_elapsed    | 1    |\n|    total_timesteps | 1024 |\n-----------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 618          |\n|    iterations           | 2            |\n|    time_elapsed         | 3            |\n|    total_timesteps      | 2048         |\n| train/                  |              |\n|    approx_kl            | 0.0016748854 |\n|    clip_fraction        | 0.00313      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.0015       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 331          |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.0012      |\n|    std                  | 0.982        |\n|    value_loss           | 648          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 579          |\n|    iterations           | 3            |\n|    time_elapsed         | 5            |\n|    total_timesteps      | 3072         |\n| train/                  |              |\n|    approx_kl            | 0.0012962846 |\n|    clip_fraction        | 0.013        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.4         |\n|    explained_variance   | 0.0195       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.86         |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.000497    |\n|    std                  | 0.982        |\n|    value_loss           | 38.2         |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 564           |\n|    iterations           | 4             |\n|    time_elapsed         | 7             |\n|    total_timesteps      | 4096          |\n| train/                  |               |\n|    approx_kl            | 0.00078751775 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.4          |\n|    explained_variance   | -0.024        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 124           |\n|    n_updates            | 30            |\n|    policy_gradient_loss | -0.000457     |\n|    std                  | 0.979         |\n|    value_loss           | 478           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 551          |\n|    iterations           | 5            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 5120         |\n| train/                  |              |\n|    approx_kl            | 0.0008366614 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.4         |\n|    explained_variance   | 0.259        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 43.4         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.000683    |\n|    std                  | 0.979        |\n|    value_loss           | 78.5         |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 544           |\n|    iterations           | 6             |\n|    time_elapsed         | 11            |\n|    total_timesteps      | 6144          |\n| train/                  |               |\n|    approx_kl            | 0.00069761125 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.4          |\n|    explained_variance   | 0.145         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 161           |\n|    n_updates            | 50            |\n|    policy_gradient_loss | -0.00115      |\n|    std                  | 0.978         |\n|    value_loss           | 401           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 538          |\n|    iterations           | 7            |\n|    time_elapsed         | 13           |\n|    total_timesteps      | 7168         |\n| train/                  |              |\n|    approx_kl            | 0.0024464503 |\n|    clip_fraction        | 0.00781      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.4         |\n|    explained_variance   | 0.551        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.47         |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.000417    |\n|    std                  | 0.987        |\n|    value_loss           | 23.4         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 536          |\n|    iterations           | 8            |\n|    time_elapsed         | 15           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0012550325 |\n|    clip_fraction        | 0.00176      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.622        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 6.28         |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.000964    |\n|    std                  | 0.995        |\n|    value_loss           | 12.6         |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 534           |\n|    iterations           | 9             |\n|    time_elapsed         | 17            |\n|    total_timesteps      | 9216          |\n| train/                  |               |\n|    approx_kl            | 0.00017995539 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.41         |\n|    explained_variance   | 0.349         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 244           |\n|    n_updates            | 80            |\n|    policy_gradient_loss | -0.000343     |\n|    std                  | 0.995         |\n|    value_loss           | 522           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 531          |\n|    iterations           | 10           |\n|    time_elapsed         | 19           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 5.272252e-05 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.621        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 306          |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.000124    |\n|    std                  | 0.994        |\n|    value_loss           | 590          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 529          |\n|    iterations           | 11           |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 11264        |\n| train/                  |              |\n|    approx_kl            | 0.0004317914 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.676        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 314          |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.000479    |\n|    std                  | 0.994        |\n|    value_loss           | 574          |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 527           |\n|    iterations           | 12            |\n|    time_elapsed         | 23            |\n|    total_timesteps      | 12288         |\n| train/                  |               |\n|    approx_kl            | 0.00013430312 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.41         |\n|    explained_variance   | 0.498         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 284           |\n|    n_updates            | 110           |\n|    policy_gradient_loss | -0.0001       |\n|    std                  | 0.993         |\n|    value_loss           | 782           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 526          |\n|    iterations           | 13           |\n|    time_elapsed         | 25           |\n|    total_timesteps      | 13312        |\n| train/                  |              |\n|    approx_kl            | 5.773251e-05 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.293        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 217          |\n|    n_updates            | 120          |\n|    policy_gradient_loss | -5.71e-05    |\n|    std                  | 0.993        |\n|    value_loss           | 530          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 526          |\n|    iterations           | 14           |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0016345752 |\n|    clip_fraction        | 0.00283      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.616        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 7.68         |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.000502    |\n|    std                  | 0.993        |\n|    value_loss           | 22.1         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 525          |\n|    iterations           | 15           |\n|    time_elapsed         | 29           |\n|    total_timesteps      | 15360        |\n| train/                  |              |\n|    approx_kl            | 0.0007879631 |\n|    clip_fraction        | 0.00215      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.2          |\n|    learning_rate        | 0.0003       |\n|    loss                 | 10.6         |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.00145     |\n|    std                  | 0.988        |\n|    value_loss           | 110          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 524          |\n|    iterations           | 16           |\n|    time_elapsed         | 31           |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0025241894 |\n|    clip_fraction        | 0.00371      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.0322       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.83e+03     |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.00218     |\n|    std                  | 0.988        |\n|    value_loss           | 2.64e+03     |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 523          |\n|    iterations           | 17           |\n|    time_elapsed         | 33           |\n|    total_timesteps      | 17408        |\n| train/                  |              |\n|    approx_kl            | 0.0062129395 |\n|    clip_fraction        | 0.0174       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.4         |\n|    explained_variance   | 0.233        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.48         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.00206     |\n|    std                  | 0.964        |\n|    value_loss           | 6.72         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 523         |\n|    iterations           | 18          |\n|    time_elapsed         | 35          |\n|    total_timesteps      | 18432       |\n| train/                  |             |\n|    approx_kl            | 0.002656097 |\n|    clip_fraction        | 0.0104      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.37       |\n|    explained_variance   | 0.833       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 0.592       |\n|    n_updates            | 170         |\n|    policy_gradient_loss | -0.000798   |\n|    std                  | 0.945       |\n|    value_loss           | 2.89        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 522          |\n|    iterations           | 19           |\n|    time_elapsed         | 37           |\n|    total_timesteps      | 19456        |\n| train/                  |              |\n|    approx_kl            | 0.0038290923 |\n|    clip_fraction        | 0.0199       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.36        |\n|    explained_variance   | 0.784        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.725        |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00116     |\n|    std                  | 0.929        |\n|    value_loss           | 4.63         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 521          |\n|    iterations           | 20           |\n|    time_elapsed         | 39           |\n|    total_timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0043509053 |\n|    clip_fraction        | 0.0167       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.33        |\n|    explained_variance   | 0.838        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.04         |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.000604    |\n|    std                  | 0.905        |\n|    value_loss           | 0.73         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 521          |\n|    iterations           | 21           |\n|    time_elapsed         | 41           |\n|    total_timesteps      | 21504        |\n| train/                  |              |\n|    approx_kl            | 0.0029570754 |\n|    clip_fraction        | 0.0175       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.31        |\n|    explained_variance   | 0.0483       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.127        |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00201     |\n|    std                  | 0.891        |\n|    value_loss           | 0.555        |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 520           |\n|    iterations           | 22            |\n|    time_elapsed         | 43            |\n|    total_timesteps      | 22528         |\n| train/                  |               |\n|    approx_kl            | 9.9129335e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.262         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 61.5          |\n|    n_updates            | 210           |\n|    policy_gradient_loss | -0.000538     |\n|    std                  | 0.891         |\n|    value_loss           | 319           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 520           |\n|    iterations           | 23            |\n|    time_elapsed         | 45            |\n|    total_timesteps      | 23552         |\n| train/                  |               |\n|    approx_kl            | 1.8306309e-06 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.645         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 119           |\n|    n_updates            | 220           |\n|    policy_gradient_loss | -2.38e-05     |\n|    std                  | 0.892         |\n|    value_loss           | 253           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 520           |\n|    iterations           | 24            |\n|    time_elapsed         | 47            |\n|    total_timesteps      | 24576         |\n| train/                  |               |\n|    approx_kl            | 6.3947635e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.625         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 24.4          |\n|    n_updates            | 230           |\n|    policy_gradient_loss | -6.57e-05     |\n|    std                  | 0.893         |\n|    value_loss           | 85.9          |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 25           |\n|    time_elapsed         | 49           |\n|    total_timesteps      | 25600        |\n| train/                  |              |\n|    approx_kl            | 0.0031772202 |\n|    clip_fraction        | 0.00127      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.3         |\n|    explained_variance   | -1.47        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.853        |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.00112     |\n|    std                  | 0.887        |\n|    value_loss           | 2.96         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 519          |\n|    iterations           | 26           |\n|    time_elapsed         | 51           |\n|    total_timesteps      | 26624        |\n| train/                  |              |\n|    approx_kl            | 0.0006750538 |\n|    clip_fraction        | 9.77e-05     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.3         |\n|    explained_variance   | 0.652        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.05         |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.00114     |\n|    std                  | 0.888        |\n|    value_loss           | 20.6         |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 519           |\n|    iterations           | 27            |\n|    time_elapsed         | 53            |\n|    total_timesteps      | 27648         |\n| train/                  |               |\n|    approx_kl            | 0.00018395041 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.797         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 44.5          |\n|    n_updates            | 260           |\n|    policy_gradient_loss | -0.000208     |\n|    std                  | 0.889         |\n|    value_loss           | 102           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 519           |\n|    iterations           | 28            |\n|    time_elapsed         | 55            |\n|    total_timesteps      | 28672         |\n| train/                  |               |\n|    approx_kl            | 0.00014173303 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.794         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 47.9          |\n|    n_updates            | 270           |\n|    policy_gradient_loss | -0.000283     |\n|    std                  | 0.889         |\n|    value_loss           | 156           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 29            |\n|    time_elapsed         | 57            |\n|    total_timesteps      | 29696         |\n| train/                  |               |\n|    approx_kl            | 1.9655738e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.459         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 179           |\n|    n_updates            | 280           |\n|    policy_gradient_loss | -0.000122     |\n|    std                  | 0.889         |\n|    value_loss           | 384           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 30            |\n|    time_elapsed         | 59            |\n|    total_timesteps      | 30720         |\n| train/                  |               |\n|    approx_kl            | 1.9680592e-06 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | 0.807         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 61.2          |\n|    n_updates            | 290           |\n|    policy_gradient_loss | -7.6e-06      |\n|    std                  | 0.889         |\n|    value_loss           | 227           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 31            |\n|    time_elapsed         | 61            |\n|    total_timesteps      | 31744         |\n| train/                  |               |\n|    approx_kl            | 0.00028551975 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.3          |\n|    explained_variance   | -0.131        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 7.47          |\n|    n_updates            | 300           |\n|    policy_gradient_loss | -0.000118     |\n|    std                  | 0.888         |\n|    value_loss           | 60            |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 518          |\n|    iterations           | 32           |\n|    time_elapsed         | 63           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0017231095 |\n|    clip_fraction        | 0.00654      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | 0.241        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.932        |\n|    n_updates            | 310          |\n|    policy_gradient_loss | -0.00215     |\n|    std                  | 0.853        |\n|    value_loss           | 4.71         |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 518         |\n|    iterations           | 33          |\n|    time_elapsed         | 65          |\n|    total_timesteps      | 33792       |\n| train/                  |             |\n|    approx_kl            | 0.003927839 |\n|    clip_fraction        | 0.0085      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | 0.424       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.21        |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.000836   |\n|    std                  | 0.842       |\n|    value_loss           | 8.77        |\n-----------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 518           |\n|    iterations           | 34            |\n|    time_elapsed         | 67            |\n|    total_timesteps      | 34816         |\n| train/                  |               |\n|    approx_kl            | 1.3827987e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.25         |\n|    explained_variance   | 0.496         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 58.3          |\n|    n_updates            | 330           |\n|    policy_gradient_loss | 5.03e-05      |\n|    std                  | 0.841         |\n|    value_loss           | 260           |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 35           |\n|    time_elapsed         | 69           |\n|    total_timesteps      | 35840        |\n| train/                  |              |\n|    approx_kl            | 0.0024241442 |\n|    clip_fraction        | 0.00303      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.553        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 55.5         |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.0011      |\n|    std                  | 0.842        |\n|    value_loss           | 29           |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 517           |\n|    iterations           | 36            |\n|    time_elapsed         | 71            |\n|    total_timesteps      | 36864         |\n| train/                  |               |\n|    approx_kl            | 0.00017448241 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.25         |\n|    explained_variance   | 0.0791        |\n|    learning_rate        | 0.0003        |\n|    loss                 | 114           |\n|    n_updates            | 350           |\n|    policy_gradient_loss | -0.000538     |\n|    std                  | 0.842         |\n|    value_loss           | 551           |\n-------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 517         |\n|    iterations           | 37          |\n|    time_elapsed         | 73          |\n|    total_timesteps      | 37888       |\n| train/                  |             |\n|    approx_kl            | 0.001688831 |\n|    clip_fraction        | 9.77e-05    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.0881     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 8.2         |\n|    n_updates            | 360         |\n|    policy_gradient_loss | -0.000958   |\n|    std                  | 0.841       |\n|    value_loss           | 88.5        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 38           |\n|    time_elapsed         | 75           |\n|    total_timesteps      | 38912        |\n| train/                  |              |\n|    approx_kl            | 0.0021283042 |\n|    clip_fraction        | 0.00488      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.756        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 8.66         |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.00119     |\n|    std                  | 0.842        |\n|    value_loss           | 40.6         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 39           |\n|    time_elapsed         | 77           |\n|    total_timesteps      | 39936        |\n| train/                  |              |\n|    approx_kl            | 0.0007195281 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.878        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 78.8         |\n|    n_updates            | 380          |\n|    policy_gradient_loss | -0.00137     |\n|    std                  | 0.84         |\n|    value_loss           | 210          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 40           |\n|    time_elapsed         | 79           |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0032362544 |\n|    clip_fraction        | 0.0217       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | 0.0496       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.37         |\n|    n_updates            | 390          |\n|    policy_gradient_loss | -0.00312     |\n|    std                  | 0.842        |\n|    value_loss           | 63.1         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 517          |\n|    iterations           | 41           |\n|    time_elapsed         | 81           |\n|    total_timesteps      | 41984        |\n| train/                  |              |\n|    approx_kl            | 0.0017931794 |\n|    clip_fraction        | 0.00176      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.457        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.48         |\n|    n_updates            | 400          |\n|    policy_gradient_loss | -0.000343    |\n|    std                  | 0.844        |\n|    value_loss           | 22.8         |\n------------------------------------------\n--------------------------------------------\n| time/                   |                |\n|    fps                  | 517            |\n|    iterations           | 42             |\n|    time_elapsed         | 83             |\n|    total_timesteps      | 43008          |\n| train/                  |                |\n|    approx_kl            | 1.26958475e-05 |\n|    clip_fraction        | 0              |\n|    clip_range           | 0.2            |\n|    entropy_loss         | -1.25          |\n|    explained_variance   | 0.889          |\n|    learning_rate        | 0.0003         |\n|    loss                 | 51.5           |\n|    n_updates            | 410            |\n|    policy_gradient_loss | 1.36e-05       |\n|    std                  | 0.845          |\n|    value_loss           | 98             |\n--------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 517           |\n|    iterations           | 43            |\n|    time_elapsed         | 85            |\n|    total_timesteps      | 44032         |\n| train/                  |               |\n|    approx_kl            | 4.0225685e-05 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.25         |\n|    explained_variance   | 0.702         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 91.2          |\n|    n_updates            | 420           |\n|    policy_gradient_loss | -1.23e-05     |\n|    std                  | 0.843         |\n|    value_loss           | 239           |\n-------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 516           |\n|    iterations           | 44            |\n|    time_elapsed         | 87            |\n|    total_timesteps      | 45056         |\n| train/                  |               |\n|    approx_kl            | 0.00019486033 |\n|    clip_fraction        | 0.00273       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.25         |\n|    explained_variance   | 0.826         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 7.55          |\n|    n_updates            | 430           |\n|    policy_gradient_loss | 0.000895      |\n|    std                  | 0.844         |\n|    value_loss           | 8.48          |\n-------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 516          |\n|    iterations           | 45           |\n|    time_elapsed         | 89           |\n|    total_timesteps      | 46080        |\n| train/                  |              |\n|    approx_kl            | 0.0015314365 |\n|    clip_fraction        | 0.000195     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | -0.406       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 52.1         |\n|    n_updates            | 440          |\n|    policy_gradient_loss | -0.00139     |\n|    std                  | 0.843        |\n|    value_loss           | 194          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 516          |\n|    iterations           | 46           |\n|    time_elapsed         | 91           |\n|    total_timesteps      | 47104        |\n| train/                  |              |\n|    approx_kl            | 0.0034644594 |\n|    clip_fraction        | 0.00439      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | -0.0135      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 0.582        |\n|    n_updates            | 450          |\n|    policy_gradient_loss | -0.000956    |\n|    std                  | 0.832        |\n|    value_loss           | 11.8         |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 516          |\n|    iterations           | 47           |\n|    time_elapsed         | 93           |\n|    total_timesteps      | 48128        |\n| train/                  |              |\n|    approx_kl            | 0.0007398266 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.309        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 69.3         |\n|    n_updates            | 460          |\n|    policy_gradient_loss | -0.00097     |\n|    std                  | 0.832        |\n|    value_loss           | 164          |\n------------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 516          |\n|    iterations           | 48           |\n|    time_elapsed         | 95           |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 1.148897e-05 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.291        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 127          |\n|    n_updates            | 470          |\n|    policy_gradient_loss | -3.65e-05    |\n|    std                  | 0.832        |\n|    value_loss           | 431          |\n------------------------------------------\n-------------------------------------------\n| time/                   |               |\n|    fps                  | 516           |\n|    iterations           | 49            |\n|    time_elapsed         | 97            |\n|    total_timesteps      | 50176         |\n| train/                  |               |\n|    approx_kl            | 2.8148643e-06 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.23         |\n|    explained_variance   | 0.473         |\n|    learning_rate        | 0.0003        |\n|    loss                 | 80.8          |\n|    n_updates            | 480           |\n|    policy_gradient_loss | 2.39e-05      |\n|    std                  | 0.832         |\n|    value_loss           | 877           |\n-------------------------------------------\n","output_type":"stream"},{"execution_count":275,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7ec73d2ea2d0>"},"metadata":{}}],"execution_count":275},{"cell_type":"code","source":"model.save(\"ppo_role2.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:00:50.947701Z","iopub.execute_input":"2025-05-05T20:00:50.948276Z","iopub.status.idle":"2025-05-05T20:00:50.959593Z","shell.execute_reply.started":"2025-05-05T20:00:50.948253Z","shell.execute_reply":"2025-05-05T20:00:50.959056Z"}},"outputs":[],"execution_count":276},{"cell_type":"code","source":"env = BitRoleThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly)\nenv = DummyVecEnv([lambda: env])\n\n\nmetrics, predictions, labels = evaluate_model(model, env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:00:58.548117Z","iopub.execute_input":"2025-05-05T20:00:58.548844Z","iopub.status.idle":"2025-05-05T20:05:49.703792Z","shell.execute_reply.started":"2025-05-05T20:00:58.548816Z","shell.execute_reply":"2025-05-05T20:05:49.703221Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":277},{"cell_type":"code","source":"# Print results\nprint(f\"Accuracy: {metrics['accuracy']:.4f}\")\nprint(f\"Precision: {metrics['precision']:.4f}\")\nprint(f\"Recall: {metrics['recall']:.4f}\")\nprint(f\"F1 Score: {metrics['f1']:.4f}\")\nprint(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(metrics['confusion_matrix'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:05:49.704802Z","iopub.execute_input":"2025-05-05T20:05:49.705013Z","iopub.status.idle":"2025-05-05T20:05:49.710335Z","shell.execute_reply.started":"2025-05-05T20:05:49.704996Z","shell.execute_reply":"2025-05-05T20:05:49.709527Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.8729\nPrecision: 0.0052\nRecall: 0.1554\nF1 Score: 0.0100\nROC AUC: 0.8587\nConfusion Matrix:\n[[288092  40829]\n [  1152    212]]\n","output_type":"stream"}],"execution_count":278},{"cell_type":"markdown","source":"end-end rl model trial","metadata":{}},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:13:04.528419Z","iopub.execute_input":"2025-05-05T20:13:04.528937Z","iopub.status.idle":"2025-05-05T20:13:04.543366Z","shell.execute_reply.started":"2025-05-05T20:13:04.528914Z","shell.execute_reply":"2025-05-05T20:13:04.542701Z"}},"outputs":[{"execution_count":286,"output_type":"execute_result","data":{"text/plain":"           user  date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190 2010-01-04                -0.737332           -0.53406   \n1       AAE0190 2010-01-05                -0.737332           -0.53406   \n2       AAE0190 2010-01-06                -0.737332           -0.53406   \n3       AAE0190 2010-01-07                -0.737332           -0.53406   \n4       AAE0190 2010-01-08                -0.737332           -0.53406   \n...         ...        ...                      ...                ...   \n330280  ZSL0305 2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305 2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305 2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305 2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305 2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n330280 -0.583959         -1.317639  \n330281 -0.583959         -1.285853  \n330282 -0.583959         -1.289826  \n330283 -0.583959         -1.361345  \n330284 -0.583959         -1.214333  \n\n[330285 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":286},{"cell_type":"code","source":"roles_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:13:08.157592Z","iopub.execute_input":"2025-05-05T20:13:08.157858Z","iopub.status.idle":"2025-05-05T20:13:08.167423Z","shell.execute_reply.started":"2025-05-05T20:13:08.157837Z","shell.execute_reply":"2025-05-05T20:13:08.166718Z"}},"outputs":[{"execution_count":287,"output_type":"execute_result","data":{"text/plain":"        user  role_0  role_1  role_2  role_3\n0    AAE0190       0       0       0       1\n1    AAF0535       0       0       1       0\n2    AAF0791       0       0       1       1\n3    AAL0706       0       1       0       0\n4    AAM0658       0       0       1       0\n..       ...     ...     ...     ...     ...\n995  ZKS0899       0       0       1       0\n996  ZMC0284       0       1       1       0\n997  ZSB0649       0       0       1       0\n998  ZSK0258       0       1       1       0\n999  ZSL0305       0       1       0       0\n\n[1000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>role_0</th>\n      <th>role_1</th>\n      <th>role_2</th>\n      <th>role_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAF0535</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAF0791</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAL0706</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAM0658</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>ZKS0899</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>ZMC0284</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>ZSB0649</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>ZSK0258</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>ZSL0305</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":287},{"cell_type":"code","source":"is_anomaly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:13:11.387997Z","iopub.execute_input":"2025-05-05T20:13:11.388675Z","iopub.status.idle":"2025-05-05T20:13:11.393088Z","shell.execute_reply.started":"2025-05-05T20:13:11.388653Z","shell.execute_reply":"2025-05-05T20:13:11.392536Z"}},"outputs":[{"execution_count":288,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"metadata":{}}],"execution_count":288},{"cell_type":"code","source":"class InsiderThreatEnv(gym.Env):\n    def __init__(self, df_features, roles_df, is_anomaly):\n        # Data\n        self.features = df_features.iloc[:, 2:].values  # Exclude user/date, shape: (330285, 11)\n        self.roles = roles_df.iloc[:, 1:].values  # Exclude user column, shape: (330285, 4)\n        self.users = df_features['user'].values\n        self.labels = is_anomaly\n        \n        # Spaces\n        self.action_space = spaces.Box(-1, 1, (1,))  # Single continuous action\n        self.observation_space = spaces.Dict({\n            \"features\": spaces.Box(-5, 5, (11,)),  # Shape: 11\n            \"role_bits\": spaces.Box(0, 1, (4,)),\n            \"user_avg\": spaces.Box(-5, 5, (11,))   # Shape: 11\n        })\n        \n        # Tracking\n        self.current_step = 0\n        self.user_history = defaultdict(list)\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(list)\n        return self._get_obs(), {}  # Return (obs, info) for gymnasium API\n\n    def _get_obs(self):\n        if self.current_step >= len(self.features):\n            return {\n                \"features\": np.zeros(11, dtype=np.float32),\n                \"role_bits\": np.zeros(4, dtype=np.float32),\n                \"user_avg\": np.zeros(11, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        user_avg = np.mean(self.user_history[user], axis=0) if self.user_history[user] else np.zeros(11)\n        \n        return {\n            \"features\": self.features[self.current_step],\n            \"role_bits\": self.roles[self.current_step],\n            \"user_avg\": user_avg\n        }\n\n    def step(self, action):\n        user = self.users[self.current_step]\n        obs = self._get_obs()\n        \n        # Store current features\n        self.user_history[user].append(self.features[self.current_step])\n        if len(self.user_history[user]) > 7:  # Keep last 7 days\n            self.user_history[user].pop(0)\n        \n        # Simple threshold decision\n        threshold = 0.5 + action[0] * 0.2  # Map action to [0.3, 0.7]\n        pred = int(np.sum(obs[\"features\"][:5]) > threshold)  # Use first 5 features for anomaly score\n        \n        # Reward calculation\n        reward = self._calculate_reward(pred, self.labels[self.current_step], obs[\"role_bits\"])\n        \n        self.current_step += 1\n        terminated = self.current_step >= len(self.features)\n        truncated = False\n        \n        info = {\"prediction\": pred, \"true_label\": self.labels[self.current_step-1]}\n        \n        return obs, reward, terminated, truncated, info  # Return 5 elements for gymnasium API\n\n    def _calculate_reward(self, pred, true_label, role_bits):\n        # Simple role-aware reward\n        role_weight = 0.5 + np.sum(role_bits)  # Higher weight for roles with more bits set\n        if true_label:\n            return 10 * role_weight if pred else -15 * role_weight\n        else:\n            return 0.1 if not pred else -2 / role_weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:33:33.637187Z","iopub.execute_input":"2025-05-05T20:33:33.63777Z","iopub.status.idle":"2025-05-05T20:33:33.648183Z","shell.execute_reply.started":"2025-05-05T20:33:33.637749Z","shell.execute_reply":"2025-05-05T20:33:33.647378Z"}},"outputs":[],"execution_count":325},{"cell_type":"code","source":"def train_simple_model(df_features, roles_df, is_anomaly):\n    env = InsiderThreatEnv(df_features, roles_df, is_anomaly)  # Single environment\n    \n    # Correct policy configuration\n    policy_kwargs = {\n        \"net_arch\": dict(pi=[64, 32], vf=[64, 32])\n    }\n    \n    model = PPO(\n        \"MultiInputPolicy\",\n        env,\n        learning_rate=3e-4,\n        n_steps=1024,  # Suitable for a single environment\n        batch_size=64,\n        verbose=1,\n        policy_kwargs=policy_kwargs,\n        tensorboard_log=\"./logs\"\n    )\n    \n    model.learn(total_timesteps=100_000)\n    return model\n\ndef evaluate_simple(model, df_features, roles_df, is_anomaly):\n    env = InsiderThreatEnv(df_features, roles_df, is_anomaly)\n    obs, _ = env.reset()\n    \n    y_true, y_pred = [], []\n    while True:\n        action, _ = model.predict(obs, deterministic=True)\n        obs, _, terminated, truncated, info = env.step(action)\n        y_true.append(info[\"true_label\"])\n        y_pred.append(info[\"prediction\"])\n        if terminated or truncated:\n            break\n    \n    from sklearn.metrics import classification_report\n    print(classification_report(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:33:46.986515Z","iopub.execute_input":"2025-05-05T20:33:46.986777Z","iopub.status.idle":"2025-05-05T20:33:46.992929Z","shell.execute_reply.started":"2025-05-05T20:33:46.986757Z","shell.execute_reply":"2025-05-05T20:33:46.992214Z"}},"outputs":[],"execution_count":326},{"cell_type":"code","source":"# Run it\nmodel = train_simple_model(df_features, roles_df, is_anomaly)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:33:48.064894Z","iopub.execute_input":"2025-05-05T20:33:48.065444Z","iopub.status.idle":"2025-05-05T20:33:48.10404Z","shell.execute_reply.started":"2025-05-05T20:33:48.065418Z","shell.execute_reply":"2025-05-05T20:33:48.103088Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/631272982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_simple_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroles_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_30/3990287678.py\u001b[0m in \u001b[0;36mtrain_simple_model\u001b[0;34m(df_features, roles_df, is_anomaly)\u001b[0m\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 308\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         total_timesteps, callback = self._setup_learn(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# pytype: disable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;31m# pytype: enable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Seeds are only used once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36m_save_obs\u001b[0;34m(self, env_idx, obs)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuf_obs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_obs_from_buf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"],"ename":"TypeError","evalue":"tuple indices must be integers or slices, not str","output_type":"error"}],"execution_count":327},{"cell_type":"code","source":"evaluate_simple(model, df_features, roles_df, is_anomaly)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def infer_high_risk_roles(roles_df, is_anomaly):\n\n    # Create a DataFrame with role numbers and anomalies\n    anomaly_df = pd.DataFrame({\n        'role_number': roles_df,\n        'is_anomaly': is_anomaly\n    })\n    \n    # Group by role to compute anomaly counts and total user-days\n    role_stats = anomaly_df.groupby('role_number').agg(\n        total_days=('is_anomaly', 'count'),\n        anomalies=('is_anomaly', 'sum')\n    )\n    \n    # Calculate anomaly rate\n    role_stats['anomaly_rate'] = role_stats['anomalies'] / role_stats['total_days']\n    \n    # Define high-risk roles (e.g., anomaly rate > 70th percentile)\n    threshold = role_stats['anomaly_rate'].quantile(0.7)\n    high_risk_roles = role_stats[role_stats['anomaly_rate'] >= threshold].index.tolist()\n    \n    print(\"Role Statistics:\")\n    print(role_stats)\n    print(f\"\\nHigh-Risk Roles (anomaly rate >= {threshold:.4f}): {high_risk_roles}\")\n    \n    return high_risk_roles\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:48:41.058028Z","iopub.execute_input":"2025-05-06T07:48:41.058302Z","iopub.status.idle":"2025-05-06T07:48:41.063563Z","shell.execute_reply.started":"2025-05-06T07:48:41.05828Z","shell.execute_reply":"2025-05-06T07:48:41.062714Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.metrics import precision_recall_curve, auc, matthews_corrcoef, balanced_accuracy_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:08:33.516374Z","iopub.execute_input":"2025-05-06T12:08:33.517Z","iopub.status.idle":"2025-05-06T12:08:33.52063Z","shell.execute_reply.started":"2025-05-06T12:08:33.516977Z","shell.execute_reply":"2025-05-06T12:08:33.519897Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:48:43.128165Z","iopub.execute_input":"2025-05-06T07:48:43.128773Z","iopub.status.idle":"2025-05-06T07:48:43.157495Z","shell.execute_reply.started":"2025-05-06T07:48:43.128734Z","shell.execute_reply":"2025-05-06T07:48:43.156936Z"}},"outputs":[{"name":"stdout","text":"Role Statistics:\n             total_days  anomalies  anomaly_rate\nrole_number                                     \n1                 17267          0      0.000000\n2                 81986        305      0.003720\n3                 34244         63      0.001840\n4                 61907        347      0.005605\n5                 49847        203      0.004072\n6                 58855        320      0.005437\n7                 13365        112      0.008380\n8                  6445          6      0.000931\n9                  4985          8      0.001605\n10                 1384          0      0.000000\n\nHigh-Risk Roles (anomaly rate >= 0.0045): [4, 6, 7]\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"[4, 6, 7]"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"from collections import defaultdict\nfrom gymnasium import Env, spaces\nfrom stable_baselines3 import PPO\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nimport uuid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:56:24.79051Z","iopub.execute_input":"2025-05-06T07:56:24.790792Z","iopub.status.idle":"2025-05-06T07:56:24.794953Z","shell.execute_reply.started":"2025-05-06T07:56:24.790759Z","shell.execute_reply":"2025-05-06T07:56:24.794261Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# Role weights (roles 1-10)\nROLE_WEIGHTS = {\n    1: 0.6666364519334633,\n    2: 1.503301351626301,\n    3: 1.0,  # Default for missing role\n    4: 1.1658889718506966,\n    5: 0.5,\n    6: 1.4732138828974453,\n    7: 1.4732138828974453,  # Matches role 6 (high-risk)\n    8: 0.5,\n    9: 0.7872542782243186,\n    10: 1.2289515996962965\n}\n\n# High-risk roles from anomaly rates\nHIGH_RISK_ROLES = [4, 6, 7]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:56:25.97145Z","iopub.execute_input":"2025-05-06T07:56:25.971711Z","iopub.status.idle":"2025-05-06T07:56:25.975896Z","shell.execute_reply.started":"2025-05-06T07:56:25.971693Z","shell.execute_reply":"2025-05-06T07:56:25.975204Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Sort by date_only and user for consistency\ndata = df_features.copy()\ndata['roles_labeled'] = roles_labeled\ndata['mu_all'] = [row for row in mu_all]\ndata['is_anomaly'] = is_anomaly\ndata = data.sort_values(['date_only', 'user']).reset_index(drop=True)\n    \n# Split by time (80% earliest, 20% latest)\nsplit_idx = int(0.8 * len(data))\ntrain_data = data.iloc[:split_idx]\ntest_data = data.iloc[split_idx:]\n    \n# Extract splits\ndf_train = train_data.drop(columns=['roles_labeled', 'mu_all', 'is_anomaly'])\nroles_train = train_data['roles_labeled'].values\nmu_train = np.array([row for row in train_data['mu_all']])\nanomaly_train = train_data['is_anomaly'].values\ndf_test = test_data.drop(columns=['roles_labeled', 'mu_all', 'is_anomaly'])\nroles_test = test_data['roles_labeled'].values\nmu_test = np.array([row for row in test_data['mu_all']])\nanomaly_test = test_data['is_anomaly'].values    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:09:54.091224Z","iopub.execute_input":"2025-05-06T09:09:54.091912Z","iopub.status.idle":"2025-05-06T09:09:54.721991Z","shell.execute_reply.started":"2025-05-06T09:09:54.091888Z","shell.execute_reply":"2025-05-06T09:09:54.721207Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"print(\"Train Set Statistics:\")\nprint(f\"Total samples: {len(df_train)}\")\nprint(f\"Anomalies: {np.sum(anomaly_train)} ({np.sum(anomaly_train)/len(anomaly_train)*100:.2f}%)\")\nhigh_risk_mask_train = np.isin(roles_train, HIGH_RISK_ROLES)\nprint(f\"High-risk role anomalies: {np.sum(anomaly_train[high_risk_mask_train])} ({np.sum(anomaly_train[high_risk_mask_train])/np.sum(high_risk_mask_train)*100:.2f}%)\")\n    \nprint(\"\\nTest Set Statistics:\")\nprint(f\"Total samples: {len(df_test)}\")\nprint(f\"Anomalies: {np.sum(anomaly_test)} ({np.sum(anomaly_test)/len(anomaly_test)*100:.2f}%)\")\nhigh_risk_mask_test = np.isin(roles_test, HIGH_RISK_ROLES)\nprint(f\"High-risk role anomalies: {np.sum(anomaly_test[high_risk_mask_test])} ({np.sum(anomaly_test[high_risk_mask_test])/np.sum(high_risk_mask_test)*100:.2f}%)\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:09:58.170416Z","iopub.execute_input":"2025-05-06T09:09:58.170949Z","iopub.status.idle":"2025-05-06T09:09:58.184914Z","shell.execute_reply.started":"2025-05-06T09:09:58.170924Z","shell.execute_reply":"2025-05-06T09:09:58.184134Z"}},"outputs":[{"name":"stdout","text":"Train Set Statistics:\nTotal samples: 264228\nAnomalies: 1099 (0.42%)\nHigh-risk role anomalies: 612 (0.57%)\n\nTest Set Statistics:\nTotal samples: 66057\nAnomalies: 265 (0.40%)\nHigh-risk role anomalies: 167 (0.62%)\n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"mu_all = np.load('/kaggle/working/mu_all.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:57:00.712237Z","iopub.execute_input":"2025-05-06T07:57:00.712522Z","iopub.status.idle":"2025-05-06T07:57:00.719987Z","shell.execute_reply.started":"2025-05-06T07:57:00.712502Z","shell.execute_reply":"2025-05-06T07:57:00.719336Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:57:07.592427Z","iopub.execute_input":"2025-05-06T07:57:07.592981Z","iopub.status.idle":"2025-05-06T07:57:07.597485Z","shell.execute_reply.started":"2025-05-06T07:57:07.592956Z","shell.execute_reply":"2025-05-06T07:57:07.596835Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"(330285, 8)"},"metadata":{}}],"execution_count":65},{"cell_type":"markdown","source":"basic RL","metadata":{}},{"cell_type":"code","source":"class BasicInsiderEnv(Env):\n    def __init__(self, features, roles, labels):\n        \"\"\"\n        features: Normalized feature matrix (n_samples x n_features)\n        roles: Array of role numbers (1-10)\n        labels: Binary anomaly labels\n        \"\"\"\n        self.features = features\n        self.roles = roles\n        self.labels = labels\n        self.n_samples = len(features)\n        \n        # Action space: 0 (normal), 1 (anomaly)\n        self.action_space = spaces.Discrete(2)  \n        \n        # Observation space: features + role\n        self.observation_space = spaces.Dict({\n            \"features\": spaces.Box(-5, 5, (features.shape[1],), dtype=np.float32),\n            \"role\": spaces.Discrete(10)  # Roles 1-10 (will subtract 1 internally)\n        })\n        \n        self.current_step = 0\n\n    def reset(self):\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        return {\n            \"features\": self.features[self.current_step],\n            \"role\": self.roles[self.current_step] - 1  # Convert to 0-9\n        }\n\n    def step(self, action):\n        reward = self._calculate_reward(action, self.labels[self.current_step], \n                                      self.roles[self.current_step])\n        \n        self.current_step += 1\n        done = self.current_step >= self.n_samples\n        \n        return self._get_obs(), reward, done, False, {}\n\n    def _calculate_reward(self, pred, true_label, role):\n        if pred == true_label:\n            return 1.0 if true_label == 1 else 0.1  # Higher reward for correct anomaly\n        else:\n            return -10.0 if (true_label == 1 and pred == 0) else -1.0  # Heavy FN penalty","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:08:40.411434Z","iopub.execute_input":"2025-05-06T10:08:40.412201Z","iopub.status.idle":"2025-05-06T10:08:40.420522Z","shell.execute_reply.started":"2025-05-06T10:08:40.412174Z","shell.execute_reply":"2025-05-06T10:08:40.419845Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"env = DummyVecEnv([lambda: BasicInsiderEnv(df_features , roles_labeled, is_anomaly)])\nmodel = PPO(\"MultiInputPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=50_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:10:01.696119Z","iopub.execute_input":"2025-05-06T10:10:01.6964Z","iopub.status.idle":"2025-05-06T10:10:01.734724Z","shell.execute_reply.started":"2025-05-06T10:10:01.696378Z","shell.execute_reply":"2025-05-06T10:10:01.733825Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3921455325.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBasicInsiderEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mroles_labeled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MultiInputPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     ) -> SelfPPO:\n\u001b[0;32m--> 308\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         total_timesteps, callback = self._setup_learn(\n\u001b[0m\u001b[1;32m    247\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36m_setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# pytype: disable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0;31m# pytype: enable=annotation-type-mismatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0menv_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_infos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_seeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# Seeds are only used once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: BasicInsiderEnv.reset() got an unexpected keyword argument 'seed'"],"ename":"TypeError","evalue":"BasicInsiderEnv.reset() got an unexpected keyword argument 'seed'","output_type":"error"}],"execution_count":119},{"cell_type":"code","source":"df_features.to_csv('df_features.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:41:11.19143Z","iopub.execute_input":"2025-05-06T10:41:11.191691Z","iopub.status.idle":"2025-05-06T10:41:16.59879Z","shell.execute_reply.started":"2025-05-06T10:41:11.191674Z","shell.execute_reply":"2025-05-06T10:41:16.598018Z"}},"outputs":[],"execution_count":120},{"cell_type":"code","source":"np.save('roles_expanded.npy', roles_expanded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:41:34.59116Z","iopub.execute_input":"2025-05-06T10:41:34.591421Z","iopub.status.idle":"2025-05-06T10:41:34.603574Z","shell.execute_reply.started":"2025-05-06T10:41:34.591402Z","shell.execute_reply":"2025-05-06T10:41:34.602863Z"}},"outputs":[],"execution_count":122},{"cell_type":"code","source":"np.save('is_anomaly.npy', is_anomaly)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:41:51.475967Z","iopub.execute_input":"2025-05-06T10:41:51.476206Z","iopub.status.idle":"2025-05-06T10:41:51.48241Z","shell.execute_reply.started":"2025-05-06T10:41:51.47619Z","shell.execute_reply":"2025-05-06T10:41:51.48185Z"}},"outputs":[],"execution_count":123},{"cell_type":"code","source":"np.save('roles_labeled.npy', roles_labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:42:30.73309Z","iopub.execute_input":"2025-05-06T10:42:30.73336Z","iopub.status.idle":"2025-05-06T10:42:30.738933Z","shell.execute_reply.started":"2025-05-06T10:42:30.733339Z","shell.execute_reply":"2025-05-06T10:42:30.738314Z"}},"outputs":[],"execution_count":126},{"cell_type":"code","source":"#mu_all has alr been saved","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:42:44.370911Z","iopub.execute_input":"2025-05-06T10:42:44.37116Z","iopub.status.idle":"2025-05-06T10:42:44.374367Z","shell.execute_reply.started":"2025-05-06T10:42:44.371143Z","shell.execute_reply":"2025-05-06T10:42:44.373629Z"}},"outputs":[],"execution_count":127},{"cell_type":"code","source":"#importing reqd files\nis_anomaly = np.load('/kaggle/working/is_anomaly.npy')\ndf_features = pd.read_csv('/kaggle/working/df_features.csv')\nmu_all = np.load('/kaggle/working/mu_all.npy')\nroles_labeled = np.load('/kaggle/working/roles_labeled.npy')\nroles_expanded = np.load('/kaggle/working/roles_expanded.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:38:03.004154Z","iopub.execute_input":"2025-05-06T15:38:03.004394Z","iopub.status.idle":"2025-05-06T15:38:03.901187Z","shell.execute_reply.started":"2025-05-06T15:38:03.004374Z","shell.execute_reply":"2025-05-06T15:38:03.900407Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"#better role representation - embeddings\ndf_features = df_features.drop(columns = 'Unnamed: 0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:38:10.152123Z","iopub.execute_input":"2025-05-06T15:38:10.152787Z","iopub.status.idle":"2025-05-06T15:38:10.183647Z","shell.execute_reply.started":"2025-05-06T15:38:10.152755Z","shell.execute_reply":"2025-05-06T15:38:10.18286Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:44:47.892426Z","iopub.execute_input":"2025-05-06T12:44:47.892716Z","iopub.status.idle":"2025-05-06T12:44:47.907311Z","shell.execute_reply.started":"2025-05-06T12:44:47.892696Z","shell.execute_reply":"2025-05-06T12:44:47.906554Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n330280 -0.583959         -1.317639  \n330281 -0.583959         -1.285853  \n330282 -0.583959         -1.289826  \n330283 -0.583959         -1.361345  \n330284 -0.583959         -1.214333  \n\n[330285 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:38:23.942768Z","iopub.execute_input":"2025-05-06T15:38:23.943343Z","iopub.status.idle":"2025-05-06T15:38:23.967967Z","shell.execute_reply.started":"2025-05-06T15:38:23.94332Z","shell.execute_reply":"2025-05-06T15:38:23.967395Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n330280       -0.287121         -1.309699       -1.107117    -1.316319   \n330281       -0.287121         -1.200445        2.137805    -1.316319   \n330282       -0.287121         -1.091191        3.760267    -1.316319   \n330283       -0.287121         -1.309699        0.515344    -1.316319   \n330284       -0.287121         -1.309699        0.515344    -1.316319   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n330280 -0.583959         -1.317639  \n330281 -0.583959         -1.285853  \n330282 -0.583959         -1.289826  \n330283 -0.583959         -1.361345  \n330284 -0.583959         -1.214333  \n\n[330285 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/df-with-pca/df_with_pca.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:44:49.983051Z","iopub.execute_input":"2025-05-06T15:44:49.983828Z","iopub.status.idle":"2025-05-06T15:44:57.721389Z","shell.execute_reply.started":"2025-05-06T15:44:49.983804Z","shell.execute_reply":"2025-05-06T15:44:57.72074Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df = df.drop(columns = {'Unnamed: 0'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:45:10.986937Z","iopub.execute_input":"2025-05-06T15:45:10.987685Z","iopub.status.idle":"2025-05-06T15:45:11.042953Z","shell.execute_reply.started":"2025-05-06T15:45:10.987653Z","shell.execute_reply":"2025-05-06T15:45:11.042387Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:45:14.231701Z","iopub.execute_input":"2025-05-06T15:45:14.232412Z","iopub.status.idle":"2025-05-06T15:45:14.302158Z","shell.execute_reply.started":"2025-05-06T15:45:14.232386Z","shell.execute_reply":"2025-05-06T15:45:14.301375Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  \\\n0            -0.287121          0.930009       -0.759447  ...   \n1            -0.287121          0.711501       -0.233484  ...   \n2            -0.287121          0.766128       -0.064106  ...   \n3            -0.287121          0.875382       -0.179997  ...   \n4            -0.287121          0.766128       -0.607898  ...   \n...                ...               ...             ...  ...   \n330280       -0.287121         -1.309699       -1.107117  ...   \n330281       -0.287121         -1.200445        2.137805  ...   \n330282       -0.287121         -1.091191        3.760267  ...   \n330283       -0.287121         -1.309699        0.515344  ...   \n330284       -0.287121         -1.309699        0.515344  ...   \n\n        role_emb_pca_40  role_emb_pca_41  role_emb_pca_42 role_emb_pca_43  \\\n0             -0.006884         0.153742         0.053482       -0.020691   \n1             -0.006884         0.153742         0.053482       -0.020691   \n2             -0.006884         0.153742         0.053482       -0.020691   \n3             -0.006884         0.153742         0.053482       -0.020691   \n4             -0.006884         0.153742         0.053482       -0.020691   \n...                 ...              ...              ...             ...   \n330280        -0.027279        -0.045802        -0.048467       -0.034873   \n330281        -0.027279        -0.045802        -0.048467       -0.034873   \n330282        -0.027279        -0.045802        -0.048467       -0.034873   \n330283        -0.027279        -0.045802        -0.048467       -0.034873   \n330284        -0.027279        -0.045802        -0.048467       -0.034873   \n\n       role_emb_pca_44  role_emb_pca_45 role_emb_pca_46 role_emb_pca_47  \\\n0             0.050259         0.006361        0.015730        0.100858   \n1             0.050259         0.006361        0.015730        0.100858   \n2             0.050259         0.006361        0.015730        0.100858   \n3             0.050259         0.006361        0.015730        0.100858   \n4             0.050259         0.006361        0.015730        0.100858   \n...                ...              ...             ...             ...   \n330280       -0.010375        -0.036870       -0.019237        0.017186   \n330281       -0.010375        -0.036870       -0.019237        0.017186   \n330282       -0.010375        -0.036870       -0.019237        0.017186   \n330283       -0.010375        -0.036870       -0.019237        0.017186   \n330284       -0.010375        -0.036870       -0.019237        0.017186   \n\n       role_emb_pca_48 role_emb_pca_49  \n0            -0.073232        0.012029  \n1            -0.073232        0.012029  \n2            -0.073232        0.012029  \n3            -0.073232        0.012029  \n4            -0.073232        0.012029  \n...                ...             ...  \n330280        0.054031        0.010085  \n330281        0.054031        0.010085  \n330282        0.054031        0.010085  \n330283        0.054031        0.010085  \n330284        0.054031        0.010085  \n\n[330285 rows x 73 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>role_emb_pca_40</th>\n      <th>role_emb_pca_41</th>\n      <th>role_emb_pca_42</th>\n      <th>role_emb_pca_43</th>\n      <th>role_emb_pca_44</th>\n      <th>role_emb_pca_45</th>\n      <th>role_emb_pca_46</th>\n      <th>role_emb_pca_47</th>\n      <th>role_emb_pca_48</th>\n      <th>role_emb_pca_49</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>-0.006884</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>-0.006884</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>-0.006884</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>-0.006884</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>-0.006884</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-0.027279</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>-0.027279</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-0.027279</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.027279</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.027279</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 73 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"feature_cols = ['after_hours_logon_count', 'total_logon_count', 'device_connects',\n       'avg_content_word_count', 'text_files_accessed', 'files_accessed',\n       'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag',\n       'keyword_richness']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:58:40.90016Z","iopub.execute_input":"2025-05-06T15:58:40.900439Z","iopub.status.idle":"2025-05-06T15:58:40.904099Z","shell.execute_reply.started":"2025-05-06T15:58:40.900417Z","shell.execute_reply":"2025-05-06T15:58:40.903409Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"# Compute cluster behavioral profiles\nbehavioral_features = [col for col in feature_cols]  # 11 features\ncluster_stats = df.groupby('cluster')[behavioral_features].agg(['mean', 'std']).reset_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:46:50.712316Z","iopub.execute_input":"2025-05-06T15:46:50.713071Z","iopub.status.idle":"2025-05-06T15:46:50.818443Z","shell.execute_reply.started":"2025-05-06T15:46:50.713036Z","shell.execute_reply":"2025-05-06T15:46:50.817393Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"cluster_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:46:58.53493Z","iopub.execute_input":"2025-05-06T15:46:58.535548Z","iopub.status.idle":"2025-05-06T15:46:58.565149Z","shell.execute_reply.started":"2025-05-06T15:46:58.535525Z","shell.execute_reply":"2025-05-06T15:46:58.564298Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   cluster after_hours_logon_count           total_logon_count            \\\n                              mean       std              mean       std   \n0        0               -0.093612  0.686939         -0.292287  0.537775   \n1        1               -0.730045  0.098721          0.030472  0.734163   \n2        2               -0.706999  0.209500         -0.219866  0.604006   \n3        3               -0.697873  0.234665         -0.215893  0.613952   \n4        4               -0.095459  0.693954          0.006772  0.697372   \n5        5               -0.703787  0.214652         -0.181798  0.629887   \n6        6                2.707330  1.837229          3.635586  1.878684   \n7        7                0.642846  0.224732         -0.058409  0.704076   \n8        8                0.615230  0.106234         -0.299954  0.515941   \n9        9               -0.264722  0.680680         -0.115666  0.682422   \n10      10               -0.197196  0.698671          0.021186  0.692456   \n11      11               -0.733842  0.068413         -0.212954  0.601260   \n12      12               -0.697730  0.240140         -0.150029  0.654572   \n13      13               -0.282784  0.659516         -0.161019  0.630837   \n14      14               -0.232401  0.685470         -0.015737  0.700485   \n15      15                0.158066  0.649377         -0.166578  0.615275   \n16      16                3.143187  2.439230          2.706500  2.313855   \n17      17               -0.721131  0.146710         -0.300772  0.524740   \n18      18               -0.104851  0.679132         -0.036045  0.634274   \n19      19               -0.271142  0.659823         -0.225246  0.597200   \n20      20               -0.727649  0.118438         -0.258905  0.576022   \n21      21                0.635275  0.339361         -0.056001  0.677813   \n22      22               -0.021278  0.710149         -0.078041  0.687841   \n23      23               -0.185612  0.676289         -0.142795  0.643032   \n24      24               -0.314644  0.654205         -0.178169  0.626934   \n25      25                0.632662  0.188627         -0.185460  0.607856   \n26      26                0.443974  0.520875          0.039492  0.725380   \n27      27                0.384902  0.617595         -0.063021  0.735878   \n28      28                0.254401  0.611816         -0.220317  0.606026   \n\n   device_connects           avg_content_word_count            \\\n              mean       std                   mean       std   \n0        -0.293458  0.188265              -0.296341  0.534136   \n1        -0.096770  0.558142               0.163680  1.147448   \n2        -0.122053  0.917778              -0.223524  0.684101   \n3        -0.239870  0.288455              -0.147450  0.820969   \n4         0.247567  1.234047               0.182661  1.164325   \n5        -0.021076  0.900025               0.100730  1.094005   \n6         0.709395  2.235635               0.162443  1.144128   \n7         0.012700  1.028032               0.027655  1.025857   \n8        -0.204375  0.398968              -0.145080  0.823981   \n9        -0.221890  0.336081              -0.084382  0.897551   \n10        0.100327  1.112205               0.140764  1.128622   \n11        0.009390  0.932205               0.093728  1.089443   \n12        0.090435  1.204279              -0.120440  0.860405   \n13        0.074087  1.150694               0.009126  1.011924   \n14        0.046679  1.089923              -0.007146  0.995703   \n15       -0.096248  0.822343              -0.103753  0.874092   \n16        0.271281  1.382523               0.231350  1.203363   \n17       -0.189478  0.446730              -0.135635  0.829346   \n18        0.246678  1.391353               0.117895  1.108954   \n19       -0.220091  0.356207              -0.118118  0.860403   \n20       -0.055461  0.982893              -0.192187  0.750790   \n21        0.152709  1.176595               0.153338  1.140824   \n22       -0.018395  1.017511              -0.110720  0.869467   \n23        0.063102  1.161667               0.010982  1.008197   \n24        0.003717  0.929273               0.036658  1.037525   \n25       -0.234371  0.313079              -0.129173  0.838994   \n26        0.122851  1.023481               0.200226  1.181983   \n27       -0.022033  0.961086              -0.074923  0.919427   \n28        0.070202  0.914211               0.216947  1.188632   \n\n   text_files_accessed  ... total_recipients           external_ratio  \\\n                  mean  ...             mean       std           mean   \n0            -0.250043  ...        -1.248701  0.075891      -0.107230   \n1             0.067179  ...        -0.879184  0.159939      -0.030058   \n2            -0.056713  ...        -0.921312  0.139907       0.057143   \n3            -0.204085  ...        -1.250004  0.074699       0.024771   \n4             0.059209  ...         1.324180  0.613493      -0.030230   \n5             0.092211  ...        -0.903122  0.152152       0.016895   \n6             0.376944  ...         0.396889  0.369043       0.012839   \n7             0.002609  ...        -0.470668  1.091796      -0.016723   \n8            -0.207532  ...        -1.246967  0.074944       0.033535   \n9            -0.143372  ...         0.212732  0.398740      -0.090315   \n10            0.153627  ...         0.231653  0.515609      -0.034613   \n11            0.034658  ...        -1.249761  0.075797      -0.041238   \n12           -0.205405  ...        -1.247045  0.076872      -0.038917   \n13           -0.015329  ...         0.057313  0.620208      -0.000343   \n14           -0.054119  ...         0.181429  0.351912      -0.083312   \n15           -0.029301  ...         0.598319  0.813403       0.011549   \n16            0.319538  ...         0.467564  0.400990       0.102508   \n17           -0.139575  ...        -0.938712  0.125397       0.059150   \n18            0.207677  ...         0.202768  0.382776       0.030586   \n19           -0.109770  ...         0.135318  0.344102       0.014278   \n20           -0.235703  ...         0.989434  0.418249       0.002800   \n21            0.141723  ...         1.357680  0.814816       0.090750   \n22           -0.041030  ...         0.945434  0.967063      -0.021168   \n23            0.165051  ...         0.571116  0.831306       0.043907   \n24            0.011504  ...        -0.197608  0.556368       0.036053   \n25           -0.020243  ...        -0.905543  0.145054      -0.005144   \n26            0.033477  ...         1.029578  0.699533       0.003914   \n27           -0.184359  ...         0.099563  0.339832       0.004732   \n28            0.070488  ...         0.169098  0.355518      -0.007251   \n\n             emails_sent            bcc_flag           keyword_richness  \\\n         std        mean       std      mean       std             mean   \n0   1.472295   -1.321239  0.035351 -0.334755  0.714299        -1.294415   \n1   1.032256   -0.956755  0.083788  0.248357  1.103954        -0.932265   \n2   1.049870   -0.954686  0.080209 -0.262426  0.796905        -0.933845   \n3   1.540906   -1.321159  0.033527 -0.378854  0.654965        -1.295427   \n4   0.747081    1.248935  0.354129  0.502457  1.146600         1.288930   \n5   1.038050   -0.958137  0.088184  0.025423  1.013973        -0.930940   \n6   0.799110    0.488789  0.265442 -0.141565  0.905723         0.525901   \n7   1.301341   -0.496920  1.140931 -0.089913  0.943667        -0.459004   \n8   1.558829   -1.321398  0.036813 -0.286494  0.771152        -1.295459   \n9   0.787735    0.152038  0.215564  0.324251  1.122917         0.180464   \n10  0.798446    0.255508  0.391629  0.045003  1.024110         0.286064   \n11  1.517207   -1.321866  0.039047 -0.343064  0.703713        -1.296715   \n12  1.500233   -1.321964  0.039963 -0.262647  0.796673        -1.295571   \n13  0.854827    0.091327  0.615827  0.003169  1.001825        -0.119147   \n14  0.795862    0.163803  0.221879  0.304640  1.118547         0.201155   \n15  0.781451    0.693618  0.756534 -0.107430  0.931284         0.723883   \n16  0.786521    0.586888  0.337967 -0.229278  0.829939         0.593615   \n17  1.033868   -0.951843  0.066889 -0.551562  0.270841        -0.927467   \n18  0.806875    0.166461  0.235206  0.382666  1.133844         0.203221   \n19  0.806924    0.148203  0.200679  0.089307  1.045414         0.187014   \n20  0.760587    1.238022  0.342673 -0.423024  0.586265         1.289273   \n21  0.754293    1.363314  0.793708  0.325189  1.123097         1.404245   \n22  0.761290    0.998179  0.838501  0.101227  1.050730         0.691226   \n23  0.796607    0.581986  0.742660  0.192093  1.086245         0.616971   \n24  0.872596   -0.167632  0.543036 -0.149532  0.899437        -0.138293   \n25  1.041384   -0.952655  0.073674 -0.137096  0.909162        -0.930457   \n26  0.757692    1.009419  0.591589  0.450997  1.142643         1.053373   \n27  0.809621    0.137315  0.228768 -0.017628  0.989911         0.173709   \n28  0.815694    0.150350  0.198716  0.194498  1.087090         0.192987   \n\n              \n         std  \n0   0.052990  \n1   0.107427  \n2   0.106076  \n3   0.051835  \n4   0.395694  \n5   0.111573  \n6   0.305936  \n7   1.161725  \n8   0.052379  \n9   0.255152  \n10  0.411411  \n11  0.053783  \n12  0.055715  \n13  0.666223  \n14  0.259169  \n15  0.773875  \n16  0.373136  \n17  0.095268  \n18  0.269371  \n19  0.237027  \n20  0.387340  \n21  0.827980  \n22  0.945483  \n23  0.759520  \n24  0.558949  \n25  0.100839  \n26  0.615371  \n27  0.262744  \n28  0.235624  \n\n[29 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>cluster</th>\n      <th colspan=\"2\" halign=\"left\">after_hours_logon_count</th>\n      <th colspan=\"2\" halign=\"left\">total_logon_count</th>\n      <th colspan=\"2\" halign=\"left\">device_connects</th>\n      <th colspan=\"2\" halign=\"left\">avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">total_recipients</th>\n      <th colspan=\"2\" halign=\"left\">external_ratio</th>\n      <th colspan=\"2\" halign=\"left\">emails_sent</th>\n      <th colspan=\"2\" halign=\"left\">bcc_flag</th>\n      <th colspan=\"2\" halign=\"left\">keyword_richness</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>...</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.093612</td>\n      <td>0.686939</td>\n      <td>-0.292287</td>\n      <td>0.537775</td>\n      <td>-0.293458</td>\n      <td>0.188265</td>\n      <td>-0.296341</td>\n      <td>0.534136</td>\n      <td>-0.250043</td>\n      <td>...</td>\n      <td>-1.248701</td>\n      <td>0.075891</td>\n      <td>-0.107230</td>\n      <td>1.472295</td>\n      <td>-1.321239</td>\n      <td>0.035351</td>\n      <td>-0.334755</td>\n      <td>0.714299</td>\n      <td>-1.294415</td>\n      <td>0.052990</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.730045</td>\n      <td>0.098721</td>\n      <td>0.030472</td>\n      <td>0.734163</td>\n      <td>-0.096770</td>\n      <td>0.558142</td>\n      <td>0.163680</td>\n      <td>1.147448</td>\n      <td>0.067179</td>\n      <td>...</td>\n      <td>-0.879184</td>\n      <td>0.159939</td>\n      <td>-0.030058</td>\n      <td>1.032256</td>\n      <td>-0.956755</td>\n      <td>0.083788</td>\n      <td>0.248357</td>\n      <td>1.103954</td>\n      <td>-0.932265</td>\n      <td>0.107427</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-0.706999</td>\n      <td>0.209500</td>\n      <td>-0.219866</td>\n      <td>0.604006</td>\n      <td>-0.122053</td>\n      <td>0.917778</td>\n      <td>-0.223524</td>\n      <td>0.684101</td>\n      <td>-0.056713</td>\n      <td>...</td>\n      <td>-0.921312</td>\n      <td>0.139907</td>\n      <td>0.057143</td>\n      <td>1.049870</td>\n      <td>-0.954686</td>\n      <td>0.080209</td>\n      <td>-0.262426</td>\n      <td>0.796905</td>\n      <td>-0.933845</td>\n      <td>0.106076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>-0.697873</td>\n      <td>0.234665</td>\n      <td>-0.215893</td>\n      <td>0.613952</td>\n      <td>-0.239870</td>\n      <td>0.288455</td>\n      <td>-0.147450</td>\n      <td>0.820969</td>\n      <td>-0.204085</td>\n      <td>...</td>\n      <td>-1.250004</td>\n      <td>0.074699</td>\n      <td>0.024771</td>\n      <td>1.540906</td>\n      <td>-1.321159</td>\n      <td>0.033527</td>\n      <td>-0.378854</td>\n      <td>0.654965</td>\n      <td>-1.295427</td>\n      <td>0.051835</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-0.095459</td>\n      <td>0.693954</td>\n      <td>0.006772</td>\n      <td>0.697372</td>\n      <td>0.247567</td>\n      <td>1.234047</td>\n      <td>0.182661</td>\n      <td>1.164325</td>\n      <td>0.059209</td>\n      <td>...</td>\n      <td>1.324180</td>\n      <td>0.613493</td>\n      <td>-0.030230</td>\n      <td>0.747081</td>\n      <td>1.248935</td>\n      <td>0.354129</td>\n      <td>0.502457</td>\n      <td>1.146600</td>\n      <td>1.288930</td>\n      <td>0.395694</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>-0.703787</td>\n      <td>0.214652</td>\n      <td>-0.181798</td>\n      <td>0.629887</td>\n      <td>-0.021076</td>\n      <td>0.900025</td>\n      <td>0.100730</td>\n      <td>1.094005</td>\n      <td>0.092211</td>\n      <td>...</td>\n      <td>-0.903122</td>\n      <td>0.152152</td>\n      <td>0.016895</td>\n      <td>1.038050</td>\n      <td>-0.958137</td>\n      <td>0.088184</td>\n      <td>0.025423</td>\n      <td>1.013973</td>\n      <td>-0.930940</td>\n      <td>0.111573</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>2.707330</td>\n      <td>1.837229</td>\n      <td>3.635586</td>\n      <td>1.878684</td>\n      <td>0.709395</td>\n      <td>2.235635</td>\n      <td>0.162443</td>\n      <td>1.144128</td>\n      <td>0.376944</td>\n      <td>...</td>\n      <td>0.396889</td>\n      <td>0.369043</td>\n      <td>0.012839</td>\n      <td>0.799110</td>\n      <td>0.488789</td>\n      <td>0.265442</td>\n      <td>-0.141565</td>\n      <td>0.905723</td>\n      <td>0.525901</td>\n      <td>0.305936</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.642846</td>\n      <td>0.224732</td>\n      <td>-0.058409</td>\n      <td>0.704076</td>\n      <td>0.012700</td>\n      <td>1.028032</td>\n      <td>0.027655</td>\n      <td>1.025857</td>\n      <td>0.002609</td>\n      <td>...</td>\n      <td>-0.470668</td>\n      <td>1.091796</td>\n      <td>-0.016723</td>\n      <td>1.301341</td>\n      <td>-0.496920</td>\n      <td>1.140931</td>\n      <td>-0.089913</td>\n      <td>0.943667</td>\n      <td>-0.459004</td>\n      <td>1.161725</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.615230</td>\n      <td>0.106234</td>\n      <td>-0.299954</td>\n      <td>0.515941</td>\n      <td>-0.204375</td>\n      <td>0.398968</td>\n      <td>-0.145080</td>\n      <td>0.823981</td>\n      <td>-0.207532</td>\n      <td>...</td>\n      <td>-1.246967</td>\n      <td>0.074944</td>\n      <td>0.033535</td>\n      <td>1.558829</td>\n      <td>-1.321398</td>\n      <td>0.036813</td>\n      <td>-0.286494</td>\n      <td>0.771152</td>\n      <td>-1.295459</td>\n      <td>0.052379</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>-0.264722</td>\n      <td>0.680680</td>\n      <td>-0.115666</td>\n      <td>0.682422</td>\n      <td>-0.221890</td>\n      <td>0.336081</td>\n      <td>-0.084382</td>\n      <td>0.897551</td>\n      <td>-0.143372</td>\n      <td>...</td>\n      <td>0.212732</td>\n      <td>0.398740</td>\n      <td>-0.090315</td>\n      <td>0.787735</td>\n      <td>0.152038</td>\n      <td>0.215564</td>\n      <td>0.324251</td>\n      <td>1.122917</td>\n      <td>0.180464</td>\n      <td>0.255152</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>-0.197196</td>\n      <td>0.698671</td>\n      <td>0.021186</td>\n      <td>0.692456</td>\n      <td>0.100327</td>\n      <td>1.112205</td>\n      <td>0.140764</td>\n      <td>1.128622</td>\n      <td>0.153627</td>\n      <td>...</td>\n      <td>0.231653</td>\n      <td>0.515609</td>\n      <td>-0.034613</td>\n      <td>0.798446</td>\n      <td>0.255508</td>\n      <td>0.391629</td>\n      <td>0.045003</td>\n      <td>1.024110</td>\n      <td>0.286064</td>\n      <td>0.411411</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>-0.733842</td>\n      <td>0.068413</td>\n      <td>-0.212954</td>\n      <td>0.601260</td>\n      <td>0.009390</td>\n      <td>0.932205</td>\n      <td>0.093728</td>\n      <td>1.089443</td>\n      <td>0.034658</td>\n      <td>...</td>\n      <td>-1.249761</td>\n      <td>0.075797</td>\n      <td>-0.041238</td>\n      <td>1.517207</td>\n      <td>-1.321866</td>\n      <td>0.039047</td>\n      <td>-0.343064</td>\n      <td>0.703713</td>\n      <td>-1.296715</td>\n      <td>0.053783</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>-0.697730</td>\n      <td>0.240140</td>\n      <td>-0.150029</td>\n      <td>0.654572</td>\n      <td>0.090435</td>\n      <td>1.204279</td>\n      <td>-0.120440</td>\n      <td>0.860405</td>\n      <td>-0.205405</td>\n      <td>...</td>\n      <td>-1.247045</td>\n      <td>0.076872</td>\n      <td>-0.038917</td>\n      <td>1.500233</td>\n      <td>-1.321964</td>\n      <td>0.039963</td>\n      <td>-0.262647</td>\n      <td>0.796673</td>\n      <td>-1.295571</td>\n      <td>0.055715</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>-0.282784</td>\n      <td>0.659516</td>\n      <td>-0.161019</td>\n      <td>0.630837</td>\n      <td>0.074087</td>\n      <td>1.150694</td>\n      <td>0.009126</td>\n      <td>1.011924</td>\n      <td>-0.015329</td>\n      <td>...</td>\n      <td>0.057313</td>\n      <td>0.620208</td>\n      <td>-0.000343</td>\n      <td>0.854827</td>\n      <td>0.091327</td>\n      <td>0.615827</td>\n      <td>0.003169</td>\n      <td>1.001825</td>\n      <td>-0.119147</td>\n      <td>0.666223</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>-0.232401</td>\n      <td>0.685470</td>\n      <td>-0.015737</td>\n      <td>0.700485</td>\n      <td>0.046679</td>\n      <td>1.089923</td>\n      <td>-0.007146</td>\n      <td>0.995703</td>\n      <td>-0.054119</td>\n      <td>...</td>\n      <td>0.181429</td>\n      <td>0.351912</td>\n      <td>-0.083312</td>\n      <td>0.795862</td>\n      <td>0.163803</td>\n      <td>0.221879</td>\n      <td>0.304640</td>\n      <td>1.118547</td>\n      <td>0.201155</td>\n      <td>0.259169</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.158066</td>\n      <td>0.649377</td>\n      <td>-0.166578</td>\n      <td>0.615275</td>\n      <td>-0.096248</td>\n      <td>0.822343</td>\n      <td>-0.103753</td>\n      <td>0.874092</td>\n      <td>-0.029301</td>\n      <td>...</td>\n      <td>0.598319</td>\n      <td>0.813403</td>\n      <td>0.011549</td>\n      <td>0.781451</td>\n      <td>0.693618</td>\n      <td>0.756534</td>\n      <td>-0.107430</td>\n      <td>0.931284</td>\n      <td>0.723883</td>\n      <td>0.773875</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>3.143187</td>\n      <td>2.439230</td>\n      <td>2.706500</td>\n      <td>2.313855</td>\n      <td>0.271281</td>\n      <td>1.382523</td>\n      <td>0.231350</td>\n      <td>1.203363</td>\n      <td>0.319538</td>\n      <td>...</td>\n      <td>0.467564</td>\n      <td>0.400990</td>\n      <td>0.102508</td>\n      <td>0.786521</td>\n      <td>0.586888</td>\n      <td>0.337967</td>\n      <td>-0.229278</td>\n      <td>0.829939</td>\n      <td>0.593615</td>\n      <td>0.373136</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>-0.721131</td>\n      <td>0.146710</td>\n      <td>-0.300772</td>\n      <td>0.524740</td>\n      <td>-0.189478</td>\n      <td>0.446730</td>\n      <td>-0.135635</td>\n      <td>0.829346</td>\n      <td>-0.139575</td>\n      <td>...</td>\n      <td>-0.938712</td>\n      <td>0.125397</td>\n      <td>0.059150</td>\n      <td>1.033868</td>\n      <td>-0.951843</td>\n      <td>0.066889</td>\n      <td>-0.551562</td>\n      <td>0.270841</td>\n      <td>-0.927467</td>\n      <td>0.095268</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>-0.104851</td>\n      <td>0.679132</td>\n      <td>-0.036045</td>\n      <td>0.634274</td>\n      <td>0.246678</td>\n      <td>1.391353</td>\n      <td>0.117895</td>\n      <td>1.108954</td>\n      <td>0.207677</td>\n      <td>...</td>\n      <td>0.202768</td>\n      <td>0.382776</td>\n      <td>0.030586</td>\n      <td>0.806875</td>\n      <td>0.166461</td>\n      <td>0.235206</td>\n      <td>0.382666</td>\n      <td>1.133844</td>\n      <td>0.203221</td>\n      <td>0.269371</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>-0.271142</td>\n      <td>0.659823</td>\n      <td>-0.225246</td>\n      <td>0.597200</td>\n      <td>-0.220091</td>\n      <td>0.356207</td>\n      <td>-0.118118</td>\n      <td>0.860403</td>\n      <td>-0.109770</td>\n      <td>...</td>\n      <td>0.135318</td>\n      <td>0.344102</td>\n      <td>0.014278</td>\n      <td>0.806924</td>\n      <td>0.148203</td>\n      <td>0.200679</td>\n      <td>0.089307</td>\n      <td>1.045414</td>\n      <td>0.187014</td>\n      <td>0.237027</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>-0.727649</td>\n      <td>0.118438</td>\n      <td>-0.258905</td>\n      <td>0.576022</td>\n      <td>-0.055461</td>\n      <td>0.982893</td>\n      <td>-0.192187</td>\n      <td>0.750790</td>\n      <td>-0.235703</td>\n      <td>...</td>\n      <td>0.989434</td>\n      <td>0.418249</td>\n      <td>0.002800</td>\n      <td>0.760587</td>\n      <td>1.238022</td>\n      <td>0.342673</td>\n      <td>-0.423024</td>\n      <td>0.586265</td>\n      <td>1.289273</td>\n      <td>0.387340</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>0.635275</td>\n      <td>0.339361</td>\n      <td>-0.056001</td>\n      <td>0.677813</td>\n      <td>0.152709</td>\n      <td>1.176595</td>\n      <td>0.153338</td>\n      <td>1.140824</td>\n      <td>0.141723</td>\n      <td>...</td>\n      <td>1.357680</td>\n      <td>0.814816</td>\n      <td>0.090750</td>\n      <td>0.754293</td>\n      <td>1.363314</td>\n      <td>0.793708</td>\n      <td>0.325189</td>\n      <td>1.123097</td>\n      <td>1.404245</td>\n      <td>0.827980</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>-0.021278</td>\n      <td>0.710149</td>\n      <td>-0.078041</td>\n      <td>0.687841</td>\n      <td>-0.018395</td>\n      <td>1.017511</td>\n      <td>-0.110720</td>\n      <td>0.869467</td>\n      <td>-0.041030</td>\n      <td>...</td>\n      <td>0.945434</td>\n      <td>0.967063</td>\n      <td>-0.021168</td>\n      <td>0.761290</td>\n      <td>0.998179</td>\n      <td>0.838501</td>\n      <td>0.101227</td>\n      <td>1.050730</td>\n      <td>0.691226</td>\n      <td>0.945483</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>-0.185612</td>\n      <td>0.676289</td>\n      <td>-0.142795</td>\n      <td>0.643032</td>\n      <td>0.063102</td>\n      <td>1.161667</td>\n      <td>0.010982</td>\n      <td>1.008197</td>\n      <td>0.165051</td>\n      <td>...</td>\n      <td>0.571116</td>\n      <td>0.831306</td>\n      <td>0.043907</td>\n      <td>0.796607</td>\n      <td>0.581986</td>\n      <td>0.742660</td>\n      <td>0.192093</td>\n      <td>1.086245</td>\n      <td>0.616971</td>\n      <td>0.759520</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>-0.314644</td>\n      <td>0.654205</td>\n      <td>-0.178169</td>\n      <td>0.626934</td>\n      <td>0.003717</td>\n      <td>0.929273</td>\n      <td>0.036658</td>\n      <td>1.037525</td>\n      <td>0.011504</td>\n      <td>...</td>\n      <td>-0.197608</td>\n      <td>0.556368</td>\n      <td>0.036053</td>\n      <td>0.872596</td>\n      <td>-0.167632</td>\n      <td>0.543036</td>\n      <td>-0.149532</td>\n      <td>0.899437</td>\n      <td>-0.138293</td>\n      <td>0.558949</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>0.632662</td>\n      <td>0.188627</td>\n      <td>-0.185460</td>\n      <td>0.607856</td>\n      <td>-0.234371</td>\n      <td>0.313079</td>\n      <td>-0.129173</td>\n      <td>0.838994</td>\n      <td>-0.020243</td>\n      <td>...</td>\n      <td>-0.905543</td>\n      <td>0.145054</td>\n      <td>-0.005144</td>\n      <td>1.041384</td>\n      <td>-0.952655</td>\n      <td>0.073674</td>\n      <td>-0.137096</td>\n      <td>0.909162</td>\n      <td>-0.930457</td>\n      <td>0.100839</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>0.443974</td>\n      <td>0.520875</td>\n      <td>0.039492</td>\n      <td>0.725380</td>\n      <td>0.122851</td>\n      <td>1.023481</td>\n      <td>0.200226</td>\n      <td>1.181983</td>\n      <td>0.033477</td>\n      <td>...</td>\n      <td>1.029578</td>\n      <td>0.699533</td>\n      <td>0.003914</td>\n      <td>0.757692</td>\n      <td>1.009419</td>\n      <td>0.591589</td>\n      <td>0.450997</td>\n      <td>1.142643</td>\n      <td>1.053373</td>\n      <td>0.615371</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>0.384902</td>\n      <td>0.617595</td>\n      <td>-0.063021</td>\n      <td>0.735878</td>\n      <td>-0.022033</td>\n      <td>0.961086</td>\n      <td>-0.074923</td>\n      <td>0.919427</td>\n      <td>-0.184359</td>\n      <td>...</td>\n      <td>0.099563</td>\n      <td>0.339832</td>\n      <td>0.004732</td>\n      <td>0.809621</td>\n      <td>0.137315</td>\n      <td>0.228768</td>\n      <td>-0.017628</td>\n      <td>0.989911</td>\n      <td>0.173709</td>\n      <td>0.262744</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>0.254401</td>\n      <td>0.611816</td>\n      <td>-0.220317</td>\n      <td>0.606026</td>\n      <td>0.070202</td>\n      <td>0.914211</td>\n      <td>0.216947</td>\n      <td>1.188632</td>\n      <td>0.070488</td>\n      <td>...</td>\n      <td>0.169098</td>\n      <td>0.355518</td>\n      <td>-0.007251</td>\n      <td>0.815694</td>\n      <td>0.150350</td>\n      <td>0.198716</td>\n      <td>0.194498</td>\n      <td>1.087090</td>\n      <td>0.192987</td>\n      <td>0.235624</td>\n    </tr>\n  </tbody>\n</table>\n<p>29 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Compute historical baselines with proper handling of NaN values\ndf['rolling_avg_logon'] = df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=1).mean()\n)\ndf['rolling_std_logon'] = df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=2).std()\n)\n\n# Fill NaN values in rolling_std_logon (e.g., when there's only 1 data point)\ndf['rolling_std_logon'] = df['rolling_std_logon'].fillna(0)\n\n# Compute Z-score, avoiding division by zero\ndf['z_score_logon'] = (\n    (df['total_logon_count'] - df['rolling_avg_logon']) / \n    df['rolling_std_logon'].replace(0, 1)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:49:25.642086Z","iopub.execute_input":"2025-05-06T15:49:25.642985Z","iopub.status.idle":"2025-05-06T15:49:26.094241Z","shell.execute_reply.started":"2025-05-06T15:49:25.642961Z","shell.execute_reply":"2025-05-06T15:49:26.093689Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:49:28.041764Z","iopub.execute_input":"2025-05-06T15:49:28.042212Z","iopub.status.idle":"2025-05-06T15:49:28.141351Z","shell.execute_reply.started":"2025-05-06T15:49:28.042188Z","shell.execute_reply":"2025-05-06T15:49:28.140593Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  \\\n0            -0.287121          0.930009       -0.759447  ...   \n1            -0.287121          0.711501       -0.233484  ...   \n2            -0.287121          0.766128       -0.064106  ...   \n3            -0.287121          0.875382       -0.179997  ...   \n4            -0.287121          0.766128       -0.607898  ...   \n...                ...               ...             ...  ...   \n330280       -0.287121         -1.309699       -1.107117  ...   \n330281       -0.287121         -1.200445        2.137805  ...   \n330282       -0.287121         -1.091191        3.760267  ...   \n330283       -0.287121         -1.309699        0.515344  ...   \n330284       -0.287121         -1.309699        0.515344  ...   \n\n        role_emb_pca_43  role_emb_pca_44  role_emb_pca_45 role_emb_pca_46  \\\n0             -0.020691         0.050259         0.006361        0.015730   \n1             -0.020691         0.050259         0.006361        0.015730   \n2             -0.020691         0.050259         0.006361        0.015730   \n3             -0.020691         0.050259         0.006361        0.015730   \n4             -0.020691         0.050259         0.006361        0.015730   \n...                 ...              ...              ...             ...   \n330280        -0.034873        -0.010375        -0.036870       -0.019237   \n330281        -0.034873        -0.010375        -0.036870       -0.019237   \n330282        -0.034873        -0.010375        -0.036870       -0.019237   \n330283        -0.034873        -0.010375        -0.036870       -0.019237   \n330284        -0.034873        -0.010375        -0.036870       -0.019237   \n\n       role_emb_pca_47  role_emb_pca_48 role_emb_pca_49 rolling_avg_logon  \\\n0             0.100858        -0.073232        0.012029          -0.53406   \n1             0.100858        -0.073232        0.012029          -0.53406   \n2             0.100858        -0.073232        0.012029          -0.53406   \n3             0.100858        -0.073232        0.012029          -0.53406   \n4             0.100858        -0.073232        0.012029          -0.53406   \n...                ...              ...             ...               ...   \n330280        0.017186         0.054031        0.010085          -0.53406   \n330281        0.017186         0.054031        0.010085          -0.53406   \n330282        0.017186         0.054031        0.010085          -0.53406   \n330283        0.017186         0.054031        0.010085          -0.53406   \n330284        0.017186         0.054031        0.010085          -0.53406   \n\n       rolling_std_logon z_score_logon  \n0                    0.0           0.0  \n1                    0.0           0.0  \n2                    0.0           0.0  \n3                    0.0           0.0  \n4                    0.0           0.0  \n...                  ...           ...  \n330280               0.0           0.0  \n330281               0.0           0.0  \n330282               0.0           0.0  \n330283               0.0           0.0  \n330284               0.0           0.0  \n\n[330285 rows x 76 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>role_emb_pca_43</th>\n      <th>role_emb_pca_44</th>\n      <th>role_emb_pca_45</th>\n      <th>role_emb_pca_46</th>\n      <th>role_emb_pca_47</th>\n      <th>role_emb_pca_48</th>\n      <th>role_emb_pca_49</th>\n      <th>rolling_avg_logon</th>\n      <th>rolling_std_logon</th>\n      <th>z_score_logon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 76 columns</p>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:49:29.594221Z","iopub.execute_input":"2025-05-06T15:49:29.594792Z","iopub.status.idle":"2025-05-06T15:49:29.800049Z","shell.execute_reply.started":"2025-05-06T15:49:29.594769Z","shell.execute_reply":"2025-05-06T15:49:29.799376Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"user                       0\ndate_only                  0\nafter_hours_logon_count    0\ntotal_logon_count          0\ndevice_connects            0\n                          ..\nrole_emb_pca_48            0\nrole_emb_pca_49            0\nrolling_avg_logon          0\nrolling_std_logon          0\nz_score_logon              0\nLength: 76, dtype: int64"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"high_level_roles = {'President', 'VicePresident', 'Manager'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:15:35.78303Z","iopub.execute_input":"2025-05-07T05:15:35.783761Z","iopub.status.idle":"2025-05-07T05:15:35.787158Z","shell.execute_reply.started":"2025-05-07T05:15:35.783733Z","shell.execute_reply":"2025-05-07T05:15:35.786302Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"df['role'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:51:02.443826Z","iopub.execute_input":"2025-05-06T15:51:02.444127Z","iopub.status.idle":"2025-05-06T15:51:02.464084Z","shell.execute_reply.started":"2025-05-06T15:51:02.444106Z","shell.execute_reply":"2025-05-06T15:51:02.463255Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"array(['Manager', 'Technician', 'Physicist', 'ProductionLineWorker',\n       'AssemblySupervisor', 'Salesman', 'ElectricalEngineer',\n       'SoftwareEngineer', 'ITAdmin', 'ComputerProgrammer', 'Engineer',\n       'SystemsEngineer', 'Scientist', 'ManagementTrainer',\n       'AdministrativeAssistant', 'Mathematician', 'ChiefEngineer',\n       'Director', 'SecurityGuard', 'ComputerScientist', 'TestEngineer',\n       'HumanResourceSpecialist', 'HealthSafetyEngineer',\n       'MechanicalEngineer', 'HardwareEngineer', 'FieldServiceEngineer',\n       'IndustrialEngineer', 'VicePresident', 'Attorney',\n       'MaterialsEngineer', 'PurchasingClerk', 'NursePractitioner',\n       'Statistician', 'TechnicalTrainer', 'LabManager',\n       'InstructionalCoordinator', 'Accountant', 'Nurse', 'President',\n       'ComputerTrainer', 'FinancialAnalyst', 'AdministrativeStaff'],\n      dtype=object)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"is_anomaly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:51:47.800962Z","iopub.execute_input":"2025-05-06T15:51:47.801334Z","iopub.status.idle":"2025-05-06T15:51:47.806908Z","shell.execute_reply.started":"2025-05-06T15:51:47.801309Z","shell.execute_reply":"2025-05-06T15:51:47.806163Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"df = pd.concat([df, pd.DataFrame(is_anomaly)], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:53:29.880134Z","iopub.execute_input":"2025-05-06T15:53:29.880643Z","iopub.status.idle":"2025-05-06T15:53:30.069576Z","shell.execute_reply.started":"2025-05-06T15:53:29.880621Z","shell.execute_reply":"2025-05-06T15:53:30.069049Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"df.rename(columns = {0:'is_anomaly'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:26.260724Z","iopub.execute_input":"2025-05-06T15:54:26.261297Z","iopub.status.idle":"2025-05-06T15:54:26.265154Z","shell.execute_reply.started":"2025-05-06T15:54:26.261275Z","shell.execute_reply":"2025-05-06T15:54:26.264319Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:27.3026Z","iopub.execute_input":"2025-05-06T15:54:27.302882Z","iopub.status.idle":"2025-05-06T15:54:27.308946Z","shell.execute_reply.started":"2025-05-06T15:54:27.302859Z","shell.execute_reply":"2025-05-06T15:54:27.308187Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49', 'rolling_avg_logon',\n       'rolling_std_logon', 'z_score_logon', 'is_anomaly'],\n      dtype='object')"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"df['is_anomaly'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:44.268003Z","iopub.execute_input":"2025-05-06T15:54:44.268288Z","iopub.status.idle":"2025-05-06T15:54:44.276423Z","shell.execute_reply.started":"2025-05-06T15:54:44.268268Z","shell.execute_reply":"2025-05-06T15:54:44.275801Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"array([0, 1])"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"role_anomaly_rates = df.groupby('role')['is_anomaly'].mean().to_dict()\ndf['role_anomaly_rate'] = df['role'].map(role_anomaly_rates)\ndf['role_sensitivity'] = df['role'].apply(lambda x: 1.5 if x in high_level_roles else 1.0)\ndf['adaptive_threshold'] = df.apply(\n    lambda row: max(0.5, min(0.95, 0.9 - row['role_anomaly_rate'] * 10)) * row['role_sensitivity'],\n    axis=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:47.339633Z","iopub.execute_input":"2025-05-06T15:54:47.339881Z","iopub.status.idle":"2025-05-06T15:54:50.86404Z","shell.execute_reply.started":"2025-05-06T15:54:47.339865Z","shell.execute_reply":"2025-05-06T15:54:50.863471Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"role_anomaly_rates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:54.464958Z","iopub.execute_input":"2025-05-06T15:54:54.465526Z","iopub.status.idle":"2025-05-06T15:54:54.470307Z","shell.execute_reply.started":"2025-05-06T15:54:54.465505Z","shell.execute_reply":"2025-05-06T15:54:54.469619Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"{'Accountant': 0.0,\n 'AdministrativeAssistant': 0.0012410027302060065,\n 'AdministrativeStaff': 0.0,\n 'AssemblySupervisor': 0.02167630057803468,\n 'Attorney': 0.0,\n 'ChiefEngineer': 0.0,\n 'ComputerProgrammer': 0.0006335529650278763,\n 'ComputerScientist': 0.000975800156128025,\n 'ComputerTrainer': 0.0,\n 'Director': 0.009875382083235363,\n 'ElectricalEngineer': 0.012746972594008922,\n 'Engineer': 0.0,\n 'FieldServiceEngineer': 0.0036213140196585617,\n 'FinancialAnalyst': 0.0,\n 'HardwareEngineer': 0.0,\n 'HealthSafetyEngineer': 0.0,\n 'HumanResourceSpecialist': 0.009013068949977467,\n 'ITAdmin': 0.003438243850833113,\n 'IndustrialEngineer': 0.0,\n 'InstructionalCoordinator': 0.0,\n 'LabManager': 0.0004816955684007707,\n 'ManagementTrainer': 0.0,\n 'Manager': 0.0,\n 'MaterialsEngineer': 0.0,\n 'Mathematician': 0.0025002500250025004,\n 'MechanicalEngineer': 0.0,\n 'Nurse': 0.0,\n 'NursePractitioner': 0.0,\n 'Physicist': 0.005589795040848502,\n 'President': 0.0,\n 'ProductionLineWorker': 0.006761933313347323,\n 'PurchasingClerk': 0.0032171581769436996,\n 'Salesman': 0.004143844749420477,\n 'Scientist': 0.003391079985256174,\n 'SecurityGuard': 0.003148148148148148,\n 'SoftwareEngineer': 0.0037458477630927982,\n 'Statistician': 0.0,\n 'SystemsEngineer': 0.00760397268777157,\n 'TechnicalTrainer': 0.0,\n 'Technician': 0.003016679317257352,\n 'TestEngineer': 0.00641333974667308,\n 'VicePresident': 0.0009633911368015414}"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# Assuming mu_all has shape (n_samples, 8)\nlatent_cols = [f'latent_{i}' for i in range(8)]\nmu_df = pd.DataFrame(mu_all, columns=latent_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:59:51.086545Z","iopub.execute_input":"2025-05-06T15:59:51.086775Z","iopub.status.idle":"2025-05-06T15:59:51.090937Z","shell.execute_reply.started":"2025-05-06T15:59:51.086759Z","shell.execute_reply":"2025-05-06T15:59:51.090166Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"latent_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:59:51.515484Z","iopub.execute_input":"2025-05-06T15:59:51.516156Z","iopub.status.idle":"2025-05-06T15:59:51.520362Z","shell.execute_reply.started":"2025-05-06T15:59:51.516135Z","shell.execute_reply":"2025-05-06T15:59:51.519752Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"['latent_0',\n 'latent_1',\n 'latent_2',\n 'latent_3',\n 'latent_4',\n 'latent_5',\n 'latent_6',\n 'latent_7']"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"mu_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:59:54.109602Z","iopub.execute_input":"2025-05-06T15:59:54.109869Z","iopub.status.idle":"2025-05-06T15:59:54.121983Z","shell.execute_reply.started":"2025-05-06T15:59:54.109848Z","shell.execute_reply":"2025-05-06T15:59:54.121304Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"        latent_0  latent_1  latent_2  latent_3  latent_4  latent_5  latent_6  \\\n0       0.162010  0.212356  0.332929  1.358423  0.865449 -0.272068 -1.299133   \n1      -0.586932 -1.693140  0.743226  1.390613  1.200229 -0.791344 -2.358883   \n2       0.009564  0.176500  0.361936  1.551322 -1.606209 -0.954709 -1.409040   \n3       0.312718 -0.854660  0.708290  1.371941  1.233096 -0.684225 -1.873350   \n4      -0.150169 -0.856407  0.752896  1.831241  1.200472 -0.927860 -1.808192   \n...          ...       ...       ...       ...       ...       ...       ...   \n330280 -2.208897  2.103745  0.458602  1.763067 -0.995745  0.276827 -0.462649   \n330281 -0.275111  2.401922  0.789105  1.548555 -1.482661  0.206049 -0.372423   \n330282  0.524928  2.767483  0.349481  1.440403 -0.617000  1.662273  0.899720   \n330283  0.793959  2.312001  1.062207  1.697968 -0.476613  0.776005 -0.128473   \n330284  1.658483  1.941789  0.536726  1.160636 -1.375117  0.191196 -0.295697   \n\n        latent_7  \n0       0.161966  \n1      -1.180279  \n2      -1.016945  \n3      -0.914131  \n4      -1.198772  \n...          ...  \n330280 -1.889442  \n330281  0.337695  \n330282 -0.520850  \n330283 -1.073551  \n330284  0.311196  \n\n[330285 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latent_0</th>\n      <th>latent_1</th>\n      <th>latent_2</th>\n      <th>latent_3</th>\n      <th>latent_4</th>\n      <th>latent_5</th>\n      <th>latent_6</th>\n      <th>latent_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.162010</td>\n      <td>0.212356</td>\n      <td>0.332929</td>\n      <td>1.358423</td>\n      <td>0.865449</td>\n      <td>-0.272068</td>\n      <td>-1.299133</td>\n      <td>0.161966</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.586932</td>\n      <td>-1.693140</td>\n      <td>0.743226</td>\n      <td>1.390613</td>\n      <td>1.200229</td>\n      <td>-0.791344</td>\n      <td>-2.358883</td>\n      <td>-1.180279</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.009564</td>\n      <td>0.176500</td>\n      <td>0.361936</td>\n      <td>1.551322</td>\n      <td>-1.606209</td>\n      <td>-0.954709</td>\n      <td>-1.409040</td>\n      <td>-1.016945</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.312718</td>\n      <td>-0.854660</td>\n      <td>0.708290</td>\n      <td>1.371941</td>\n      <td>1.233096</td>\n      <td>-0.684225</td>\n      <td>-1.873350</td>\n      <td>-0.914131</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.150169</td>\n      <td>-0.856407</td>\n      <td>0.752896</td>\n      <td>1.831241</td>\n      <td>1.200472</td>\n      <td>-0.927860</td>\n      <td>-1.808192</td>\n      <td>-1.198772</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>-2.208897</td>\n      <td>2.103745</td>\n      <td>0.458602</td>\n      <td>1.763067</td>\n      <td>-0.995745</td>\n      <td>0.276827</td>\n      <td>-0.462649</td>\n      <td>-1.889442</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>-0.275111</td>\n      <td>2.401922</td>\n      <td>0.789105</td>\n      <td>1.548555</td>\n      <td>-1.482661</td>\n      <td>0.206049</td>\n      <td>-0.372423</td>\n      <td>0.337695</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>0.524928</td>\n      <td>2.767483</td>\n      <td>0.349481</td>\n      <td>1.440403</td>\n      <td>-0.617000</td>\n      <td>1.662273</td>\n      <td>0.899720</td>\n      <td>-0.520850</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>0.793959</td>\n      <td>2.312001</td>\n      <td>1.062207</td>\n      <td>1.697968</td>\n      <td>-0.476613</td>\n      <td>0.776005</td>\n      <td>-0.128473</td>\n      <td>-1.073551</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>1.658483</td>\n      <td>1.941789</td>\n      <td>0.536726</td>\n      <td>1.160636</td>\n      <td>-1.375117</td>\n      <td>0.191196</td>\n      <td>-0.295697</td>\n      <td>0.311196</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:57:45.699475Z","iopub.execute_input":"2025-05-06T15:57:45.699747Z","iopub.status.idle":"2025-05-06T15:57:45.704971Z","shell.execute_reply.started":"2025-05-06T15:57:45.699726Z","shell.execute_reply":"2025-05-06T15:57:45.704143Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49', 'rolling_avg_logon',\n       'rolling_std_logon', 'z_score_logon', 'is_anomaly', 'role_anomaly_rate',\n       'role_sensitivity', 'adaptive_threshold'],\n      dtype='object')"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"embedding_cols = [f'role_emb_pca_{i}' for i in range(50)] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:58:00.89166Z","iopub.execute_input":"2025-05-06T15:58:00.892445Z","iopub.status.idle":"2025-05-06T15:58:00.895897Z","shell.execute_reply.started":"2025-05-06T15:58:00.892417Z","shell.execute_reply":"2025-05-06T15:58:00.895006Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"history_cols = ['z_score_logon']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:58:10.080788Z","iopub.execute_input":"2025-05-06T15:58:10.081221Z","iopub.status.idle":"2025-05-06T15:58:10.085366Z","shell.execute_reply.started":"2025-05-06T15:58:10.081192Z","shell.execute_reply":"2025-05-06T15:58:10.084482Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"feature_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:58:45.520405Z","iopub.execute_input":"2025-05-06T15:58:45.520662Z","iopub.status.idle":"2025-05-06T15:58:45.525495Z","shell.execute_reply.started":"2025-05-06T15:58:45.520642Z","shell.execute_reply":"2025-05-06T15:58:45.524924Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"['after_hours_logon_count',\n 'total_logon_count',\n 'device_connects',\n 'avg_content_word_count',\n 'text_files_accessed',\n 'files_accessed',\n 'total_recipients',\n 'external_ratio',\n 'emails_sent',\n 'bcc_flag',\n 'keyword_richness']"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"df[feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:00:37.228573Z","iopub.execute_input":"2025-05-06T16:00:37.2291Z","iopub.status.idle":"2025-05-06T16:00:37.24895Z","shell.execute_reply.started":"2025-05-06T16:00:37.229075Z","shell.execute_reply":"2025-05-06T16:00:37.248255Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"        after_hours_logon_count  total_logon_count  device_connects  \\\n0                     -0.737332           -0.53406        -0.331274   \n1                     -0.737332           -0.53406        -0.331274   \n2                     -0.737332           -0.53406        -0.331274   \n3                     -0.737332           -0.53406        -0.331274   \n4                     -0.737332           -0.53406        -0.331274   \n...                         ...                ...              ...   \n330280                -0.737332           -0.53406        -0.331274   \n330281                -0.737332           -0.53406        -0.331274   \n330282                -0.737332           -0.53406        -0.331274   \n330283                -0.737332           -0.53406        -0.331274   \n330284                -0.737332           -0.53406        -0.331274   \n\n        avg_content_word_count  text_files_accessed  files_accessed  \\\n0                    -0.396378            -0.285834       -0.287121   \n1                    -0.396378            -0.285834       -0.287121   \n2                    -0.396378            -0.285834       -0.287121   \n3                    -0.396378            -0.285834       -0.287121   \n4                    -0.396378            -0.285834       -0.287121   \n...                        ...                  ...             ...   \n330280               -0.396378            -0.285834       -0.287121   \n330281               -0.396378            -0.285834       -0.287121   \n330282               -0.396378            -0.285834       -0.287121   \n330283               -0.396378            -0.285834       -0.287121   \n330284               -0.396378            -0.285834       -0.287121   \n\n        total_recipients  external_ratio  emails_sent  bcc_flag  \\\n0               0.930009       -0.759447     1.141349 -0.583959   \n1               0.711501       -0.233484     0.952298 -0.583959   \n2               0.766128       -0.064106     1.141349 -0.583959   \n3               0.875382       -0.179997     1.141349 -0.583959   \n4               0.766128       -0.607898     0.952298 -0.583959   \n...                  ...             ...          ...       ...   \n330280         -1.309699       -1.107117    -1.316319 -0.583959   \n330281         -1.200445        2.137805    -1.316319 -0.583959   \n330282         -1.091191        3.760267    -1.316319 -0.583959   \n330283         -1.309699        0.515344    -1.316319 -0.583959   \n330284         -1.309699        0.515344    -1.316319 -0.583959   \n\n        keyword_richness  \n0               0.386906  \n1               0.374986  \n2               1.463670  \n3               0.323333  \n4               0.001496  \n...                  ...  \n330280         -1.317639  \n330281         -1.285853  \n330282         -1.289826  \n330283         -1.361345  \n330284         -1.214333  \n\n[330285 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.317639</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.285853</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.289826</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.361345</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.214333</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 11 columns</p>\n</div>"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"all_features = pd.concat(\n    [df[['user','date_only']], df[feature_cols], mu_df[latent_cols], df[embedding_cols + history_cols]],\n    axis=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:18:41.610538Z","iopub.execute_input":"2025-05-06T16:18:41.610797Z","iopub.status.idle":"2025-05-06T16:18:41.730849Z","shell.execute_reply.started":"2025-05-06T16:18:41.610777Z","shell.execute_reply":"2025-05-06T16:18:41.730147Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"all_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:18:43.420209Z","iopub.execute_input":"2025-05-06T16:18:43.420475Z","iopub.status.idle":"2025-05-06T16:18:43.515327Z","shell.execute_reply.started":"2025-05-06T16:18:43.420453Z","shell.execute_reply":"2025-05-06T16:18:43.514644Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  \\\n0            -0.287121          0.930009       -0.759447  ...   \n1            -0.287121          0.711501       -0.233484  ...   \n2            -0.287121          0.766128       -0.064106  ...   \n3            -0.287121          0.875382       -0.179997  ...   \n4            -0.287121          0.766128       -0.607898  ...   \n...                ...               ...             ...  ...   \n330280       -0.287121         -1.309699       -1.107117  ...   \n330281       -0.287121         -1.200445        2.137805  ...   \n330282       -0.287121         -1.091191        3.760267  ...   \n330283       -0.287121         -1.309699        0.515344  ...   \n330284       -0.287121         -1.309699        0.515344  ...   \n\n        role_emb_pca_41  role_emb_pca_42  role_emb_pca_43  role_emb_pca_44  \\\n0              0.153742         0.053482        -0.020691         0.050259   \n1              0.153742         0.053482        -0.020691         0.050259   \n2              0.153742         0.053482        -0.020691         0.050259   \n3              0.153742         0.053482        -0.020691         0.050259   \n4              0.153742         0.053482        -0.020691         0.050259   \n...                 ...              ...              ...              ...   \n330280        -0.045802        -0.048467        -0.034873        -0.010375   \n330281        -0.045802        -0.048467        -0.034873        -0.010375   \n330282        -0.045802        -0.048467        -0.034873        -0.010375   \n330283        -0.045802        -0.048467        -0.034873        -0.010375   \n330284        -0.045802        -0.048467        -0.034873        -0.010375   \n\n        role_emb_pca_45  role_emb_pca_46  role_emb_pca_47  role_emb_pca_48  \\\n0              0.006361         0.015730         0.100858        -0.073232   \n1              0.006361         0.015730         0.100858        -0.073232   \n2              0.006361         0.015730         0.100858        -0.073232   \n3              0.006361         0.015730         0.100858        -0.073232   \n4              0.006361         0.015730         0.100858        -0.073232   \n...                 ...              ...              ...              ...   \n330280        -0.036870        -0.019237         0.017186         0.054031   \n330281        -0.036870        -0.019237         0.017186         0.054031   \n330282        -0.036870        -0.019237         0.017186         0.054031   \n330283        -0.036870        -0.019237         0.017186         0.054031   \n330284        -0.036870        -0.019237         0.017186         0.054031   \n\n        role_emb_pca_49  z_score_logon  \n0              0.012029            0.0  \n1              0.012029            0.0  \n2              0.012029            0.0  \n3              0.012029            0.0  \n4              0.012029            0.0  \n...                 ...            ...  \n330280         0.010085            0.0  \n330281         0.010085            0.0  \n330282         0.010085            0.0  \n330283         0.010085            0.0  \n330284         0.010085            0.0  \n\n[330285 rows x 72 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>role_emb_pca_41</th>\n      <th>role_emb_pca_42</th>\n      <th>role_emb_pca_43</th>\n      <th>role_emb_pca_44</th>\n      <th>role_emb_pca_45</th>\n      <th>role_emb_pca_46</th>\n      <th>role_emb_pca_47</th>\n      <th>role_emb_pca_48</th>\n      <th>role_emb_pca_49</th>\n      <th>z_score_logon</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 72 columns</p>\n</div>"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:16:01.688986Z","iopub.execute_input":"2025-05-06T16:16:01.689694Z","iopub.status.idle":"2025-05-06T16:16:01.69424Z","shell.execute_reply.started":"2025-05-06T16:16:01.68967Z","shell.execute_reply":"2025-05-06T16:16:01.693453Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"(330285, 80)"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"all_features['z_score_logon'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:17:31.514744Z","iopub.execute_input":"2025-05-06T16:17:31.515244Z","iopub.status.idle":"2025-05-06T16:17:31.523655Z","shell.execute_reply.started":"2025-05-06T16:17:31.515221Z","shell.execute_reply":"2025-05-06T16:17:31.523054Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"array([ 0.        , -2.26778684,  0.37796447, ...,  1.65615734,\n        0.61237244,  0.10619885])"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"all_features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:19:02.112568Z","iopub.execute_input":"2025-05-06T16:19:02.113149Z","iopub.status.idle":"2025-05-06T16:19:02.118006Z","shell.execute_reply.started":"2025-05-06T16:19:02.113126Z","shell.execute_reply":"2025-05-06T16:19:02.117273Z"}},"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'latent_0', 'latent_1', 'latent_2',\n       'latent_3', 'latent_4', 'latent_5', 'latent_6', 'latent_7',\n       'role_emb_pca_0', 'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3',\n       'role_emb_pca_4', 'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7',\n       'role_emb_pca_8', 'role_emb_pca_9', 'role_emb_pca_10',\n       'role_emb_pca_11', 'role_emb_pca_12', 'role_emb_pca_13',\n       'role_emb_pca_14', 'role_emb_pca_15', 'role_emb_pca_16',\n       'role_emb_pca_17', 'role_emb_pca_18', 'role_emb_pca_19',\n       'role_emb_pca_20', 'role_emb_pca_21', 'role_emb_pca_22',\n       'role_emb_pca_23', 'role_emb_pca_24', 'role_emb_pca_25',\n       'role_emb_pca_26', 'role_emb_pca_27', 'role_emb_pca_28',\n       'role_emb_pca_29', 'role_emb_pca_30', 'role_emb_pca_31',\n       'role_emb_pca_32', 'role_emb_pca_33', 'role_emb_pca_34',\n       'role_emb_pca_35', 'role_emb_pca_36', 'role_emb_pca_37',\n       'role_emb_pca_38', 'role_emb_pca_39', 'role_emb_pca_40',\n       'role_emb_pca_41', 'role_emb_pca_42', 'role_emb_pca_43',\n       'role_emb_pca_44', 'role_emb_pca_45', 'role_emb_pca_46',\n       'role_emb_pca_47', 'role_emb_pca_48', 'role_emb_pca_49',\n       'z_score_logon'],\n      dtype='object')"},"metadata":{}}],"execution_count":68},{"cell_type":"code","source":"all_features = all_features.sort_values(['user', 'date_only']).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:26:48.720313Z","iopub.execute_input":"2025-05-06T16:26:48.720596Z","iopub.status.idle":"2025-05-06T16:26:49.006446Z","shell.execute_reply.started":"2025-05-06T16:26:48.720576Z","shell.execute_reply":"2025-05-06T16:26:49.005825Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/df-with-pca/df_with_pca.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:10.542007Z","iopub.execute_input":"2025-05-07T05:10:10.542251Z","iopub.status.idle":"2025-05-07T05:10:14.787905Z","shell.execute_reply.started":"2025-05-07T05:10:10.542235Z","shell.execute_reply":"2025-05-07T05:10:14.786916Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"df = df.drop(columns = 'Unnamed: 0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:17.36265Z","iopub.execute_input":"2025-05-07T05:10:17.362907Z","iopub.status.idle":"2025-05-07T05:10:17.433191Z","shell.execute_reply.started":"2025-05-07T05:10:17.362887Z","shell.execute_reply":"2025-05-07T05:10:17.432399Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"new_df = df.sort_values(['user', 'date_only'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:18.802025Z","iopub.execute_input":"2025-05-07T05:10:18.802597Z","iopub.status.idle":"2025-05-07T05:10:18.923785Z","shell.execute_reply.started":"2025-05-07T05:10:18.802573Z","shell.execute_reply":"2025-05-07T05:10:18.923227Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:20.181739Z","iopub.execute_input":"2025-05-07T05:10:20.182104Z","iopub.status.idle":"2025-05-07T05:10:20.187609Z","shell.execute_reply.started":"2025-05-07T05:10:20.182081Z","shell.execute_reply":"2025-05-07T05:10:20.186857Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49'],\n      dtype='object')"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"new_df['user_day_seq'] = df.groupby('user').cumcount()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:24.366243Z","iopub.execute_input":"2025-05-07T05:10:24.366759Z","iopub.status.idle":"2025-05-07T05:10:24.405557Z","shell.execute_reply.started":"2025-05-07T05:10:24.366736Z","shell.execute_reply":"2025-05-07T05:10:24.404832Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"new_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:27.791399Z","iopub.execute_input":"2025-05-07T05:10:27.792073Z","iopub.status.idle":"2025-05-07T05:10:27.871804Z","shell.execute_reply.started":"2025-05-07T05:10:27.792048Z","shell.execute_reply":"2025-05-07T05:10:27.871059Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  \\\n0            -0.287121          0.930009       -0.759447  ...   \n1            -0.287121          0.711501       -0.233484  ...   \n2            -0.287121          0.766128       -0.064106  ...   \n3            -0.287121          0.875382       -0.179997  ...   \n4            -0.287121          0.766128       -0.607898  ...   \n...                ...               ...             ...  ...   \n330280       -0.287121         -1.309699       -1.107117  ...   \n330281       -0.287121         -1.200445        2.137805  ...   \n330282       -0.287121         -1.091191        3.760267  ...   \n330283       -0.287121         -1.309699        0.515344  ...   \n330284       -0.287121         -1.309699        0.515344  ...   \n\n        role_emb_pca_41  role_emb_pca_42  role_emb_pca_43 role_emb_pca_44  \\\n0              0.153742         0.053482        -0.020691        0.050259   \n1              0.153742         0.053482        -0.020691        0.050259   \n2              0.153742         0.053482        -0.020691        0.050259   \n3              0.153742         0.053482        -0.020691        0.050259   \n4              0.153742         0.053482        -0.020691        0.050259   \n...                 ...              ...              ...             ...   \n330280        -0.045802        -0.048467        -0.034873       -0.010375   \n330281        -0.045802        -0.048467        -0.034873       -0.010375   \n330282        -0.045802        -0.048467        -0.034873       -0.010375   \n330283        -0.045802        -0.048467        -0.034873       -0.010375   \n330284        -0.045802        -0.048467        -0.034873       -0.010375   \n\n       role_emb_pca_45  role_emb_pca_46 role_emb_pca_47 role_emb_pca_48  \\\n0             0.006361         0.015730        0.100858       -0.073232   \n1             0.006361         0.015730        0.100858       -0.073232   \n2             0.006361         0.015730        0.100858       -0.073232   \n3             0.006361         0.015730        0.100858       -0.073232   \n4             0.006361         0.015730        0.100858       -0.073232   \n...                ...              ...             ...             ...   \n330280       -0.036870        -0.019237        0.017186        0.054031   \n330281       -0.036870        -0.019237        0.017186        0.054031   \n330282       -0.036870        -0.019237        0.017186        0.054031   \n330283       -0.036870        -0.019237        0.017186        0.054031   \n330284       -0.036870        -0.019237        0.017186        0.054031   \n\n       role_emb_pca_49 user_day_seq  \n0             0.012029            0  \n1             0.012029            1  \n2             0.012029            2  \n3             0.012029            3  \n4             0.012029            4  \n...                ...          ...  \n330280        0.010085          341  \n330281        0.010085          342  \n330282        0.010085          343  \n330283        0.010085          344  \n330284        0.010085          345  \n\n[330285 rows x 74 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>role_emb_pca_41</th>\n      <th>role_emb_pca_42</th>\n      <th>role_emb_pca_43</th>\n      <th>role_emb_pca_44</th>\n      <th>role_emb_pca_45</th>\n      <th>role_emb_pca_46</th>\n      <th>role_emb_pca_47</th>\n      <th>role_emb_pca_48</th>\n      <th>role_emb_pca_49</th>\n      <th>user_day_seq</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>0.153742</td>\n      <td>0.053482</td>\n      <td>-0.020691</td>\n      <td>0.050259</td>\n      <td>0.006361</td>\n      <td>0.015730</td>\n      <td>0.100858</td>\n      <td>-0.073232</td>\n      <td>0.012029</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>341</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>343</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.045802</td>\n      <td>-0.048467</td>\n      <td>-0.034873</td>\n      <td>-0.010375</td>\n      <td>-0.036870</td>\n      <td>-0.019237</td>\n      <td>0.017186</td>\n      <td>0.054031</td>\n      <td>0.010085</td>\n      <td>345</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 74 columns</p>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:39.102022Z","iopub.execute_input":"2025-05-07T05:10:39.10229Z","iopub.status.idle":"2025-05-07T05:10:39.107208Z","shell.execute_reply.started":"2025-05-07T05:10:39.102271Z","shell.execute_reply":"2025-05-07T05:10:39.106452Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49', 'user_day_seq'],\n      dtype='object')"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"mu_df = np.load('/kaggle/working/mu_all.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:11:47.557767Z","iopub.execute_input":"2025-05-07T05:11:47.558077Z","iopub.status.idle":"2025-05-07T05:11:47.564399Z","shell.execute_reply.started":"2025-05-07T05:11:47.558057Z","shell.execute_reply":"2025-05-07T05:11:47.563803Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"behavioral_features = [\n    'after_hours_logon_count', 'total_logon_count', 'device_connects',\n    'avg_content_word_count', 'text_files_accessed', 'files_accessed',\n    'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag',\n    'keyword_richness', 'z_score_logon'\n]\n\nlatent_features = [f'latent_{i}' for i in range(8)]\nrole_features = [f'role_emb_pca_{i}' for i in range(50)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:09:58.166713Z","iopub.execute_input":"2025-05-07T05:09:58.167533Z","iopub.status.idle":"2025-05-07T05:09:58.172663Z","shell.execute_reply.started":"2025-05-07T05:09:58.167499Z","shell.execute_reply":"2025-05-07T05:09:58.171741Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"mu_df = pd.DataFrame(mu_df, columns=latent_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:01.501653Z","iopub.execute_input":"2025-05-07T05:13:01.502361Z","iopub.status.idle":"2025-05-07T05:13:01.505984Z","shell.execute_reply.started":"2025-05-07T05:13:01.502334Z","shell.execute_reply":"2025-05-07T05:13:01.505176Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"mu_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:02.941869Z","iopub.execute_input":"2025-05-07T05:13:02.942208Z","iopub.status.idle":"2025-05-07T05:13:02.954977Z","shell.execute_reply.started":"2025-05-07T05:13:02.942185Z","shell.execute_reply":"2025-05-07T05:13:02.954206Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"        latent_0  latent_1  latent_2  latent_3  latent_4  latent_5  latent_6  \\\n0       0.162010  0.212356  0.332929  1.358423  0.865449 -0.272068 -1.299133   \n1      -0.586932 -1.693140  0.743226  1.390613  1.200229 -0.791344 -2.358883   \n2       0.009564  0.176500  0.361936  1.551322 -1.606209 -0.954709 -1.409040   \n3       0.312718 -0.854660  0.708290  1.371941  1.233096 -0.684225 -1.873350   \n4      -0.150169 -0.856407  0.752896  1.831241  1.200472 -0.927860 -1.808192   \n...          ...       ...       ...       ...       ...       ...       ...   \n330280 -2.208897  2.103745  0.458602  1.763067 -0.995745  0.276827 -0.462649   \n330281 -0.275111  2.401922  0.789105  1.548555 -1.482661  0.206049 -0.372423   \n330282  0.524928  2.767483  0.349481  1.440403 -0.617000  1.662273  0.899720   \n330283  0.793959  2.312001  1.062207  1.697968 -0.476613  0.776005 -0.128473   \n330284  1.658483  1.941789  0.536726  1.160636 -1.375117  0.191196 -0.295697   \n\n        latent_7  \n0       0.161966  \n1      -1.180279  \n2      -1.016945  \n3      -0.914131  \n4      -1.198772  \n...          ...  \n330280 -1.889442  \n330281  0.337695  \n330282 -0.520850  \n330283 -1.073551  \n330284  0.311196  \n\n[330285 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latent_0</th>\n      <th>latent_1</th>\n      <th>latent_2</th>\n      <th>latent_3</th>\n      <th>latent_4</th>\n      <th>latent_5</th>\n      <th>latent_6</th>\n      <th>latent_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.162010</td>\n      <td>0.212356</td>\n      <td>0.332929</td>\n      <td>1.358423</td>\n      <td>0.865449</td>\n      <td>-0.272068</td>\n      <td>-1.299133</td>\n      <td>0.161966</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.586932</td>\n      <td>-1.693140</td>\n      <td>0.743226</td>\n      <td>1.390613</td>\n      <td>1.200229</td>\n      <td>-0.791344</td>\n      <td>-2.358883</td>\n      <td>-1.180279</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.009564</td>\n      <td>0.176500</td>\n      <td>0.361936</td>\n      <td>1.551322</td>\n      <td>-1.606209</td>\n      <td>-0.954709</td>\n      <td>-1.409040</td>\n      <td>-1.016945</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.312718</td>\n      <td>-0.854660</td>\n      <td>0.708290</td>\n      <td>1.371941</td>\n      <td>1.233096</td>\n      <td>-0.684225</td>\n      <td>-1.873350</td>\n      <td>-0.914131</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.150169</td>\n      <td>-0.856407</td>\n      <td>0.752896</td>\n      <td>1.831241</td>\n      <td>1.200472</td>\n      <td>-0.927860</td>\n      <td>-1.808192</td>\n      <td>-1.198772</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>-2.208897</td>\n      <td>2.103745</td>\n      <td>0.458602</td>\n      <td>1.763067</td>\n      <td>-0.995745</td>\n      <td>0.276827</td>\n      <td>-0.462649</td>\n      <td>-1.889442</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>-0.275111</td>\n      <td>2.401922</td>\n      <td>0.789105</td>\n      <td>1.548555</td>\n      <td>-1.482661</td>\n      <td>0.206049</td>\n      <td>-0.372423</td>\n      <td>0.337695</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>0.524928</td>\n      <td>2.767483</td>\n      <td>0.349481</td>\n      <td>1.440403</td>\n      <td>-0.617000</td>\n      <td>1.662273</td>\n      <td>0.899720</td>\n      <td>-0.520850</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>0.793959</td>\n      <td>2.312001</td>\n      <td>1.062207</td>\n      <td>1.697968</td>\n      <td>-0.476613</td>\n      <td>0.776005</td>\n      <td>-0.128473</td>\n      <td>-1.073551</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>1.658483</td>\n      <td>1.941789</td>\n      <td>0.536726</td>\n      <td>1.160636</td>\n      <td>-1.375117</td>\n      <td>0.191196</td>\n      <td>-0.295697</td>\n      <td>0.311196</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 8 columns</p>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"new_df = pd.concat([\n    new_df, mu_df\n], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:06.521817Z","iopub.execute_input":"2025-05-07T05:13:06.522536Z","iopub.status.idle":"2025-05-07T05:13:06.625515Z","shell.execute_reply.started":"2025-05-07T05:13:06.522509Z","shell.execute_reply":"2025-05-07T05:13:06.624975Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:55:22.842798Z","iopub.execute_input":"2025-05-06T16:55:22.843496Z","iopub.status.idle":"2025-05-06T16:55:22.848291Z","shell.execute_reply.started":"2025-05-06T16:55:22.843474Z","shell.execute_reply":"2025-05-06T16:55:22.847513Z"}},"outputs":[{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49', 'user_day_seq', 'latent_0',\n       'latent_1', 'latent_2', 'latent_3', 'latent_4', 'latent_5', 'latent_6',\n       'latent_7'],\n      dtype='object')"},"metadata":{}}],"execution_count":119},{"cell_type":"code","source":"# Compute historical baselines with proper handling of NaN values\nnew_df['rolling_avg_logon'] = new_df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=1).mean()\n)\nnew_df['rolling_std_logon'] = new_df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=2).std()\n)\n\n# Fill NaN values in rolling_std_logon (e.g., when there's only 1 data point)\nnew_df['rolling_std_logon'] = new_df['rolling_std_logon'].fillna(0)\n\n# Compute Z-score, avoiding division by zero\nnew_df['z_score_logon'] = (\n    (new_df['total_logon_count'] - new_df['rolling_avg_logon']) / \n    new_df['rolling_std_logon'].replace(0, 1)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:24.981969Z","iopub.execute_input":"2025-05-07T05:13:24.982586Z","iopub.status.idle":"2025-05-07T05:13:25.779918Z","shell.execute_reply.started":"2025-05-07T05:13:24.982548Z","shell.execute_reply":"2025-05-07T05:13:25.779349Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"scaler = StandardScaler()\nnew_df[behavioral_features + latent_features + role_features] = scaler.fit_transform(\n    new_df[behavioral_features + latent_features + role_features]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:30.043362Z","iopub.execute_input":"2025-05-07T05:13:30.044046Z","iopub.status.idle":"2025-05-07T05:13:30.660702Z","shell.execute_reply.started":"2025-05-07T05:13:30.044012Z","shell.execute_reply":"2025-05-07T05:13:30.659989Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/pandas/core/algorithms.py:1743: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  return lib.map_infer(values, mapper, convert=convert)\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# Create temporal features from existing data\ndef add_temporal_features(group):\n    # Use z_score_logon as base for temporal patterns\n    group['logon_trend'] = group['z_score_logon'].rolling(7, min_periods=1).mean()\n    group['logon_volatility'] = group['z_score_logon'].rolling(7, min_periods=1).std()\n    return group\n\nnew_df = new_df.groupby('user').apply(add_temporal_features).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:33.721763Z","iopub.execute_input":"2025-05-07T05:13:33.722065Z","iopub.status.idle":"2025-05-07T05:13:36.46843Z","shell.execute_reply.started":"2025-05-07T05:13:33.722044Z","shell.execute_reply":"2025-05-07T05:13:36.467879Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3699887942.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  new_df = new_df.groupby('user').apply(add_temporal_features).reset_index(drop=True)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"new_df.fillna(0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:39.801744Z","iopub.execute_input":"2025-05-07T05:13:39.802041Z","iopub.status.idle":"2025-05-07T05:13:40.406064Z","shell.execute_reply.started":"2025-05-07T05:13:39.80202Z","shell.execute_reply":"2025-05-07T05:13:40.40549Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"new_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:42.541762Z","iopub.execute_input":"2025-05-07T05:13:42.542053Z","iopub.status.idle":"2025-05-07T05:13:42.753964Z","shell.execute_reply.started":"2025-05-07T05:13:42.542032Z","shell.execute_reply":"2025-05-07T05:13:42.753192Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"user                       0\ndate_only                  0\nafter_hours_logon_count    0\ntotal_logon_count          0\ndevice_connects            0\n                          ..\nrolling_avg_logon          0\nrolling_std_logon          0\nz_score_logon              0\nlogon_trend                0\nlogon_volatility           0\nLength: 87, dtype: int64"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"new_df.fillna(0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:46.326728Z","iopub.execute_input":"2025-05-07T05:13:46.327257Z","iopub.status.idle":"2025-05-07T05:13:46.515273Z","shell.execute_reply.started":"2025-05-07T05:13:46.327231Z","shell.execute_reply":"2025-05-07T05:13:46.514415Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:49.222161Z","iopub.execute_input":"2025-05-07T05:13:49.222569Z","iopub.status.idle":"2025-05-07T05:13:49.227743Z","shell.execute_reply.started":"2025-05-07T05:13:49.222546Z","shell.execute_reply":"2025-05-07T05:13:49.227004Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49', 'user_day_seq', 'latent_0',\n       'latent_1', 'latent_2', 'latent_3', 'latent_4', 'latent_5', 'latent_6',\n       'latent_7', 'rolling_avg_logon', 'rolling_std_logon', 'z_score_logon',\n       'logon_trend', 'logon_volatility'],\n      dtype='object')"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"is_anomaly = np.load('/kaggle/working/is_anomaly.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:15:13.877176Z","iopub.execute_input":"2025-05-07T05:15:13.877857Z","iopub.status.idle":"2025-05-07T05:15:13.882411Z","shell.execute_reply.started":"2025-05-07T05:15:13.877831Z","shell.execute_reply":"2025-05-07T05:15:13.881871Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"df_features = new_df.copy()\ndf_features['role'] = df_features['role']  # Ensure this column exists\ndf_features['has_left'] = df_features['has_left']\ndf_features['is_anomaly'] = is_anomaly\nis_anomaly = df_features['is_anomaly'].values\n\nrole_anomaly_rates = df_features.groupby('role')['is_anomaly'].mean().to_dict()\ndf_features['role_anomaly_rate'] = df_features['role'].map(role_anomaly_rates)\ndf_features['role_sensitivity'] = df_features['role'].apply(lambda x: 1.5 if x in high_level_roles else 1.0)\ndf_features['adaptive_threshold'] = df_features.apply(\n    lambda row: max(0.5, min(0.95, 0.9 - row['role_anomaly_rate'] * 10)) * row['role_sensitivity'],\n    axis=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:15:48.922769Z","iopub.execute_input":"2025-05-07T05:15:48.923061Z","iopub.status.idle":"2025-05-07T05:15:52.493574Z","shell.execute_reply.started":"2025-05-07T05:15:48.92304Z","shell.execute_reply":"2025-05-07T05:15:52.493057Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:15:56.501825Z","iopub.execute_input":"2025-05-07T05:15:56.502438Z","iopub.status.idle":"2025-05-07T05:15:56.604123Z","shell.execute_reply.started":"2025-05-07T05:15:56.502412Z","shell.execute_reply":"2025-05-07T05:15:56.603212Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  latent_7  \\\n0            -0.287121          0.930009       -0.759447  ...  0.432792   \n1            -0.287121          0.711501       -0.233484  ... -1.183691   \n2            -0.287121          0.766128       -0.064106  ... -0.986985   \n3            -0.287121          0.875382       -0.179997  ... -0.863165   \n4            -0.287121          0.766128       -0.607898  ... -1.205961   \n...                ...               ...             ...  ...       ...   \n330280       -0.287121         -1.309699       -1.107117  ... -2.037744   \n330281       -0.287121         -1.200445        2.137805  ...  0.644425   \n330282       -0.287121         -1.091191        3.760267  ... -0.389531   \n330283       -0.287121         -1.309699        0.515344  ... -1.055157   \n330284       -0.287121         -1.309699        0.515344  ...  0.612511   \n\n        rolling_avg_logon  rolling_std_logon z_score_logon logon_trend  \\\n0                -0.53406                0.0      0.000031    0.000031   \n1                -0.53406                0.0      0.000031    0.000031   \n2                -0.53406                0.0      0.000031    0.000031   \n3                -0.53406                0.0      0.000031    0.000031   \n4                -0.53406                0.0      0.000031    0.000031   \n...                   ...                ...           ...         ...   \n330280           -0.53406                0.0      0.000031    0.000031   \n330281           -0.53406                0.0      0.000031    0.000031   \n330282           -0.53406                0.0      0.000031    0.000031   \n330283           -0.53406                0.0      0.000031    0.000031   \n330284           -0.53406                0.0      0.000031    0.000031   \n\n        logon_volatility is_anomaly role_anomaly_rate role_sensitivity  \\\n0                    0.0          0          0.000000              1.5   \n1                    0.0          0          0.000000              1.5   \n2                    0.0          0          0.000000              1.5   \n3                    0.0          0          0.000000              1.5   \n4                    0.0          0          0.000000              1.5   \n...                  ...        ...               ...              ...   \n330280               0.0          0          0.005779              1.0   \n330281               0.0          0          0.005779              1.0   \n330282               0.0          0          0.005779              1.0   \n330283               0.0          0          0.005779              1.0   \n330284               0.0          0          0.005779              1.0   \n\n       adaptive_threshold  \n0                1.350000  \n1                1.350000  \n2                1.350000  \n3                1.350000  \n4                1.350000  \n...                   ...  \n330280           0.842207  \n330281           0.842207  \n330282           0.842207  \n330283           0.842207  \n330284           0.842207  \n\n[330285 rows x 91 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>latent_7</th>\n      <th>rolling_avg_logon</th>\n      <th>rolling_std_logon</th>\n      <th>z_score_logon</th>\n      <th>logon_trend</th>\n      <th>logon_volatility</th>\n      <th>is_anomaly</th>\n      <th>role_anomaly_rate</th>\n      <th>role_sensitivity</th>\n      <th>adaptive_threshold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>0.432792</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>-1.183691</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>-0.986985</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>-0.863165</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>-1.205961</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-2.037744</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>0.644425</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-0.389531</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-1.055157</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>0.612511</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 91 columns</p>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"df_features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:43.813968Z","iopub.execute_input":"2025-05-06T17:03:43.814664Z","iopub.status.idle":"2025-05-06T17:03:43.819513Z","shell.execute_reply.started":"2025-05-06T17:03:43.814634Z","shell.execute_reply":"2025-05-06T17:03:43.818788Z"}},"outputs":[{"execution_count":140,"output_type":"execute_result","data":{"text/plain":"Index(['user', 'date_only', 'after_hours_logon_count', 'total_logon_count',\n       'device_connects', 'avg_content_word_count', 'text_files_accessed',\n       'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent',\n       'bcc_flag', 'keyword_richness', 'month_year', 'last_seen_month',\n       'has_left', 'role', 'functional_unit', 'department', 'team',\n       'supervisor', 'role_text', 'cluster', 'role_emb_pca_0',\n       'role_emb_pca_1', 'role_emb_pca_2', 'role_emb_pca_3', 'role_emb_pca_4',\n       'role_emb_pca_5', 'role_emb_pca_6', 'role_emb_pca_7', 'role_emb_pca_8',\n       'role_emb_pca_9', 'role_emb_pca_10', 'role_emb_pca_11',\n       'role_emb_pca_12', 'role_emb_pca_13', 'role_emb_pca_14',\n       'role_emb_pca_15', 'role_emb_pca_16', 'role_emb_pca_17',\n       'role_emb_pca_18', 'role_emb_pca_19', 'role_emb_pca_20',\n       'role_emb_pca_21', 'role_emb_pca_22', 'role_emb_pca_23',\n       'role_emb_pca_24', 'role_emb_pca_25', 'role_emb_pca_26',\n       'role_emb_pca_27', 'role_emb_pca_28', 'role_emb_pca_29',\n       'role_emb_pca_30', 'role_emb_pca_31', 'role_emb_pca_32',\n       'role_emb_pca_33', 'role_emb_pca_34', 'role_emb_pca_35',\n       'role_emb_pca_36', 'role_emb_pca_37', 'role_emb_pca_38',\n       'role_emb_pca_39', 'role_emb_pca_40', 'role_emb_pca_41',\n       'role_emb_pca_42', 'role_emb_pca_43', 'role_emb_pca_44',\n       'role_emb_pca_45', 'role_emb_pca_46', 'role_emb_pca_47',\n       'role_emb_pca_48', 'role_emb_pca_49', 'user_day_seq', 'latent_0',\n       'latent_1', 'latent_2', 'latent_3', 'latent_4', 'latent_5', 'latent_6',\n       'latent_7', 'rolling_avg_logon', 'rolling_std_logon', 'z_score_logon',\n       'logon_trend', 'logon_volatility', 'is_anomaly', 'role_anomaly_rate',\n       'role_sensitivity', 'adaptive_threshold'],\n      dtype='object')"},"metadata":{}}],"execution_count":140},{"cell_type":"code","source":"\nclass UserDayEnv(gym.Env):\n    def __init__(self, user_data):\n        super().__init__()  # Modern super() initialization\n        \n        # Maintain exact observation shape\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(behavioral_features) + len(latent_features) + len(role_features) + 2),  # 72D\n            dtype=np.float32\n        )\n        \n        # Maintain same action space\n        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n        \n        # Enhanced reward parameters\n        self.anomaly_weight = 50  # Base weight for true positives\n        self.normal_weight = 1     # Base weight for true negatives\n        self.has_left_bonus = 2.0  # Multiplier for departed users\n        self.fp_count = 0          # False positive counter\n        self.total_preds = 0       # Total predictions counter\n        \n        # Temporal tracking\n        self.last_5_scores = []    # Track recent scores for trend analysis\n        self.user_data = user_data.sort_values('date_only').copy()\n        \n        # Calculate class weights for imbalance handling\n        self.pos_weight = len(user_data) / (2 * max(1, user_data['is_anomaly'].sum()))\n        self.neg_weight = len(user_data) / (2 * max(1, (~user_data['is_anomaly']).sum()))\n\n    def reset(self, seed=None, options=None):\n        \"\"\"Maintains exact reset signature and functionality\"\"\"\n        self.current_step = 0\n        self.fp_count = 0\n        self.total_preds = 0\n        self.last_5_scores = []\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        \"\"\"Maintains exact observation structure\"\"\"\n        row = self.user_data.iloc[self.current_step]\n        obs = np.concatenate([\n            row[behavioral_features].values.astype(np.float32),\n            row[latent_features].values.astype(np.float32),\n            row[role_features].values.astype(np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        return obs\n\n    def step(self, action):\n        \"\"\"Maintains exact step signature with enhanced rewards\"\"\"\n        reward = self._calculate_reward(action)\n        row = self.user_data.iloc[self.current_step]\n        info = {\n            'final_action': 1 if action[0] >= row['adaptive_threshold'] else 0,\n            'true_label': row['is_anomaly']\n        }\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n            \n        return obs, reward, done, False, info\n\n    def _calculate_reward(self, action):\n        \"\"\"Enhanced reward logic while maintaining original structure\"\"\"\n        row = self.user_data.iloc[self.current_step]\n        true_label = row['is_anomaly']\n        threshold = row['adaptive_threshold']\n        self.total_preds += 1\n        \n        # Maintain original action thresholding\n        anomaly_score = action[0]\n        final_action = 1 if anomaly_score >= threshold else 0\n        \n        # Track recent scores for temporal consistency\n        self.last_5_scores.append(anomaly_score)\n        if len(self.last_5_scores) > 5:\n            self.last_5_scores.pop(0)\n        \n        # Dynamic FP rate adjustment (original logic)\n        fp_rate = self.fp_count / max(1, self.total_preds)\n        if fp_rate > 0.05:\n            self.anomaly_weight = max(20, self.anomaly_weight * 0.9)\n        \n        # Enhanced reward calculation\n        has_left_bonus = self.has_left_bonus if row['has_left'] == 1 else 1.0\n        \n        if final_action == true_label:\n            if true_label == 1:  # True Positive\n                # Add temporal consistency bonus\n                trend_bonus = 1.5 if len(self.last_5_scores) >= 3 and np.polyfit(\n                    range(len(self.last_5_scores)), self.last_5_scores, 1)[0] > 0.1 else 1.0\n                \n                reward = (self.anomaly_weight * has_left_bonus * trend_bonus * self.pos_weight)\n            else:  # True Negative\n                reward = self.normal_weight * self.neg_weight\n        else:\n            if final_action == 1:  # False Positive\n                reward = -10 * (1 + (1 - row['role_anomaly_rate']))  # Cluster-aware penalty\n                self.fp_count += 1\n            else:  # False Negative\n                reward = -15 * (1 + row['role_anomaly_rate'])  # Higher penalty for high-risk roles\n        \n        return float(reward)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:06:34.004935Z","iopub.execute_input":"2025-05-06T19:06:34.00524Z","iopub.status.idle":"2025-05-06T19:06:34.017698Z","shell.execute_reply.started":"2025-05-06T19:06:34.005217Z","shell.execute_reply":"2025-05-06T19:06:34.016837Z"}},"outputs":[],"execution_count":260},{"cell_type":"code","source":"user_clusters = df_features.groupby('user')['cluster'].first()\ncluster_users = defaultdict(list)\nfor user, cluster in user_clusters.items():\n    cluster_users[cluster].append(user)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:10:20.399578Z","iopub.execute_input":"2025-05-06T17:10:20.39986Z","iopub.status.idle":"2025-05-06T17:10:20.42198Z","shell.execute_reply.started":"2025-05-06T17:10:20.399841Z","shell.execute_reply":"2025-05-06T17:10:20.421033Z"}},"outputs":[],"execution_count":149},{"cell_type":"code","source":"user_clusters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:10:20.897772Z","iopub.execute_input":"2025-05-06T17:10:20.898074Z","iopub.status.idle":"2025-05-06T17:10:20.904045Z","shell.execute_reply.started":"2025-05-06T17:10:20.898049Z","shell.execute_reply":"2025-05-06T17:10:20.903485Z"}},"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"user\nAAE0190    22\nAAF0535     1\nAAF0791    23\nAAL0706     8\nAAM0658    17\n           ..\nZKS0899     2\nZMC0284    14\nZSB0649    17\nZSK0258    27\nZSL0305    11\nName: cluster, Length: 1000, dtype: int64"},"metadata":{}}],"execution_count":150},{"cell_type":"code","source":"cluster_policies = {}\nfor cluster, users in cluster_users.items():\n    cluster_data = df_features[df_features['user'].isin(users)]\n    env = UserDayEnv(cluster_data)\n    model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, n_steps=2048, batch_size=64, n_epochs=10)\n    model.learn(total_timesteps=10000)\n    cluster_policies[cluster] = model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:10:34.39889Z","iopub.execute_input":"2025-05-06T17:10:34.399608Z","iopub.status.idle":"2025-05-06T17:24:11.047243Z","shell.execute_reply.started":"2025-05-06T17:10:34.399583Z","shell.execute_reply":"2025-05-06T17:24:11.046701Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 470  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 406         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.015664257 |\n|    clip_fraction        | 0.143       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00989    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 74.9        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0241     |\n|    std                  | 0.945       |\n|    value_loss           | 157         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 391         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018218918 |\n|    clip_fraction        | 0.148       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.00259    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 55.6        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0284     |\n|    std                  | 0.879       |\n|    value_loss           | 105         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 383         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011954019 |\n|    clip_fraction        | 0.102       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | -0.0084     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 24.5        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0196     |\n|    std                  | 0.844       |\n|    value_loss           | 70.3        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 379          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0119094355 |\n|    clip_fraction        | 0.116        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | -0.0113      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 23.2         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0212      |\n|    std                  | 0.813        |\n|    value_loss           | 48           |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 473  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 412         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.017017381 |\n|    clip_fraction        | 0.158       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.000929   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 88.1        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0259     |\n|    std                  | 0.936       |\n|    value_loss           | 397         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018551355 |\n|    clip_fraction        | 0.149       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.000175   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 86.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.024      |\n|    std                  | 0.877       |\n|    value_loss           | 167         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009618515 |\n|    clip_fraction        | 0.141       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -3.21e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 82.3        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0201     |\n|    std                  | 0.847       |\n|    value_loss           | 137         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.6e+03     |\n|    ep_rew_mean          | -3.35e+03   |\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009928298 |\n|    clip_fraction        | 0.0863      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.00271    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.1        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0172     |\n|    std                  | 0.817       |\n|    value_loss           | 71.4        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 435  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 394         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.015691657 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00129    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 82.3        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0274     |\n|    std                  | 0.949       |\n|    value_loss           | 260         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 381        |\n|    iterations           | 3          |\n|    time_elapsed         | 16         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.01937034 |\n|    clip_fraction        | 0.162      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.33      |\n|    explained_variance   | -0.00359   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 64.9       |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0266    |\n|    std                  | 0.885      |\n|    value_loss           | 136        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 374         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.014921214 |\n|    clip_fraction        | 0.142       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -0.000227   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44          |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0251     |\n|    std                  | 0.831       |\n|    value_loss           | 91.3        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 371         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009444515 |\n|    clip_fraction        | 0.0867      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -0.00276    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 31.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0194     |\n|    std                  | 0.801       |\n|    value_loss           | 75.5        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 465  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 406         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018536344 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.00215    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 91.3        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0284     |\n|    std                  | 0.941       |\n|    value_loss           | 294         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 390         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.015174836 |\n|    clip_fraction        | 0.153       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -9.43e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.4        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0236     |\n|    std                  | 0.884       |\n|    value_loss           | 116         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 381          |\n|    iterations           | 4            |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0099372575 |\n|    clip_fraction        | 0.107        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | -3.99e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 40           |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0202      |\n|    std                  | 0.833        |\n|    value_loss           | 76.1         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 1.02e+04     |\n|    ep_rew_mean          | -3.16e+03    |\n| time/                   |              |\n|    fps                  | 377          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0078084557 |\n|    clip_fraction        | 0.1          |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.22        |\n|    explained_variance   | -0.000106    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 42.3         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0186      |\n|    std                  | 0.812        |\n|    value_loss           | 88           |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 464  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 404         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019787587 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 4.54e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 123         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0299     |\n|    std                  | 0.944       |\n|    value_loss           | 362         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 388         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.022384519 |\n|    clip_fraction        | 0.209       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.000434   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 57.6        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0312     |\n|    std                  | 0.87        |\n|    value_loss           | 129         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 382         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.006933286 |\n|    clip_fraction        | 0.075       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.000181    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.016      |\n|    std                  | 0.829       |\n|    value_loss           | 91.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.71e+03    |\n|    ep_rew_mean          | -1.66e+03   |\n| time/                   |             |\n|    fps                  | 377         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.007977542 |\n|    clip_fraction        | 0.0578      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.00347    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.8        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0136     |\n|    std                  | 0.789       |\n|    value_loss           | 61.7        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 466  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 409         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.016551184 |\n|    clip_fraction        | 0.176       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00135    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 150         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0267     |\n|    std                  | 0.946       |\n|    value_loss           | 406         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.016667157 |\n|    clip_fraction        | 0.142       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -3.45e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 75.8        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0248     |\n|    std                  | 0.867       |\n|    value_loss           | 173         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 385         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.014724545 |\n|    clip_fraction        | 0.119       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -9.14e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 64.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.022      |\n|    std                  | 0.805       |\n|    value_loss           | 113         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 1.02e+04     |\n|    ep_rew_mean          | -4.03e+03    |\n| time/                   |              |\n|    fps                  | 379          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0092053525 |\n|    clip_fraction        | 0.103        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.19        |\n|    explained_variance   | 2.4e-05      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 33.1         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0183      |\n|    std                  | 0.781        |\n|    value_loss           | 95.9         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 474  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 411         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.020102765 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.000612    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 103         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0296     |\n|    std                  | 0.939       |\n|    value_loss           | 314         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.012644824 |\n|    clip_fraction        | 0.143       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -4.7e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 95.8        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0245     |\n|    std                  | 0.878       |\n|    value_loss           | 142         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 384         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009902739 |\n|    clip_fraction        | 0.116       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.000165    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.1        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0201     |\n|    std                  | 0.829       |\n|    value_loss           | 77.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 8.8e+03     |\n|    ep_rew_mean          | -2.76e+03   |\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.005748291 |\n|    clip_fraction        | 0.0637      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -0.00108    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 81.4        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.013      |\n|    std                  | 0.812       |\n|    value_loss           | 102         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 468  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 410         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019049495 |\n|    clip_fraction        | 0.152       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.0014      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 117         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0249     |\n|    std                  | 0.939       |\n|    value_loss           | 318         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.020445101 |\n|    clip_fraction        | 0.15        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | 5.88e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 64.1        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.025      |\n|    std                  | 0.86        |\n|    value_loss           | 124         |\n-----------------------------------------\n---------------------------------------\n| time/                   |           |\n|    fps                  | 385       |\n|    iterations           | 4         |\n|    time_elapsed         | 21        |\n|    total_timesteps      | 8192      |\n| train/                  |           |\n|    approx_kl            | 0.0094244 |\n|    clip_fraction        | 0.128     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.24     |\n|    explained_variance   | -0.000441 |\n|    learning_rate        | 0.0003    |\n|    loss                 | 47.1      |\n|    n_updates            | 30        |\n|    policy_gradient_loss | -0.0189   |\n|    std                  | 0.827     |\n|    value_loss           | 102       |\n---------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 9.99e+03     |\n|    ep_rew_mean          | -1.48e+03    |\n| time/                   |              |\n|    fps                  | 381          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0047836313 |\n|    clip_fraction        | 0.0514       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.22        |\n|    explained_variance   | 0.000114     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 23.6         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0117      |\n|    std                  | 0.804        |\n|    value_loss           | 76.4         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 470  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 408         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018618576 |\n|    clip_fraction        | 0.171       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00297    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 92.4        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0278     |\n|    std                  | 0.944       |\n|    value_loss           | 277         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018763144 |\n|    clip_fraction        | 0.181       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.000366   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 77.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0284     |\n|    std                  | 0.876       |\n|    value_loss           | 141         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009976419 |\n|    clip_fraction        | 0.0839      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.000267    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.5        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0172     |\n|    std                  | 0.837       |\n|    value_loss           | 112         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 382         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009666296 |\n|    clip_fraction        | 0.0891      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -0.00528    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.9        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0201     |\n|    std                  | 0.804       |\n|    value_loss           | 74.6        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 469  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 409         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018396076 |\n|    clip_fraction        | 0.173       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00686    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 84.9        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.028      |\n|    std                  | 0.939       |\n|    value_loss           | 268         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 394        |\n|    iterations           | 3          |\n|    time_elapsed         | 15         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.02185563 |\n|    clip_fraction        | 0.198      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.32      |\n|    explained_variance   | -0.000366  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 77.6       |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.031     |\n|    std                  | 0.884      |\n|    value_loss           | 144        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 387         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011011514 |\n|    clip_fraction        | 0.137       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.000505    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 50.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0233     |\n|    std                  | 0.843       |\n|    value_loss           | 96.4        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 383          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0071009235 |\n|    clip_fraction        | 0.0733       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | 0.00205      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 61.2         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.017       |\n|    std                  | 0.821        |\n|    value_loss           | 77.5         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 470  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 411         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019062106 |\n|    clip_fraction        | 0.179       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00106    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 99.5        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0282     |\n|    std                  | 0.941       |\n|    value_loss           | 277         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.012278893 |\n|    clip_fraction        | 0.128       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.00117    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 65.3        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0219     |\n|    std                  | 0.881       |\n|    value_loss           | 145         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.68e+03    |\n|    ep_rew_mean          | -2.71e+03   |\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010170508 |\n|    clip_fraction        | 0.129       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.00366     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 78.8        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0211     |\n|    std                  | 0.832       |\n|    value_loss           | 102         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 7.68e+03   |\n|    ep_rew_mean          | -2.71e+03  |\n| time/                   |            |\n|    fps                  | 381        |\n|    iterations           | 5          |\n|    time_elapsed         | 26         |\n|    total_timesteps      | 10240      |\n| train/                  |            |\n|    approx_kl            | 0.00760065 |\n|    clip_fraction        | 0.0725     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.22      |\n|    explained_variance   | -0.0579    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 29.5       |\n|    n_updates            | 40         |\n|    policy_gradient_loss | -0.0156    |\n|    std                  | 0.809      |\n|    value_loss           | 86.2       |\n----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 475  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 413         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.015694184 |\n|    clip_fraction        | 0.171       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00132    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 112         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0292     |\n|    std                  | 0.951       |\n|    value_loss           | 306         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.021294553 |\n|    clip_fraction        | 0.145       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.00147    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 57.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0279     |\n|    std                  | 0.873       |\n|    value_loss           | 111         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012108969 |\n|    clip_fraction        | 0.101       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.000324   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 48.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0218     |\n|    std                  | 0.81        |\n|    value_loss           | 72.1        |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 382          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0075460076 |\n|    clip_fraction        | 0.0756       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | -0.0017      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 37.5         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.017       |\n|    std                  | 0.783        |\n|    value_loss           | 82.1         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 475  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 411         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018964112 |\n|    clip_fraction        | 0.187       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00266    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 99.6        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0289     |\n|    std                  | 0.943       |\n|    value_loss           | 254         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.011534298 |\n|    clip_fraction        | 0.15        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 7e-05       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32.8        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0238     |\n|    std                  | 0.898       |\n|    value_loss           | 94.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.49e+03    |\n|    ep_rew_mean          | -2.35e+03   |\n| time/                   |             |\n|    fps                  | 387         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009650502 |\n|    clip_fraction        | 0.0884      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.000807    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.5        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.017      |\n|    std                  | 0.868       |\n|    value_loss           | 72.9        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 6.49e+03     |\n|    ep_rew_mean          | -2.35e+03    |\n| time/                   |              |\n|    fps                  | 383          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0066161403 |\n|    clip_fraction        | 0.0542       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | -0.00711     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 31.7         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0146      |\n|    std                  | 0.836        |\n|    value_loss           | 57.6         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 472  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 413         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019015973 |\n|    clip_fraction        | 0.19        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00338    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 107         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0316     |\n|    std                  | 0.941       |\n|    value_loss           | 292         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.009696374 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.34       |\n|    explained_variance   | 0.000168    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 73.7        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0204     |\n|    std                  | 0.906       |\n|    value_loss           | 150         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.5e+03     |\n|    ep_rew_mean          | -3.79e+03   |\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.014610247 |\n|    clip_fraction        | 0.159       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.28       |\n|    explained_variance   | 0.000215    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.6        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0255     |\n|    std                  | 0.858       |\n|    value_loss           | 95.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.5e+03     |\n|    ep_rew_mean          | -3.79e+03   |\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.006845763 |\n|    clip_fraction        | 0.0916      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.0056     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 37.6        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0177     |\n|    std                  | 0.834       |\n|    value_loss           | 84.4        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 465  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 410         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.016374137 |\n|    clip_fraction        | 0.151       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.000176    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 121         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0253     |\n|    std                  | 0.937       |\n|    value_loss           | 346         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.016395181 |\n|    clip_fraction        | 0.157       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.000134   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.3        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0222     |\n|    std                  | 0.867       |\n|    value_loss           | 105         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008501591 |\n|    clip_fraction        | 0.104       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | 2.16e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.3        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0188     |\n|    std                  | 0.82        |\n|    value_loss           | 87.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.01e+04    |\n|    ep_rew_mean          | -2.11e+03   |\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008937798 |\n|    clip_fraction        | 0.0847      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.00101    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 29.5        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0169     |\n|    std                  | 0.804       |\n|    value_loss           | 71.5        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 471  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 413         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.017941613 |\n|    clip_fraction        | 0.186       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00163    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 109         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0292     |\n|    std                  | 0.947       |\n|    value_loss           | 395         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 395        |\n|    iterations           | 3          |\n|    time_elapsed         | 15         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.01996646 |\n|    clip_fraction        | 0.185      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.33      |\n|    explained_variance   | -8.64e-05  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 58.3       |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0305    |\n|    std                  | 0.887      |\n|    value_loss           | 199        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 387         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.016673477 |\n|    clip_fraction        | 0.157       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -2.43e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 70.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0244     |\n|    std                  | 0.83        |\n|    value_loss           | 124         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 382          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0073889657 |\n|    clip_fraction        | 0.0838       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.22        |\n|    explained_variance   | -3.41e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 43.1         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.018       |\n|    std                  | 0.809        |\n|    value_loss           | 96.8         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 473  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 411         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.013750114 |\n|    clip_fraction        | 0.143       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.000284   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 91.5        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.026      |\n|    std                  | 0.944       |\n|    value_loss           | 294         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.021576427 |\n|    clip_fraction        | 0.189       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.000142   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0274     |\n|    std                  | 0.872       |\n|    value_loss           | 137         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 384         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011122808 |\n|    clip_fraction        | 0.0929      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -0.000508   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.1        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0187     |\n|    std                  | 0.833       |\n|    value_loss           | 76.2        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009796833 |\n|    clip_fraction        | 0.0943      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -0.00257    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0183     |\n|    std                  | 0.807       |\n|    value_loss           | 70.7        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 465  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 409         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019811228 |\n|    clip_fraction        | 0.177       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.000148    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 93          |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0298     |\n|    std                  | 0.937       |\n|    value_loss           | 365         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018305287 |\n|    clip_fraction        | 0.152       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | -9.16e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60          |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.027      |\n|    std                  | 0.855       |\n|    value_loss           | 137         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 386          |\n|    iterations           | 4            |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0100939805 |\n|    clip_fraction        | 0.0978       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.22        |\n|    explained_variance   | -5.22e-05    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 33.9         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0197      |\n|    std                  | 0.799        |\n|    value_loss           | 87.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.63e+03    |\n|    ep_rew_mean          | -3.15e+03   |\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009765027 |\n|    clip_fraction        | 0.0955      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.18       |\n|    explained_variance   | -3.56e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0175     |\n|    std                  | 0.779       |\n|    value_loss           | 95.6        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 473  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 413         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.013586598 |\n|    clip_fraction        | 0.13        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.0102     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 73.4        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.024      |\n|    std                  | 0.942       |\n|    value_loss           | 276         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 397         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.017670937 |\n|    clip_fraction        | 0.149       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -5.34e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 65.9        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0264     |\n|    std                  | 0.871       |\n|    value_loss           | 140         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 388         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012338574 |\n|    clip_fraction        | 0.117       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | 0.000115    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0213     |\n|    std                  | 0.822       |\n|    value_loss           | 79.5        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 384         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008653108 |\n|    clip_fraction        | 0.0979      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.00178    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.8        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0197     |\n|    std                  | 0.799       |\n|    value_loss           | 90.7        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 466  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 410        |\n|    iterations           | 2          |\n|    time_elapsed         | 9          |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01936618 |\n|    clip_fraction        | 0.173      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.000431   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 69.7       |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0275    |\n|    std                  | 0.935      |\n|    value_loss           | 287        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018422639 |\n|    clip_fraction        | 0.164       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.000167   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.8        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0264     |\n|    std                  | 0.87        |\n|    value_loss           | 135         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 6.36e+03   |\n|    ep_rew_mean          | -3.75e+03  |\n| time/                   |            |\n|    fps                  | 386        |\n|    iterations           | 4          |\n|    time_elapsed         | 21         |\n|    total_timesteps      | 8192       |\n| train/                  |            |\n|    approx_kl            | 0.01775353 |\n|    clip_fraction        | 0.158      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.23      |\n|    explained_variance   | 4.89e-05   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 43.1       |\n|    n_updates            | 30         |\n|    policy_gradient_loss | -0.0262    |\n|    std                  | 0.817      |\n|    value_loss           | 90.2       |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 6.36e+03     |\n|    ep_rew_mean          | -3.75e+03    |\n| time/                   |              |\n|    fps                  | 382          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0042217826 |\n|    clip_fraction        | 0.0536       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.00288      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 30.2         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0118      |\n|    std                  | 0.793        |\n|    value_loss           | 74.4         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 470  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 413        |\n|    iterations           | 2          |\n|    time_elapsed         | 9          |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01839855 |\n|    clip_fraction        | 0.173      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | -0.00272   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 61.7       |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0279    |\n|    std                  | 0.941      |\n|    value_loss           | 200        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 397         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.022213329 |\n|    clip_fraction        | 0.146       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.000122   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.1        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.024      |\n|    std                  | 0.864       |\n|    value_loss           | 125         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 388         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008019491 |\n|    clip_fraction        | 0.104       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -7.32e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 52.6        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0191     |\n|    std                  | 0.819       |\n|    value_loss           | 99.6        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 383         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010227541 |\n|    clip_fraction        | 0.09        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.2        |\n|    explained_variance   | -0.00129    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 28.8        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0169     |\n|    std                  | 0.799       |\n|    value_loss           | 65.7        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 476  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 414        |\n|    iterations           | 2          |\n|    time_elapsed         | 9          |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01806911 |\n|    clip_fraction        | 0.175      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.000784   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 112        |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0277    |\n|    std                  | 0.939      |\n|    value_loss           | 329        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.024058122 |\n|    clip_fraction        | 0.143       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.000334    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 71.1        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0266     |\n|    std                  | 0.856       |\n|    value_loss           | 177         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 388         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011926051 |\n|    clip_fraction        | 0.12        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -4.16e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.1        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0211     |\n|    std                  | 0.809       |\n|    value_loss           | 94.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9e+03       |\n|    ep_rew_mean          | -3.4e+03    |\n| time/                   |             |\n|    fps                  | 383         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009993171 |\n|    clip_fraction        | 0.111       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.19       |\n|    explained_variance   | -0.00261    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 36.4        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0209     |\n|    std                  | 0.784       |\n|    value_loss           | 81.2        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 473  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 405         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.017003931 |\n|    clip_fraction        | 0.178       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 7.73e-05    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 74          |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0295     |\n|    std                  | 0.945       |\n|    value_loss           | 315         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 390         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.014538186 |\n|    clip_fraction        | 0.167       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.000401   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0266     |\n|    std                  | 0.882       |\n|    value_loss           | 133         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 384         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010941191 |\n|    clip_fraction        | 0.0996      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.00013    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 69.1        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0198     |\n|    std                  | 0.831       |\n|    value_loss           | 136         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 379        |\n|    iterations           | 5          |\n|    time_elapsed         | 26         |\n|    total_timesteps      | 10240      |\n| train/                  |            |\n|    approx_kl            | 0.00952203 |\n|    clip_fraction        | 0.0721     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.21      |\n|    explained_variance   | -0.00486   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 43.8       |\n|    n_updates            | 40         |\n|    policy_gradient_loss | -0.017     |\n|    std                  | 0.795      |\n|    value_loss           | 87.1       |\n----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 465  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 408        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.02155205 |\n|    clip_fraction        | 0.189      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.00011    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 84         |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0304    |\n|    std                  | 0.93       |\n|    value_loss           | 291        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 391         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.013660229 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -4.86e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 79.7        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.024      |\n|    std                  | 0.881       |\n|    value_loss           | 195         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 384        |\n|    iterations           | 4          |\n|    time_elapsed         | 21         |\n|    total_timesteps      | 8192       |\n| train/                  |            |\n|    approx_kl            | 0.01171352 |\n|    clip_fraction        | 0.13       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.27      |\n|    explained_variance   | -3.23e-05  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 87.9       |\n|    n_updates            | 30         |\n|    policy_gradient_loss | -0.0144    |\n|    std                  | 0.842      |\n|    value_loss           | 201        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1e+04       |\n|    ep_rew_mean          | -2.07e+03   |\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.012151728 |\n|    clip_fraction        | 0.0888      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -0.00104    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.3        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0178     |\n|    std                  | 0.792       |\n|    value_loss           | 66.2        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 471  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 413         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019489381 |\n|    clip_fraction        | 0.178       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.000623    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 77.9        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0287     |\n|    std                  | 0.933       |\n|    value_loss           | 236         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 395        |\n|    iterations           | 3          |\n|    time_elapsed         | 15         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.01596301 |\n|    clip_fraction        | 0.148      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.3       |\n|    explained_variance   | 0.000213   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 32.9       |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0241    |\n|    std                  | 0.868      |\n|    value_loss           | 87.6       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.34e+03    |\n|    ep_rew_mean          | -2.36e+03   |\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009549503 |\n|    clip_fraction        | 0.115       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.000365    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.2        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0226     |\n|    std                  | 0.841       |\n|    value_loss           | 91.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.34e+03    |\n|    ep_rew_mean          | -2.36e+03   |\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.007520377 |\n|    clip_fraction        | 0.0771      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | -0.0079     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 39.7        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0166     |\n|    std                  | 0.819       |\n|    value_loss           | 71.4        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 461  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 408        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01890197 |\n|    clip_fraction        | 0.191      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | -0.00162   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 74         |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0289    |\n|    std                  | 0.931      |\n|    value_loss           | 234        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.012315642 |\n|    clip_fraction        | 0.153       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | -0.00049    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0236     |\n|    std                  | 0.871       |\n|    value_loss           | 117         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 384          |\n|    iterations           | 4            |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0060332837 |\n|    clip_fraction        | 0.0662       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.27        |\n|    explained_variance   | -0.000404    |\n|    learning_rate        | 0.0003       |\n|    loss                 | 38.2         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0114      |\n|    std                  | 0.851        |\n|    value_loss           | 96.6         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 9.68e+03     |\n|    ep_rew_mean          | -936         |\n| time/                   |              |\n|    fps                  | 380          |\n|    iterations           | 5            |\n|    time_elapsed         | 26           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0049575716 |\n|    clip_fraction        | 0.0569       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | 0.00239      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 49.2         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0123      |\n|    std                  | 0.828        |\n|    value_loss           | 72           |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 471  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 412         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.014107099 |\n|    clip_fraction        | 0.156       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.0033     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 67.2        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0252     |\n|    std                  | 0.931       |\n|    value_loss           | 240         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.013964262 |\n|    clip_fraction        | 0.146       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.000253   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 83.9        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.022      |\n|    std                  | 0.877       |\n|    value_loss           | 179         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.41e+03    |\n|    ep_rew_mean          | -3.32e+03   |\n| time/                   |             |\n|    fps                  | 385         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011322684 |\n|    clip_fraction        | 0.15        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -8.81e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 46.6        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0256     |\n|    std                  | 0.841       |\n|    value_loss           | 101         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.41e+03    |\n|    ep_rew_mean          | -3.32e+03   |\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008079622 |\n|    clip_fraction        | 0.0769      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | -0.00466    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 39.5        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0169     |\n|    std                  | 0.806       |\n|    value_loss           | 74          |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 475  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 411         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018959496 |\n|    clip_fraction        | 0.191       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.000965   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 127         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0308     |\n|    std                  | 0.938       |\n|    value_loss           | 296         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 395        |\n|    iterations           | 3          |\n|    time_elapsed         | 15         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.01607246 |\n|    clip_fraction        | 0.139      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.3       |\n|    explained_variance   | 0.000766   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 39.7       |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0244    |\n|    std                  | 0.859      |\n|    value_loss           | 114        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 386         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008442313 |\n|    clip_fraction        | 0.0967      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.000928   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0193     |\n|    std                  | 0.822       |\n|    value_loss           | 83.2        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 382         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008623085 |\n|    clip_fraction        | 0.0845      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.00139    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.7        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0179     |\n|    std                  | 0.795       |\n|    value_loss           | 78.5        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 468  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 410         |\n|    iterations           | 2           |\n|    time_elapsed         | 9           |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.017470134 |\n|    clip_fraction        | 0.18        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.00122     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 86.7        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0283     |\n|    std                  | 0.934       |\n|    value_loss           | 273         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 394         |\n|    iterations           | 3           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.024419528 |\n|    clip_fraction        | 0.159       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.000476    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 56.3        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0259     |\n|    std                  | 0.855       |\n|    value_loss           | 119         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 385         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008511343 |\n|    clip_fraction        | 0.0766      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.000377   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0125     |\n|    std                  | 0.811       |\n|    value_loss           | 91.1        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.86e+03    |\n|    ep_rew_mean          | -1.6e+03    |\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 5           |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008564093 |\n|    clip_fraction        | 0.087       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.2        |\n|    explained_variance   | -0.00144    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 68.1        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0163     |\n|    std                  | 0.793       |\n|    value_loss           | 108         |\n-----------------------------------------\n","output_type":"stream"}],"execution_count":151},{"cell_type":"code","source":"cluster_policies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:28:39.878665Z","iopub.execute_input":"2025-05-06T17:28:39.879183Z","iopub.status.idle":"2025-05-06T17:28:39.884468Z","shell.execute_reply.started":"2025-05-06T17:28:39.879159Z","shell.execute_reply":"2025-05-06T17:28:39.883751Z"}},"outputs":[{"execution_count":152,"output_type":"execute_result","data":{"text/plain":"{22: <stable_baselines3.ppo.ppo.PPO at 0x78e837882050>,\n 1: <stable_baselines3.ppo.ppo.PPO at 0x78e837800fd0>,\n 23: <stable_baselines3.ppo.ppo.PPO at 0x78e837b10750>,\n 8: <stable_baselines3.ppo.ppo.PPO at 0x78e837b51cd0>,\n 17: <stable_baselines3.ppo.ppo.PPO at 0x78e8378660d0>,\n 3: <stable_baselines3.ppo.ppo.PPO at 0x78e83789e910>,\n 24: <stable_baselines3.ppo.ppo.PPO at 0x78e83789ee10>,\n 0: <stable_baselines3.ppo.ppo.PPO at 0x78e8378c2250>,\n 13: <stable_baselines3.ppo.ppo.PPO at 0x78e83789f350>,\n 26: <stable_baselines3.ppo.ppo.PPO at 0x78e8378e1a50>,\n 27: <stable_baselines3.ppo.ppo.PPO at 0x78e836602a50>,\n 10: <stable_baselines3.ppo.ppo.PPO at 0x78e8378e1650>,\n 16: <stable_baselines3.ppo.ppo.PPO at 0x78e836619410>,\n 9: <stable_baselines3.ppo.ppo.PPO at 0x78e836649ad0>,\n 25: <stable_baselines3.ppo.ppo.PPO at 0x78e836603f10>,\n 28: <stable_baselines3.ppo.ppo.PPO at 0x78e83666a890>,\n 7: <stable_baselines3.ppo.ppo.PPO at 0x78e8366ac3d0>,\n 4: <stable_baselines3.ppo.ppo.PPO at 0x78e8366af590>,\n 15: <stable_baselines3.ppo.ppo.PPO at 0x78e8366da550>,\n 6: <stable_baselines3.ppo.ppo.PPO at 0x78e8366feed0>,\n 5: <stable_baselines3.ppo.ppo.PPO at 0x78e8366324d0>,\n 2: <stable_baselines3.ppo.ppo.PPO at 0x78e8378c0790>,\n 19: <stable_baselines3.ppo.ppo.PPO at 0x78e837be8b10>,\n 11: <stable_baselines3.ppo.ppo.PPO at 0x78e83664b7d0>,\n 14: <stable_baselines3.ppo.ppo.PPO at 0x78e837f303d0>,\n 12: <stable_baselines3.ppo.ppo.PPO at 0x78e837fc5410>,\n 18: <stable_baselines3.ppo.ppo.PPO at 0x78e837fc7e50>,\n 21: <stable_baselines3.ppo.ppo.PPO at 0x78e837f29b90>,\n 20: <stable_baselines3.ppo.ppo.PPO at 0x78e837f51910>}"},"metadata":{}}],"execution_count":152},{"cell_type":"code","source":"type(cluster_policies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:30:07.958298Z","iopub.execute_input":"2025-05-06T17:30:07.958983Z","iopub.status.idle":"2025-05-06T17:30:07.963357Z","shell.execute_reply.started":"2025-05-06T17:30:07.958958Z","shell.execute_reply":"2025-05-06T17:30:07.962633Z"}},"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"dict"},"metadata":{}}],"execution_count":157},{"cell_type":"code","source":"os.makedirs(\"cluster_policies\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:34:21.188245Z","iopub.execute_input":"2025-05-06T17:34:21.189005Z","iopub.status.idle":"2025-05-06T17:34:21.192861Z","shell.execute_reply.started":"2025-05-06T17:34:21.188973Z","shell.execute_reply":"2025-05-06T17:34:21.192079Z"}},"outputs":[],"execution_count":164},{"cell_type":"code","source":"# Save each cluster policy\nfor cluster_id, model in cluster_policies.items():\n        if not isinstance(model, PPO):\n            print(f\"Warning: Model for cluster {cluster_id} is not a PPO model. Skipping.\")\n            continue\n        model_path = os.path.join(\"cluster_policies\", f\"ppo_cluster_{cluster_id}.zip\")\n        model.save(model_path)\n        print(f\"Saved cluster policy for cluster {cluster_id} to {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:34:46.778939Z","iopub.execute_input":"2025-05-06T17:34:46.77949Z","iopub.status.idle":"2025-05-06T17:34:47.013974Z","shell.execute_reply.started":"2025-05-06T17:34:46.779467Z","shell.execute_reply":"2025-05-06T17:34:47.013374Z"}},"outputs":[{"name":"stdout","text":"Saved cluster policy for cluster 22 to cluster_policies/ppo_cluster_22.zip\nSaved cluster policy for cluster 1 to cluster_policies/ppo_cluster_1.zip\nSaved cluster policy for cluster 23 to cluster_policies/ppo_cluster_23.zip\nSaved cluster policy for cluster 8 to cluster_policies/ppo_cluster_8.zip\nSaved cluster policy for cluster 17 to cluster_policies/ppo_cluster_17.zip\nSaved cluster policy for cluster 3 to cluster_policies/ppo_cluster_3.zip\nSaved cluster policy for cluster 24 to cluster_policies/ppo_cluster_24.zip\nSaved cluster policy for cluster 0 to cluster_policies/ppo_cluster_0.zip\nSaved cluster policy for cluster 13 to cluster_policies/ppo_cluster_13.zip\nSaved cluster policy for cluster 26 to cluster_policies/ppo_cluster_26.zip\nSaved cluster policy for cluster 27 to cluster_policies/ppo_cluster_27.zip\nSaved cluster policy for cluster 10 to cluster_policies/ppo_cluster_10.zip\nSaved cluster policy for cluster 16 to cluster_policies/ppo_cluster_16.zip\nSaved cluster policy for cluster 9 to cluster_policies/ppo_cluster_9.zip\nSaved cluster policy for cluster 25 to cluster_policies/ppo_cluster_25.zip\nSaved cluster policy for cluster 28 to cluster_policies/ppo_cluster_28.zip\nSaved cluster policy for cluster 7 to cluster_policies/ppo_cluster_7.zip\nSaved cluster policy for cluster 4 to cluster_policies/ppo_cluster_4.zip\nSaved cluster policy for cluster 15 to cluster_policies/ppo_cluster_15.zip\nSaved cluster policy for cluster 6 to cluster_policies/ppo_cluster_6.zip\nSaved cluster policy for cluster 5 to cluster_policies/ppo_cluster_5.zip\nSaved cluster policy for cluster 2 to cluster_policies/ppo_cluster_2.zip\nSaved cluster policy for cluster 19 to cluster_policies/ppo_cluster_19.zip\nSaved cluster policy for cluster 11 to cluster_policies/ppo_cluster_11.zip\nSaved cluster policy for cluster 14 to cluster_policies/ppo_cluster_14.zip\nSaved cluster policy for cluster 12 to cluster_policies/ppo_cluster_12.zip\nSaved cluster policy for cluster 18 to cluster_policies/ppo_cluster_18.zip\nSaved cluster policy for cluster 21 to cluster_policies/ppo_cluster_21.zip\nSaved cluster policy for cluster 20 to cluster_policies/ppo_cluster_20.zip\n","output_type":"stream"}],"execution_count":166},{"cell_type":"code","source":"# Check dtypes for role_features\nprint(df_features[role_features].dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:51:05.826287Z","iopub.execute_input":"2025-05-06T17:51:05.826564Z","iopub.status.idle":"2025-05-06T17:51:05.9219Z","shell.execute_reply.started":"2025-05-06T17:51:05.826543Z","shell.execute_reply":"2025-05-06T17:51:05.921175Z"}},"outputs":[{"name":"stdout","text":"role_emb_pca_0     float32\nrole_emb_pca_1     float32\nrole_emb_pca_2     float32\nrole_emb_pca_3     float32\nrole_emb_pca_4     float32\nrole_emb_pca_5     float32\nrole_emb_pca_6     float32\nrole_emb_pca_7     float32\nrole_emb_pca_8     float32\nrole_emb_pca_9     float32\nrole_emb_pca_10    float32\nrole_emb_pca_11    float32\nrole_emb_pca_12    float32\nrole_emb_pca_13    float32\nrole_emb_pca_14    float32\nrole_emb_pca_15    float32\nrole_emb_pca_16    float32\nrole_emb_pca_17    float32\nrole_emb_pca_18    float32\nrole_emb_pca_19    float32\nrole_emb_pca_20    float32\nrole_emb_pca_21    float32\nrole_emb_pca_22    float32\nrole_emb_pca_23    float32\nrole_emb_pca_24    float32\nrole_emb_pca_25    float32\nrole_emb_pca_26    float32\nrole_emb_pca_27    float32\nrole_emb_pca_28    float32\nrole_emb_pca_29    float32\nrole_emb_pca_30    float32\nrole_emb_pca_31    float32\nrole_emb_pca_32    float32\nrole_emb_pca_33    float32\nrole_emb_pca_34    float32\nrole_emb_pca_35    float32\nrole_emb_pca_36    float32\nrole_emb_pca_37    float32\nrole_emb_pca_38    float32\nrole_emb_pca_39    float32\nrole_emb_pca_40    float32\nrole_emb_pca_41    float32\nrole_emb_pca_42    float32\nrole_emb_pca_43    float32\nrole_emb_pca_44    float32\nrole_emb_pca_45    float32\nrole_emb_pca_46    float32\nrole_emb_pca_47    float32\nrole_emb_pca_48    float32\nrole_emb_pca_49    float32\ndtype: object\n","output_type":"stream"}],"execution_count":187},{"cell_type":"code","source":"class MetaControllerEnv(gym.Env):\n    def __init__(self, df, cluster_policies):\n        super().__init__()  # Key fix: use modern super() syntax\n        \n        # Define action space first\n        self.action_space = spaces.Discrete(len(cluster_policies))\n        \n        # Define observation space\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(role_features),),\n            dtype=np.float32\n        )\n\n        # Initialize other attributes\n        self.df = df\n        self.cluster_policies = cluster_policies\n        self.current_user = None\n        self.user_data = None\n        self.current_step = 0\n\n    def reset(self, seed=None, options=None):\n        self.current_user = np.random.choice(self.df['user'].unique())\n        self.user_data = self.df[self.df['user'] == self.current_user]\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        return self.user_data.iloc[self.current_step][role_features].values.astype(np.float32)\n\n    def step(self, action):\n        chosen_cluster = list(self.cluster_policies.keys())[action]\n        policy = self.cluster_policies[chosen_cluster]\n        \n        obs = self._get_obs().astype(np.float32)  # Ensure float32\n        anomaly_score = policy.predict(obs, deterministic=True)[0]\n        \n        true_cluster = self.user_data.iloc[self.current_step]['cluster']\n        reward = 1.0 if chosen_cluster == true_cluster else -0.5\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n        \n        return self._get_obs(), reward, done, False, {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:56:51.719338Z","iopub.execute_input":"2025-05-06T17:56:51.719763Z","iopub.status.idle":"2025-05-06T17:56:51.727435Z","shell.execute_reply.started":"2025-05-06T17:56:51.719737Z","shell.execute_reply":"2025-05-06T17:56:51.726735Z"}},"outputs":[],"execution_count":203},{"cell_type":"code","source":"# Ensure all features are float32\nrole_features = [f'role_emb_pca_{i}' for i in range(50)]\ndf_features[role_features] = df_features[role_features].astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:56:00.929117Z","iopub.execute_input":"2025-05-06T17:56:00.929802Z","iopub.status.idle":"2025-05-06T17:56:01.007022Z","shell.execute_reply.started":"2025-05-06T17:56:00.929779Z","shell.execute_reply":"2025-05-06T17:56:01.00646Z"}},"outputs":[],"execution_count":200},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# First ensure all cluster policies use proper dtype\nfor cluster, policy in cluster_policies.items():\n    policy.policy.obs_to_tensor = lambda x: (th.as_tensor(x.astype(np.float32), False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:07:29.744898Z","iopub.execute_input":"2025-05-06T18:07:29.745371Z","iopub.status.idle":"2025-05-06T18:07:29.749343Z","shell.execute_reply.started":"2025-05-06T18:07:29.745347Z","shell.execute_reply":"2025-05-06T18:07:29.748554Z"}},"outputs":[],"execution_count":212},{"cell_type":"code","source":"class MetaControllerEnv(gym.Env):\n    def __init__(self, df, cluster_policies):\n        super().__init__()\n        \n        # Subset df to include necessary columns\n        self.df = df[\n            ['user', 'cluster'] + \n            behavioral_features + latent_features + role_features + \n            ['logon_trend', 'logon_volatility']\n        ]\n        \n        # Check for NaN values in numeric columns\n        numeric_cols = behavioral_features + latent_features + role_features + ['logon_trend', 'logon_volatility']\n        if self.df[numeric_cols].isna().any().any():\n            raise ValueError(\"NaN values found in numeric columns\")\n        \n        # Ensure numeric columns are float32\n        for col in numeric_cols:\n            self.df[col] = self.df[col].astype(np.float32)\n        \n        # Define action and observation spaces\n        self.action_space = spaces.Discrete(len(cluster_policies))\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(role_features),),\n            dtype=np.float32\n        )\n        \n        self.cluster_policies = cluster_policies\n        self.current_user = None\n        self.user_data = None\n        self.current_step = 0\n\n    def reset(self, seed=None, options=None):\n        self.current_user = np.random.choice(self.df['user'].unique())\n        self.user_data = self.df[self.df['user'] == self.current_user]\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        obs = self.user_data.iloc[self.current_step][role_features].to_numpy(dtype=np.float32)\n        return obs\n\n    def step(self, action):\n        chosen_cluster = list(self.cluster_policies.keys())[action]\n        policy = self.cluster_policies[chosen_cluster]\n        \n        # Construct the full observation for the cluster policy (72 features)\n        row = self.user_data.iloc[self.current_step]\n        cluster_obs = np.concatenate([\n            row[behavioral_features].to_numpy(dtype=np.float32),\n            row[latent_features].to_numpy(dtype=np.float32),\n            row[role_features].to_numpy(dtype=np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        \n        # Ensure cluster_obs is numeric\n        if not np.issubdtype(cluster_obs.dtype, np.floating):\n            raise ValueError(f\"Cluster observation contains non-numeric data: {cluster_obs.dtype}\")\n        \n        # Predict using the cluster policy\n        anomaly_score, _ = policy.predict(cluster_obs, deterministic=True)\n        \n        true_cluster = self.user_data.iloc[self.current_step]['cluster']\n        reward = 1.0 if chosen_cluster == true_cluster else -0.5\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n\n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n        return self._get_obs(), reward, done, False, {}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:18:08.566533Z","iopub.execute_input":"2025-05-06T18:18:08.567119Z","iopub.status.idle":"2025-05-06T18:18:08.576786Z","shell.execute_reply.started":"2025-05-06T18:18:08.567094Z","shell.execute_reply":"2025-05-06T18:18:08.575938Z"}},"outputs":[],"execution_count":230},{"cell_type":"code","source":"import torch as th","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:10:57.414213Z","iopub.execute_input":"2025-05-06T18:10:57.414955Z","iopub.status.idle":"2025-05-06T18:10:57.4187Z","shell.execute_reply.started":"2025-05-06T18:10:57.414932Z","shell.execute_reply":"2025-05-06T18:10:57.417299Z"}},"outputs":[],"execution_count":221},{"cell_type":"code","source":"meta_env = MetaControllerEnv(\n    df_features[df_features['cluster'].isin(cluster_policies.keys())],\n    cluster_policies\n)\n\nmeta_policy = PPO(\n    \"MlpPolicy\",\n    meta_env,\n    verbose=1,\n    learning_rate=1e-4,\n    n_steps=512,\n    batch_size=32\n)\n\nmeta_policy.learn(total_timesteps=20000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:18:12.124969Z","iopub.execute_input":"2025-05-06T18:18:12.125675Z","iopub.status.idle":"2025-05-06T18:19:58.686449Z","shell.execute_reply.started":"2025-05-06T18:18:12.125651Z","shell.execute_reply":"2025-05-06T18:19:58.685905Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/tmp/ipykernel_31/428013604.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.df[col] = self.df[col].astype(np.float32)\n/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 346      |\n|    ep_rew_mean     | -154     |\n| time/              |          |\n|    fps             | 254      |\n|    iterations      | 1        |\n|    time_elapsed    | 2        |\n|    total_timesteps | 512      |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 396         |\n|    ep_rew_mean          | -168        |\n| time/                   |             |\n|    fps                  | 222         |\n|    iterations           | 2           |\n|    time_elapsed         | 4           |\n|    total_timesteps      | 1024        |\n| train/                  |             |\n|    approx_kl            | 0.006586613 |\n|    clip_fraction        | 0.026       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | -0.0198     |\n|    learning_rate        | 0.0001      |\n|    loss                 | 4.52        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0194     |\n|    value_loss           | 28.9        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 370         |\n|    ep_rew_mean          | -163        |\n| time/                   |             |\n|    fps                  | 210         |\n|    iterations           | 3           |\n|    time_elapsed         | 7           |\n|    total_timesteps      | 1536        |\n| train/                  |             |\n|    approx_kl            | 0.006603054 |\n|    clip_fraction        | 0.0309      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | -0.0941     |\n|    learning_rate        | 0.0001      |\n|    loss                 | 4.2         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0207     |\n|    value_loss           | 21.5        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 348          |\n|    ep_rew_mean          | -155         |\n| time/                   |              |\n|    fps                  | 205          |\n|    iterations           | 4            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 2048         |\n| train/                  |              |\n|    approx_kl            | 0.0041783922 |\n|    clip_fraction        | 0.0131       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.169        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.49         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0149      |\n|    value_loss           | 19.4         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 347         |\n|    ep_rew_mean          | -156        |\n| time/                   |             |\n|    fps                  | 202         |\n|    iterations           | 5           |\n|    time_elapsed         | 12          |\n|    total_timesteps      | 2560        |\n| train/                  |             |\n|    approx_kl            | 0.006559136 |\n|    clip_fraction        | 0.0121      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.63        |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.55        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0124     |\n|    value_loss           | 17.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 347         |\n|    ep_rew_mean          | -155        |\n| time/                   |             |\n|    fps                  | 200         |\n|    iterations           | 6           |\n|    time_elapsed         | 15          |\n|    total_timesteps      | 3072        |\n| train/                  |             |\n|    approx_kl            | 0.010053496 |\n|    clip_fraction        | 0.0297      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | -0.432      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1           |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.0178     |\n|    value_loss           | 12.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 347         |\n|    ep_rew_mean          | -155        |\n| time/                   |             |\n|    fps                  | 199         |\n|    iterations           | 7           |\n|    time_elapsed         | 17          |\n|    total_timesteps      | 3584        |\n| train/                  |             |\n|    approx_kl            | 0.005495933 |\n|    clip_fraction        | 0.0139      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.568       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.94        |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.0111     |\n|    value_loss           | 13.2        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 347         |\n|    ep_rew_mean          | -155        |\n| time/                   |             |\n|    fps                  | 198         |\n|    iterations           | 8           |\n|    time_elapsed         | 20          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.012528968 |\n|    clip_fraction        | 0.06        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | -0.3        |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.25        |\n|    n_updates            | 70          |\n|    policy_gradient_loss | -0.0175     |\n|    value_loss           | 11.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 342          |\n|    ep_rew_mean          | -153         |\n| time/                   |              |\n|    fps                  | 197          |\n|    iterations           | 9            |\n|    time_elapsed         | 23           |\n|    total_timesteps      | 4608         |\n| train/                  |              |\n|    approx_kl            | 0.0034595435 |\n|    clip_fraction        | 0.00176      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.702        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1            |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.00804     |\n|    value_loss           | 13.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 342          |\n|    ep_rew_mean          | -153         |\n| time/                   |              |\n|    fps                  | 197          |\n|    iterations           | 10           |\n|    time_elapsed         | 25           |\n|    total_timesteps      | 5120         |\n| train/                  |              |\n|    approx_kl            | 0.0048309616 |\n|    clip_fraction        | 0.0168       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | -0.0436      |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.1          |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.0149      |\n|    value_loss           | 10.1         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 342          |\n|    ep_rew_mean          | -152         |\n| time/                   |              |\n|    fps                  | 197          |\n|    iterations           | 11           |\n|    time_elapsed         | 28           |\n|    total_timesteps      | 5632         |\n| train/                  |              |\n|    approx_kl            | 0.0014300746 |\n|    clip_fraction        | 0.00449      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.787        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.42         |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00746     |\n|    value_loss           | 15.5         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 343          |\n|    ep_rew_mean          | -152         |\n| time/                   |              |\n|    fps                  | 197          |\n|    iterations           | 12           |\n|    time_elapsed         | 31           |\n|    total_timesteps      | 6144         |\n| train/                  |              |\n|    approx_kl            | 0.0039972006 |\n|    clip_fraction        | 0.00117      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.728        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.08         |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.0119      |\n|    value_loss           | 9.28         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 343         |\n|    ep_rew_mean          | -153        |\n| time/                   |             |\n|    fps                  | 196         |\n|    iterations           | 13          |\n|    time_elapsed         | 33          |\n|    total_timesteps      | 6656        |\n| train/                  |             |\n|    approx_kl            | 0.002693989 |\n|    clip_fraction        | 0.00195     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.738       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.61        |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.00776    |\n|    value_loss           | 11          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 342         |\n|    ep_rew_mean          | -152        |\n| time/                   |             |\n|    fps                  | 196         |\n|    iterations           | 14          |\n|    time_elapsed         | 36          |\n|    total_timesteps      | 7168        |\n| train/                  |             |\n|    approx_kl            | 0.009960563 |\n|    clip_fraction        | 0.041       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | -0.26       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.15        |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.0186     |\n|    value_loss           | 10.7        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 342         |\n|    ep_rew_mean          | -151        |\n| time/                   |             |\n|    fps                  | 196         |\n|    iterations           | 15          |\n|    time_elapsed         | 39          |\n|    total_timesteps      | 7680        |\n| train/                  |             |\n|    approx_kl            | 0.010199119 |\n|    clip_fraction        | 0.0492      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.868       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.36        |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.0185     |\n|    value_loss           | 6.88        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 342          |\n|    ep_rew_mean          | -151         |\n| time/                   |              |\n|    fps                  | 196          |\n|    iterations           | 16           |\n|    time_elapsed         | 41           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0034869732 |\n|    clip_fraction        | 0.00898      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.771        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.89         |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.0103      |\n|    value_loss           | 8.25         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 343          |\n|    ep_rew_mean          | -151         |\n| time/                   |              |\n|    fps                  | 196          |\n|    iterations           | 17           |\n|    time_elapsed         | 44           |\n|    total_timesteps      | 8704         |\n| train/                  |              |\n|    approx_kl            | 0.0029738825 |\n|    clip_fraction        | 0.00703      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.346        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.28         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.00729     |\n|    value_loss           | 8.49         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 343          |\n|    ep_rew_mean          | -151         |\n| time/                   |              |\n|    fps                  | 195          |\n|    iterations           | 18           |\n|    time_elapsed         | 47           |\n|    total_timesteps      | 9216         |\n| train/                  |              |\n|    approx_kl            | 0.0021982132 |\n|    clip_fraction        | 0.0084       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.37        |\n|    explained_variance   | -1.08        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 0.447        |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.00783     |\n|    value_loss           | 9.69         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 345         |\n|    ep_rew_mean          | -153        |\n| time/                   |             |\n|    fps                  | 195         |\n|    iterations           | 19          |\n|    time_elapsed         | 49          |\n|    total_timesteps      | 9728        |\n| train/                  |             |\n|    approx_kl            | 0.002679138 |\n|    clip_fraction        | 0.00508     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.249       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 0.49        |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.00663    |\n|    value_loss           | 9.66        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 341         |\n|    ep_rew_mean          | -151        |\n| time/                   |             |\n|    fps                  | 195         |\n|    iterations           | 20          |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.003575224 |\n|    clip_fraction        | 0.00488     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.602       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.25        |\n|    n_updates            | 190         |\n|    policy_gradient_loss | -0.0076     |\n|    value_loss           | 9.49        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | -150         |\n| time/                   |              |\n|    fps                  | 195          |\n|    iterations           | 21           |\n|    time_elapsed         | 55           |\n|    total_timesteps      | 10752        |\n| train/                  |              |\n|    approx_kl            | 0.0026322445 |\n|    clip_fraction        | 0.00879      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.67         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.31         |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00996     |\n|    value_loss           | 11.5         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 338          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 22           |\n|    time_elapsed         | 57           |\n|    total_timesteps      | 11264        |\n| train/                  |              |\n|    approx_kl            | 0.0051607615 |\n|    clip_fraction        | 0.0316       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.497        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.9          |\n|    n_updates            | 210          |\n|    policy_gradient_loss | -0.013       |\n|    value_loss           | 8.51         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 338         |\n|    ep_rew_mean          | -149        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 23          |\n|    time_elapsed         | 60          |\n|    total_timesteps      | 11776       |\n| train/                  |             |\n|    approx_kl            | 0.004653508 |\n|    clip_fraction        | 0.00684     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.818       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.58        |\n|    n_updates            | 220         |\n|    policy_gradient_loss | -0.0125     |\n|    value_loss           | 10.6        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 339          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 24           |\n|    time_elapsed         | 63           |\n|    total_timesteps      | 12288        |\n| train/                  |              |\n|    approx_kl            | 0.0035662532 |\n|    clip_fraction        | 0.00684      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.34        |\n|    explained_variance   | 0.516        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.33         |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.0109      |\n|    value_loss           | 9.06         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 339          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 25           |\n|    time_elapsed         | 65           |\n|    total_timesteps      | 12800        |\n| train/                  |              |\n|    approx_kl            | 0.0015237464 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.652        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.46         |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.00612     |\n|    value_loss           | 13.7         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 340         |\n|    ep_rew_mean          | -148        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 26          |\n|    time_elapsed         | 68          |\n|    total_timesteps      | 13312       |\n| train/                  |             |\n|    approx_kl            | 0.008537121 |\n|    clip_fraction        | 0.0234      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.761       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 4.95        |\n|    n_updates            | 250         |\n|    policy_gradient_loss | -0.0136     |\n|    value_loss           | 8.26        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 27           |\n|    time_elapsed         | 71           |\n|    total_timesteps      | 13824        |\n| train/                  |              |\n|    approx_kl            | 0.0029732455 |\n|    clip_fraction        | 0.00273      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.7          |\n|    learning_rate        | 0.0001       |\n|    loss                 | 10.4         |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.00758     |\n|    value_loss           | 14.4         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 28           |\n|    time_elapsed         | 73           |\n|    total_timesteps      | 14336        |\n| train/                  |              |\n|    approx_kl            | 0.0070894035 |\n|    clip_fraction        | 0.0201       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.928        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.25         |\n|    n_updates            | 270          |\n|    policy_gradient_loss | -0.0147      |\n|    value_loss           | 10.7         |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 343        |\n|    ep_rew_mean          | -149       |\n| time/                   |            |\n|    fps                  | 194        |\n|    iterations           | 29         |\n|    time_elapsed         | 76         |\n|    total_timesteps      | 14848      |\n| train/                  |            |\n|    approx_kl            | 0.00546401 |\n|    clip_fraction        | 0.00215    |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -3.34      |\n|    explained_variance   | 0.866      |\n|    learning_rate        | 0.0001     |\n|    loss                 | 2.98       |\n|    n_updates            | 280        |\n|    policy_gradient_loss | -0.00929   |\n|    value_loss           | 13.9       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 343         |\n|    ep_rew_mean          | -149        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 30          |\n|    time_elapsed         | 79          |\n|    total_timesteps      | 15360       |\n| train/                  |             |\n|    approx_kl            | 0.010939641 |\n|    clip_fraction        | 0.0996      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.31       |\n|    explained_variance   | 0.626       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.22        |\n|    n_updates            | 290         |\n|    policy_gradient_loss | -0.0217     |\n|    value_loss           | 9.73        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 342         |\n|    ep_rew_mean          | -149        |\n| time/                   |             |\n|    fps                  | 193         |\n|    iterations           | 31          |\n|    time_elapsed         | 81          |\n|    total_timesteps      | 15872       |\n| train/                  |             |\n|    approx_kl            | 0.004625761 |\n|    clip_fraction        | 0.00527     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.34       |\n|    explained_variance   | 0.868       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 4.47        |\n|    n_updates            | 300         |\n|    policy_gradient_loss | -0.00904    |\n|    value_loss           | 11.1        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 344          |\n|    ep_rew_mean          | -150         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 32           |\n|    time_elapsed         | 84           |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0011033434 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.879        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.62         |\n|    n_updates            | 310          |\n|    policy_gradient_loss | -0.00553     |\n|    value_loss           | 10           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 344         |\n|    ep_rew_mean          | -150        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 33          |\n|    time_elapsed         | 87          |\n|    total_timesteps      | 16896       |\n| train/                  |             |\n|    approx_kl            | 0.009997454 |\n|    clip_fraction        | 0.0514      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.34       |\n|    explained_variance   | 0.575       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 0.92        |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.0167     |\n|    value_loss           | 8.41        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | -148         |\n| time/                   |              |\n|    fps                  | 193          |\n|    iterations           | 34           |\n|    time_elapsed         | 89           |\n|    total_timesteps      | 17408        |\n| train/                  |              |\n|    approx_kl            | 0.0023444064 |\n|    clip_fraction        | 0.00684      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.72         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.27         |\n|    n_updates            | 330          |\n|    policy_gradient_loss | -0.0107      |\n|    value_loss           | 8.14         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 341         |\n|    ep_rew_mean          | -148        |\n| time/                   |             |\n|    fps                  | 193         |\n|    iterations           | 35          |\n|    time_elapsed         | 92          |\n|    total_timesteps      | 17920       |\n| train/                  |             |\n|    approx_kl            | 0.009704363 |\n|    clip_fraction        | 0.0531      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.31       |\n|    explained_variance   | 0.679       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 8.47        |\n|    n_updates            | 340         |\n|    policy_gradient_loss | -0.0191     |\n|    value_loss           | 17.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 341         |\n|    ep_rew_mean          | -148        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 36          |\n|    time_elapsed         | 94          |\n|    total_timesteps      | 18432       |\n| train/                  |             |\n|    approx_kl            | 0.009966431 |\n|    clip_fraction        | 0.0514      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.33       |\n|    explained_variance   | 0.614       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 0.611       |\n|    n_updates            | 350         |\n|    policy_gradient_loss | -0.0188     |\n|    value_loss           | 9.73        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 344          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 37           |\n|    time_elapsed         | 97           |\n|    total_timesteps      | 18944        |\n| train/                  |              |\n|    approx_kl            | 0.0018711266 |\n|    clip_fraction        | 0.00352      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.32        |\n|    explained_variance   | 0.68         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 9.37         |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.00826     |\n|    value_loss           | 14           |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 344          |\n|    ep_rew_mean          | -149         |\n| time/                   |              |\n|    fps                  | 194          |\n|    iterations           | 38           |\n|    time_elapsed         | 100          |\n|    total_timesteps      | 19456        |\n| train/                  |              |\n|    approx_kl            | 0.0035460254 |\n|    clip_fraction        | 0.00254      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.745        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.81         |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.0104      |\n|    value_loss           | 12.9         |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 345         |\n|    ep_rew_mean          | -149        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 39          |\n|    time_elapsed         | 102         |\n|    total_timesteps      | 19968       |\n| train/                  |             |\n|    approx_kl            | 0.009863915 |\n|    clip_fraction        | 0.0764      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.33       |\n|    explained_variance   | 0.668       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.8         |\n|    n_updates            | 380         |\n|    policy_gradient_loss | -0.0201     |\n|    value_loss           | 6.91        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 345         |\n|    ep_rew_mean          | -148        |\n| time/                   |             |\n|    fps                  | 194         |\n|    iterations           | 40          |\n|    time_elapsed         | 105         |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.005258891 |\n|    clip_fraction        | 0.0156      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.32       |\n|    explained_variance   | 0.76        |\n|    learning_rate        | 0.0001      |\n|    loss                 | 6.82        |\n|    n_updates            | 390         |\n|    policy_gradient_loss | -0.011      |\n|    value_loss           | 11.4        |\n-----------------------------------------\n","output_type":"stream"},{"execution_count":231,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x78e842307310>"},"metadata":{}}],"execution_count":231},{"cell_type":"code","source":"df_features.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:02:46.694974Z","iopub.execute_input":"2025-05-06T18:02:46.695757Z","iopub.status.idle":"2025-05-06T18:02:46.700077Z","shell.execute_reply.started":"2025-05-06T18:02:46.695733Z","shell.execute_reply":"2025-05-06T18:02:46.699401Z"}},"outputs":[{"execution_count":209,"output_type":"execute_result","data":{"text/plain":"(330285, 91)"},"metadata":{}}],"execution_count":209},{"cell_type":"code","source":"print(\"Behavioral features dtypes:\", df_features[behavioral_features].dtypes)\nprint(\"Latent features dtypes:\", df_features[latent_features].dtypes)\nprint(\"Role features dtypes:\", df_features[role_features].dtypes)\nprint(\"Logon trend dtype:\", df_features['logon_trend'].dtype)\nprint(\"Logon volatility dtype:\", df_features['logon_volatility'].dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:36:24.203926Z","iopub.execute_input":"2025-05-06T17:36:24.204788Z","iopub.status.idle":"2025-05-06T17:36:24.270603Z","shell.execute_reply.started":"2025-05-06T17:36:24.204759Z","shell.execute_reply":"2025-05-06T17:36:24.269827Z"}},"outputs":[{"name":"stdout","text":"Behavioral features dtypes: after_hours_logon_count    float64\ntotal_logon_count          float64\ndevice_connects            float64\navg_content_word_count     float64\ntext_files_accessed        float64\nfiles_accessed             float64\ntotal_recipients           float64\nexternal_ratio             float64\nemails_sent                float64\nbcc_flag                   float64\nkeyword_richness           float64\nz_score_logon              float64\ndtype: object\nLatent features dtypes: latent_0    float64\nlatent_1    float64\nlatent_2    float64\nlatent_3    float64\nlatent_4    float64\nlatent_5    float64\nlatent_6    float64\nlatent_7    float64\ndtype: object\nRole features dtypes: role_emb_pca_0     float64\nrole_emb_pca_1     float64\nrole_emb_pca_2     float64\nrole_emb_pca_3     float64\nrole_emb_pca_4     float64\nrole_emb_pca_5     float64\nrole_emb_pca_6     float64\nrole_emb_pca_7     float64\nrole_emb_pca_8     float64\nrole_emb_pca_9     float64\nrole_emb_pca_10    float64\nrole_emb_pca_11    float64\nrole_emb_pca_12    float64\nrole_emb_pca_13    float64\nrole_emb_pca_14    float64\nrole_emb_pca_15    float64\nrole_emb_pca_16    float64\nrole_emb_pca_17    float64\nrole_emb_pca_18    float64\nrole_emb_pca_19    float64\nrole_emb_pca_20    float64\nrole_emb_pca_21    float64\nrole_emb_pca_22    float64\nrole_emb_pca_23    float64\nrole_emb_pca_24    float64\nrole_emb_pca_25    float64\nrole_emb_pca_26    float64\nrole_emb_pca_27    float64\nrole_emb_pca_28    float64\nrole_emb_pca_29    float64\nrole_emb_pca_30    float64\nrole_emb_pca_31    float64\nrole_emb_pca_32    float64\nrole_emb_pca_33    float64\nrole_emb_pca_34    float64\nrole_emb_pca_35    float64\nrole_emb_pca_36    float64\nrole_emb_pca_37    float64\nrole_emb_pca_38    float64\nrole_emb_pca_39    float64\nrole_emb_pca_40    float64\nrole_emb_pca_41    float64\nrole_emb_pca_42    float64\nrole_emb_pca_43    float64\nrole_emb_pca_44    float64\nrole_emb_pca_45    float64\nrole_emb_pca_46    float64\nrole_emb_pca_47    float64\nrole_emb_pca_48    float64\nrole_emb_pca_49    float64\ndtype: object\nLogon trend dtype: float64\nLogon volatility dtype: float64\n","output_type":"stream"}],"execution_count":169},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_anomaly(user_day_data):\n    cluster_idx, _ = meta_policy.predict(user_day_data[role_features].to_numpy(dtype=np.float32))\n    chosen_cluster = list(cluster_policies.keys())[cluster_idx]\n    \n    policy = cluster_policies[chosen_cluster]\n    obs = np.concatenate([\n        user_day_data[behavioral_features].to_numpy(dtype=np.float32),\n        user_day_data[latent_features].to_numpy(dtype=np.float32),\n        user_day_data[role_features].to_numpy(dtype=np.float32),\n        np.array([user_day_data['logon_trend'], user_day_data['logon_volatility']], dtype=np.float32)\n    ])\n    anomaly_score, _ = policy.predict(obs)\n    threshold = user_day_data['adaptive_threshold']\n    return 1 if anomaly_score >= threshold else 0\n\n# Run inference\npredictions = np.zeros(len(df))\nfor i in range(len(df)):\n    predictions[i] = predict_anomaly(df_features.iloc[i])\n\ndf_features['final_prediction'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:21:43.987622Z","iopub.execute_input":"2025-05-06T18:21:43.988333Z","iopub.status.idle":"2025-05-06T18:37:01.122112Z","shell.execute_reply.started":"2025-05-06T18:21:43.988307Z","shell.execute_reply":"2025-05-06T18:37:01.121545Z"}},"outputs":[],"execution_count":232},{"cell_type":"code","source":"df_features['final_prediction'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:41:02.260032Z","iopub.execute_input":"2025-05-06T18:41:02.260307Z","iopub.status.idle":"2025-05-06T18:41:02.269936Z","shell.execute_reply.started":"2025-05-06T18:41:02.260286Z","shell.execute_reply":"2025-05-06T18:41:02.26924Z"}},"outputs":[{"execution_count":235,"output_type":"execute_result","data":{"text/plain":"final_prediction\n0.0    290281\n1.0     40004\nName: count, dtype: int64"},"metadata":{}}],"execution_count":235},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:41:49.000301Z","iopub.execute_input":"2025-05-06T18:41:49.000567Z","iopub.status.idle":"2025-05-06T18:41:49.004264Z","shell.execute_reply.started":"2025-05-06T18:41:49.000544Z","shell.execute_reply":"2025-05-06T18:41:49.003653Z"}},"outputs":[],"execution_count":237},{"cell_type":"code","source":"precision, recall, f1, _ = precision_recall_fscore_support(\n    df_features['is_anomaly'], df_features['final_prediction'], average='binary'\n)\nauc_roc = roc_auc_score(df_features['is_anomaly'], df_features['final_prediction'])\n\nprint(\"Performance of Temporal-Aware HRL with Custom Reward Logic:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"AUC-ROC: {auc_roc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:41:50.624034Z","iopub.execute_input":"2025-05-06T18:41:50.624586Z","iopub.status.idle":"2025-05-06T18:41:50.960971Z","shell.execute_reply.started":"2025-05-06T18:41:50.624565Z","shell.execute_reply":"2025-05-06T18:41:50.960154Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"},{"name":"stdout","text":"Performance of Temporal-Aware HRL with Custom Reward Logic:\nPrecision: 0.0050\nRecall: 0.1466\nF1 Score: 0.0097\nAUC-ROC: 0.5128\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"}],"execution_count":238},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:44:27.884545Z","iopub.execute_input":"2025-05-06T18:44:27.884813Z","iopub.status.idle":"2025-05-06T18:44:27.888431Z","shell.execute_reply.started":"2025-05-06T18:44:27.884793Z","shell.execute_reply":"2025-05-06T18:44:27.887642Z"}},"outputs":[],"execution_count":243},{"cell_type":"code","source":"cm = confusion_matrix(df_features['is_anomaly'], df_features['final_prediction'])\n\n# Create a new figure\nplt.figure(figsize=(8, 6))\n# Plot the confusion matrix using seaborn heatmap\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal', 'Anomaly'], \n            yticklabels=['Normal', 'Anomaly'])\nplt.title('Confusion Matrix for Anomaly Detection')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:44:29.344551Z","iopub.execute_input":"2025-05-06T18:44:29.344813Z","iopub.status.idle":"2025-05-06T18:44:29.651767Z","shell.execute_reply.started":"2025-05-06T18:44:29.344791Z","shell.execute_reply":"2025-05-06T18:44:29.651068Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":244},{"cell_type":"code","source":"meta_policy.save(\"meta_policy.zip\")\nprint(\"Meta-policy model saved to meta_policy.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:50:18.965183Z","iopub.execute_input":"2025-05-06T18:50:18.965431Z","iopub.status.idle":"2025-05-06T18:50:18.98061Z","shell.execute_reply.started":"2025-05-06T18:50:18.965413Z","shell.execute_reply":"2025-05-06T18:50:18.980022Z"}},"outputs":[{"name":"stdout","text":"Meta-policy model saved to meta_policy.zip\n","output_type":"stream"}],"execution_count":246},{"cell_type":"code","source":"correct_selections = 0\ntotal_selections = 0\nfor i in range(100):  # Test on 100 steps\n    obs, _ = meta_env.reset()\n    action, _ = meta_policy.predict(obs)\n    chosen_cluster = list(cluster_policies.keys())[action]\n    true_cluster = meta_env.user_data.iloc[meta_env.current_step]['cluster']\n    if chosen_cluster == true_cluster:\n        correct_selections += 1\n    total_selections += 1\n    meta_env.step(action)\n\naccuracy = correct_selections / total_selections\nprint(f\"Meta-Controller Cluster Selection Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:54:23.925395Z","iopub.execute_input":"2025-05-06T18:54:23.925928Z","iopub.status.idle":"2025-05-06T18:54:27.837353Z","shell.execute_reply.started":"2025-05-06T18:54:23.925905Z","shell.execute_reply":"2025-05-06T18:54:27.836587Z"}},"outputs":[{"name":"stdout","text":"Meta-Controller Cluster Selection Accuracy: 0.0500\n","output_type":"stream"}],"execution_count":249},{"cell_type":"markdown","source":"imporving the HRL","metadata":{}},{"cell_type":"code","source":"class UserDayEnv(gym.Env):\n    def __init__(self, user_data):\n        super().__init__()\n        self.user_data = user_data[\n            behavioral_features + latent_features + role_features + \n            ['logon_trend', 'logon_volatility', 'is_anomaly', 'adaptive_threshold', 'has_left']\n        ]\n        self.current_step = 0\n        \n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(behavioral_features) + len(latent_features) + len(role_features) + 2,),\n            dtype=np.float32\n        )\n        \n        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n        \n        self.anomaly_weight = 200  # Increased to prioritize anomalies\n        self.normal_weight = 1\n        self.has_left_bonus = 2.0\n        self.fp_count = 0\n        self.total_preds = 0\n\n    def reset(self, seed=None, options=None):\n        self.current_step = 0\n        self.fp_count = 0\n        self.total_preds = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        row = self.user_data.iloc[self.current_step]\n        obs = np.concatenate([\n            row[behavioral_features].to_numpy(dtype=np.float32),\n            row[latent_features].to_numpy(dtype=np.float32),\n            row[role_features].to_numpy(dtype=np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        return obs\n\n    def step(self, action):\n        reward = self._calculate_reward(action)\n        row = self.user_data.iloc[self.current_step]\n        info = {'final_action': 1 if action[0] >= row['adaptive_threshold'] else 0}\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n            \n        return obs, reward, done, False, info\n\n    def _calculate_reward(self, action):\n        row = self.user_data.iloc[self.current_step]\n        true_label = row['is_anomaly']\n        threshold = row['adaptive_threshold']\n        self.total_preds += 1\n        \n        anomaly_score = action[0]\n        final_action = 1 if anomaly_score >= threshold else 0\n        \n        fp_rate = self.fp_count / max(1, self.total_preds)\n        if fp_rate > 0.1:  # Relaxed FP rate threshold\n            self.anomaly_weight = max(100, self.anomaly_weight * 0.95)  # Slower decrease\n        \n        has_left_bonus = self.has_left_bonus if row['has_left'] == 1 else 1.0\n        if final_action == true_label:\n            reward = self.anomaly_weight * has_left_bonus if true_label == 1 else self.normal_weight\n        else:\n            reward = -10 if final_action == 1 else -15  # Increased penalty for FNs\n        \n        if final_action == 1 and true_label == 0:\n            self.fp_count += 1\n        \n        return reward","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:17:09.299171Z","iopub.execute_input":"2025-05-06T19:17:09.299756Z","iopub.status.idle":"2025-05-06T19:17:09.30979Z","shell.execute_reply.started":"2025-05-06T19:17:09.299733Z","shell.execute_reply":"2025-05-06T19:17:09.308983Z"}},"outputs":[],"execution_count":271},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:17:14.358974Z","iopub.execute_input":"2025-05-06T19:17:14.359746Z","iopub.status.idle":"2025-05-06T19:17:14.453447Z","shell.execute_reply.started":"2025-05-06T19:17:14.359714Z","shell.execute_reply":"2025-05-06T19:17:14.452617Z"}},"outputs":[{"execution_count":272,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n330280  ZSL0305  2011-05-10                -0.737332           -0.53406   \n330281  ZSL0305  2011-05-11                -0.737332           -0.53406   \n330282  ZSL0305  2011-05-12                -0.737332           -0.53406   \n330283  ZSL0305  2011-05-13                -0.737332           -0.53406   \n330284  ZSL0305  2011-05-16                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n330280        -0.331274               -0.396378            -0.285834   \n330281        -0.331274               -0.396378            -0.285834   \n330282        -0.331274               -0.396378            -0.285834   \n330283        -0.331274               -0.396378            -0.285834   \n330284        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  ...  \\\n0            -0.287121          0.930009       -0.759447  ...   \n1            -0.287121          0.711501       -0.233484  ...   \n2            -0.287121          0.766128       -0.064106  ...   \n3            -0.287121          0.875382       -0.179997  ...   \n4            -0.287121          0.766128       -0.607898  ...   \n...                ...               ...             ...  ...   \n330280       -0.287121         -1.309699       -1.107117  ...   \n330281       -0.287121         -1.200445        2.137805  ...   \n330282       -0.287121         -1.091191        3.760267  ...   \n330283       -0.287121         -1.309699        0.515344  ...   \n330284       -0.287121         -1.309699        0.515344  ...   \n\n        rolling_avg_logon  rolling_std_logon  z_score_logon logon_trend  \\\n0                -0.53406                0.0       0.000031    0.000031   \n1                -0.53406                0.0       0.000031    0.000031   \n2                -0.53406                0.0       0.000031    0.000031   \n3                -0.53406                0.0       0.000031    0.000031   \n4                -0.53406                0.0       0.000031    0.000031   \n...                   ...                ...            ...         ...   \n330280           -0.53406                0.0       0.000031    0.000031   \n330281           -0.53406                0.0       0.000031    0.000031   \n330282           -0.53406                0.0       0.000031    0.000031   \n330283           -0.53406                0.0       0.000031    0.000031   \n330284           -0.53406                0.0       0.000031    0.000031   \n\n       logon_volatility  is_anomaly role_anomaly_rate role_sensitivity  \\\n0                   0.0           0          0.000000              1.5   \n1                   0.0           0          0.000000              1.5   \n2                   0.0           0          0.000000              1.5   \n3                   0.0           0          0.000000              1.5   \n4                   0.0           0          0.000000              1.5   \n...                 ...         ...               ...              ...   \n330280              0.0           0          0.005779              1.0   \n330281              0.0           0          0.005779              1.0   \n330282              0.0           0          0.005779              1.0   \n330283              0.0           0          0.005779              1.0   \n330284              0.0           0          0.005779              1.0   \n\n       adaptive_threshold final_prediction  \n0                1.350000              0.0  \n1                1.350000              0.0  \n2                1.350000              0.0  \n3                1.350000              0.0  \n4                1.350000              0.0  \n...                   ...              ...  \n330280           0.842207              0.0  \n330281           0.842207              0.0  \n330282           0.842207              0.0  \n330283           0.842207              0.0  \n330284           0.842207              0.0  \n\n[330285 rows x 92 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>...</th>\n      <th>rolling_avg_logon</th>\n      <th>rolling_std_logon</th>\n      <th>z_score_logon</th>\n      <th>logon_trend</th>\n      <th>logon_volatility</th>\n      <th>is_anomaly</th>\n      <th>role_anomaly_rate</th>\n      <th>role_sensitivity</th>\n      <th>adaptive_threshold</th>\n      <th>final_prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1.350000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330280</th>\n      <td>ZSL0305</td>\n      <td>2011-05-10</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>-1.107117</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330281</th>\n      <td>ZSL0305</td>\n      <td>2011-05-11</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.200445</td>\n      <td>2.137805</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330282</th>\n      <td>ZSL0305</td>\n      <td>2011-05-12</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.091191</td>\n      <td>3.760267</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>ZSL0305</td>\n      <td>2011-05-13</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330284</th>\n      <td>ZSL0305</td>\n      <td>2011-05-16</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>...</td>\n      <td>-0.53406</td>\n      <td>0.0</td>\n      <td>0.000031</td>\n      <td>0.000031</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.005779</td>\n      <td>1.0</td>\n      <td>0.842207</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>330285 rows × 92 columns</p>\n</div>"},"metadata":{}}],"execution_count":272},{"cell_type":"code","source":"cluster_policies = {}\nfor cluster, users in cluster_users.items():\n    cluster_data = df_features[df_features['user'].isin(users)]\n    env = UserDayEnv(cluster_data)\n    model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, n_steps=2048, batch_size=64, n_epochs=10)\n    model.learn(total_timesteps=10000)\n    cluster_policies[cluster] = model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:17:15.503839Z","iopub.execute_input":"2025-05-06T19:17:15.504114Z","iopub.status.idle":"2025-05-06T19:31:18.522287Z","shell.execute_reply.started":"2025-05-06T19:17:15.504092Z","shell.execute_reply":"2025-05-06T19:31:18.521473Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 449  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 393          |\n|    iterations           | 2            |\n|    time_elapsed         | 10           |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0050237644 |\n|    clip_fraction        | 0.055        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.43        |\n|    explained_variance   | 0.000742     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 1.43e+03     |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.00932     |\n|    std                  | 1.02         |\n|    value_loss           | 800          |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 378         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.019858867 |\n|    clip_fraction        | 0.148       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.0451      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 79.7        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0262     |\n|    std                  | 0.942       |\n|    value_loss           | 170         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008767535 |\n|    clip_fraction        | 0.109       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 0.667       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 49.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0176     |\n|    std                  | 0.906       |\n|    value_loss           | 97          |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 366          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0051163165 |\n|    clip_fraction        | 0.0617       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.31        |\n|    explained_variance   | 0.473        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 58.6         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.00933     |\n|    std                  | 0.888        |\n|    value_loss           | 158          |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 443  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.012259239 |\n|    clip_fraction        | 0.149       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.00135     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.23e+03    |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.014      |\n|    std                  | 0.972       |\n|    value_loss           | 2.34e+03    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 377         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.016330753 |\n|    clip_fraction        | 0.148       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | 0.137       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 183         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0233     |\n|    std                  | 0.907       |\n|    value_loss           | 219         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012525291 |\n|    clip_fraction        | 0.114       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | -0.0423     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0187     |\n|    std                  | 0.847       |\n|    value_loss           | 80.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.6e+03     |\n|    ep_rew_mean          | -1.77e+03   |\n| time/                   |             |\n|    fps                  | 366         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.011229391 |\n|    clip_fraction        | 0.107       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.00343    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0179     |\n|    std                  | 0.818       |\n|    value_loss           | 142         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 446  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 388         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.011272127 |\n|    clip_fraction        | 0.1         |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.00136     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 4.31e+03    |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.00634    |\n|    std                  | 0.986       |\n|    value_loss           | 5.97e+03    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 375         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.017475039 |\n|    clip_fraction        | 0.151       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.37       |\n|    explained_variance   | 0.0972      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 53.1        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0246     |\n|    std                  | 0.924       |\n|    value_loss           | 133         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012716776 |\n|    clip_fraction        | 0.139       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | -0.0667     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.2        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0243     |\n|    std                  | 0.87        |\n|    value_loss           | 85.9        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 363         |\n|    iterations           | 5           |\n|    time_elapsed         | 28          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.011024705 |\n|    clip_fraction        | 0.099       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.0861     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 49.9        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0196     |\n|    std                  | 0.825       |\n|    value_loss           | 94.9        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.021081263 |\n|    clip_fraction        | 0.194       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00337    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 128         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0308     |\n|    std                  | 0.941       |\n|    value_loss           | 394         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 378         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.015539145 |\n|    clip_fraction        | 0.177       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.00029     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 80.8        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0253     |\n|    std                  | 0.879       |\n|    value_loss           | 269         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011631306 |\n|    clip_fraction        | 0.0917      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.00471    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 32          |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.021      |\n|    std                  | 0.813       |\n|    value_loss           | 94.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.02e+04    |\n|    ep_rew_mean          | -3.13e+03   |\n| time/                   |             |\n|    fps                  | 366         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.005844524 |\n|    clip_fraction        | 0.0565      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.19       |\n|    explained_variance   | 0.0362      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0156     |\n|    std                  | 0.774       |\n|    value_loss           | 79.7        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 449  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.016908826 |\n|    clip_fraction        | 0.16        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.00653     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 94.9        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0244     |\n|    std                  | 0.936       |\n|    value_loss           | 265         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 377         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.010938134 |\n|    clip_fraction        | 0.132       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.34       |\n|    explained_variance   | -0.000151   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 151         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0158     |\n|    std                  | 0.911       |\n|    value_loss           | 898         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 369         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.015686458 |\n|    clip_fraction        | 0.171       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.28       |\n|    explained_variance   | 0.0135      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41          |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0263     |\n|    std                  | 0.852       |\n|    value_loss           | 85.8        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.71e+03    |\n|    ep_rew_mean          | -1.35e+03   |\n| time/                   |             |\n|    fps                  | 365         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008623401 |\n|    clip_fraction        | 0.0876      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | -0.0498     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 35.8        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0152     |\n|    std                  | 0.811       |\n|    value_loss           | 56.9        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 452  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018518142 |\n|    clip_fraction        | 0.188       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00427    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 126         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0288     |\n|    std                  | 0.942       |\n|    value_loss           | 326         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 378         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.017808633 |\n|    clip_fraction        | 0.171       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | -0.000607   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 67.4        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0265     |\n|    std                  | 0.887       |\n|    value_loss           | 108         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 371         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009788456 |\n|    clip_fraction        | 0.0897      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | -0.00273    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 102         |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0137     |\n|    std                  | 0.846       |\n|    value_loss           | 167         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 1.02e+04     |\n|    ep_rew_mean          | -1.94e+03    |\n| time/                   |              |\n|    fps                  | 367          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0075064907 |\n|    clip_fraction        | 0.0678       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | -0.0181      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 54.8         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.015       |\n|    std                  | 0.815        |\n|    value_loss           | 71.1         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 452  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019919286 |\n|    clip_fraction        | 0.191       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.0136     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 67.4        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0318     |\n|    std                  | 0.941       |\n|    value_loss           | 274         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.010259481 |\n|    clip_fraction        | 0.113       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.34       |\n|    explained_variance   | -0.000152   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 601         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0117     |\n|    std                  | 0.911       |\n|    value_loss           | 1.11e+03    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 372         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.018538263 |\n|    clip_fraction        | 0.152       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | -0.172      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.4        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0246     |\n|    std                  | 0.839       |\n|    value_loss           | 90          |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 8.8e+03     |\n|    ep_rew_mean          | -2.41e+03   |\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.013721089 |\n|    clip_fraction        | 0.126       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.00964    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 38.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0223     |\n|    std                  | 0.79        |\n|    value_loss           | 81          |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 455  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 398         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019635143 |\n|    clip_fraction        | 0.199       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.00412     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 189         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0295     |\n|    std                  | 0.94        |\n|    value_loss           | 423         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 381        |\n|    iterations           | 3          |\n|    time_elapsed         | 16         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.02706004 |\n|    clip_fraction        | 0.173      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.31      |\n|    explained_variance   | 0.00165    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 45         |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0255    |\n|    std                  | 0.86       |\n|    value_loss           | 149        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 372         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.013598953 |\n|    clip_fraction        | 0.106       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | -0.00111    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0202     |\n|    std                  | 0.806       |\n|    value_loss           | 71.6        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.99e+03    |\n|    ep_rew_mean          | -2.89e+03   |\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010786943 |\n|    clip_fraction        | 0.101       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.18       |\n|    explained_variance   | -0.00591    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 47.9        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0215     |\n|    std                  | 0.772       |\n|    value_loss           | 85          |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 453  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 396        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01712306 |\n|    clip_fraction        | 0.154      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.39      |\n|    explained_variance   | -0.00157   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 125        |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0261    |\n|    std                  | 0.939      |\n|    value_loss           | 411        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 378         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.008937565 |\n|    clip_fraction        | 0.0801      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | 0.0657      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 72.6        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0108     |\n|    std                  | 0.954       |\n|    value_loss           | 167         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 371         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.016445395 |\n|    clip_fraction        | 0.178       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | -0.000511   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 53.7        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0285     |\n|    std                  | 0.886       |\n|    value_loss           | 107         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009005206 |\n|    clip_fraction        | 0.0906      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | 0.0467      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 481         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.00787    |\n|    std                  | 0.864       |\n|    value_loss           | 1.16e+03    |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 395        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01057339 |\n|    clip_fraction        | 0.123      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.42      |\n|    explained_variance   | 0.00156    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 3.85e+03   |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.00832   |\n|    std                  | 0.997      |\n|    value_loss           | 7.51e+03   |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 378         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.014158443 |\n|    clip_fraction        | 0.135       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.12       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 64.7        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0199     |\n|    std                  | 0.937       |\n|    value_loss           | 177         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012466345 |\n|    clip_fraction        | 0.129       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | -0.0986     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 46.2        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0158     |\n|    std                  | 0.897       |\n|    value_loss           | 321         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 369          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0132463835 |\n|    clip_fraction        | 0.153        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.27        |\n|    explained_variance   | 0.0966       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 32.9         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.024       |\n|    std                  | 0.848        |\n|    value_loss           | 67.8         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.009033959 |\n|    clip_fraction        | 0.137       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | 0.00262     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 997         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.00882    |\n|    std                  | 0.988       |\n|    value_loss           | 3.41e+03    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 378         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018222129 |\n|    clip_fraction        | 0.153       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | 0.259       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 53.4        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.026      |\n|    std                  | 0.918       |\n|    value_loss           | 141         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 7.68e+03     |\n|    ep_rew_mean          | -3.13e+03    |\n| time/                   |              |\n|    fps                  | 372          |\n|    iterations           | 4            |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0138331335 |\n|    clip_fraction        | 0.108        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | 0.185        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 47           |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0214      |\n|    std                  | 0.841        |\n|    value_loss           | 120          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.68e+03    |\n|    ep_rew_mean          | -3.13e+03   |\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009290494 |\n|    clip_fraction        | 0.121       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | -0.000659   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.7        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0181     |\n|    std                  | 0.8         |\n|    value_loss           | 87.4        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.016122572 |\n|    clip_fraction        | 0.176       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.0104     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 158         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0276     |\n|    std                  | 0.949       |\n|    value_loss           | 366         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.008828929 |\n|    clip_fraction        | 0.11        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | -0.119      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 61.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0151     |\n|    std                  | 0.918       |\n|    value_loss           | 114         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 374         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011957049 |\n|    clip_fraction        | 0.121       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | 0.0155      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 224         |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0177     |\n|    std                  | 0.881       |\n|    value_loss           | 253         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 370          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0074100955 |\n|    clip_fraction        | 0.0835       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | 0.117        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 179          |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.00991     |\n|    std                  | 0.868        |\n|    value_loss           | 728          |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 455  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 397          |\n|    iterations           | 2            |\n|    time_elapsed         | 10           |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0072382074 |\n|    clip_fraction        | 0.0862       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.4         |\n|    explained_variance   | 0.04         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 75.4         |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.0107      |\n|    std                  | 0.969        |\n|    value_loss           | 379          |\n------------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 382         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.008496435 |\n|    clip_fraction        | 0.0862      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.428       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 91.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0108     |\n|    std                  | 0.956       |\n|    value_loss           | 270         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.49e+03    |\n|    ep_rew_mean          | -1.7e+03    |\n| time/                   |             |\n|    fps                  | 375         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010107113 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | 0.0476      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 161         |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00914    |\n|    std                  | 0.938       |\n|    value_loss           | 1.71e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.49e+03    |\n|    ep_rew_mean          | -1.7e+03    |\n| time/                   |             |\n|    fps                  | 369         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010374877 |\n|    clip_fraction        | 0.0947      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.685       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 56.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0157     |\n|    std                  | 0.888       |\n|    value_loss           | 122         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 455  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 397         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.012208838 |\n|    clip_fraction        | 0.143       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.4        |\n|    explained_variance   | 0.00267     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 319         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0148     |\n|    std                  | 0.967       |\n|    value_loss           | 1.39e+03    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.017914731 |\n|    clip_fraction        | 0.176       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | -0.0176     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 82.9        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0285     |\n|    std                  | 0.901       |\n|    value_loss           | 199         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.5e+03     |\n|    ep_rew_mean          | -3.38e+03   |\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010329161 |\n|    clip_fraction        | 0.155       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | -0.00362    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 63          |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0124     |\n|    std                  | 0.87        |\n|    value_loss           | 1.02e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 7.5e+03     |\n|    ep_rew_mean          | -3.38e+03   |\n| time/                   |             |\n|    fps                  | 369         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.007960148 |\n|    clip_fraction        | 0.11        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | 0.0158      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 34.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.019      |\n|    std                  | 0.847       |\n|    value_loss           | 128         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 454  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n---------------------------------------\n| time/                   |           |\n|    fps                  | 396       |\n|    iterations           | 2         |\n|    time_elapsed         | 10        |\n|    total_timesteps      | 4096      |\n| train/                  |           |\n|    approx_kl            | 0.0169336 |\n|    clip_fraction        | 0.146     |\n|    clip_range           | 0.2       |\n|    entropy_loss         | -1.38     |\n|    explained_variance   | -0.000819 |\n|    learning_rate        | 0.0003    |\n|    loss                 | 105       |\n|    n_updates            | 10        |\n|    policy_gradient_loss | -0.0264   |\n|    std                  | 0.933     |\n|    value_loss           | 256       |\n---------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.019409113 |\n|    clip_fraction        | 0.185       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.0228     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 58.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0262     |\n|    std                  | 0.874       |\n|    value_loss           | 115         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009106614 |\n|    clip_fraction        | 0.0932      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -0.00376    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.4        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0201     |\n|    std                  | 0.838       |\n|    value_loss           | 103         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1.01e+04    |\n|    ep_rew_mean          | -1.97e+03   |\n| time/                   |             |\n|    fps                  | 369         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008641994 |\n|    clip_fraction        | 0.0737      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.0108      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27.4        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.016      |\n|    std                  | 0.815       |\n|    value_loss           | 57.2        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 452  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 395        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01696785 |\n|    clip_fraction        | 0.152      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.39      |\n|    explained_variance   | 0.000164   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 189        |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0254    |\n|    std                  | 0.946      |\n|    value_loss           | 523        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 379         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.012258194 |\n|    clip_fraction        | 0.135       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.34       |\n|    explained_variance   | -0.00642    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 250         |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0152     |\n|    std                  | 0.902       |\n|    value_loss           | 589         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 372         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.013306203 |\n|    clip_fraction        | 0.115       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | 0.053       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 53.4        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0189     |\n|    std                  | 0.861       |\n|    value_loss           | 135         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008905754 |\n|    clip_fraction        | 0.0943      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.00669    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 297         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0119     |\n|    std                  | 0.839       |\n|    value_loss           | 368         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 452  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 393         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019932065 |\n|    clip_fraction        | 0.212       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.00192     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 102         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0331     |\n|    std                  | 0.939       |\n|    value_loss           | 308         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 379         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.016826596 |\n|    clip_fraction        | 0.169       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.00125     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 78          |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0287     |\n|    std                  | 0.868       |\n|    value_loss           | 182         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 371         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.012579487 |\n|    clip_fraction        | 0.141       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -7.62e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 76.3        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0225     |\n|    std                  | 0.82        |\n|    value_loss           | 132         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 368          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0074774255 |\n|    clip_fraction        | 0.0831       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.21        |\n|    explained_variance   | 0.00573      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 269          |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0114      |\n|    std                  | 0.802        |\n|    value_loss           | 312          |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 450  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 393        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01824513 |\n|    clip_fraction        | 0.169      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | -0.00512   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 134        |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0277    |\n|    std                  | 0.939      |\n|    value_loss           | 326        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 376         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.013628116 |\n|    clip_fraction        | 0.123       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.00035    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 84.2        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0235     |\n|    std                  | 0.868       |\n|    value_loss           | 182         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.008393918 |\n|    clip_fraction        | 0.139       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.00012     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.25e+03    |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0117     |\n|    std                  | 0.85        |\n|    value_loss           | 978         |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 9.63e+03   |\n|    ep_rew_mean          | -3.2e+03   |\n| time/                   |            |\n|    fps                  | 367        |\n|    iterations           | 5          |\n|    time_elapsed         | 27         |\n|    total_timesteps      | 10240      |\n| train/                  |            |\n|    approx_kl            | 0.01275764 |\n|    clip_fraction        | 0.114      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.23      |\n|    explained_variance   | -0.225     |\n|    learning_rate        | 0.0003     |\n|    loss                 | 46.6       |\n|    n_updates            | 40         |\n|    policy_gradient_loss | -0.0188    |\n|    std                  | 0.814      |\n|    value_loss           | 95         |\n----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 447  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019158829 |\n|    clip_fraction        | 0.174       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.00791     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 92          |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0296     |\n|    std                  | 0.936       |\n|    value_loss           | 211         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 379         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.018270425 |\n|    clip_fraction        | 0.156       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.059      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51          |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0281     |\n|    std                  | 0.868       |\n|    value_loss           | 112         |\n-----------------------------------------\n------------------------------------------\n| time/                   |              |\n|    fps                  | 372          |\n|    iterations           | 4            |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0064746146 |\n|    clip_fraction        | 0.0887       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | -0.0254      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 30.7         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0159      |\n|    std                  | 0.844        |\n|    value_loss           | 103          |\n------------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 368        |\n|    iterations           | 5          |\n|    time_elapsed         | 27         |\n|    total_timesteps      | 10240      |\n| train/                  |            |\n|    approx_kl            | 0.00894547 |\n|    clip_fraction        | 0.0939     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.23      |\n|    explained_variance   | 0.134      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 19.8       |\n|    n_updates            | 40         |\n|    policy_gradient_loss | -0.0175    |\n|    std                  | 0.812      |\n|    value_loss           | 71.7       |\n----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 448  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 392         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.015250081 |\n|    clip_fraction        | 0.162       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.0102     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 143         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0201     |\n|    std                  | 0.953       |\n|    value_loss           | 374         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 376         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.022452563 |\n|    clip_fraction        | 0.181       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 0.000267    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 71.6        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0291     |\n|    std                  | 0.892       |\n|    value_loss           | 151         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.36e+03    |\n|    ep_rew_mean          | -3.68e+03   |\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 4           |\n|    time_elapsed         | 22          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011917666 |\n|    clip_fraction        | 0.123       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -0.00243    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 78.3        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0218     |\n|    std                  | 0.832       |\n|    value_loss           | 120         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 6.36e+03     |\n|    ep_rew_mean          | -3.68e+03    |\n| time/                   |              |\n|    fps                  | 366          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0068189846 |\n|    clip_fraction        | 0.0907       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.22        |\n|    explained_variance   | 0.0403       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 32.5         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0186      |\n|    std                  | 0.81         |\n|    value_loss           | 74.1         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.016437044 |\n|    clip_fraction        | 0.153       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.00234     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 80.5        |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0257     |\n|    std                  | 0.94        |\n|    value_loss           | 253         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.007575943 |\n|    clip_fraction        | 0.0773      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.35       |\n|    explained_variance   | -0.000108   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.83e+03    |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0076     |\n|    std                  | 0.929       |\n|    value_loss           | 6.24e+03    |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.019327078 |\n|    clip_fraction        | 0.158       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | -0.185      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44          |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0228     |\n|    std                  | 0.87        |\n|    value_loss           | 96.4        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010075312 |\n|    clip_fraction        | 0.0958      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.0375      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 48.3        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0187     |\n|    std                  | 0.839       |\n|    value_loss           | 86.8        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 454  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 398        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01987362 |\n|    clip_fraction        | 0.182      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.00387    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 139        |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0284    |\n|    std                  | 0.937      |\n|    value_loss           | 319        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.022803914 |\n|    clip_fraction        | 0.147       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | -0.00253    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 52.9        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0271     |\n|    std                  | 0.844       |\n|    value_loss           | 115         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010898367 |\n|    clip_fraction        | 0.101       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.000226    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.2        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0182     |\n|    std                  | 0.819       |\n|    value_loss           | 76.7        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 9e+03        |\n|    ep_rew_mean          | -2.36e+03    |\n| time/                   |              |\n|    fps                  | 368          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0070677074 |\n|    clip_fraction        | 0.0763       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | -0.00399     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 29.3         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0158      |\n|    std                  | 0.792        |\n|    value_loss           | 63.7         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.016528921 |\n|    clip_fraction        | 0.147       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.00129    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 145         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0227     |\n|    std                  | 0.946       |\n|    value_loss           | 519         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 380         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.016660653 |\n|    clip_fraction        | 0.141       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.00186     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 69.6        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0237     |\n|    std                  | 0.876       |\n|    value_loss           | 148         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 374         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.011288462 |\n|    clip_fraction        | 0.0981      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -0.00406    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41.2        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0188     |\n|    std                  | 0.834       |\n|    value_loss           | 94          |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.008642231 |\n|    clip_fraction        | 0.0854      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.22       |\n|    explained_variance   | -0.0241     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.1        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0165     |\n|    std                  | 0.798       |\n|    value_loss           | 72.8        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 454  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 398         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019910492 |\n|    clip_fraction        | 0.192       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.00431    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 121         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0315     |\n|    std                  | 0.938       |\n|    value_loss           | 350         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 381        |\n|    iterations           | 3          |\n|    time_elapsed         | 16         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.01527712 |\n|    clip_fraction        | 0.154      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.33      |\n|    explained_variance   | 0.000709   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 960        |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.0153    |\n|    std                  | 0.89       |\n|    value_loss           | 883        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.010509955 |\n|    clip_fraction        | 0.15        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | -0.0382     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 27          |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0229     |\n|    std                  | 0.846       |\n|    value_loss           | 78.3        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 1e+04       |\n|    ep_rew_mean          | -2.43e+03   |\n| time/                   |             |\n|    fps                  | 368         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010423822 |\n|    clip_fraction        | 0.114       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | -0.00362    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 141         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0118     |\n|    std                  | 0.82        |\n|    value_loss           | 566         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 453  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.017608777 |\n|    clip_fraction        | 0.169       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -2.43e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 102         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0283     |\n|    std                  | 0.94        |\n|    value_loss           | 238         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.021659844 |\n|    clip_fraction        | 0.188       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.000127    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 49.3        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0289     |\n|    std                  | 0.875       |\n|    value_loss           | 133         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 7.34e+03     |\n|    ep_rew_mean          | -3.03e+03    |\n| time/                   |              |\n|    fps                  | 374          |\n|    iterations           | 4            |\n|    time_elapsed         | 21           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0127436435 |\n|    clip_fraction        | 0.125        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.000921     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 39.6         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0226      |\n|    std                  | 0.829        |\n|    value_loss           | 97.7         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 7.34e+03     |\n|    ep_rew_mean          | -3.03e+03    |\n| time/                   |              |\n|    fps                  | 369          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0071186055 |\n|    clip_fraction        | 0.074        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.21        |\n|    explained_variance   | 0.00186      |\n|    learning_rate        | 0.0003       |\n|    loss                 | 19.1         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0161      |\n|    std                  | 0.802        |\n|    value_loss           | 63.5         |\n------------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 446  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 395         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.019224614 |\n|    clip_fraction        | 0.198       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | -0.000541   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 191         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0295     |\n|    std                  | 0.943       |\n|    value_loss           | 394         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.022774257 |\n|    clip_fraction        | 0.138       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.00484    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 42.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0241     |\n|    std                  | 0.858       |\n|    value_loss           | 120         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.007040357 |\n|    clip_fraction        | 0.0954      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -3.15e-05   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 650         |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00388    |\n|    std                  | 0.844       |\n|    value_loss           | 891         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 9.68e+03    |\n|    ep_rew_mean          | -3.52e+03   |\n| time/                   |             |\n|    fps                  | 369         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009925613 |\n|    clip_fraction        | 0.0924      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | -0.0117     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.2        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0168     |\n|    std                  | 0.815       |\n|    value_loss           | 134         |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 449  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 396         |\n|    iterations           | 2           |\n|    time_elapsed         | 10          |\n|    total_timesteps      | 4096        |\n| train/                  |             |\n|    approx_kl            | 0.018718958 |\n|    clip_fraction        | 0.147       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | -0.00239    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 101         |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0255     |\n|    std                  | 0.931       |\n|    value_loss           | 230         |\n-----------------------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 382        |\n|    iterations           | 3          |\n|    time_elapsed         | 16         |\n|    total_timesteps      | 6144       |\n| train/                  |            |\n|    approx_kl            | 0.01409086 |\n|    clip_fraction        | 0.127      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.31      |\n|    explained_variance   | 0.000985   |\n|    learning_rate        | 0.0003     |\n|    loss                 | 42.7       |\n|    n_updates            | 20         |\n|    policy_gradient_loss | -0.022     |\n|    std                  | 0.874      |\n|    value_loss           | 118        |\n----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 6.41e+03   |\n|    ep_rew_mean          | -2.84e+03  |\n| time/                   |            |\n|    fps                  | 376        |\n|    iterations           | 4          |\n|    time_elapsed         | 21         |\n|    total_timesteps      | 8192       |\n| train/                  |            |\n|    approx_kl            | 0.00782713 |\n|    clip_fraction        | 0.0989     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.27      |\n|    explained_variance   | 0.0551     |\n|    learning_rate        | 0.0003     |\n|    loss                 | 39         |\n|    n_updates            | 30         |\n|    policy_gradient_loss | -0.0187    |\n|    std                  | 0.849      |\n|    value_loss           | 111        |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 6.41e+03    |\n|    ep_rew_mean          | -2.84e+03   |\n| time/                   |             |\n|    fps                  | 371         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010444827 |\n|    clip_fraction        | 0.0771      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.0517      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 21          |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0171     |\n|    std                  | 0.807       |\n|    value_loss           | 53.9        |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 448  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 394        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01785793 |\n|    clip_fraction        | 0.172      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | 0.00367    |\n|    learning_rate        | 0.0003     |\n|    loss                 | 122        |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0278    |\n|    std                  | 0.941      |\n|    value_loss           | 285        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 381         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.015570263 |\n|    clip_fraction        | 0.165       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.33       |\n|    explained_variance   | 0.000493    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 61.7        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0258     |\n|    std                  | 0.898       |\n|    value_loss           | 136         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.009583206 |\n|    clip_fraction        | 0.113       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.198       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 44.5        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0171     |\n|    std                  | 0.876       |\n|    value_loss           | 99.1        |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 370         |\n|    iterations           | 5           |\n|    time_elapsed         | 27          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.010797134 |\n|    clip_fraction        | 0.111       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | -0.021      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 54.4        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0204     |\n|    std                  | 0.85        |\n|    value_loss           | 97          |\n-----------------------------------------\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"-----------------------------\n| time/              |      |\n|    fps             | 451  |\n|    iterations      | 1    |\n|    time_elapsed    | 4    |\n|    total_timesteps | 2048 |\n-----------------------------\n----------------------------------------\n| time/                   |            |\n|    fps                  | 395        |\n|    iterations           | 2          |\n|    time_elapsed         | 10         |\n|    total_timesteps      | 4096       |\n| train/                  |            |\n|    approx_kl            | 0.01769663 |\n|    clip_fraction        | 0.187      |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.38      |\n|    explained_variance   | -0.000644  |\n|    learning_rate        | 0.0003     |\n|    loss                 | 79.5       |\n|    n_updates            | 10         |\n|    policy_gradient_loss | -0.0283    |\n|    std                  | 0.936      |\n|    value_loss           | 273        |\n----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 379         |\n|    iterations           | 3           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.019607484 |\n|    clip_fraction        | 0.152       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.31       |\n|    explained_variance   | -0.000631   |\n|    learning_rate        | 0.0003      |\n|    loss                 | 40.4        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0245     |\n|    std                  | 0.863       |\n|    value_loss           | 113         |\n-----------------------------------------\n-----------------------------------------\n| time/                   |             |\n|    fps                  | 373         |\n|    iterations           | 4           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.007781824 |\n|    clip_fraction        | 0.0842      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.000487    |\n|    learning_rate        | 0.0003      |\n|    loss                 | 384         |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.00993    |\n|    std                  | 0.849       |\n|    value_loss           | 534         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 9.86e+03     |\n|    ep_rew_mean          | -3.11e+03    |\n| time/                   |              |\n|    fps                  | 369          |\n|    iterations           | 5            |\n|    time_elapsed         | 27           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0077540604 |\n|    clip_fraction        | 0.0903       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | -0.122       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 71.2         |\n|    n_updates            | 40           |\n|    policy_gradient_loss | -0.0138      |\n|    std                  | 0.826        |\n|    value_loss           | 177          |\n------------------------------------------\n","output_type":"stream"}],"execution_count":273},{"cell_type":"code","source":"class MetaControllerEnv(gym.Env):\n    def __init__(self, df, cluster_policies):\n        super().__init__()\n        \n        self.df = df[\n            ['user', 'cluster'] + \n            behavioral_features + latent_features + role_features + \n            ['logon_trend', 'logon_volatility', 'is_anomaly', 'adaptive_threshold']\n        ]\n        \n        self.action_space = spaces.Discrete(len(cluster_policies))\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(role_features),),\n            dtype=np.float32\n        )\n        \n        self.cluster_policies = cluster_policies\n        self.current_user = None\n        self.user_data = None\n        self.current_step = 0\n        # For tracking selection accuracy\n        self.correct_selections = 0\n        self.total_selections = 0\n\n    def reset(self, seed=None, options=None):\n        while True:  # Ensure user_data is not empty\n            self.current_user = np.random.choice(self.df['user'].unique())\n            self.user_data = self.df[self.df['user'] == self.current_user]\n            if len(self.user_data) > 0:\n                break\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        obs = self.user_data.iloc[self.current_step][role_features].to_numpy(dtype=np.float32)\n        return obs\n\n    def step(self, action):\n        chosen_cluster = list(self.cluster_policies.keys())[action]\n        policy = self.cluster_policies[chosen_cluster]\n        \n        # Construct the full observation for the cluster policy (72 features)\n        row = self.user_data.iloc[self.current_step]\n        cluster_obs = np.concatenate([\n            row[behavioral_features].to_numpy(dtype=np.float32),\n            row[latent_features].to_numpy(dtype=np.float32),\n            row[role_features].to_numpy(dtype=np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        \n        anomaly_score, _ = policy.predict(cluster_obs, deterministic=True)\n        \n        # Compute reward based on anomaly detection performance\n        true_label = row['is_anomaly']\n        threshold = row['adaptive_threshold']\n        final_action = 1 if anomaly_score >= threshold else 0\n        \n        if final_action == true_label:\n            reward = 200 if true_label == 1 else 1  # High reward for detecting anomalies\n        else:\n            reward = -10 if final_action == 1 else -15\n        \n        # Track cluster selection accuracy for debugging\n        true_cluster = self.user_data.iloc[self.current_step]['cluster']\n        if chosen_cluster == true_cluster:\n            self.correct_selections += 1\n        self.total_selections += 1\n        if self.total_selections % 100 == 0:  # Print every 100 steps\n            print(f\"Meta-Controller Selection Accuracy: {self.correct_selections / self.total_selections:.4f}\")\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n\n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n        return obs, reward, done, False, {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:32:41.449655Z","iopub.execute_input":"2025-05-06T19:32:41.45037Z","iopub.status.idle":"2025-05-06T19:32:41.460803Z","shell.execute_reply.started":"2025-05-06T19:32:41.450349Z","shell.execute_reply":"2025-05-06T19:32:41.460061Z"}},"outputs":[],"execution_count":274},{"cell_type":"code","source":"meta_env = MetaControllerEnv(\n    df_features[df_features['cluster'].isin(cluster_policies.keys())],\n    cluster_policies\n)\n\nmeta_policy = PPO(\n    \"MlpPolicy\",\n    meta_env,\n    verbose=1,\n    learning_rate=1e-4,\n    n_steps=512,\n    batch_size=32\n)\n\nmeta_policy.learn(total_timesteps=20000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:32:47.389323Z","iopub.execute_input":"2025-05-06T19:32:47.389583Z","iopub.status.idle":"2025-05-06T19:34:24.855799Z","shell.execute_reply.started":"2025-05-06T19:32:47.389564Z","shell.execute_reply":"2025-05-06T19:34:24.854934Z"}},"outputs":[{"name":"stdout","text":"Using cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Meta-Controller Selection Accuracy: 0.0300\nMeta-Controller Selection Accuracy: 0.0350\nMeta-Controller Selection Accuracy: 0.0333\nMeta-Controller Selection Accuracy: 0.0325\nMeta-Controller Selection Accuracy: 0.0380\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 346      |\n|    ep_rew_mean     | 346      |\n| time/              |          |\n|    fps             | 284      |\n|    iterations      | 1        |\n|    time_elapsed    | 1        |\n|    total_timesteps | 512      |\n---------------------------------\nMeta-Controller Selection Accuracy: 0.0333\nMeta-Controller Selection Accuracy: 0.0300\nMeta-Controller Selection Accuracy: 0.0288\nMeta-Controller Selection Accuracy: 0.0289\nMeta-Controller Selection Accuracy: 0.0300\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 346          |\n|    ep_rew_mean          | 346          |\n| time/                   |              |\n|    fps                  | 243          |\n|    iterations           | 2            |\n|    time_elapsed         | 4            |\n|    total_timesteps      | 1024         |\n| train/                  |              |\n|    approx_kl            | 0.0038076886 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.37        |\n|    explained_variance   | 0.116        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 75.9         |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.0113      |\n|    value_loss           | 193          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0282\nMeta-Controller Selection Accuracy: 0.0283\nMeta-Controller Selection Accuracy: 0.0292\nMeta-Controller Selection Accuracy: 0.0300\nMeta-Controller Selection Accuracy: 0.0300\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 346         |\n|    ep_rew_mean          | 346         |\n| time/                   |             |\n|    fps                  | 231         |\n|    iterations           | 3           |\n|    time_elapsed         | 6           |\n|    total_timesteps      | 1536        |\n| train/                  |             |\n|    approx_kl            | 0.006680779 |\n|    clip_fraction        | 0.0184      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.0412      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 60.5        |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.0195     |\n|    value_loss           | 177         |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0294\nMeta-Controller Selection Accuracy: 0.0294\nMeta-Controller Selection Accuracy: 0.0322\nMeta-Controller Selection Accuracy: 0.0332\nMeta-Controller Selection Accuracy: 0.0325\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 346          |\n|    ep_rew_mean          | 346          |\n| time/                   |              |\n|    fps                  | 226          |\n|    iterations           | 4            |\n|    time_elapsed         | 9            |\n|    total_timesteps      | 2048         |\n| train/                  |              |\n|    approx_kl            | 0.0020785362 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.37        |\n|    explained_variance   | -0.275       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 52.6         |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.0109      |\n|    value_loss           | 158          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0329\nMeta-Controller Selection Accuracy: 0.0323\nMeta-Controller Selection Accuracy: 0.0322\nMeta-Controller Selection Accuracy: 0.0325\nMeta-Controller Selection Accuracy: 0.0336\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 361         |\n|    ep_rew_mean          | 361         |\n| time/                   |             |\n|    fps                  | 223         |\n|    iterations           | 5           |\n|    time_elapsed         | 11          |\n|    total_timesteps      | 2560        |\n| train/                  |             |\n|    approx_kl            | 0.003401378 |\n|    clip_fraction        | 0.00293     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.191       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 43.9        |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0106     |\n|    value_loss           | 148         |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0342\nMeta-Controller Selection Accuracy: 0.0352\nMeta-Controller Selection Accuracy: 0.0354\nMeta-Controller Selection Accuracy: 0.0348\nMeta-Controller Selection Accuracy: 0.0357\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 359          |\n|    ep_rew_mean          | 359          |\n| time/                   |              |\n|    fps                  | 221          |\n|    iterations           | 6            |\n|    time_elapsed         | 13           |\n|    total_timesteps      | 3072         |\n| train/                  |              |\n|    approx_kl            | 0.0028372617 |\n|    clip_fraction        | 0.000781     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.37        |\n|    explained_variance   | -0.317       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 34.1         |\n|    n_updates            | 50           |\n|    policy_gradient_loss | -0.0116      |\n|    value_loss           | 124          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0365\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0373\nMeta-Controller Selection Accuracy: 0.0376\nMeta-Controller Selection Accuracy: 0.0377\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 340         |\n|    ep_rew_mean          | 340         |\n| time/                   |             |\n|    fps                  | 219         |\n|    iterations           | 7           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 3584        |\n| train/                  |             |\n|    approx_kl            | 0.003310062 |\n|    clip_fraction        | 0.000391    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | -0.0171     |\n|    learning_rate        | 0.0001      |\n|    loss                 | 34.5        |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.0117     |\n|    value_loss           | 129         |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0381\nMeta-Controller Selection Accuracy: 0.0381\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0385\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | 329          |\n| time/                   |              |\n|    fps                  | 217          |\n|    iterations           | 8            |\n|    time_elapsed         | 18           |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0018231132 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.37        |\n|    explained_variance   | -0.0169      |\n|    learning_rate        | 0.0001       |\n|    loss                 | 44.4         |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00759     |\n|    value_loss           | 352          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0395\nMeta-Controller Selection Accuracy: 0.0395\nMeta-Controller Selection Accuracy: 0.0393\nMeta-Controller Selection Accuracy: 0.0391\nMeta-Controller Selection Accuracy: 0.0389\nMeta-Controller Selection Accuracy: 0.0387\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 341         |\n|    ep_rew_mean          | 330         |\n| time/                   |             |\n|    fps                  | 216         |\n|    iterations           | 9           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 4608        |\n| train/                  |             |\n|    approx_kl            | 0.003706506 |\n|    clip_fraction        | 0.000977    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.37       |\n|    explained_variance   | -0.269      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.47        |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.00933    |\n|    value_loss           | 92.9        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0381\nMeta-Controller Selection Accuracy: 0.0380\nMeta-Controller Selection Accuracy: 0.0378\nMeta-Controller Selection Accuracy: 0.0380\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 339          |\n|    ep_rew_mean          | 329          |\n| time/                   |              |\n|    fps                  | 215          |\n|    iterations           | 10           |\n|    time_elapsed         | 23           |\n|    total_timesteps      | 5120         |\n| train/                  |              |\n|    approx_kl            | 0.0040794313 |\n|    clip_fraction        | 0.00586      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.572        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 36.9         |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.0093      |\n|    value_loss           | 120          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0389\nMeta-Controller Selection Accuracy: 0.0389\nMeta-Controller Selection Accuracy: 0.0389\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 339         |\n|    ep_rew_mean          | 330         |\n| time/                   |             |\n|    fps                  | 215         |\n|    iterations           | 11          |\n|    time_elapsed         | 26          |\n|    total_timesteps      | 5632        |\n| train/                  |             |\n|    approx_kl            | 0.003267861 |\n|    clip_fraction        | 0.000391    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.537       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 25.3        |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.0108     |\n|    value_loss           | 104         |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0395\nMeta-Controller Selection Accuracy: 0.0391\nMeta-Controller Selection Accuracy: 0.0388\nMeta-Controller Selection Accuracy: 0.0393\nMeta-Controller Selection Accuracy: 0.0390\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 340         |\n|    ep_rew_mean          | 332         |\n| time/                   |             |\n|    fps                  | 215         |\n|    iterations           | 12          |\n|    time_elapsed         | 28          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.004081449 |\n|    clip_fraction        | 0.00332     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.743       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 44.3        |\n|    n_updates            | 110         |\n|    policy_gradient_loss | -0.0133     |\n|    value_loss           | 134         |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0384\nMeta-Controller Selection Accuracy: 0.0387\nMeta-Controller Selection Accuracy: 0.0391\nMeta-Controller Selection Accuracy: 0.0392\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | 333          |\n| time/                   |              |\n|    fps                  | 215          |\n|    iterations           | 13           |\n|    time_elapsed         | 30           |\n|    total_timesteps      | 6656         |\n| train/                  |              |\n|    approx_kl            | 0.0036363145 |\n|    clip_fraction        | 0.00332      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.318        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 23.5         |\n|    n_updates            | 120          |\n|    policy_gradient_loss | -0.0119      |\n|    value_loss           | 92           |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0390\nMeta-Controller Selection Accuracy: 0.0390\nMeta-Controller Selection Accuracy: 0.0390\nMeta-Controller Selection Accuracy: 0.0391\nMeta-Controller Selection Accuracy: 0.0386\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 341         |\n|    ep_rew_mean          | 334         |\n| time/                   |             |\n|    fps                  | 214         |\n|    iterations           | 14          |\n|    time_elapsed         | 33          |\n|    total_timesteps      | 7168        |\n| train/                  |             |\n|    approx_kl            | 0.005019883 |\n|    clip_fraction        | 0.00234     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.425       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 57          |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.0128     |\n|    value_loss           | 137         |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0383\nMeta-Controller Selection Accuracy: 0.0386\nMeta-Controller Selection Accuracy: 0.0388\nMeta-Controller Selection Accuracy: 0.0389\nMeta-Controller Selection Accuracy: 0.0386\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 341         |\n|    ep_rew_mean          | 335         |\n| time/                   |             |\n|    fps                  | 214         |\n|    iterations           | 15          |\n|    time_elapsed         | 35          |\n|    total_timesteps      | 7680        |\n| train/                  |             |\n|    approx_kl            | 0.010339346 |\n|    clip_fraction        | 0.0236      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.676       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 24.5        |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.016      |\n|    value_loss           | 76.9        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0383\nMeta-Controller Selection Accuracy: 0.0386\nMeta-Controller Selection Accuracy: 0.0382\nMeta-Controller Selection Accuracy: 0.0380\nMeta-Controller Selection Accuracy: 0.0377\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 337          |\n|    ep_rew_mean          | 331          |\n| time/                   |              |\n|    fps                  | 214          |\n|    iterations           | 16           |\n|    time_elapsed         | 38           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0077745034 |\n|    clip_fraction        | 0.0252       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.793        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 17.9         |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.0124      |\n|    value_loss           | 67.2         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0377\nMeta-Controller Selection Accuracy: 0.0373\nMeta-Controller Selection Accuracy: 0.0375\nMeta-Controller Selection Accuracy: 0.0380\nMeta-Controller Selection Accuracy: 0.0383\nMeta-Controller Selection Accuracy: 0.0384\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 334          |\n|    ep_rew_mean          | 327          |\n| time/                   |              |\n|    fps                  | 213          |\n|    iterations           | 17           |\n|    time_elapsed         | 40           |\n|    total_timesteps      | 8704         |\n| train/                  |              |\n|    approx_kl            | 0.0013893096 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.625        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 26.1         |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.00787     |\n|    value_loss           | 82.3         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0385\nMeta-Controller Selection Accuracy: 0.0382\nMeta-Controller Selection Accuracy: 0.0381\nMeta-Controller Selection Accuracy: 0.0380\nMeta-Controller Selection Accuracy: 0.0382\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 334         |\n|    ep_rew_mean          | 328         |\n| time/                   |             |\n|    fps                  | 213         |\n|    iterations           | 18          |\n|    time_elapsed         | 43          |\n|    total_timesteps      | 9216        |\n| train/                  |             |\n|    approx_kl            | 0.005417511 |\n|    clip_fraction        | 0.0107      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.408       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 9.73        |\n|    n_updates            | 170         |\n|    policy_gradient_loss | -0.0145     |\n|    value_loss           | 65.5        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0380\nMeta-Controller Selection Accuracy: 0.0379\nMeta-Controller Selection Accuracy: 0.0383\nMeta-Controller Selection Accuracy: 0.0384\nMeta-Controller Selection Accuracy: 0.0381\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 335          |\n|    ep_rew_mean          | 329          |\n| time/                   |              |\n|    fps                  | 213          |\n|    iterations           | 19           |\n|    time_elapsed         | 45           |\n|    total_timesteps      | 9728         |\n| train/                  |              |\n|    approx_kl            | 0.0015851132 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.488        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 60.7         |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00643     |\n|    value_loss           | 128          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0379\nMeta-Controller Selection Accuracy: 0.0377\nMeta-Controller Selection Accuracy: 0.0373\nMeta-Controller Selection Accuracy: 0.0371\nMeta-Controller Selection Accuracy: 0.0372\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 335          |\n|    ep_rew_mean          | 330          |\n| time/                   |              |\n|    fps                  | 213          |\n|    iterations           | 20           |\n|    time_elapsed         | 47           |\n|    total_timesteps      | 10240        |\n| train/                  |              |\n|    approx_kl            | 0.0054662223 |\n|    clip_fraction        | 0.00645      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.789        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 24.9         |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.0121      |\n|    value_loss           | 84.3         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0372\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0370\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 336          |\n|    ep_rew_mean          | 330          |\n| time/                   |              |\n|    fps                  | 213          |\n|    iterations           | 21           |\n|    time_elapsed         | 50           |\n|    total_timesteps      | 10752        |\n| train/                  |              |\n|    approx_kl            | 0.0020495844 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.622        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 33.7         |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00639     |\n|    value_loss           | 98.5         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0365\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 336         |\n|    ep_rew_mean          | 331         |\n| time/                   |             |\n|    fps                  | 213         |\n|    iterations           | 22          |\n|    time_elapsed         | 52          |\n|    total_timesteps      | 11264       |\n| train/                  |             |\n|    approx_kl            | 0.005646928 |\n|    clip_fraction        | 0.0127      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.57        |\n|    learning_rate        | 0.0001      |\n|    loss                 | 16.8        |\n|    n_updates            | 210         |\n|    policy_gradient_loss | -0.012      |\n|    value_loss           | 65.7        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0364\nMeta-Controller Selection Accuracy: 0.0362\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0366\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 337          |\n|    ep_rew_mean          | 331          |\n| time/                   |              |\n|    fps                  | 213          |\n|    iterations           | 23           |\n|    time_elapsed         | 55           |\n|    total_timesteps      | 11776        |\n| train/                  |              |\n|    approx_kl            | 0.0030084625 |\n|    clip_fraction        | 0.00723      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.59         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 30.9         |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.00958     |\n|    value_loss           | 87.7         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0369\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 337         |\n|    ep_rew_mean          | 332         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 24          |\n|    time_elapsed         | 57          |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.008227255 |\n|    clip_fraction        | 0.0191      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.384       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 25.1        |\n|    n_updates            | 230         |\n|    policy_gradient_loss | -0.0153     |\n|    value_loss           | 58          |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0364\nMeta-Controller Selection Accuracy: 0.0365\nMeta-Controller Selection Accuracy: 0.0366\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 337         |\n|    ep_rew_mean          | 333         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 25          |\n|    time_elapsed         | 60          |\n|    total_timesteps      | 12800       |\n| train/                  |             |\n|    approx_kl            | 0.005643442 |\n|    clip_fraction        | 0.0113      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.647       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 32.2        |\n|    n_updates            | 240         |\n|    policy_gradient_loss | -0.0132     |\n|    value_loss           | 80          |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0365\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0369\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 338          |\n|    ep_rew_mean          | 333          |\n| time/                   |              |\n|    fps                  | 212          |\n|    iterations           | 26           |\n|    time_elapsed         | 62           |\n|    total_timesteps      | 13312        |\n| train/                  |              |\n|    approx_kl            | 0.0014692713 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.46         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 45.6         |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.00716     |\n|    value_loss           | 109          |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0373\nMeta-Controller Selection Accuracy: 0.0373\nMeta-Controller Selection Accuracy: 0.0371\nMeta-Controller Selection Accuracy: 0.0370\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 338         |\n|    ep_rew_mean          | 334         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 27          |\n|    time_elapsed         | 64          |\n|    total_timesteps      | 13824       |\n| train/                  |             |\n|    approx_kl            | 0.003392194 |\n|    clip_fraction        | 0.00195     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.767       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 25          |\n|    n_updates            | 260         |\n|    policy_gradient_loss | -0.0113     |\n|    value_loss           | 69.8        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0366\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 339         |\n|    ep_rew_mean          | 334         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 28          |\n|    time_elapsed         | 67          |\n|    total_timesteps      | 14336       |\n| train/                  |             |\n|    approx_kl            | 0.004743025 |\n|    clip_fraction        | 0.0172      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.77        |\n|    learning_rate        | 0.0001      |\n|    loss                 | 6.82        |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.0103     |\n|    value_loss           | 54.7        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0370\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 335         |\n|    ep_rew_mean          | 317         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 29          |\n|    time_elapsed         | 69          |\n|    total_timesteps      | 14848       |\n| train/                  |             |\n|    approx_kl            | 0.004116414 |\n|    clip_fraction        | 0.00566     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.557       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 30.6        |\n|    n_updates            | 280         |\n|    policy_gradient_loss | -0.0104     |\n|    value_loss           | 79.8        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0368\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 335           |\n|    ep_rew_mean          | 317           |\n| time/                   |               |\n|    fps                  | 212           |\n|    iterations           | 30            |\n|    time_elapsed         | 72            |\n|    total_timesteps      | 15360         |\n| train/                  |               |\n|    approx_kl            | 0.00016982725 |\n|    clip_fraction        | 0             |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -3.35         |\n|    explained_variance   | 0.134         |\n|    learning_rate        | 0.0001        |\n|    loss                 | 1.61e+03      |\n|    n_updates            | 290           |\n|    policy_gradient_loss | -0.00179      |\n|    value_loss           | 2.8e+03       |\n-------------------------------------------\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0366\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0370\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 337         |\n|    ep_rew_mean          | 320         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 31          |\n|    time_elapsed         | 74          |\n|    total_timesteps      | 15872       |\n| train/                  |             |\n|    approx_kl            | 0.001659927 |\n|    clip_fraction        | 0           |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.512       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 29.9        |\n|    n_updates            | 300         |\n|    policy_gradient_loss | -0.00693    |\n|    value_loss           | 81.1        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0371\nMeta-Controller Selection Accuracy: 0.0371\nMeta-Controller Selection Accuracy: 0.0371\nMeta-Controller Selection Accuracy: 0.0371\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 337         |\n|    ep_rew_mean          | 321         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 32          |\n|    time_elapsed         | 77          |\n|    total_timesteps      | 16384       |\n| train/                  |             |\n|    approx_kl            | 0.008257961 |\n|    clip_fraction        | 0.0258      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.506       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 11.9        |\n|    n_updates            | 310         |\n|    policy_gradient_loss | -0.015      |\n|    value_loss           | 70.5        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0369\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 338         |\n|    ep_rew_mean          | 322         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 33          |\n|    time_elapsed         | 79          |\n|    total_timesteps      | 16896       |\n| train/                  |             |\n|    approx_kl            | 0.005214157 |\n|    clip_fraction        | 0.00957     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.815       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 30.6        |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.0121     |\n|    value_loss           | 72.6        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0370\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 338         |\n|    ep_rew_mean          | 322         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 34          |\n|    time_elapsed         | 81          |\n|    total_timesteps      | 17408       |\n| train/                  |             |\n|    approx_kl            | 0.004274727 |\n|    clip_fraction        | 0.000586    |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.787       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 32.7        |\n|    n_updates            | 330         |\n|    policy_gradient_loss | -0.0114     |\n|    value_loss           | 87.6        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0370\nMeta-Controller Selection Accuracy: 0.0369\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0368\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 338          |\n|    ep_rew_mean          | 323          |\n| time/                   |              |\n|    fps                  | 212          |\n|    iterations           | 35           |\n|    time_elapsed         | 84           |\n|    total_timesteps      | 17920        |\n| train/                  |              |\n|    approx_kl            | 0.0072314544 |\n|    clip_fraction        | 0.0166       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.823        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 21.7         |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.012       |\n|    value_loss           | 63.7         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0368\nMeta-Controller Selection Accuracy: 0.0367\nMeta-Controller Selection Accuracy: 0.0367\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 341          |\n|    ep_rew_mean          | 326          |\n| time/                   |              |\n|    fps                  | 212          |\n|    iterations           | 36           |\n|    time_elapsed         | 86           |\n|    total_timesteps      | 18432        |\n| train/                  |              |\n|    approx_kl            | 0.0062728743 |\n|    clip_fraction        | 0.024        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.556        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 8.72         |\n|    n_updates            | 350          |\n|    policy_gradient_loss | -0.0126      |\n|    value_loss           | 47.8         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0365\nMeta-Controller Selection Accuracy: 0.0365\nMeta-Controller Selection Accuracy: 0.0364\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0363\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 343         |\n|    ep_rew_mean          | 328         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 37          |\n|    time_elapsed         | 89          |\n|    total_timesteps      | 18944       |\n| train/                  |             |\n|    approx_kl            | 0.006453947 |\n|    clip_fraction        | 0.00879     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.35       |\n|    explained_variance   | 0.555       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 35.5        |\n|    n_updates            | 360         |\n|    policy_gradient_loss | -0.0113     |\n|    value_loss           | 59.8        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0362\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0363\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 340         |\n|    ep_rew_mean          | 325         |\n| time/                   |             |\n|    fps                  | 212         |\n|    iterations           | 38          |\n|    time_elapsed         | 91          |\n|    total_timesteps      | 19456       |\n| train/                  |             |\n|    approx_kl            | 0.009814604 |\n|    clip_fraction        | 0.068       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -3.36       |\n|    explained_variance   | 0.668       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 18.3        |\n|    n_updates            | 370         |\n|    policy_gradient_loss | -0.0147     |\n|    value_loss           | 48.2        |\n-----------------------------------------\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0362\nMeta-Controller Selection Accuracy: 0.0362\nMeta-Controller Selection Accuracy: 0.0363\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 342          |\n|    ep_rew_mean          | 327          |\n| time/                   |              |\n|    fps                  | 212          |\n|    iterations           | 39           |\n|    time_elapsed         | 94           |\n|    total_timesteps      | 19968        |\n| train/                  |              |\n|    approx_kl            | 0.0011262794 |\n|    clip_fraction        | 0            |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.36        |\n|    explained_variance   | 0.0662       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 26.9         |\n|    n_updates            | 380          |\n|    policy_gradient_loss | -0.00575     |\n|    value_loss           | 51.7         |\n------------------------------------------\nMeta-Controller Selection Accuracy: 0.0363\nMeta-Controller Selection Accuracy: 0.0362\nMeta-Controller Selection Accuracy: 0.0361\nMeta-Controller Selection Accuracy: 0.0361\nMeta-Controller Selection Accuracy: 0.0362\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 342          |\n|    ep_rew_mean          | 328          |\n| time/                   |              |\n|    fps                  | 212          |\n|    iterations           | 40           |\n|    time_elapsed         | 96           |\n|    total_timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0030467045 |\n|    clip_fraction        | 0.00156      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -3.35        |\n|    explained_variance   | 0.671        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 15.8         |\n|    n_updates            | 390          |\n|    policy_gradient_loss | -0.00653     |\n|    value_loss           | 61.3         |\n------------------------------------------\n","output_type":"stream"},{"execution_count":275,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x78e8508e03d0>"},"metadata":{}}],"execution_count":275},{"cell_type":"code","source":"def predict_anomaly(user_day_data):\n    cluster_idx, _ = meta_policy.predict(user_day_data[role_features].to_numpy(dtype=np.float32))\n    chosen_cluster = list(cluster_policies.keys())[cluster_idx]\n    \n    policy = cluster_policies[chosen_cluster]\n    obs = np.concatenate([\n        user_day_data[behavioral_features].to_numpy(dtype=np.float32),\n        user_day_data[latent_features].to_numpy(dtype=np.float32),\n        user_day_data[role_features].to_numpy(dtype=np.float32),\n        np.array([user_day_data['logon_trend'], user_day_data['logon_volatility']], dtype=np.float32)\n    ])\n    anomaly_score, _ = policy.predict(obs)\n    threshold = user_day_data['adaptive_threshold']\n    user_day_data['anomaly_score'] = anomaly_score\n    return 1 if anomaly_score >= threshold else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:36:28.968479Z","iopub.execute_input":"2025-05-06T19:36:28.969248Z","iopub.status.idle":"2025-05-06T19:36:28.97436Z","shell.execute_reply.started":"2025-05-06T19:36:28.969218Z","shell.execute_reply":"2025-05-06T19:36:28.973667Z"}},"outputs":[],"execution_count":277},{"cell_type":"code","source":"predictions = np.zeros(len(df_features))\nanomaly_scores = np.zeros(len(df_features))\nfor i in range(len(df_features)):\n    row = df_features.iloc[i].copy()\n    predictions[i] = predict_anomaly(row)\n    anomaly_scores[i] = row['anomaly_score'] if 'anomaly_score' in row else 0\n\ndf['final_prediction'] = predictions\ndf['anomaly_score'] = anomaly_scores","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision, recall, f1, _ = precision_recall_fscore_support(\n    df_features['is_anomaly'], df_features['final_prediction'], average='binary'\n)\nprint(\"Performance of Temporal-Aware HRL with Custom Reward Logic:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:06:27.835999Z","iopub.execute_input":"2025-05-06T20:06:27.836573Z","iopub.status.idle":"2025-05-06T20:06:28.055725Z","shell.execute_reply.started":"2025-05-06T20:06:27.836549Z","shell.execute_reply":"2025-05-06T20:06:28.054932Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"},{"name":"stdout","text":"Performance of Temporal-Aware HRL with Custom Reward Logic:\nPrecision: 0.0050\nRecall: 0.1466\nF1 Score: 0.0097\n","output_type":"stream"}],"execution_count":289},{"cell_type":"code","source":"cm = confusion_matrix(df_features['is_anomaly'], df_features['final_prediction'])\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal', 'Anomaly'], \n            yticklabels=['Normal', 'Anomaly'])\nplt.title('Confusion Matrix for Anomaly Detection')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:03:48.276785Z","iopub.execute_input":"2025-05-06T20:03:48.277506Z","iopub.status.idle":"2025-05-06T20:03:48.533679Z","shell.execute_reply.started":"2025-05-06T20:03:48.277481Z","shell.execute_reply":"2025-05-06T20:03:48.533049Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:605: DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":283},{"cell_type":"code","source":"# Save each cluster policy\nfor cluster_id, model in cluster_policies.items():\n        if not isinstance(model, PPO):\n            print(f\"Warning: Model for cluster {cluster_id} is not a PPO model. Skipping.\")\n            continue\n        model_path = os.path.join(\"cluster_policies_2\", f\"ppo_cluster_{cluster_id}.zip\")\n        model.save(model_path)\n        print(f\"Saved cluster policy for cluster {cluster_id} to {model_path}\")\n\nmeta_policy.save(\"meta_policy_2.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:04:46.615809Z","iopub.execute_input":"2025-05-06T20:04:46.616497Z","iopub.status.idle":"2025-05-06T20:04:46.856655Z","shell.execute_reply.started":"2025-05-06T20:04:46.616472Z","shell.execute_reply":"2025-05-06T20:04:46.855987Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path 'cluster_policies_2' does not exist. Will create it.\n  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n","output_type":"stream"},{"name":"stdout","text":"Saved cluster policy for cluster 22 to cluster_policies_2/ppo_cluster_22.zip\nSaved cluster policy for cluster 1 to cluster_policies_2/ppo_cluster_1.zip\nSaved cluster policy for cluster 23 to cluster_policies_2/ppo_cluster_23.zip\nSaved cluster policy for cluster 8 to cluster_policies_2/ppo_cluster_8.zip\nSaved cluster policy for cluster 17 to cluster_policies_2/ppo_cluster_17.zip\nSaved cluster policy for cluster 3 to cluster_policies_2/ppo_cluster_3.zip\nSaved cluster policy for cluster 24 to cluster_policies_2/ppo_cluster_24.zip\nSaved cluster policy for cluster 0 to cluster_policies_2/ppo_cluster_0.zip\nSaved cluster policy for cluster 13 to cluster_policies_2/ppo_cluster_13.zip\nSaved cluster policy for cluster 26 to cluster_policies_2/ppo_cluster_26.zip\nSaved cluster policy for cluster 27 to cluster_policies_2/ppo_cluster_27.zip\nSaved cluster policy for cluster 10 to cluster_policies_2/ppo_cluster_10.zip\nSaved cluster policy for cluster 16 to cluster_policies_2/ppo_cluster_16.zip\nSaved cluster policy for cluster 9 to cluster_policies_2/ppo_cluster_9.zip\nSaved cluster policy for cluster 25 to cluster_policies_2/ppo_cluster_25.zip\nSaved cluster policy for cluster 28 to cluster_policies_2/ppo_cluster_28.zip\nSaved cluster policy for cluster 7 to cluster_policies_2/ppo_cluster_7.zip\nSaved cluster policy for cluster 4 to cluster_policies_2/ppo_cluster_4.zip\nSaved cluster policy for cluster 15 to cluster_policies_2/ppo_cluster_15.zip\nSaved cluster policy for cluster 6 to cluster_policies_2/ppo_cluster_6.zip\nSaved cluster policy for cluster 5 to cluster_policies_2/ppo_cluster_5.zip\nSaved cluster policy for cluster 2 to cluster_policies_2/ppo_cluster_2.zip\nSaved cluster policy for cluster 19 to cluster_policies_2/ppo_cluster_19.zip\nSaved cluster policy for cluster 11 to cluster_policies_2/ppo_cluster_11.zip\nSaved cluster policy for cluster 14 to cluster_policies_2/ppo_cluster_14.zip\nSaved cluster policy for cluster 12 to cluster_policies_2/ppo_cluster_12.zip\nSaved cluster policy for cluster 18 to cluster_policies_2/ppo_cluster_18.zip\nSaved cluster policy for cluster 21 to cluster_policies_2/ppo_cluster_21.zip\nSaved cluster policy for cluster 20 to cluster_policies_2/ppo_cluster_20.zip\n","output_type":"stream"}],"execution_count":285},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix, roc_curve, auc, precision_recall_curve","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RL with ppo guided reward","metadata":{}},{"cell_type":"code","source":"df_features = df_features.sort_values(['user', 'date_only'])\ngrouped_data = df_features.groupby('user')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:18:09.299585Z","iopub.execute_input":"2025-05-07T05:18:09.300172Z","iopub.status.idle":"2025-05-07T05:18:09.571757Z","shell.execute_reply.started":"2025-05-07T05:18:09.300152Z","shell.execute_reply":"2025-05-07T05:18:09.571073Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"temporal_features = ['logon_trend', 'logon_volatility']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:18:55.699633Z","iopub.execute_input":"2025-05-07T05:18:55.700348Z","iopub.status.idle":"2025-05-07T05:18:55.703662Z","shell.execute_reply.started":"2025-05-07T05:18:55.700322Z","shell.execute_reply":"2025-05-07T05:18:55.702845Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"all_features = behavioral_features + latent_features + role_features + temporal_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:18:56.270011Z","iopub.execute_input":"2025-05-07T05:18:56.270501Z","iopub.status.idle":"2025-05-07T05:18:56.273869Z","shell.execute_reply.started":"2025-05-07T05:18:56.27048Z","shell.execute_reply":"2025-05-07T05:18:56.272995Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"user_data_dict = {}\nfor user, group in grouped_data:\n    user_data_dict[user] = {\n        'X': group[all_features].to_numpy().astype(np.float32),\n        'y': group['is_anomaly'].to_numpy(),\n        'thresholds': group['adaptive_threshold'].to_numpy(),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:18:59.1452Z","iopub.execute_input":"2025-05-07T05:18:59.145685Z","iopub.status.idle":"2025-05-07T05:18:59.748287Z","shell.execute_reply.started":"2025-05-07T05:18:59.145663Z","shell.execute_reply":"2025-05-07T05:18:59.74769Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"X_all = df_features[all_features].to_numpy()\ny_all = df_features['is_anomaly'].to_numpy()\nuser_ids_all = df_features['user'].to_numpy()\nadaptive_thresholds_all = df_features['adaptive_threshold'].to_numpy()\n\nX_mean = X_all.mean(axis=0)\nX_std = X_all.std(axis=0) + 1e-8\nX_normalized = (X_all - X_mean) / X_std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:21:00.259757Z","iopub.execute_input":"2025-05-07T05:21:00.260069Z","iopub.status.idle":"2025-05-07T05:21:00.537226Z","shell.execute_reply.started":"2025-05-07T05:21:00.260047Z","shell.execute_reply":"2025-05-07T05:21:00.536586Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"for user in user_data_dict:\n    user_data_dict[user]['X'] = (user_data_dict[user]['X'] - X_mean) / X_std\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:21:08.079881Z","iopub.execute_input":"2025-05-07T05:21:08.080409Z","iopub.status.idle":"2025-05-07T05:21:08.166899Z","shell.execute_reply.started":"2025-05-07T05:21:08.080388Z","shell.execute_reply":"2025-05-07T05:21:08.166368Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"import xgboost as xgb\nprint(\"Training XGBoost for reward model...\")\nxgb_model = xgb.XGBClassifier(\n    objective=\"binary:logistic\",\n    scale_pos_weight=(len(y_all) - sum(y_all)) / sum(y_all),  # Handle class imbalance\n    max_depth=4,\n    n_estimators=50,\n    learning_rate=0.1,\n    random_state=42\n)\nxgb_model.fit(X_normalized, y_all)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:21:29.819979Z","iopub.execute_input":"2025-05-07T05:21:29.820481Z","iopub.status.idle":"2025-05-07T05:21:33.084568Z","shell.execute_reply.started":"2025-05-07T05:21:29.820457Z","shell.execute_reply":"2025-05-07T05:21:33.083883Z"}},"outputs":[{"name":"stdout","text":"Training XGBoost for reward model...\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=50, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=50, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=50, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"class AnomalyDetectionEnv(gym.Env):\n    def __init__(self, user_data_dict, xgb_model, oversample_ratio=0.3):\n        super().__init__()\n        self.user_data_dict = user_data_dict\n        self.xgb_model = xgb_model\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(all_features),),  # 72 features\n            dtype=np.float32\n        )\n        self.action_space = spaces.Box(\n            low=0,\n            high=1,\n            shape=(1,),\n            dtype=np.float32\n        )\n        # For balanced sampling\n        self.all_users = list(user_data_dict.keys())\n        self.anomaly_users = [\n            user for user, data in user_data_dict.items()\n            if np.any(data['y'] == 1)\n        ]\n        self.oversample_ratio = oversample_ratio\n        self.current_user = None\n        self.current_data = None\n        self.current_step = 0\n\n    def reset(self, seed=None, options=None):\n        if seed is not None:\n            np.random.seed(seed)\n        # Ignore options for now (can be used for future customization)\n        _ = options  # Unused but required by Gymnasium API\n        \n        # Balanced sampling: 50% chance to sample a user with anomalies\n        if self.anomaly_users and np.random.random() < self.oversample_ratio:\n            self.current_user = np.random.choice(self.anomaly_users)\n        else:\n            self.current_user = np.random.choice(self.all_users)\n        \n        self.current_data = self.user_data_dict[self.current_user]\n        self.current_step = 0\n        return self.current_data['X'][self.current_step], {}\n\n    def step(self, action):\n        true_label = self.current_data['y'][self.current_step]\n        threshold = self.current_data['thresholds'][self.current_step]\n        \n        # Convert action (anomaly_score) to binary prediction\n        pred = 1 if action[0] >= threshold else 0\n        \n        # Get XGBoost probability for anomaly\n        xgb_proba = self.xgb_model.predict_proba(\n            self.current_data['X'][self.current_step].reshape(1, -1)\n        )[0, 1]\n        \n        # Reward structure inspired by provided code\n        if pred == true_label:\n            reward = (\n                100.0 * xgb_proba if true_label == 1 else 1.0 * (1 - xgb_proba)\n            )\n        else:\n            reward = (\n                -10.0 * (1 - xgb_proba) if pred == 1 else -5.0 * xgb_proba\n            )\n        \n        reward = float(reward)  # Ensure reward is a float\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.current_data['X'])\n        truncated = False\n        info = {\"user_id\": self.current_user}\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self.current_data['X'][self.current_step]\n        \n        return obs, reward, done, truncated, info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:25:52.78116Z","iopub.execute_input":"2025-05-07T05:25:52.781398Z","iopub.status.idle":"2025-05-07T05:25:52.790872Z","shell.execute_reply.started":"2025-05-07T05:25:52.781381Z","shell.execute_reply":"2025-05-07T05:25:52.790159Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"env = AnomalyDetectionEnv(\n    user_data_dict,\n    xgb_model,\n    oversample_ratio=0.3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:26:03.544636Z","iopub.execute_input":"2025-05-07T05:26:03.544911Z","iopub.status.idle":"2025-05-07T05:26:03.55469Z","shell.execute_reply.started":"2025-05-07T05:26:03.544892Z","shell.execute_reply":"2025-05-07T05:26:03.553906Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"print(\"Training PPO...\")\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs={\"net_arch\": [64, 64]},\n    learning_rate=3e-4,\n    n_steps=2048,\n    batch_size=64,\n    n_epochs=10,\n    gamma=0.99,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:26:12.399812Z","iopub.execute_input":"2025-05-07T05:26:12.400098Z","iopub.status.idle":"2025-05-07T05:26:12.411342Z","shell.execute_reply.started":"2025-05-07T05:26:12.400077Z","shell.execute_reply":"2025-05-07T05:26:12.410618Z"}},"outputs":[{"name":"stdout","text":"Training PPO...\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"model.learn(total_timesteps=100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:26:18.029297Z","iopub.execute_input":"2025-05-07T05:26:18.029565Z","iopub.status.idle":"2025-05-07T05:29:47.002326Z","shell.execute_reply.started":"2025-05-07T05:26:18.029543Z","shell.execute_reply":"2025-05-07T05:29:47.001661Z"}},"outputs":[{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 293      |\n|    ep_rew_mean     | 118      |\n| time/              |          |\n|    fps             | 626      |\n|    iterations      | 1        |\n|    time_elapsed    | 3        |\n|    total_timesteps | 2048     |\n---------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 270          |\n|    ep_rew_mean          | 96.4         |\n| time/                   |              |\n|    fps                  | 490          |\n|    iterations           | 2            |\n|    time_elapsed         | 8            |\n|    total_timesteps      | 4096         |\n| train/                  |              |\n|    approx_kl            | 0.0041549043 |\n|    clip_fraction        | 0.0275       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | -0.00236     |\n|    learning_rate        | 0.0003       |\n|    loss                 | 574          |\n|    n_updates            | 10           |\n|    policy_gradient_loss | -0.00441     |\n|    std                  | 0.981        |\n|    value_loss           | 3.37e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 281         |\n|    ep_rew_mean          | -13.2       |\n| time/                   |             |\n|    fps                  | 487         |\n|    iterations           | 3           |\n|    time_elapsed         | 12          |\n|    total_timesteps      | 6144        |\n| train/                  |             |\n|    approx_kl            | 0.006488935 |\n|    clip_fraction        | 0.0333      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.0202      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.07e+03    |\n|    n_updates            | 20          |\n|    policy_gradient_loss | -0.00575    |\n|    std                  | 0.961       |\n|    value_loss           | 3.1e+03     |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 289         |\n|    ep_rew_mean          | -40.9       |\n| time/                   |             |\n|    fps                  | 487         |\n|    iterations           | 4           |\n|    time_elapsed         | 16          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.017112488 |\n|    clip_fraction        | 0.16        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.34       |\n|    explained_variance   | 0.0219      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 85.6        |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.0235     |\n|    std                  | 0.899       |\n|    value_loss           | 286         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 294         |\n|    ep_rew_mean          | -34.2       |\n| time/                   |             |\n|    fps                  | 486         |\n|    iterations           | 5           |\n|    time_elapsed         | 21          |\n|    total_timesteps      | 10240       |\n| train/                  |             |\n|    approx_kl            | 0.009447482 |\n|    clip_fraction        | 0.108       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.29       |\n|    explained_variance   | 0.289       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 404         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0123     |\n|    std                  | 0.868       |\n|    value_loss           | 755         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 301         |\n|    ep_rew_mean          | -64.9       |\n| time/                   |             |\n|    fps                  | 486         |\n|    iterations           | 6           |\n|    time_elapsed         | 25          |\n|    total_timesteps      | 12288       |\n| train/                  |             |\n|    approx_kl            | 0.008748349 |\n|    clip_fraction        | 0.0995      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | 0.096       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 87.8        |\n|    n_updates            | 50          |\n|    policy_gradient_loss | -0.00905    |\n|    std                  | 0.863       |\n|    value_loss           | 1.35e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 300         |\n|    ep_rew_mean          | -64.2       |\n| time/                   |             |\n|    fps                  | 488         |\n|    iterations           | 7           |\n|    time_elapsed         | 29          |\n|    total_timesteps      | 14336       |\n| train/                  |             |\n|    approx_kl            | 0.012239636 |\n|    clip_fraction        | 0.119       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | -0.0176     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 51.8        |\n|    n_updates            | 60          |\n|    policy_gradient_loss | -0.0186     |\n|    std                  | 0.819       |\n|    value_loss           | 145         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | -15.7        |\n| time/                   |              |\n|    fps                  | 487          |\n|    iterations           | 8            |\n|    time_elapsed         | 33           |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0109322425 |\n|    clip_fraction        | 0.114        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.163        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 44.8         |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.0172      |\n|    std                  | 0.794        |\n|    value_loss           | 328          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 298          |\n|    ep_rew_mean          | -17.3        |\n| time/                   |              |\n|    fps                  | 486          |\n|    iterations           | 9            |\n|    time_elapsed         | 37           |\n|    total_timesteps      | 18432        |\n| train/                  |              |\n|    approx_kl            | 0.0049318927 |\n|    clip_fraction        | 0.0363       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.18        |\n|    explained_variance   | 0.13         |\n|    learning_rate        | 0.0003       |\n|    loss                 | 5.1e+03      |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.00473     |\n|    std                  | 0.789        |\n|    value_loss           | 6.1e+03      |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 298         |\n|    ep_rew_mean          | -3.69       |\n| time/                   |             |\n|    fps                  | 485         |\n|    iterations           | 10          |\n|    time_elapsed         | 42          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.009436459 |\n|    clip_fraction        | 0.105       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.16       |\n|    explained_variance   | 0.611       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 45.8        |\n|    n_updates            | 90          |\n|    policy_gradient_loss | -0.0176     |\n|    std                  | 0.756       |\n|    value_loss           | 117         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 294         |\n|    ep_rew_mean          | 8.98        |\n| time/                   |             |\n|    fps                  | 485         |\n|    iterations           | 11          |\n|    time_elapsed         | 46          |\n|    total_timesteps      | 22528       |\n| train/                  |             |\n|    approx_kl            | 0.006576507 |\n|    clip_fraction        | 0.0552      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.12       |\n|    explained_variance   | 0.269       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 77          |\n|    n_updates            | 100         |\n|    policy_gradient_loss | -0.00972    |\n|    std                  | 0.734       |\n|    value_loss           | 411         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 291          |\n|    ep_rew_mean          | 27           |\n| time/                   |              |\n|    fps                  | 486          |\n|    iterations           | 12           |\n|    time_elapsed         | 50           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0060084285 |\n|    clip_fraction        | 0.0543       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.11        |\n|    explained_variance   | 0.0098       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 302          |\n|    n_updates            | 110          |\n|    policy_gradient_loss | -0.00631     |\n|    std                  | 0.73         |\n|    value_loss           | 1.14e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 291         |\n|    ep_rew_mean          | 33.3        |\n| time/                   |             |\n|    fps                  | 486         |\n|    iterations           | 13          |\n|    time_elapsed         | 54          |\n|    total_timesteps      | 26624       |\n| train/                  |             |\n|    approx_kl            | 0.005699211 |\n|    clip_fraction        | 0.0392      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | 0.136       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 2.86e+03    |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.00676    |\n|    std                  | 0.72        |\n|    value_loss           | 4.05e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 292         |\n|    ep_rew_mean          | 45.7        |\n| time/                   |             |\n|    fps                  | 486         |\n|    iterations           | 14          |\n|    time_elapsed         | 58          |\n|    total_timesteps      | 28672       |\n| train/                  |             |\n|    approx_kl            | 0.009194415 |\n|    clip_fraction        | 0.0918      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | 0.512       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 52.6        |\n|    n_updates            | 130         |\n|    policy_gradient_loss | -0.0121     |\n|    std                  | 0.708       |\n|    value_loss           | 281         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 36.5         |\n| time/                   |              |\n|    fps                  | 485          |\n|    iterations           | 15           |\n|    time_elapsed         | 63           |\n|    total_timesteps      | 30720        |\n| train/                  |              |\n|    approx_kl            | 0.0073932833 |\n|    clip_fraction        | 0.063        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.05        |\n|    explained_variance   | 0.675        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 24.9         |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.0114      |\n|    std                  | 0.682        |\n|    value_loss           | 160          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 298          |\n|    ep_rew_mean          | 34.7         |\n| time/                   |              |\n|    fps                  | 485          |\n|    iterations           | 16           |\n|    time_elapsed         | 67           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0141502395 |\n|    clip_fraction        | 0.141        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.01        |\n|    explained_variance   | 0.673        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 50.2         |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.0212      |\n|    std                  | 0.655        |\n|    value_loss           | 98           |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 299         |\n|    ep_rew_mean          | 48.6        |\n| time/                   |             |\n|    fps                  | 484         |\n|    iterations           | 17          |\n|    time_elapsed         | 71          |\n|    total_timesteps      | 34816       |\n| train/                  |             |\n|    approx_kl            | 0.008399764 |\n|    clip_fraction        | 0.0841      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.973      |\n|    explained_variance   | 0.787       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 23.3        |\n|    n_updates            | 160         |\n|    policy_gradient_loss | -0.0135     |\n|    std                  | 0.627       |\n|    value_loss           | 70.3        |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 301          |\n|    ep_rew_mean          | 71.5         |\n| time/                   |              |\n|    fps                  | 484          |\n|    iterations           | 18           |\n|    time_elapsed         | 76           |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0069253724 |\n|    clip_fraction        | 0.0704       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.932       |\n|    explained_variance   | 0.784        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 17.5         |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.0127      |\n|    std                  | 0.602        |\n|    value_loss           | 82.2         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 302          |\n|    ep_rew_mean          | 110          |\n| time/                   |              |\n|    fps                  | 485          |\n|    iterations           | 19           |\n|    time_elapsed         | 80           |\n|    total_timesteps      | 38912        |\n| train/                  |              |\n|    approx_kl            | 0.0085665835 |\n|    clip_fraction        | 0.0943       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.911       |\n|    explained_variance   | 0.384        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 257          |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00984     |\n|    std                  | 0.601        |\n|    value_loss           | 192          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 297          |\n|    ep_rew_mean          | 130          |\n| time/                   |              |\n|    fps                  | 485          |\n|    iterations           | 20           |\n|    time_elapsed         | 84           |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0052156476 |\n|    clip_fraction        | 0.0405       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.903       |\n|    explained_variance   | 0.272        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 777          |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.00648     |\n|    std                  | 0.593        |\n|    value_loss           | 2.47e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 295         |\n|    ep_rew_mean          | 163         |\n| time/                   |             |\n|    fps                  | 485         |\n|    iterations           | 21          |\n|    time_elapsed         | 88          |\n|    total_timesteps      | 43008       |\n| train/                  |             |\n|    approx_kl            | 0.006139733 |\n|    clip_fraction        | 0.0534      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.889      |\n|    explained_variance   | 0.744       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 30.7        |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.00833    |\n|    std                  | 0.584       |\n|    value_loss           | 127         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 297         |\n|    ep_rew_mean          | 175         |\n| time/                   |             |\n|    fps                  | 485         |\n|    iterations           | 22          |\n|    time_elapsed         | 92          |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.004564206 |\n|    clip_fraction        | 0.0348      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.879      |\n|    explained_variance   | 0.037       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 608         |\n|    n_updates            | 210         |\n|    policy_gradient_loss | -0.00545    |\n|    std                  | 0.581       |\n|    value_loss           | 1.36e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 176          |\n| time/                   |              |\n|    fps                  | 485          |\n|    iterations           | 23           |\n|    time_elapsed         | 97           |\n|    total_timesteps      | 47104        |\n| train/                  |              |\n|    approx_kl            | 0.0066515985 |\n|    clip_fraction        | 0.0683       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.873       |\n|    explained_variance   | 0.212        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 59.4         |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.00662     |\n|    std                  | 0.578        |\n|    value_loss           | 927          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 186          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 24           |\n|    time_elapsed         | 101          |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0051709088 |\n|    clip_fraction        | 0.0528       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.866       |\n|    explained_variance   | 0.648        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 74.4         |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00897     |\n|    std                  | 0.571        |\n|    value_loss           | 241          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 293         |\n|    ep_rew_mean          | 184         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 25          |\n|    time_elapsed         | 105         |\n|    total_timesteps      | 51200       |\n| train/                  |             |\n|    approx_kl            | 0.006884098 |\n|    clip_fraction        | 0.0749      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.841      |\n|    explained_variance   | 0.797       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 60          |\n|    n_updates            | 240         |\n|    policy_gradient_loss | -0.0126     |\n|    std                  | 0.553       |\n|    value_loss           | 103         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 293         |\n|    ep_rew_mean          | 177         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 26          |\n|    time_elapsed         | 110         |\n|    total_timesteps      | 53248       |\n| train/                  |             |\n|    approx_kl            | 0.007332205 |\n|    clip_fraction        | 0.0788      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.813      |\n|    explained_variance   | 0.74        |\n|    learning_rate        | 0.0003      |\n|    loss                 | 41          |\n|    n_updates            | 250         |\n|    policy_gradient_loss | -0.0112     |\n|    std                  | 0.54        |\n|    value_loss           | 71.4        |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 297         |\n|    ep_rew_mean          | 189         |\n| time/                   |             |\n|    fps                  | 484         |\n|    iterations           | 27          |\n|    time_elapsed         | 114         |\n|    total_timesteps      | 55296       |\n| train/                  |             |\n|    approx_kl            | 0.006926286 |\n|    clip_fraction        | 0.0533      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.782      |\n|    explained_variance   | 0.172       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 26.9        |\n|    n_updates            | 260         |\n|    policy_gradient_loss | -0.00866    |\n|    std                  | 0.518       |\n|    value_loss           | 92.6        |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 295        |\n|    ep_rew_mean          | 194        |\n| time/                   |            |\n|    fps                  | 484        |\n|    iterations           | 28         |\n|    time_elapsed         | 118        |\n|    total_timesteps      | 57344      |\n| train/                  |            |\n|    approx_kl            | 0.01284451 |\n|    clip_fraction        | 0.13       |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.755     |\n|    explained_variance   | 0.649      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 7.51       |\n|    n_updates            | 270        |\n|    policy_gradient_loss | -0.0101    |\n|    std                  | 0.512      |\n|    value_loss           | 59.1       |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 296         |\n|    ep_rew_mean          | 207         |\n| time/                   |             |\n|    fps                  | 484         |\n|    iterations           | 29          |\n|    time_elapsed         | 122         |\n|    total_timesteps      | 59392       |\n| train/                  |             |\n|    approx_kl            | 0.009027453 |\n|    clip_fraction        | 0.0916      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.75       |\n|    explained_variance   | 0.522       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 119         |\n|    n_updates            | 280         |\n|    policy_gradient_loss | -0.0102     |\n|    std                  | 0.512       |\n|    value_loss           | 119         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 214          |\n| time/                   |              |\n|    fps                  | 484          |\n|    iterations           | 30           |\n|    time_elapsed         | 126          |\n|    total_timesteps      | 61440        |\n| train/                  |              |\n|    approx_kl            | 0.0064085987 |\n|    clip_fraction        | 0.0704       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.744       |\n|    explained_variance   | 0.625        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 52           |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.00929     |\n|    std                  | 0.507        |\n|    value_loss           | 144          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 296          |\n|    ep_rew_mean          | 234          |\n| time/                   |              |\n|    fps                  | 484          |\n|    iterations           | 31           |\n|    time_elapsed         | 131          |\n|    total_timesteps      | 63488        |\n| train/                  |              |\n|    approx_kl            | 0.0065569887 |\n|    clip_fraction        | 0.0642       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.727       |\n|    explained_variance   | 0.349        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 27.6         |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.011       |\n|    std                  | 0.496        |\n|    value_loss           | 114          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 235          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 32           |\n|    time_elapsed         | 135          |\n|    total_timesteps      | 65536        |\n| train/                  |              |\n|    approx_kl            | 0.0063048173 |\n|    clip_fraction        | 0.0578       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.708       |\n|    explained_variance   | 0.137        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.38e+03     |\n|    n_updates            | 310          |\n|    policy_gradient_loss | -0.00518     |\n|    std                  | 0.486        |\n|    value_loss           | 2.01e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 294         |\n|    ep_rew_mean          | 221         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 33          |\n|    time_elapsed         | 139         |\n|    total_timesteps      | 67584       |\n| train/                  |             |\n|    approx_kl            | 0.006347351 |\n|    clip_fraction        | 0.0666      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.698      |\n|    explained_variance   | -0.0262     |\n|    learning_rate        | 0.0003      |\n|    loss                 | 46.9        |\n|    n_updates            | 320         |\n|    policy_gradient_loss | -0.00492    |\n|    std                  | 0.487       |\n|    value_loss           | 324         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 250          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 34           |\n|    time_elapsed         | 143          |\n|    total_timesteps      | 69632        |\n| train/                  |              |\n|    approx_kl            | 0.0076838383 |\n|    clip_fraction        | 0.0685       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.699       |\n|    explained_variance   | 0.602        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 56.5         |\n|    n_updates            | 330          |\n|    policy_gradient_loss | -0.00992     |\n|    std                  | 0.487        |\n|    value_loss           | 83.2         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 250          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 35           |\n|    time_elapsed         | 148          |\n|    total_timesteps      | 71680        |\n| train/                  |              |\n|    approx_kl            | 0.0035075736 |\n|    clip_fraction        | 0.0156       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.694       |\n|    explained_variance   | 0.185        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 9.34e+03     |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.00408     |\n|    std                  | 0.481        |\n|    value_loss           | 8.49e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 293         |\n|    ep_rew_mean          | 258         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 36          |\n|    time_elapsed         | 152         |\n|    total_timesteps      | 73728       |\n| train/                  |             |\n|    approx_kl            | 0.008890776 |\n|    clip_fraction        | 0.0619      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.685      |\n|    explained_variance   | 0.493       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 233         |\n|    n_updates            | 350         |\n|    policy_gradient_loss | -0.00836    |\n|    std                  | 0.478       |\n|    value_loss           | 322         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 272          |\n| time/                   |              |\n|    fps                  | 484          |\n|    iterations           | 37           |\n|    time_elapsed         | 156          |\n|    total_timesteps      | 75776        |\n| train/                  |              |\n|    approx_kl            | 0.0047920328 |\n|    clip_fraction        | 0.0493       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.681       |\n|    explained_variance   | 0.239        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.86e+03     |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.00429     |\n|    std                  | 0.478        |\n|    value_loss           | 3.18e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 297          |\n|    ep_rew_mean          | 278          |\n| time/                   |              |\n|    fps                  | 484          |\n|    iterations           | 38           |\n|    time_elapsed         | 160          |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0054844376 |\n|    clip_fraction        | 0.0463       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.679       |\n|    explained_variance   | 0.169        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 122          |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.00618     |\n|    std                  | 0.476        |\n|    value_loss           | 3.44e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 293          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 39           |\n|    time_elapsed         | 165          |\n|    total_timesteps      | 79872        |\n| train/                  |              |\n|    approx_kl            | 0.0064474326 |\n|    clip_fraction        | 0.0503       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.668       |\n|    explained_variance   | 0.769        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 14.8         |\n|    n_updates            | 380          |\n|    policy_gradient_loss | -0.00823     |\n|    std                  | 0.467        |\n|    value_loss           | 79.3         |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 297          |\n|    ep_rew_mean          | 319          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 40           |\n|    time_elapsed         | 169          |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0070643667 |\n|    clip_fraction        | 0.0432       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.654       |\n|    explained_variance   | 0.0644       |\n|    learning_rate        | 0.0003       |\n|    loss                 | 2.38e+03     |\n|    n_updates            | 390          |\n|    policy_gradient_loss | -0.0053      |\n|    std                  | 0.464        |\n|    value_loss           | 2.97e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 300         |\n|    ep_rew_mean          | 325         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 41          |\n|    time_elapsed         | 173         |\n|    total_timesteps      | 83968       |\n| train/                  |             |\n|    approx_kl            | 0.005004253 |\n|    clip_fraction        | 0.0367      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.644      |\n|    explained_variance   | 0.211       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 1.02e+03    |\n|    n_updates            | 400         |\n|    policy_gradient_loss | -0.00552    |\n|    std                  | 0.456       |\n|    value_loss           | 2.18e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 296         |\n|    ep_rew_mean          | 328         |\n| time/                   |             |\n|    fps                  | 484         |\n|    iterations           | 42          |\n|    time_elapsed         | 177         |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.008204941 |\n|    clip_fraction        | 0.0885      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.63       |\n|    explained_variance   | 0.717       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 33.5        |\n|    n_updates            | 410         |\n|    policy_gradient_loss | -0.0128     |\n|    std                  | 0.453       |\n|    value_loss           | 104         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 370          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 43           |\n|    time_elapsed         | 181          |\n|    total_timesteps      | 88064        |\n| train/                  |              |\n|    approx_kl            | 0.0058214646 |\n|    clip_fraction        | 0.0525       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.625       |\n|    explained_variance   | 0.346        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 130          |\n|    n_updates            | 420          |\n|    policy_gradient_loss | -0.0091      |\n|    std                  | 0.451        |\n|    value_loss           | 2.78e+03     |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 293        |\n|    ep_rew_mean          | 393        |\n| time/                   |            |\n|    fps                  | 484        |\n|    iterations           | 44         |\n|    time_elapsed         | 186        |\n|    total_timesteps      | 90112      |\n| train/                  |            |\n|    approx_kl            | 0.00820956 |\n|    clip_fraction        | 0.0602     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.62      |\n|    explained_variance   | 0.135      |\n|    learning_rate        | 0.0003     |\n|    loss                 | 7.21e+03   |\n|    n_updates            | 430        |\n|    policy_gradient_loss | -0.00601   |\n|    std                  | 0.448      |\n|    value_loss           | 1.93e+04   |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 417          |\n| time/                   |              |\n|    fps                  | 484          |\n|    iterations           | 45           |\n|    time_elapsed         | 190          |\n|    total_timesteps      | 92160        |\n| train/                  |              |\n|    approx_kl            | 0.0046120826 |\n|    clip_fraction        | 0.0469       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.607       |\n|    explained_variance   | 0.286        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 4.7e+03      |\n|    n_updates            | 440          |\n|    policy_gradient_loss | -0.00822     |\n|    std                  | 0.44         |\n|    value_loss           | 8.26e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 295         |\n|    ep_rew_mean          | 408         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 46          |\n|    time_elapsed         | 194         |\n|    total_timesteps      | 94208       |\n| train/                  |             |\n|    approx_kl            | 0.006039829 |\n|    clip_fraction        | 0.0496      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.584      |\n|    explained_variance   | 0.239       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 6.66e+03    |\n|    n_updates            | 450         |\n|    policy_gradient_loss | -0.00463    |\n|    std                  | 0.427       |\n|    value_loss           | 1.02e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 296          |\n|    ep_rew_mean          | 418          |\n| time/                   |              |\n|    fps                  | 483          |\n|    iterations           | 47           |\n|    time_elapsed         | 199          |\n|    total_timesteps      | 96256        |\n| train/                  |              |\n|    approx_kl            | 0.0065686135 |\n|    clip_fraction        | 0.0622       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.558       |\n|    explained_variance   | 0.857        |\n|    learning_rate        | 0.0003       |\n|    loss                 | 179          |\n|    n_updates            | 460          |\n|    policy_gradient_loss | -0.00863     |\n|    std                  | 0.417        |\n|    value_loss           | 225          |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 295         |\n|    ep_rew_mean          | 404         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 48          |\n|    time_elapsed         | 203         |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.009005915 |\n|    clip_fraction        | 0.0661      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.543      |\n|    explained_variance   | 0.0233      |\n|    learning_rate        | 0.0003      |\n|    loss                 | 43.3        |\n|    n_updates            | 470         |\n|    policy_gradient_loss | -0.00734    |\n|    std                  | 0.415       |\n|    value_loss           | 2.87e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 296         |\n|    ep_rew_mean          | 394         |\n| time/                   |             |\n|    fps                  | 483         |\n|    iterations           | 49          |\n|    time_elapsed         | 207         |\n|    total_timesteps      | 100352      |\n| train/                  |             |\n|    approx_kl            | 0.008182525 |\n|    clip_fraction        | 0.0813      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.544      |\n|    explained_variance   | 0.698       |\n|    learning_rate        | 0.0003      |\n|    loss                 | 162         |\n|    n_updates            | 480         |\n|    policy_gradient_loss | -0.0111     |\n|    std                  | 0.419       |\n|    value_loss           | 260         |\n-----------------------------------------\n","output_type":"stream"},{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7f7c6389e990>"},"metadata":{}}],"execution_count":74},{"cell_type":"code","source":"model.save(\"ppo_anomaly_detector_xgb.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:34:54.0399Z","iopub.execute_input":"2025-05-07T05:34:54.040205Z","iopub.status.idle":"2025-05-07T05:34:54.054424Z","shell.execute_reply.started":"2025-05-07T05:34:54.040184Z","shell.execute_reply":"2025-05-07T05:34:54.053717Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"def evaluate_model(model, user_data_dict, n_samples=1000):\n    true_labels = []\n    predictions = []\n    anomaly_scores = []\n    \n    # Randomly select users to evaluate\n    users_to_evaluate = np.random.choice(\n        list(user_data_dict.keys()), \n        size=min(n_samples, len(user_data_dict)), \n        replace=False\n    )\n    \n    # Evaluate each selected user\n    for user in users_to_evaluate:\n        data = user_data_dict[user]\n        for i in range(len(data['X'])):\n            obs = data['X'][i]\n            action, _ = model.predict(obs, deterministic=True)\n            \n            # Store results\n            true_labels.append(data['y'][i])\n            predictions.append(1 if action[0] >= data['thresholds'][i] else 0)\n            anomaly_scores.append(float(action[0]))\n    \n    precision = precision_score(true_labels, predictions, zero_division=0)\n    recall = recall_score(true_labels, predictions, zero_division=0)\n    f1 = f1_score(true_labels, predictions, zero_division=0)\n    \n    print(\"\\nSimple Evaluation Results:\")\n    print(f\"Evaluated {len(predictions)} samples\")\n    print(f\"Anomaly rate: {np.mean(true_labels):.2%}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    \n    if sum(true_labels) > 0:\n        fpr, tpr, _ = roc_curve(true_labels, anomaly_scores)\n        plt.plot(fpr, tpr)\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.show()\n    else:\n        print(\"No anomalies found in evaluation set - cannot plot ROC curve\")\n\n# Run the simple evaluation\nevaluate_model(model, user_data_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:35:07.55986Z","iopub.execute_input":"2025-05-07T05:35:07.560155Z","iopub.status.idle":"2025-05-07T05:38:17.915199Z","shell.execute_reply.started":"2025-05-07T05:35:07.560135Z","shell.execute_reply":"2025-05-07T05:38:17.914338Z"}},"outputs":[{"name":"stdout","text":"\nSimple Evaluation Results:\nEvaluated 330285 samples\nAnomaly rate: 0.41%\nPrecision: 0.1660\nRecall: 0.3189\nF1 Score: 0.2183\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":77},{"cell_type":"markdown","source":"improving using hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"feature_importances = xgb_model.feature_importances_\nfeature_importance_weights = feature_importances / feature_importances.sum() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:45:26.234035Z","iopub.execute_input":"2025-05-07T05:45:26.234315Z","iopub.status.idle":"2025-05-07T05:45:26.238683Z","shell.execute_reply.started":"2025-05-07T05:45:26.234296Z","shell.execute_reply":"2025-05-07T05:45:26.23787Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"class AnomalyDetectionEnv(gym.Env):\n    def __init__(self, user_data_dict, xgb_model, feature_weights, oversample_ratio=0.5):\n        super().__init__()\n        self.user_data_dict = user_data_dict\n        self.xgb_model = xgb_model\n        self.feature_weights = feature_weights\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(all_features),),\n            dtype=np.float32\n        )\n        self.action_space = spaces.Box(\n            low=0,\n            high=1,\n            shape=(1,),\n            dtype=np.float32\n        )\n        self.all_users = list(user_data_dict.keys())\n        self.anomaly_users = [\n            user for user, data in user_data_dict.items()\n            if np.any(data['y'] == 1)\n        ]\n        self.oversample_ratio = oversample_ratio\n        self.current_user = None\n        self.current_data = None\n        self.current_step = 0\n        self.fp_count = 0\n        self.total_preds = 0\n\n    def reset(self, seed=None, options=None):\n        if seed is not None:\n            np.random.seed(seed)\n        _ = options\n        \n        if self.anomaly_users and np.random.random() < self.oversample_ratio:\n            self.current_user = np.random.choice(self.anomaly_users)\n        else:\n            self.current_user = np.random.choice(self.all_users)\n        \n        self.current_data = self.user_data_dict[self.current_user]\n        self.current_step = 0\n        return self.current_data['X'][self.current_step], {}\n\n    def step(self, action):\n        true_label = self.current_data['y'][self.current_step]\n        threshold = self.current_data['thresholds'][self.current_step]\n        obs = self.current_data['X'][self.current_step]\n        \n        pred = 1 if action[0] >= threshold else 0\n        \n        # Get XGBoost probability for anomaly\n        xgb_proba = self.xgb_model.predict_proba(obs.reshape(1, -1))[0, 1]\n        \n        # Compute feature contribution to reward (weighted by importance)\n        feature_contrib = np.abs(obs) * self.feature_weights\n        feature_score = feature_contrib.sum()\n        \n        # Updated reward function\n        if pred == true_label:\n            reward = (\n                150.0 * xgb_proba * (1 + 0.1 * feature_score) if true_label == 1 else\n                2.0 * (1 - xgb_proba) * (1 + 0.05 * feature_score)\n            )\n        else:\n            reward = (\n                -15.0 * (1 - xgb_proba) * (1 + 0.1 * feature_score) if pred == 1 else\n                -8.0 * xgb_proba * (1 + 0.1 * feature_score)\n            )\n        \n        reward = float(reward)\n        \n        # Track FP rate for threshold adjustment\n        if pred == 1 and true_label == 0:\n            self.fp_count += 1\n        self.total_preds += 1\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.current_data['X'])\n        truncated = False\n        info = {\"user_id\": self.current_user}\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self.current_data['X'][self.current_step]\n        \n        return obs, reward, done, truncated, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:45:56.319459Z","iopub.execute_input":"2025-05-07T05:45:56.319723Z","iopub.status.idle":"2025-05-07T05:45:56.330134Z","shell.execute_reply.started":"2025-05-07T05:45:56.319703Z","shell.execute_reply":"2025-05-07T05:45:56.329341Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"env = AnomalyDetectionEnv(\n    user_data_dict,\n    xgb_model,\n    feature_importance_weights,\n    oversample_ratio=0.4\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:46:05.43967Z","iopub.execute_input":"2025-05-07T05:46:05.440205Z","iopub.status.idle":"2025-05-07T05:46:05.449839Z","shell.execute_reply.started":"2025-05-07T05:46:05.440184Z","shell.execute_reply":"2025-05-07T05:46:05.44913Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"print(\"Training PPO...\")\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs={\"net_arch\": [128, 128]},\n    learning_rate=1e-4,\n    n_steps=4096,\n    batch_size=128,\n    n_epochs=10,\n    gamma=0.99,\n    verbose=1\n)\nmodel.learn(total_timesteps=200000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:46:16.068421Z","iopub.execute_input":"2025-05-07T05:46:16.068977Z","iopub.status.idle":"2025-05-07T05:52:10.678764Z","shell.execute_reply.started":"2025-05-07T05:46:16.068956Z","shell.execute_reply":"2025-05-07T05:52:10.678026Z"}},"outputs":[{"name":"stdout","text":"Training PPO...\nUsing cuda device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 317      |\n|    ep_rew_mean     | -132     |\n| time/              |          |\n|    fps             | 670      |\n|    iterations      | 1        |\n|    time_elapsed    | 6        |\n|    total_timesteps | 4096     |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 284         |\n|    ep_rew_mean          | -19.6       |\n| time/                   |             |\n|    fps                  | 612         |\n|    iterations           | 2           |\n|    time_elapsed         | 13          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.005963591 |\n|    clip_fraction        | 0.0225      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.42       |\n|    explained_variance   | -0.000282   |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.03e+03    |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0066     |\n|    std                  | 0.995       |\n|    value_loss           | 7.95e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 302          |\n|    ep_rew_mean          | -137         |\n| time/                   |              |\n|    fps                  | 593          |\n|    iterations           | 3            |\n|    time_elapsed         | 20           |\n|    total_timesteps      | 12288        |\n| train/                  |              |\n|    approx_kl            | 0.0016666264 |\n|    clip_fraction        | 0.00251      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.41        |\n|    explained_variance   | 0.0119       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.09e+03     |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.00234     |\n|    std                  | 0.99         |\n|    value_loss           | 1.21e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 300         |\n|    ep_rew_mean          | -159        |\n| time/                   |             |\n|    fps                  | 585         |\n|    iterations           | 4           |\n|    time_elapsed         | 28          |\n|    total_timesteps      | 16384       |\n| train/                  |             |\n|    approx_kl            | 0.013228277 |\n|    clip_fraction        | 0.116       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.39       |\n|    explained_variance   | 0.093       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 250         |\n|    n_updates            | 30          |\n|    policy_gradient_loss | -0.023      |\n|    std                  | 0.957       |\n|    value_loss           | 572         |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 302         |\n|    ep_rew_mean          | -110        |\n| time/                   |             |\n|    fps                  | 577         |\n|    iterations           | 5           |\n|    time_elapsed         | 35          |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.009147991 |\n|    clip_fraction        | 0.0758      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.36       |\n|    explained_variance   | 0.0139      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 166         |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.0138     |\n|    std                  | 0.93        |\n|    value_loss           | 418         |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 296          |\n|    ep_rew_mean          | -51          |\n| time/                   |              |\n|    fps                  | 575          |\n|    iterations           | 6            |\n|    time_elapsed         | 42           |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0034375996 |\n|    clip_fraction        | 0.00815      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.34        |\n|    explained_variance   | 0.0793       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.81e+03     |\n|    n_updates            | 50           |\n|    policy_gradient_loss | -0.00241     |\n|    std                  | 0.924        |\n|    value_loss           | 6.7e+03      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | -10.7        |\n| time/                   |              |\n|    fps                  | 573          |\n|    iterations           | 7            |\n|    time_elapsed         | 49           |\n|    total_timesteps      | 28672        |\n| train/                  |              |\n|    approx_kl            | 0.0030414276 |\n|    clip_fraction        | 0.00681      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.34        |\n|    explained_variance   | 0.0565       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.4e+03      |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.00375     |\n|    std                  | 0.919        |\n|    value_loss           | 6.33e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | -11.6        |\n| time/                   |              |\n|    fps                  | 572          |\n|    iterations           | 8            |\n|    time_elapsed         | 57           |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0037600237 |\n|    clip_fraction        | 0.0111       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.33        |\n|    explained_variance   | 0.0913       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.73e+03     |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00442     |\n|    std                  | 0.912        |\n|    value_loss           | 1.01e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 296         |\n|    ep_rew_mean          | 23.9        |\n| time/                   |             |\n|    fps                  | 572         |\n|    iterations           | 9           |\n|    time_elapsed         | 64          |\n|    total_timesteps      | 36864       |\n| train/                  |             |\n|    approx_kl            | 0.009272782 |\n|    clip_fraction        | 0.0747      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.121       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 253         |\n|    n_updates            | 80          |\n|    policy_gradient_loss | -0.00738    |\n|    std                  | 0.911       |\n|    value_loss           | 4.98e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 284          |\n|    ep_rew_mean          | 167          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 10           |\n|    time_elapsed         | 71           |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0035303207 |\n|    clip_fraction        | 0.012        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.32        |\n|    explained_variance   | 0.186        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.37e+03     |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.00327     |\n|    std                  | 0.909        |\n|    value_loss           | 7.44e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 285          |\n|    ep_rew_mean          | 227          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 11           |\n|    time_elapsed         | 79           |\n|    total_timesteps      | 45056        |\n| train/                  |              |\n|    approx_kl            | 0.0018440401 |\n|    clip_fraction        | 0.00779      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.32        |\n|    explained_variance   | 0.0648       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.34e+03     |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00392     |\n|    std                  | 0.91         |\n|    value_loss           | 1.61e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 282         |\n|    ep_rew_mean          | 262         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 12          |\n|    time_elapsed         | 86          |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.004167795 |\n|    clip_fraction        | 0.0229      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.116       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.17e+04    |\n|    n_updates            | 110         |\n|    policy_gradient_loss | -0.00431    |\n|    std                  | 0.905       |\n|    value_loss           | 1.21e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 288         |\n|    ep_rew_mean          | 280         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 13          |\n|    time_elapsed         | 93          |\n|    total_timesteps      | 53248       |\n| train/                  |             |\n|    approx_kl            | 0.005039891 |\n|    clip_fraction        | 0.0272      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.32       |\n|    explained_variance   | 0.195       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 294         |\n|    n_updates            | 120         |\n|    policy_gradient_loss | -0.00308    |\n|    std                  | 0.897       |\n|    value_loss           | 5.49e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 291          |\n|    ep_rew_mean          | 272          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 14           |\n|    time_elapsed         | 101          |\n|    total_timesteps      | 57344        |\n| train/                  |              |\n|    approx_kl            | 0.0050706104 |\n|    clip_fraction        | 0.0207       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.31        |\n|    explained_variance   | 0.271        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.33e+03     |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.00396     |\n|    std                  | 0.894        |\n|    value_loss           | 5.33e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 289          |\n|    ep_rew_mean          | 276          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 15           |\n|    time_elapsed         | 108          |\n|    total_timesteps      | 61440        |\n| train/                  |              |\n|    approx_kl            | 0.0037174332 |\n|    clip_fraction        | 0.0073       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.3         |\n|    explained_variance   | 0.111        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.29e+03     |\n|    n_updates            | 140          |\n|    policy_gradient_loss | -0.00266     |\n|    std                  | 0.889        |\n|    value_loss           | 7.09e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 327          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 16           |\n|    time_elapsed         | 115          |\n|    total_timesteps      | 65536        |\n| train/                  |              |\n|    approx_kl            | 0.0059765885 |\n|    clip_fraction        | 0.035        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.3         |\n|    explained_variance   | 0.27         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 271          |\n|    n_updates            | 150          |\n|    policy_gradient_loss | -0.00774     |\n|    std                  | 0.879        |\n|    value_loss           | 846          |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 352          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 17           |\n|    time_elapsed         | 122          |\n|    total_timesteps      | 69632        |\n| train/                  |              |\n|    approx_kl            | 0.0026176083 |\n|    clip_fraction        | 0.00706      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.29        |\n|    explained_variance   | 0.111        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.66e+03     |\n|    n_updates            | 160          |\n|    policy_gradient_loss | -0.00316     |\n|    std                  | 0.873        |\n|    value_loss           | 1.55e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 293         |\n|    ep_rew_mean          | 403         |\n| time/                   |             |\n|    fps                  | 567         |\n|    iterations           | 18          |\n|    time_elapsed         | 129         |\n|    total_timesteps      | 73728       |\n| train/                  |             |\n|    approx_kl            | 0.003778836 |\n|    clip_fraction        | 0.0125      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.28       |\n|    explained_variance   | 0.133       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.03e+04    |\n|    n_updates            | 170         |\n|    policy_gradient_loss | -0.00245    |\n|    std                  | 0.87        |\n|    value_loss           | 1.09e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | 408          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 19           |\n|    time_elapsed         | 137          |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0028844615 |\n|    clip_fraction        | 0.00908      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | 0.135        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.1e+04      |\n|    n_updates            | 180          |\n|    policy_gradient_loss | -0.00243     |\n|    std                  | 0.869        |\n|    value_loss           | 1.91e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 515          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 20           |\n|    time_elapsed         | 144          |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0044380953 |\n|    clip_fraction        | 0.0198       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.27        |\n|    explained_variance   | 0.234        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 153          |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.00346     |\n|    std                  | 0.862        |\n|    value_loss           | 8.75e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 294         |\n|    ep_rew_mean          | 548         |\n| time/                   |             |\n|    fps                  | 567         |\n|    iterations           | 21          |\n|    time_elapsed         | 151         |\n|    total_timesteps      | 86016       |\n| train/                  |             |\n|    approx_kl            | 0.002035338 |\n|    clip_fraction        | 0.00422     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | 0.0724      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.04e+04    |\n|    n_updates            | 200         |\n|    policy_gradient_loss | -0.00185    |\n|    std                  | 0.859       |\n|    value_loss           | 3.89e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 285          |\n|    ep_rew_mean          | 649          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 22           |\n|    time_elapsed         | 158          |\n|    total_timesteps      | 90112        |\n| train/                  |              |\n|    approx_kl            | 0.0032455728 |\n|    clip_fraction        | 0.013        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.26        |\n|    explained_variance   | 0.273        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.5e+03      |\n|    n_updates            | 210          |\n|    policy_gradient_loss | -0.00263     |\n|    std                  | 0.85         |\n|    value_loss           | 8.4e+03      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 279          |\n|    ep_rew_mean          | 693          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 23           |\n|    time_elapsed         | 166          |\n|    total_timesteps      | 94208        |\n| train/                  |              |\n|    approx_kl            | 0.0023331326 |\n|    clip_fraction        | 0.00564      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.107        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 8.07e+03     |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.00288     |\n|    std                  | 0.845        |\n|    value_loss           | 2.37e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 276          |\n|    ep_rew_mean          | 745          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 24           |\n|    time_elapsed         | 173          |\n|    total_timesteps      | 98304        |\n| train/                  |              |\n|    approx_kl            | 0.0023948806 |\n|    clip_fraction        | 0.00891      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.125        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.09e+04     |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00263     |\n|    std                  | 0.839        |\n|    value_loss           | 2.41e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 271         |\n|    ep_rew_mean          | 726         |\n| time/                   |             |\n|    fps                  | 567         |\n|    iterations           | 25          |\n|    time_elapsed         | 180         |\n|    total_timesteps      | 102400      |\n| train/                  |             |\n|    approx_kl            | 0.001755717 |\n|    clip_fraction        | 0.00588     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.175       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.37e+04    |\n|    n_updates            | 240         |\n|    policy_gradient_loss | -0.00208    |\n|    std                  | 0.841       |\n|    value_loss           | 4.06e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 271          |\n|    ep_rew_mean          | 761          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 26           |\n|    time_elapsed         | 187          |\n|    total_timesteps      | 106496       |\n| train/                  |              |\n|    approx_kl            | 0.0019768882 |\n|    clip_fraction        | 0.00513      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | 0.225        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.3e+04      |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.00168     |\n|    std                  | 0.837        |\n|    value_loss           | 1.37e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 260          |\n|    ep_rew_mean          | 763          |\n| time/                   |              |\n|    fps                  | 567          |\n|    iterations           | 27           |\n|    time_elapsed         | 194          |\n|    total_timesteps      | 110592       |\n| train/                  |              |\n|    approx_kl            | 0.0033995376 |\n|    clip_fraction        | 0.011        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.24        |\n|    explained_variance   | 0.161        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.62e+03     |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.00299     |\n|    std                  | 0.838        |\n|    value_loss           | 4.04e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 262         |\n|    ep_rew_mean          | 852         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 28          |\n|    time_elapsed         | 201         |\n|    total_timesteps      | 114688      |\n| train/                  |             |\n|    approx_kl            | 0.003491811 |\n|    clip_fraction        | 0.0185      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.165       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.38e+04    |\n|    n_updates            | 270         |\n|    policy_gradient_loss | -0.00359    |\n|    std                  | 0.829       |\n|    value_loss           | 2.32e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 268         |\n|    ep_rew_mean          | 809         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 29          |\n|    time_elapsed         | 209         |\n|    total_timesteps      | 118784      |\n| train/                  |             |\n|    approx_kl            | 0.002655053 |\n|    clip_fraction        | 0.00862     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.23       |\n|    explained_variance   | 0.218       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.77e+04    |\n|    n_updates            | 280         |\n|    policy_gradient_loss | -0.00268    |\n|    std                  | 0.823       |\n|    value_loss           | 3.2e+04     |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 275          |\n|    ep_rew_mean          | 786          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 30           |\n|    time_elapsed         | 216          |\n|    total_timesteps      | 122880       |\n| train/                  |              |\n|    approx_kl            | 0.0025560479 |\n|    clip_fraction        | 0.00518      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.116        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.18e+03     |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.00204     |\n|    std                  | 0.825        |\n|    value_loss           | 3.69e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 281          |\n|    ep_rew_mean          | 753          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 31           |\n|    time_elapsed         | 223          |\n|    total_timesteps      | 126976       |\n| train/                  |              |\n|    approx_kl            | 0.0033031204 |\n|    clip_fraction        | 0.0155       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.281        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 8.41e+03     |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.00351     |\n|    std                  | 0.825        |\n|    value_loss           | 1.17e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 282          |\n|    ep_rew_mean          | 716          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 32           |\n|    time_elapsed         | 230          |\n|    total_timesteps      | 131072       |\n| train/                  |              |\n|    approx_kl            | 0.0039033452 |\n|    clip_fraction        | 0.0141       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.341        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.4e+03      |\n|    n_updates            | 310          |\n|    policy_gradient_loss | -0.00269     |\n|    std                  | 0.83         |\n|    value_loss           | 2.37e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 282          |\n|    ep_rew_mean          | 658          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 33           |\n|    time_elapsed         | 237          |\n|    total_timesteps      | 135168       |\n| train/                  |              |\n|    approx_kl            | 0.0056287562 |\n|    clip_fraction        | 0.0354       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.348        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.03e+04     |\n|    n_updates            | 320          |\n|    policy_gradient_loss | -0.00555     |\n|    std                  | 0.82         |\n|    value_loss           | 1.02e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 288         |\n|    ep_rew_mean          | 711         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 34          |\n|    time_elapsed         | 245         |\n|    total_timesteps      | 139264      |\n| train/                  |             |\n|    approx_kl            | 0.005666063 |\n|    clip_fraction        | 0.0274      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.21       |\n|    explained_variance   | 0.231       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.43e+03    |\n|    n_updates            | 330         |\n|    policy_gradient_loss | -0.00293    |\n|    std                  | 0.808       |\n|    value_loss           | 1.63e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 287          |\n|    ep_rew_mean          | 666          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 35           |\n|    time_elapsed         | 252          |\n|    total_timesteps      | 143360       |\n| train/                  |              |\n|    approx_kl            | 0.0021097043 |\n|    clip_fraction        | 0.00593      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.0585       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.74e+04     |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.00344     |\n|    std                  | 0.802        |\n|    value_loss           | 2.78e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 288          |\n|    ep_rew_mean          | 766          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 36           |\n|    time_elapsed         | 259          |\n|    total_timesteps      | 147456       |\n| train/                  |              |\n|    approx_kl            | 0.0027309381 |\n|    clip_fraction        | 0.0136       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.267        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.02e+04     |\n|    n_updates            | 350          |\n|    policy_gradient_loss | -0.00348     |\n|    std                  | 0.797        |\n|    value_loss           | 2.4e+04      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 290          |\n|    ep_rew_mean          | 810          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 37           |\n|    time_elapsed         | 266          |\n|    total_timesteps      | 151552       |\n| train/                  |              |\n|    approx_kl            | 0.0015513871 |\n|    clip_fraction        | 0.00676      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.19        |\n|    explained_variance   | 0.0997       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.34e+04     |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.00214     |\n|    std                  | 0.791        |\n|    value_loss           | 3.68e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 283          |\n|    ep_rew_mean          | 896          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 38           |\n|    time_elapsed         | 273          |\n|    total_timesteps      | 155648       |\n| train/                  |              |\n|    approx_kl            | 0.0024323321 |\n|    clip_fraction        | 0.0164       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.18        |\n|    explained_variance   | 0.112        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.94e+03     |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.00455     |\n|    std                  | 0.782        |\n|    value_loss           | 3.71e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 276          |\n|    ep_rew_mean          | 966          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 39           |\n|    time_elapsed         | 280          |\n|    total_timesteps      | 159744       |\n| train/                  |              |\n|    approx_kl            | 0.0024578213 |\n|    clip_fraction        | 0.00823      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.17        |\n|    explained_variance   | 0.274        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.44e+03     |\n|    n_updates            | 380          |\n|    policy_gradient_loss | -0.00195     |\n|    std                  | 0.779        |\n|    value_loss           | 2.73e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 273         |\n|    ep_rew_mean          | 977         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 40          |\n|    time_elapsed         | 288         |\n|    total_timesteps      | 163840      |\n| train/                  |             |\n|    approx_kl            | 0.004964961 |\n|    clip_fraction        | 0.02        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.17       |\n|    explained_variance   | -0.00311    |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.45e+04    |\n|    n_updates            | 390         |\n|    policy_gradient_loss | -0.00369    |\n|    std                  | 0.773       |\n|    value_loss           | 3.12e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 277         |\n|    ep_rew_mean          | 931         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 41          |\n|    time_elapsed         | 295         |\n|    total_timesteps      | 167936      |\n| train/                  |             |\n|    approx_kl            | 0.002064092 |\n|    clip_fraction        | 0.00928     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.16       |\n|    explained_variance   | 0.0922      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 8.59e+03    |\n|    n_updates            | 400         |\n|    policy_gradient_loss | -0.00326    |\n|    std                  | 0.771       |\n|    value_loss           | 2.55e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 279          |\n|    ep_rew_mean          | 937          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 42           |\n|    time_elapsed         | 302          |\n|    total_timesteps      | 172032       |\n| train/                  |              |\n|    approx_kl            | 0.0025198911 |\n|    clip_fraction        | 0.00859      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.16        |\n|    explained_variance   | 0.292        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.2e+03      |\n|    n_updates            | 410          |\n|    policy_gradient_loss | -0.00229     |\n|    std                  | 0.772        |\n|    value_loss           | 3.22e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 279          |\n|    ep_rew_mean          | 921          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 43           |\n|    time_elapsed         | 309          |\n|    total_timesteps      | 176128       |\n| train/                  |              |\n|    approx_kl            | 0.0016599494 |\n|    clip_fraction        | 0.00715      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.16        |\n|    explained_variance   | 0.177        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.52e+04     |\n|    n_updates            | 420          |\n|    policy_gradient_loss | -0.00295     |\n|    std                  | 0.768        |\n|    value_loss           | 2.97e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 272          |\n|    ep_rew_mean          | 811          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 44           |\n|    time_elapsed         | 316          |\n|    total_timesteps      | 180224       |\n| train/                  |              |\n|    approx_kl            | 0.0029177433 |\n|    clip_fraction        | 0.0114       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.15        |\n|    explained_variance   | 0.129        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.69e+04     |\n|    n_updates            | 430          |\n|    policy_gradient_loss | -0.00327     |\n|    std                  | 0.767        |\n|    value_loss           | 5.84e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 276          |\n|    ep_rew_mean          | 750          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 45           |\n|    time_elapsed         | 324          |\n|    total_timesteps      | 184320       |\n| train/                  |              |\n|    approx_kl            | 0.0018722644 |\n|    clip_fraction        | 0.00515      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.15        |\n|    explained_variance   | 0.229        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.91e+03     |\n|    n_updates            | 440          |\n|    policy_gradient_loss | -0.00191     |\n|    std                  | 0.763        |\n|    value_loss           | 2.97e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 286         |\n|    ep_rew_mean          | 746         |\n| time/                   |             |\n|    fps                  | 568         |\n|    iterations           | 46          |\n|    time_elapsed         | 331         |\n|    total_timesteps      | 188416      |\n| train/                  |             |\n|    approx_kl            | 0.002102642 |\n|    clip_fraction        | 0.00386     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | 0.637       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 389         |\n|    n_updates            | 450         |\n|    policy_gradient_loss | -0.00128    |\n|    std                  | 0.76        |\n|    value_loss           | 1.42e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 666          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 47           |\n|    time_elapsed         | 338          |\n|    total_timesteps      | 192512       |\n| train/                  |              |\n|    approx_kl            | 0.0026228055 |\n|    clip_fraction        | 0.0117       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 0.208        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.4e+03      |\n|    n_updates            | 460          |\n|    policy_gradient_loss | -0.0026      |\n|    std                  | 0.753        |\n|    value_loss           | 3.01e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 720          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 48           |\n|    time_elapsed         | 345          |\n|    total_timesteps      | 196608       |\n| train/                  |              |\n|    approx_kl            | 0.0052041877 |\n|    clip_fraction        | 0.0219       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 0.211        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.66e+04     |\n|    n_updates            | 470          |\n|    policy_gradient_loss | -0.00443     |\n|    std                  | 0.742        |\n|    value_loss           | 1.48e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 296          |\n|    ep_rew_mean          | 722          |\n| time/                   |              |\n|    fps                  | 568          |\n|    iterations           | 49           |\n|    time_elapsed         | 353          |\n|    total_timesteps      | 200704       |\n| train/                  |              |\n|    approx_kl            | 0.0017622691 |\n|    clip_fraction        | 0.00596      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.12        |\n|    explained_variance   | 0.102        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.48e+04     |\n|    n_updates            | 480          |\n|    policy_gradient_loss | -0.00298     |\n|    std                  | 0.74         |\n|    value_loss           | 5.53e+04     |\n------------------------------------------\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7f7c5709fc10>"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"def evaluate_model_curves(model, user_data_dict, n_eval_samples=10000):\n    predictions = []\n    true_labels = []\n    anomaly_scores = []\n    \n    # Sample users for evaluation\n    sampled_users = np.random.choice(\n        list(user_data_dict.keys()),\n        size=min(len(user_data_dict), n_eval_samples // 10),\n        replace=False\n    )\n    \n    for user in sampled_users:\n        data = user_data_dict[user]\n        for i in range(len(data['X'])):\n            obs = data['X'][i]\n            action, _ = model.predict(obs, deterministic=True)\n            true_label = data['y'][i]\n            threshold = data['thresholds'][i]\n            \n            pred = 1 if action[0] >= threshold else 0\n            \n            predictions.append(pred)\n            true_labels.append(true_label)\n            anomaly_scores.append(action[0])\n\n    # Metrics\n    precision = precision_score(true_labels, predictions, zero_division=0)\n    recall = recall_score(true_labels, predictions, zero_division=0)\n    f1 = f1_score(true_labels, predictions, zero_division=0)\n    auc_score = roc_auc_score(true_labels, anomaly_scores) if len(np.unique(true_labels)) > 1 else 0.0\n\n    # Compute FPR using confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    tn, fp, fn, tp = cm.ravel()\n    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n\n    # Confusion matrix plot\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n                xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # ROC curve\n    fpr_roc, tpr, _ = roc_curve(true_labels, anomaly_scores)\n    roc_auc = auc(fpr_roc, tpr)\n    plt.figure()\n    plt.plot(fpr_roc, tpr, label=f\"ROC curve (AUC = {roc_auc:.4f})\")\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve\")\n    plt.legend(loc=\"best\")\n    plt.show()\n\n    # PR curve\n    precision_pr, recall_pr, _ = precision_recall_curve(true_labels, anomaly_scores)\n    plt.figure()\n    plt.plot(recall_pr, precision_pr, label=\"Precision-Recall curve\")\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision-Recall Curve\")\n    plt.legend(loc=\"best\")\n    plt.show()\n\n    # Print results\n    print(f\"Class balance: {np.mean(true_labels):.4f} anomalies\")\n    print(f\"Evaluation Metrics (n={len(predictions)} samples):\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"FPR: {fpr:.4f}\")\n    print(f\"AUC-ROC: {auc_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T06:08:53.656329Z","iopub.execute_input":"2025-05-07T06:08:53.657059Z","iopub.status.idle":"2025-05-07T06:08:53.668225Z","shell.execute_reply.started":"2025-05-07T06:08:53.657034Z","shell.execute_reply":"2025-05-07T06:08:53.667486Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"evaluate_model_curves(model, user_data_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T06:08:59.647772Z","iopub.execute_input":"2025-05-07T06:08:59.648084Z","iopub.status.idle":"2025-05-07T06:12:10.845758Z","shell.execute_reply.started":"2025-05-07T06:08:59.648061Z","shell.execute_reply":"2025-05-07T06:12:10.844986Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Class balance: 0.0041 anomalies\nEvaluation Metrics (n=330285 samples):\nPrecision: 0.0921\nRecall: 0.6298\nF1 Score: 0.1607\nFPR: 0.0258\nAUC-ROC: 0.8788\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"model.save('xgboost-guided-ppo-improved')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T06:15:02.804613Z","iopub.execute_input":"2025-05-07T06:15:02.805215Z","iopub.status.idle":"2025-05-07T06:15:02.820839Z","shell.execute_reply.started":"2025-05-07T06:15:02.805189Z","shell.execute_reply":"2025-05-07T06:15:02.820254Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}