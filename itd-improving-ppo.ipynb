{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11422967,"sourceType":"datasetVersion","datasetId":7153855},{"sourceId":11424466,"sourceType":"datasetVersion","datasetId":7154956},{"sourceId":11673316,"sourceType":"datasetVersion","datasetId":7326109},{"sourceId":11703407,"sourceType":"datasetVersion","datasetId":7345979}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:18:45.707762Z","iopub.status.idle":"2025-05-21T16:18:45.710287Z","shell.execute_reply.started":"2025-05-21T16:18:45.707990Z","shell.execute_reply":"2025-05-21T16:18:45.708007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade pip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:25:43.607367Z","iopub.execute_input":"2025-05-21T16:25:43.607699Z","iopub.status.idle":"2025-05-21T16:25:49.310552Z","shell.execute_reply.started":"2025-05-21T16:25:43.607670Z","shell.execute_reply":"2025-05-21T16:25:49.304847Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-25.1.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"pip install stable-baselines3[extra]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:30:26.962846Z","iopub.execute_input":"2025-05-21T16:30:26.963178Z","iopub.status.idle":"2025-05-21T16:30:31.758462Z","shell.execute_reply.started":"2025-05-21T16:30:26.963149Z","shell.execute_reply":"2025-05-21T16:30:31.752010Z"}},"outputs":[{"name":"stdout","text":"Collecting stable-baselines3[extra]\n  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\nCollecting gymnasium<1.2.0,>=0.29.1 (from stable-baselines3[extra])\n  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.0.2)\nRequirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.6.0)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (3.1.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (3.10.1)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (4.11.0.86)\nCollecting pygame (from stable-baselines3[extra])\n  Downloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (2.18.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (7.0.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (4.67.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (14.0.0)\nCollecting ale-py>=0.9.0 (from stable-baselines3[extra])\n  Downloading ale_py-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/site-packages (from stable-baselines3[extra]) (11.1.0)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/site-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (4.13.1)\nCollecting farama-notifications>=0.0.1 (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra])\n  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\nRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.2)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.72.0rc1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.4)\nRequirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (78.1.0)\nRequirement already satisfied: six>1.9 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas->stable-baselines3[extra]) (2025.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich->stable-baselines3[extra]) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich->stable-baselines3[extra]) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\nDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\nDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ale_py-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\nDownloading pygame-2.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: farama-notifications, pygame, gymnasium, ale-py, stable-baselines3\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [stable-baselines3]stable-baselines3]\n\u001b[1A\u001b[2KSuccessfully installed ale-py-0.11.0 farama-notifications-0.0.4 gymnasium-1.1.1 pygame-2.6.1 stable-baselines3-2.6.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Dropout, RepeatVector, TimeDistributed, Masking, BatchNormalization, Bidirectional\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport tensorflow as tf\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nimport gym\nfrom gym import spaces","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:24.581887Z","iopub.execute_input":"2025-05-21T16:38:24.582170Z","iopub.status.idle":"2025-05-21T16:38:24.594293Z","shell.execute_reply.started":"2025-05-21T16:38:24.582147Z","shell.execute_reply":"2025-05-21T16:38:24.588231Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from tensorflow.keras.layers import Lambda, TimeDistributed\nfrom tensorflow.keras.models import Model\nimport tensorflow.keras.backend as K","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:26.581961Z","iopub.execute_input":"2025-05-21T16:38:26.582263Z","iopub.status.idle":"2025-05-21T16:38:26.593752Z","shell.execute_reply.started":"2025-05-21T16:38:26.582239Z","shell.execute_reply":"2025-05-21T16:38:26.588030Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import os\nfrom tensorflow.keras.models import save_model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, Layer\nimport ast\nfrom sklearn.preprocessing import OneHotEncoder\nimport json\nfrom collections import defaultdict, deque","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:31.022728Z","iopub.execute_input":"2025-05-21T16:38:31.023019Z","iopub.status.idle":"2025-05-21T16:38:31.034437Z","shell.execute_reply.started":"2025-05-21T16:38:31.022995Z","shell.execute_reply":"2025-05-21T16:38:31.028560Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense\nimport random\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:32.843536Z","iopub.execute_input":"2025-05-21T16:38:32.843842Z","iopub.status.idle":"2025-05-21T16:38:32.854606Z","shell.execute_reply.started":"2025-05-21T16:38:32.843818Z","shell.execute_reply":"2025-05-21T16:38:32.848782Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:33.522041Z","iopub.execute_input":"2025-05-21T16:38:33.522349Z","iopub.status.idle":"2025-05-21T16:38:33.768854Z","shell.execute_reply.started":"2025-05-21T16:38:33.522324Z","shell.execute_reply":"2025-05-21T16:38:33.762340Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve, auc, precision_score, recall_score, f1_score, matthews_corrcoef, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Lambda, RepeatVector, TimeDistributed, Dropout, Attention\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:35.562223Z","iopub.execute_input":"2025-05-21T16:38:35.562852Z","iopub.status.idle":"2025-05-21T16:38:35.575641Z","shell.execute_reply.started":"2025-05-21T16:38:35.562820Z","shell.execute_reply":"2025-05-21T16:38:35.569057Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:36.862434Z","iopub.execute_input":"2025-05-21T16:38:36.862724Z","iopub.status.idle":"2025-05-21T16:38:37.127690Z","shell.execute_reply.started":"2025-05-21T16:38:36.862700Z","shell.execute_reply":"2025-05-21T16:38:37.122755Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/lstm-vae/user_day_sequences (3).csv')\ndata = data['activity_sequence']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:04.629519Z","iopub.execute_input":"2025-05-04T14:31:04.630107Z","iopub.status.idle":"2025-05-04T14:31:04.962114Z","shell.execute_reply.started":"2025-05-04T14:31:04.630082Z","shell.execute_reply":"2025-05-04T14:31:04.961514Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_int_list(activity_sequence):\n    try:\n        int_list = ast.literal_eval(activity_sequence)\n\n        if all(isinstance(item, int) for item in int_list):\n          return int_list\n        else:\n          return [int(x) for x in int_list]\n    except (SyntaxError, ValueError):\n        print(f\"Invalid activity sequence: {activity_sequence}\")\n        return [] \n\ndata = data.apply(convert_to_int_list) # Corrected line to apply function to the Series directly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:06.284706Z","iopub.execute_input":"2025-05-04T14:31:06.285314Z","iopub.status.idle":"2025-05-04T14:31:12.131852Z","shell.execute_reply.started":"2025-05-04T14:31:06.285287Z","shell.execute_reply":"2025-05-04T14:31:12.131308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.132820Z","iopub.execute_input":"2025-05-04T14:31:12.133077Z","iopub.status.idle":"2025-05-04T14:31:12.203791Z","shell.execute_reply.started":"2025-05-04T14:31:12.133054Z","shell.execute_reply":"2025-05-04T14:31:12.203205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = data.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.204515Z","iopub.execute_input":"2025-05-04T14:31:12.205007Z","iopub.status.idle":"2025-05-04T14:31:12.283692Z","shell.execute_reply.started":"2025-05-04T14:31:12.204965Z","shell.execute_reply":"2025-05-04T14:31:12.283195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parse strings to lists\nsequences = [seq for seq in df]\n\n# Get unique labels\nall_labels = set()\nfor seq in sequences:\n    all_labels.update(seq)\nlabels = sorted(list(all_labels)) \nV = len(labels)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.285188Z","iopub.execute_input":"2025-05-04T14:31:12.285527Z","iopub.status.idle":"2025-05-04T14:31:12.459488Z","shell.execute_reply.started":"2025-05-04T14:31:12.285505Z","shell.execute_reply":"2025-05-04T14:31:12.458710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = OneHotEncoder(categories=[labels], handle_unknown='ignore') \nmax_len = 86  #longest sequence\n\n# Converting sequences to one-hot encoded arrays\nX = []\nfor seq in sequences:\n    seq_array = np.array(seq).reshape(-1, 1)\n    one_hot = encoder.fit_transform(seq_array).toarray() \n    # Pad to max_len\n    padded = np.pad(one_hot, ((0, max_len - len(seq)), (0, 0)), mode='constant')  # Shape: (max_len, V)\n    X.append(padded)\nX = np.array(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:31:12.460178Z","iopub.execute_input":"2025-05-04T14:31:12.460385Z","iopub.status.idle":"2025-05-04T14:34:01.981615Z","shell.execute_reply.started":"2025-05-04T14:31:12.460369Z","shell.execute_reply":"2025-05-04T14:34:01.981003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('X.npy', X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:34:01.983251Z","iopub.execute_input":"2025-05-04T14:34:01.983493Z","iopub.status.idle":"2025-05-04T14:34:03.720854Z","shell.execute_reply.started":"2025-05-04T14:34:01.983476Z","shell.execute_reply":"2025-05-04T14:34:03.720020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:21:05.609170Z","iopub.execute_input":"2025-05-04T13:21:05.609383Z","iopub.status.idle":"2025-05-04T13:21:05.615395Z","shell.execute_reply.started":"2025-05-04T13:21:05.609366Z","shell.execute_reply":"2025-05-04T13:21:05.614520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:48:58.559838Z","iopub.execute_input":"2025-05-04T13:48:58.560166Z","iopub.status.idle":"2025-05-04T13:48:58.567966Z","shell.execute_reply.started":"2025-05-04T13:48:58.560106Z","shell.execute_reply":"2025-05-04T13:48:58.567373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = np.load('/kaggle/working/X.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:30:31.055242Z","iopub.execute_input":"2025-05-04T14:30:31.055538Z","iopub.status.idle":"2025-05-04T14:30:31.103283Z","shell.execute_reply.started":"2025-05-04T14:30:31.055516Z","shell.execute_reply":"2025-05-04T14:30:31.102539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"viewing and selecting top features","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv('/kaggle/input/features-extracted/final_features_extracted.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:49:02.784123Z","iopub.execute_input":"2025-05-04T13:49:02.784789Z","iopub.status.idle":"2025-05-04T13:49:03.534254Z","shell.execute_reply.started":"2025-05-04T13:49:02.784764Z","shell.execute_reply":"2025-05-04T13:49:03.533609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:32:27.391777Z","iopub.execute_input":"2025-05-04T13:32:27.392053Z","iopub.status.idle":"2025-05-04T13:32:27.465797Z","shell.execute_reply.started":"2025-05-04T13:32:27.392032Z","shell.execute_reply":"2025-05-04T13:32:27.465036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:32:30.501588Z","iopub.execute_input":"2025-05-04T13:32:30.502163Z","iopub.status.idle":"2025-05-04T13:32:30.506892Z","shell.execute_reply.started":"2025-05-04T13:32:30.502139Z","shell.execute_reply":"2025-05-04T13:32:30.506300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df_forseq = pd.read_csv('/kaggle/input/reqd-data-lstmrl/merged_df.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:34:03.721737Z","iopub.execute_input":"2025-05-04T14:34:03.721993Z","iopub.status.idle":"2025-05-04T14:34:05.068325Z","shell.execute_reply.started":"2025-05-04T14:34:03.721956Z","shell.execute_reply":"2025-05-04T14:34:05.067458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_to_encode = merged_df_forseq['aggregated_sequence']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:40:21.925904Z","iopub.execute_input":"2025-05-04T15:40:21.926687Z","iopub.status.idle":"2025-05-04T15:40:21.929956Z","shell.execute_reply.started":"2025-05-04T15:40:21.926661Z","shell.execute_reply":"2025-05-04T15:40:21.929325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_to_encode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T13:32:37.161391Z","iopub.execute_input":"2025-05-04T13:32:37.161687Z","iopub.status.idle":"2025-05-04T13:32:37.167406Z","shell.execute_reply.started":"2025-05-04T13:32:37.161662Z","shell.execute_reply":"2025-05-04T13:32:37.166850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AttentionLSTMVAE:\n    def __init__(self, vocab_size, max_len, hidden_size=32, latent_dim=8):\n        self.vocab_size = vocab_size\n        self.max_len = max_len\n        self.hidden_size = hidden_size\n        self.latent_dim = latent_dim\n        self.model = self.build_model()\n\n    def sampling(self, args):\n        mu, log_var = args\n        epsilon = K.random_normal(shape=(K.shape(mu)[0], self.latent_dim))\n        return mu + K.exp(0.5 * log_var) * epsilon\n\n    def build_model(self):\n        # Encoder\n        inputs = Input(shape=(self.max_len, self.vocab_size))\n        h = LSTM(self.hidden_size, return_sequences=True)(inputs)\n        h = Attention()([h, h])  # Self-attention\n        h = LSTM(self.hidden_size)(h)  # Aggregate sequence\n        mu = Dense(self.latent_dim, name='mu')(h)\n        log_var = Dense(self.latent_dim, name='log_var')(h)\n        z = Lambda(self.sampling, output_shape=(self.latent_dim,), name='z')([mu, log_var])\n\n        # Decoder\n        z_repeated = RepeatVector(self.max_len)(z)\n        decoder_out = LSTM(self.hidden_size, return_sequences=True)(z_repeated)\n        decoder_out = Attention()([decoder_out, decoder_out])  # Self-attention\n        outputs = TimeDistributed(Dense(self.vocab_size, activation='softmax'))(decoder_out)\n\n        # Custom Loss Layer\n        class VAELossLayer(tf.keras.layers.Layer):\n            def __init__(self, max_len, **kwargs):\n                super(VAELossLayer, self).__init__(**kwargs)\n                self.max_len = max_len\n\n            def call(self, inputs):\n                x, x_decoded, mu, log_var = inputs\n                # Reconstruction loss\n                recon_loss = tf.reduce_mean(\n                    tf.keras.losses.categorical_crossentropy(x, x_decoded)\n                ) * self.max_len\n                # KL divergence\n                kl_loss = -0.5 * tf.reduce_mean(\n                    1 + log_var - tf.square(mu) - tf.exp(log_var)\n                )\n                # Add loss\n                self.add_loss(recon_loss + 0.1 * kl_loss)\n                return x_decoded\n\n        loss_layer = VAELossLayer(self.max_len)\n        outputs = loss_layer([inputs, outputs, mu, log_var])\n\n        vae = Model(inputs, outputs)\n        vae.compile(optimizer='adam')\n        return vae\n\n    def get_encoder(self):\n        encoder = Model(self.model.input, self.model.get_layer('z').output)\n        return encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:42.645950Z","iopub.execute_input":"2025-05-04T14:35:42.646539Z","iopub.status.idle":"2025-05-04T14:35:42.655415Z","shell.execute_reply.started":"2025-05-04T14:35:42.646517Z","shell.execute_reply":"2025-05-04T14:35:42.654659Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"V = 12\nmax_len = 86\nvae = AttentionLSTMVAE(\n        vocab_size=V,\n        max_len=max_len\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:46.665133Z","iopub.execute_input":"2025-05-04T14:35:46.665373Z","iopub.status.idle":"2025-05-04T14:35:46.749080Z","shell.execute_reply.started":"2025-05-04T14:35:46.665357Z","shell.execute_reply":"2025-05-04T14:35:46.748557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vae.model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:46.964292Z","iopub.execute_input":"2025-05-04T14:35:46.964826Z","iopub.status.idle":"2025-05-04T14:35:46.985931Z","shell.execute_reply.started":"2025-05-04T14:35:46.964807Z","shell.execute_reply":"2025-05-04T14:35:46.985275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_size = 0.6\nval_size = 0.2\ntest_size = 0.2\n# Split into train+val and test\nX_train_val, X_test = train_test_split(\n            X, test_size=test_size, random_state=42\n        )\n        \n# Split train+val into train and val\nval_size_adjusted = val_size / (train_size + val_size)  # Adjust for train+val proportion\nX_train, X_val = train_test_split(\n            X_train_val, test_size=val_size_adjusted, random_state=42\n        )\n        \nprint(f\"Train samples: {X_train.shape[0]}\")\nprint(f\"Validation samples: {X_val.shape[0]}\")\nprint(f\"Test samples: {X_test.shape[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:35:49.979959Z","iopub.execute_input":"2025-05-04T14:35:49.980531Z","iopub.status.idle":"2025-05-04T14:35:51.382254Z","shell.execute_reply.started":"2025-05-04T14:35:49.980505Z","shell.execute_reply":"2025-05-04T14:35:51.381615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = vae.model.fit(\n            X_train, X_train,\n            epochs=10,\n            batch_size=32,\n            validation_data=(X_val, None),\n            verbose=1\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:36:02.665680Z","iopub.execute_input":"2025-05-04T14:36:02.665924Z","iopub.status.idle":"2025-05-04T14:57:43.579703Z","shell.execute_reply.started":"2025-05-04T14:36:02.665908Z","shell.execute_reply":"2025-05-04T14:57:43.579036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_vae_model(vae, save_dir=\"/kaggle/working/vae_model\"):\n    \"\"\"Save all components of the VAE\"\"\"\n    os.makedirs(save_dir, exist_ok=True)\n    \n    # Save models\n    save_model(vae.model, os.path.join(save_dir, \"vae.h5\"))\n    save_model(vae.get_encoder(), os.path.join(save_dir, \"encoder.h5\"))\n\n    # Save config\n    config = {\n        'vocab_size': vae.vocab_size,\n        'max_len': vae.max_len,\n        'hidden_size': vae.hidden_size,\n        'latent_dim': vae.latent_dim\n    }\n    with open(os.path.join(save_dir, 'config.json'), 'w') as f:\n        json.dump(config, f)\n    \n    print(f\"Model saved to {save_dir}\")\n\nsave_vae_model(vae, \"attention_lstmvae_1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:57:55.765932Z","iopub.execute_input":"2025-05-04T14:57:55.766674Z","iopub.status.idle":"2025-05-04T14:57:55.844465Z","shell.execute_reply.started":"2025-05-04T14:57:55.766645Z","shell.execute_reply":"2025-05-04T14:57:55.843951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:38:02.978771Z","iopub.execute_input":"2025-05-06T15:38:02.978984Z","iopub.status.idle":"2025-05-06T15:38:02.990457Z","shell.execute_reply.started":"2025-05-06T15:38:02.978967Z","shell.execute_reply":"2025-05-06T15:38:02.989703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_vae(vae, X_test, history, index_to_token=None, batch_size=32):\n    try:\n        # Set matplotlib backend\n        plt.switch_backend('Agg')\n\n        # Define loss functions\n        def compute_recon_loss(x, x_pred):\n            return tf.reduce_mean(\n                tf.keras.losses.categorical_crossentropy(x, x_pred)\n            ) * vae.max_len\n\n        def compute_kl_loss(mu, log_var):\n            return -0.5 * tf.reduce_mean(1 + log_var - tf.square(mu) - tf.exp(log_var))\n\n        # Evaluate\n        encoder = vae.get_encoder()\n        mu_model = Model(vae.model.input, vae.model.get_layer('mu').output)\n        log_var_model = Model(vae.model.input, vae.model.get_layer('log_var').output)\n\n        X_pred = vae.model.predict(X_test, batch_size=batch_size)\n        mu = mu_model.predict(X_test, batch_size=batch_size)\n        log_var = log_var_model.predict(X_test, batch_size=batch_size)\n\n        recon_loss = compute_recon_loss(X_test, X_pred).numpy()\n        kl_loss = compute_kl_loss(mu, log_var).numpy()\n        total_loss = recon_loss + 0.1 * kl_loss\n\n        print(f\"Test Set Metrics:\")\n        print(f\"Reconstruction Loss: {recon_loss:.4f}\")\n        print(f\"KL Divergence: {kl_loss:.4f}\")\n        print(f\"Total Loss: {total_loss:.4f}\")\n\n        # Visualization 1: Loss Curves\n        plt.figure(figsize=(10, 6))\n        plt.plot(history.history['loss'], label='Training Loss')\n        plt.plot(history.history['val_loss'], label='Validation Loss')\n        plt.axhline(y=total_loss, color='r', linestyle='--', label='Test Loss')\n        plt.title('Training, Validation, and Test Loss')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss')\n        plt.legend()\n        plt.grid(True)\n        plt.show()\n\n        # Visualization 2: Latent Space\n        z = encoder.predict(X_test, batch_size=batch_size)\n        if vae.latent_dim > 2:\n            z_embedded = TSNE(n_components=2, random_state=42).fit_transform(z)\n        else:\n            z_embedded = z\n        plt.figure(figsize=(8, 6))\n        plt.scatter(z_embedded[:, 0], z_embedded[:, 1], alpha=0.5, s=10)\n        plt.title('Latent Space Visualization (Test Set)')\n        plt.xlabel('Component 1')\n        plt.ylabel('Component 2')\n        plt.grid(True)\n        plt.show()\n\n        # Visualization 3: Reconstructed Sequences\n        plt.figure(figsize=(12, 10))\n        for i in range(min(5, X_test.shape[0])):\n            orig_seq = np.argmax(X_test[i], axis=-1)\n            pred_seq = np.argmax(X_pred[i], axis=-1)\n            \n            if index_to_token:\n                orig_text = ''.join([index_to_token[idx] for idx in orig_seq])\n                pred_text = ''.join([index_to_token[idx] for idx in pred_seq])\n            else:\n                orig_text = str(orig_seq)\n                pred_text = str(pred_seq)\n            \n            plt.subplot(5, 2, 2 * i + 1)\n            sns.heatmap(X_test[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Original Sequence {i+1}\\n{orig_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n            \n            plt.subplot(5, 2, 2 * i + 2)\n            sns.heatmap(X_pred[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Reconstructed Sequence {i+1}\\n{pred_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n        \n        plt.tight_layout()\n        plt.show()\n\n        return {\n            'recon_loss': recon_loss,\n            'kl_loss': kl_loss,\n            'total_loss': total_loss\n        }\n    \n    except Exception as e:\n        print(f\"Error in evaluate_vae: {str(e)}\")\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T14:58:20.705604Z","iopub.execute_input":"2025-05-04T14:58:20.706148Z","iopub.status.idle":"2025-05-04T14:58:20.718559Z","shell.execute_reply.started":"2025-05-04T14:58:20.706123Z","shell.execute_reply":"2025-05-04T14:58:20.717745Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:14:56.879917Z","iopub.status.idle":"2025-05-21T15:14:56.881709Z","shell.execute_reply.started":"2025-05-21T15:14:56.880047Z","shell.execute_reply":"2025-05-21T15:14:56.880060Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"index_to_token = {i: chr(65 + i) for i in range(V)}\nmetrics = evaluate_vae(vae, X_test, history, index_to_token=index_to_token, batch_size=32)\nif metrics is None:\n        print(\"Evaluation failed. Check test data or model predictions.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:11:40.660682Z","iopub.execute_input":"2025-05-04T15:11:40.661756Z","iopub.status.idle":"2025-05-04T15:19:23.907303Z","shell.execute_reply.started":"2025-05-04T15:11:40.661725Z","shell.execute_reply":"2025-05-04T15:19:23.906735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = vae.get_encoder()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:23:46.626119Z","iopub.execute_input":"2025-05-04T15:23:46.626402Z","iopub.status.idle":"2025-05-04T15:23:46.631652Z","shell.execute_reply.started":"2025-05-04T15:23:46.626381Z","shell.execute_reply":"2025-05-04T15:23:46.631125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"z = encoder.predict(X_test, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:31:28.065872Z","iopub.execute_input":"2025-05-04T15:31:28.066183Z","iopub.status.idle":"2025-05-04T15:31:36.735099Z","shell.execute_reply.started":"2025-05-04T15:31:28.066158Z","shell.execute_reply":"2025-05-04T15:31:36.734395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_pred = vae.model.predict(X_test, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:32:10.776054Z","iopub.execute_input":"2025-05-04T15:32:10.776746Z","iopub.status.idle":"2025-05-04T15:32:25.105814Z","shell.execute_reply.started":"2025-05-04T15:32:10.776721Z","shell.execute_reply":"2025-05-04T15:32:25.105229Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"z_embedded = TSNE(n_components=2, random_state=42).fit_transform(z)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:32:47.231713Z","iopub.execute_input":"2025-05-04T15:32:47.232160Z","iopub.status.idle":"2025-05-04T15:33:21.122691Z","shell.execute_reply.started":"2025-05-04T15:32:47.232136Z","shell.execute_reply":"2025-05-04T15:33:21.121683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(z_embedded[:, 0], z_embedded[:, 1], alpha=0.5, s=10)\nplt.title('Latent Space Visualization (Test Set)')\nplt.xlabel('Component 1')\nplt.ylabel('Component 2')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nif vae.latent_dim > 2:\n            \nelse:\n        z_embedded = z\n        plt.figure(figsize=(8, 6))\n        plt.scatter(z_embedded[:, 0], z_embedded[:, 1], alpha=0.5, s=10)\n        plt.title('Latent Space Visualization (Test Set)')\n        plt.xlabel('Component 1')\n        plt.ylabel('Component 2')\n        plt.grid(True)\n        plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:25:23.765844Z","iopub.execute_input":"2025-05-04T15:25:23.766130Z","iopub.status.idle":"2025-05-04T15:31:04.859916Z","shell.execute_reply.started":"2025-05-04T15:25:23.766108Z","shell.execute_reply":"2025-05-04T15:31:04.858880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nfor i in range(min(5, X_test.shape[0])):\n            orig_seq = np.argmax(X_test[i], axis=-1)\n            pred_seq = np.argmax(X_pred[i], axis=-1)\n            \n            if index_to_token:\n                orig_text = ''.join([index_to_token[idx] for idx in orig_seq])\n                pred_text = ''.join([index_to_token[idx] for idx in pred_seq])\n            else:\n                orig_text = str(orig_seq)\n                pred_text = str(pred_seq)\n            \n            plt.subplot(5, 2, 2 * i + 1)\n            sns.heatmap(X_test[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Original Sequence {i+1}\\n{orig_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n            \n            plt.subplot(5, 2, 2 * i + 2)\n            sns.heatmap(X_pred[i].T, cbar=False, cmap='viridis')\n            plt.title(f'Reconstructed Sequence {i+1}\\n{pred_text[:50]}...')\n            plt.xlabel('Time Step')\n            plt.ylabel('Vocabulary')\n        \n            plt.tight_layout()\n            plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:31:10.845136Z","iopub.execute_input":"2025-05-04T15:31:10.845398Z","iopub.status.idle":"2025-05-04T15:31:10.868885Z","shell.execute_reply.started":"2025-05-04T15:31:10.845377Z","shell.execute_reply":"2025-05-04T15:31:10.867965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"beh = pd.read_csv('/kaggle/input/reqd-data-lstmrl/beh.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:57.547622Z","iopub.execute_input":"2025-05-06T07:31:57.548191Z","iopub.status.idle":"2025-05-06T07:31:57.609061Z","shell.execute_reply.started":"2025-05-06T07:31:57.548168Z","shell.execute_reply":"2025-05-06T07:31:57.608404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info = pd.read_csv('/kaggle/input/reqd-data-lstmrl/merged_df.csv')\ninfo = info.drop(columns={'Unnamed: 0'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:57.827109Z","iopub.execute_input":"2025-05-06T07:31:57.827761Z","iopub.status.idle":"2025-05-06T07:31:58.846659Z","shell.execute_reply.started":"2025-05-06T07:31:57.827736Z","shell.execute_reply":"2025-05-06T07:31:58.845931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:59.526934Z","iopub.execute_input":"2025-05-06T07:31:59.527584Z","iopub.status.idle":"2025-05-06T07:31:59.648983Z","shell.execute_reply.started":"2025-05-06T07:31:59.527559Z","shell.execute_reply":"2025-05-06T07:31:59.648153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info = info.iloc[:,:22]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:03.427421Z","iopub.execute_input":"2025-05-06T07:32:03.428083Z","iopub.status.idle":"2025-05-06T07:32:03.451560Z","shell.execute_reply.started":"2025-05-06T07:32:03.428057Z","shell.execute_reply":"2025-05-06T07:32:03.450851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:03.786888Z","iopub.execute_input":"2025-05-06T07:32:03.787527Z","iopub.status.idle":"2025-05-06T07:32:03.893276Z","shell.execute_reply.started":"2025-05-06T07:32:03.787504Z","shell.execute_reply":"2025-05-06T07:32:03.892531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles = pd.read_csv('/kaggle/input/reqd-data-lstmrl/role_mappings_users.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:08.012455Z","iopub.execute_input":"2025-05-06T07:32:08.012719Z","iopub.status.idle":"2025-05-06T07:32:08.021841Z","shell.execute_reply.started":"2025-05-06T07:32:08.012699Z","shell.execute_reply":"2025-05-06T07:32:08.021164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles['role'] = (\n    roles['role_0'] * 1 + \n    roles['role_1'] * 2 + \n    roles['role_2'] * 4 + \n    roles['role_3'] * 8\n)\n\n# Create role lookup dictionary\nrole_lookup = dict(zip(roles['user'], roles['role']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:32:15.122360Z","iopub.execute_input":"2025-05-06T07:32:15.122987Z","iopub.status.idle":"2025-05-06T07:32:15.128733Z","shell.execute_reply.started":"2025-05-06T07:32:15.122965Z","shell.execute_reply":"2025-05-06T07:32:15.128121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seq_to_encode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:40:49.755760Z","iopub.execute_input":"2025-05-04T15:40:49.756040Z","iopub.status.idle":"2025-05-04T15:40:49.762132Z","shell.execute_reply.started":"2025-05-04T15:40:49.756022Z","shell.execute_reply":"2025-05-04T15:40:49.761396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if isinstance(seq_to_encode, str):\n    seq_to_encode = ast.literal_eval(seq_to_encode)  # Convert to a real list\n\n# If seq_to_encode is a pandas Series or list of lists (non-strings), ensure it's in the right format\nif isinstance(seq_to_encode, list) or isinstance(seq_to_encode, pd.Series):\n    # You might need to process each item in the series individually if they're not already lists\n    seq_to_encode = [ast.literal_eval(str(item)) if isinstance(item, str) else item for item in seq_to_encode]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:43:45.630804Z","iopub.execute_input":"2025-05-04T15:43:45.631153Z","iopub.status.idle":"2025-05-04T15:43:49.742241Z","shell.execute_reply.started":"2025-05-04T15:43:45.631128Z","shell.execute_reply":"2025-05-04T15:43:49.741637Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(seq_to_encode[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:43:49.743386Z","iopub.execute_input":"2025-05-04T15:43:49.743680Z","iopub.status.idle":"2025-05-04T15:43:49.748266Z","shell.execute_reply.started":"2025-05-04T15:43:49.743657Z","shell.execute_reply":"2025-05-04T15:43:49.747677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = OneHotEncoder(categories=[labels], handle_unknown='ignore') \nmax_len = 86  #longest sequence\n\n# Converting sequences to one-hot encoded arrays\nseqs = []\nfor seq in seq_to_encode:\n    seq_array = np.array(seq).reshape(-1, 1)\n    one_hot = encoder.fit_transform(seq_array).toarray() \n    # Pad to max_len\n    padded = np.pad(one_hot, ((0, max_len - len(seq)), (0, 0)), mode='constant')  # Shape: (max_len, V)\n    seqs.append(padded)\nseqs = np.array(seqs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:43:53.685009Z","iopub.execute_input":"2025-05-04T15:43:53.685361Z","iopub.status.idle":"2025-05-04T15:46:41.625617Z","shell.execute_reply.started":"2025-05-04T15:43:53.685334Z","shell.execute_reply":"2025-05-04T15:46:41.625023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seqs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:46:41.627311Z","iopub.execute_input":"2025-05-04T15:46:41.627524Z","iopub.status.idle":"2025-05-04T15:46:41.633919Z","shell.execute_reply.started":"2025-05-04T15:46:41.627509Z","shell.execute_reply":"2025-05-04T15:46:41.633252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"seqs.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:46:41.634532Z","iopub.execute_input":"2025-05-04T15:46:41.634773Z","iopub.status.idle":"2025-05-04T15:46:41.651170Z","shell.execute_reply.started":"2025-05-04T15:46:41.634748Z","shell.execute_reply":"2025-05-04T15:46:41.650491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('seqs.npy', seqs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:47:46.725546Z","iopub.execute_input":"2025-05-04T15:47:46.725818Z","iopub.status.idle":"2025-05-04T15:47:49.339692Z","shell.execute_reply.started":"2025-05-04T15:47:46.725796Z","shell.execute_reply":"2025-05-04T15:47:49.338787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(seq_to_encode)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:36:24.865779Z","iopub.execute_input":"2025-05-04T15:36:24.866421Z","iopub.status.idle":"2025-05-04T15:36:24.870762Z","shell.execute_reply.started":"2025-05-04T15:36:24.866398Z","shell.execute_reply":"2025-05-04T15:36:24.870090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = vae.get_encoder()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:48:18.986050Z","iopub.execute_input":"2025-05-04T15:48:18.986329Z","iopub.status.idle":"2025-05-04T15:48:18.991512Z","shell.execute_reply.started":"2025-05-04T15:48:18.986310Z","shell.execute_reply":"2025-05-04T15:48:18.990811Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tensor = tf.convert_to_tensor(seqs, dtype=tf.float32)\nmu_all = encoder.predict(tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:48:23.584964Z","iopub.execute_input":"2025-05-04T15:48:23.585256Z","iopub.status.idle":"2025-05-04T15:49:05.762449Z","shell.execute_reply.started":"2025-05-04T15:48:23.585233Z","shell.execute_reply":"2025-05-04T15:49:05.761822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:49:05.763646Z","iopub.execute_input":"2025-05-04T15:49:05.763865Z","iopub.status.idle":"2025-05-04T15:49:05.768422Z","shell.execute_reply.started":"2025-05-04T15:49:05.763848Z","shell.execute_reply":"2025-05-04T15:49:05.767881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_latent = pd.DataFrame(index=range(seqs.shape[0]))\n\ndf_latent['latent_vector'] = list(mu_all)\n\n# Verify latent vectors\nprint(\"Latent vector shape:\", mu_all.shape)\nprint(\"Sample latent vector:\", df_latent['latent_vector'].iloc[0])\n\nmu_mean = np.mean(mu_all, axis=0)\nmu_std = np.std(mu_all, axis=0)\nprint(\"Mu mean:\", mu_mean)  \nprint(\"Mu std:\", mu_std)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:49:37.605225Z","iopub.execute_input":"2025-05-04T15:49:37.605482Z","iopub.status.idle":"2025-05-04T15:49:37.726534Z","shell.execute_reply.started":"2025-05-04T15:49:37.605463Z","shell.execute_reply":"2025-05-04T15:49:37.725925Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_latent.to_pickle('vae_latent_vectors.pkl')  \nprint(\"Saved DataFrame to 'vae_latent_vectors.pkl'\")\nnp.save('mu_all.npy', mu_all)\nprint(\"Saved latent vectors to 'mu_all.npy'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:49:48.026102Z","iopub.execute_input":"2025-05-04T15:49:48.026369Z","iopub.status.idle":"2025-05-04T15:49:50.548646Z","shell.execute_reply.started":"2025-05-04T15:49:48.026348Z","shell.execute_reply":"2025-05-04T15:49:50.547874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_ids = info['user']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:06.788268Z","iopub.execute_input":"2025-05-06T07:33:06.788547Z","iopub.status.idle":"2025-05-06T07:33:06.792356Z","shell.execute_reply.started":"2025-05-06T07:33:06.788525Z","shell.execute_reply":"2025-05-06T07:33:06.791585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:06.665017Z","iopub.execute_input":"2025-05-04T15:57:06.665293Z","iopub.status.idle":"2025-05-04T15:57:06.669693Z","shell.execute_reply.started":"2025-05-04T15:57:06.665274Z","shell.execute_reply":"2025-05-04T15:57:06.669141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:15.405635Z","iopub.execute_input":"2025-05-04T15:57:15.405902Z","iopub.status.idle":"2025-05-04T15:57:15.475856Z","shell.execute_reply.started":"2025-05-04T15:57:15.405883Z","shell.execute_reply":"2025-05-04T15:57:15.475155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_combined = np.column_stack([\n    info,                # Original features (excluding VAE error)\n    np.array([role_lookup[uid] for uid in user_ids]),  # Lookup role for each user-day\n    mu_all                 # VAE reconstruction error\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:29.440557Z","iopub.execute_input":"2025-05-04T15:57:29.441027Z","iopub.status.idle":"2025-05-04T15:57:29.951069Z","shell.execute_reply.started":"2025-05-04T15:57:29.441000Z","shell.execute_reply":"2025-05-04T15:57:29.950249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_combined.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:37.984786Z","iopub.execute_input":"2025-05-04T15:57:37.985067Z","iopub.status.idle":"2025-05-04T15:57:37.989669Z","shell.execute_reply.started":"2025-05-04T15:57:37.985047Z","shell.execute_reply":"2025-05-04T15:57:37.989112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_combined = X_combined[:,2:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:51.946092Z","iopub.execute_input":"2025-05-04T15:57:51.946343Z","iopub.status.idle":"2025-05-04T15:57:51.949695Z","shell.execute_reply.started":"2025-05-04T15:57:51.946325Z","shell.execute_reply":"2025-05-04T15:57:51.949102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_combined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:57:53.885296Z","iopub.execute_input":"2025-05-04T15:57:53.885532Z","iopub.status.idle":"2025-05-04T15:57:53.890539Z","shell.execute_reply.started":"2025-05-04T15:57:53.885515Z","shell.execute_reply":"2025-05-04T15:57:53.890012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('X_combined', X_combined)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:50:12.265491Z","iopub.execute_input":"2025-05-04T15:50:12.265759Z","iopub.status.idle":"2025-05-04T15:50:12.809682Z","shell.execute_reply.started":"2025-05-04T15:50:12.265740Z","shell.execute_reply":"2025-05-04T15:50:12.808845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_combined.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T15:58:02.325687Z","iopub.execute_input":"2025-05-04T15:58:02.326365Z","iopub.status.idle":"2025-05-04T15:58:02.330700Z","shell.execute_reply.started":"2025-05-04T15:58:02.326338Z","shell.execute_reply":"2025-05-04T15:58:02.330026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:17:23.215957Z","iopub.execute_input":"2025-05-04T16:17:23.216242Z","iopub.status.idle":"2025-05-04T16:17:23.221658Z","shell.execute_reply.started":"2025-05-04T16:17:23.216222Z","shell.execute_reply":"2025-05-04T16:17:23.220960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temporal_features = [\n        'after_hours_logon_count', 'weekend_logon_flag', \n        'total_logon_count', 'after_hours_connects'\n    ]\ndevice_features = [\n        'device_connects', 'device_pc_count'\n    ]\nfile_features = [\n        'binary_files_accessed', 'text_files_accessed',\n        'file_type_entropy', 'sensitive_keyword_count', 'avg_content_word_count'\n    ]\nemail_features = [\n        'emails_sent', 'external_ratio', 'bcc_flag', 'total_recipients'\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:14:31.995888Z","iopub.execute_input":"2025-05-04T16:14:31.996433Z","iopub.status.idle":"2025-05-04T16:14:32.000364Z","shell.execute_reply.started":"2025-05-04T16:14:31.996410Z","shell.execute_reply":"2025-05-04T16:14:31.999807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:17:41.265850Z","iopub.execute_input":"2025-05-04T16:17:41.266208Z","iopub.status.idle":"2025-05-04T16:17:41.337536Z","shell.execute_reply.started":"2025-05-04T16:17:41.266185Z","shell.execute_reply":"2025-05-04T16:17:41.336817Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info.iloc[:,2:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:18:00.465421Z","iopub.execute_input":"2025-05-04T16:18:00.466025Z","iopub.status.idle":"2025-05-04T16:18:00.498583Z","shell.execute_reply.started":"2025-05-04T16:18:00.465976Z","shell.execute_reply":"2025-05-04T16:18:00.497969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\ninfo.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:42.987403Z","iopub.execute_input":"2025-05-06T07:33:42.987667Z","iopub.status.idle":"2025-05-06T07:33:43.177620Z","shell.execute_reply.started":"2025-05-06T07:33:42.987648Z","shell.execute_reply":"2025-05-06T07:33:43.176777Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:46.528652Z","iopub.execute_input":"2025-05-06T07:33:46.528945Z","iopub.status.idle":"2025-05-06T07:33:46.667077Z","shell.execute_reply.started":"2025-05-06T07:33:46.528922Z","shell.execute_reply":"2025-05-06T07:33:46.666339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"beh","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:50.677579Z","iopub.execute_input":"2025-05-06T07:33:50.678276Z","iopub.status.idle":"2025-05-06T07:33:50.691734Z","shell.execute_reply.started":"2025-05-06T07:33:50.678251Z","shell.execute_reply":"2025-05-06T07:33:50.691055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"beh.rename(columns={'Unnamed: 0': 'user'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:53.347310Z","iopub.execute_input":"2025-05-06T07:33:53.347572Z","iopub.status.idle":"2025-05-06T07:33:53.351949Z","shell.execute_reply.started":"2025-05-06T07:33:53.347551Z","shell.execute_reply":"2025-05-06T07:33:53.351185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"labels_df = beh.melt(\n    id_vars=['user'], \n    var_name='date', \n    value_name='is_anomaly'\n)\n\n# Convert to datetime and sort\nlabels_df['date'] = pd.to_datetime(labels_df['date'])\nlabels_df = labels_df.sort_values(['user', 'date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:53.867283Z","iopub.execute_input":"2025-05-06T07:33:53.867551Z","iopub.status.idle":"2025-05-06T07:33:54.007680Z","shell.execute_reply.started":"2025-05-06T07:33:53.867530Z","shell.execute_reply":"2025-05-06T07:33:54.007130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df = pd.read_csv('/kaggle/input/reqd-data-lstmrl/merged_df.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:57.387250Z","iopub.execute_input":"2025-05-06T07:33:57.387528Z","iopub.status.idle":"2025-05-06T07:33:58.042513Z","shell.execute_reply.started":"2025-05-06T07:33:57.387506Z","shell.execute_reply":"2025-05-06T07:33:58.041705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df = merged_df.rename(columns = {'date_only':'date'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:58.043662Z","iopub.execute_input":"2025-05-06T07:33:58.043946Z","iopub.status.idle":"2025-05-06T07:33:58.075953Z","shell.execute_reply.started":"2025-05-06T07:33:58.043918Z","shell.execute_reply":"2025-05-06T07:33:58.075368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"merged_df['date'] = pd.to_datetime(merged_df['date'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:33:58.147054Z","iopub.execute_input":"2025-05-06T07:33:58.147299Z","iopub.status.idle":"2025-05-06T07:33:58.184421Z","shell.execute_reply.started":"2025-05-06T07:33:58.147279Z","shell.execute_reply":"2025-05-06T07:33:58.183913Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aligned_df = pd.merge(\n    merged_df,\n    labels_df,\n    on=['user', 'date'],\n    how='inner'  # Only keep rows present in both\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:00.392393Z","iopub.execute_input":"2025-05-06T07:34:00.392657Z","iopub.status.idle":"2025-05-06T07:34:00.552556Z","shell.execute_reply.started":"2025-05-06T07:34:00.392637Z","shell.execute_reply":"2025-05-06T07:34:00.551965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"aligned_df = aligned_df.drop(columns='Unnamed: 0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:00.667085Z","iopub.execute_input":"2025-05-06T07:34:00.667353Z","iopub.status.idle":"2025-05-06T07:34:00.695643Z","shell.execute_reply.started":"2025-05-06T07:34:00.667334Z","shell.execute_reply":"2025-05-06T07:34:00.695099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly = aligned_df[['is_anomaly']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:02.727221Z","iopub.execute_input":"2025-05-06T07:34:02.727489Z","iopub.status.idle":"2025-05-06T07:34:02.732353Z","shell.execute_reply.started":"2025-05-06T07:34:02.727469Z","shell.execute_reply":"2025-05-06T07:34:02.731763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly = is_anomaly.to_numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:03.066969Z","iopub.execute_input":"2025-05-06T07:34:03.067688Z","iopub.status.idle":"2025-05-06T07:34:03.070917Z","shell.execute_reply.started":"2025-05-06T07:34:03.067661Z","shell.execute_reply":"2025-05-06T07:34:03.070109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly=is_anomaly.reshape(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:12.427434Z","iopub.execute_input":"2025-05-06T07:34:12.427938Z","iopub.status.idle":"2025-05-06T07:34:12.431267Z","shell.execute_reply.started":"2025-05-06T07:34:12.427912Z","shell.execute_reply":"2025-05-06T07:34:12.430568Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:18.272651Z","iopub.execute_input":"2025-05-06T07:34:18.273304Z","iopub.status.idle":"2025-05-06T07:34:18.277915Z","shell.execute_reply.started":"2025-05-06T07:34:18.273276Z","shell.execute_reply":"2025-05-06T07:34:18.277303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = info.drop(columns=['user', 'date_only'])\ny = is_anomaly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:28:34.921188Z","iopub.execute_input":"2025-05-04T16:28:34.921444Z","iopub.status.idle":"2025-05-04T16:28:34.936691Z","shell.execute_reply.started":"2025-05-04T16:28:34.921425Z","shell.execute_reply":"2025-05-04T16:28:34.935816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x.shape, y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:28:37.261223Z","iopub.execute_input":"2025-05-04T16:28:37.261886Z","iopub.status.idle":"2025-05-04T16:28:37.266225Z","shell.execute_reply.started":"2025-05-04T16:28:37.261864Z","shell.execute_reply":"2025-05-04T16:28:37.265630Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:29:28.061310Z","iopub.execute_input":"2025-05-04T16:29:28.061596Z","iopub.status.idle":"2025-05-04T16:29:28.065345Z","shell.execute_reply.started":"2025-05-04T16:29:28.061576Z","shell.execute_reply":"2025-05-04T16:29:28.064565Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmi_selector = SelectKBest(mutual_info_classif, k=10)  # Change k as needed (top 10 features here)\nX_mi = mi_selector.fit_transform(x, y)\n\n# Get the selected feature names\nselected_mi_features = x.columns[mi_selector.get_support()]\nprint(\"Selected features by Mutual Information:\")\nprint(selected_mi_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:29:48.101928Z","iopub.execute_input":"2025-05-04T16:29:48.102627Z","iopub.status.idle":"2025-05-04T16:30:25.358015Z","shell.execute_reply.started":"2025-05-04T16:29:48.102604Z","shell.execute_reply":"2025-05-04T16:30:25.357149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correlation_matrix = x.corr()\n\n# Plotting the correlation matrix\nplt.figure(figsize=(12, 10))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\nplt.title(\"Correlation Matrix\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:34:18.502936Z","iopub.execute_input":"2025-05-04T16:34:18.503713Z","iopub.status.idle":"2025-05-04T16:34:19.337069Z","shell.execute_reply.started":"2025-05-04T16:34:18.503683Z","shell.execute_reply":"2025-05-04T16:34:19.336266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit a Random Forest Classifier to assess feature importances\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(x, y)\n\n# Get feature importances\nimportances = rf.feature_importances_\n\n# Sort features by importance\nindices = np.argsort(importances)[::-1]  # Sorting in descending order of importance\n\n# Get top K features (e.g., top 5)\ntop_k = 10\ntop_k_indices = indices[:top_k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:35:02.275913Z","iopub.execute_input":"2025-05-04T16:35:02.276202Z","iopub.status.idle":"2025-05-04T16:35:24.859712Z","shell.execute_reply.started":"2025-05-04T16:35:02.276181Z","shell.execute_reply":"2025-05-04T16:35:24.858754Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List top K feature names\ntop_k_feature_names = x.columns[top_k_indices]\nprint(f\"Top {top_k} important features: {top_k_feature_names}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:38:01.849761Z","iopub.execute_input":"2025-05-04T16:38:01.850474Z","iopub.status.idle":"2025-05-04T16:38:01.854715Z","shell.execute_reply.started":"2025-05-04T16:38:01.850450Z","shell.execute_reply":"2025-05-04T16:38:01.853954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols = ['after_hours_logon_count', 'total_logon_count','device_connects','avg_content_word_count', 'text_files_accessed', 'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag','keyword_richness' ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:28.228395Z","iopub.execute_input":"2025-05-06T07:34:28.229101Z","iopub.status.idle":"2025-05-06T07:34:28.233238Z","shell.execute_reply.started":"2025-05-06T07:34:28.229068Z","shell.execute_reply":"2025-05-06T07:34:28.232420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(feature_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:31.787889Z","iopub.execute_input":"2025-05-06T07:31:31.788151Z","iopub.status.idle":"2025-05-06T07:31:31.793610Z","shell.execute_reply.started":"2025-05-06T07:31:31.788132Z","shell.execute_reply":"2025-05-06T07:31:31.793005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:46:35.165884Z","iopub.execute_input":"2025-05-04T16:46:35.166165Z","iopub.status.idle":"2025-05-04T16:46:35.295770Z","shell.execute_reply.started":"2025-05-04T16:46:35.166145Z","shell.execute_reply":"2025-05-04T16:46:35.295090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = info[ ['user','date_only'] + feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:32.447062Z","iopub.execute_input":"2025-05-06T07:34:32.447320Z","iopub.status.idle":"2025-05-06T07:34:32.464659Z","shell.execute_reply.started":"2025-05-06T07:34:32.447301Z","shell.execute_reply":"2025-05-06T07:34:32.464003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:32.727340Z","iopub.execute_input":"2025-05-06T07:34:32.727914Z","iopub.status.idle":"2025-05-06T07:34:32.741366Z","shell.execute_reply.started":"2025-05-06T07:34:32.727893Z","shell.execute_reply":"2025-05-06T07:34:32.740620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"role_data = np.array([role_lookup[uid] for uid in user_ids])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:40.848131Z","iopub.execute_input":"2025-05-06T07:34:40.848816Z","iopub.status.idle":"2025-05-06T07:34:40.901116Z","shell.execute_reply.started":"2025-05-06T07:34:40.848773Z","shell.execute_reply":"2025-05-06T07:34:40.900381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"role_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:49:09.385758Z","iopub.execute_input":"2025-05-04T16:49:09.386047Z","iopub.status.idle":"2025-05-04T16:49:09.390903Z","shell.execute_reply.started":"2025-05-04T16:49:09.386025Z","shell.execute_reply":"2025-05-04T16:49:09.390171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"role_data.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:34:57.542746Z","iopub.execute_input":"2025-05-06T07:34:57.543458Z","iopub.status.idle":"2025-05-06T07:34:57.547746Z","shell.execute_reply.started":"2025-05-06T07:34:57.543434Z","shell.execute_reply":"2025-05-06T07:34:57.547137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(role_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:35:36.647215Z","iopub.execute_input":"2025-05-06T07:35:36.647726Z","iopub.status.idle":"2025-05-06T07:35:36.659208Z","shell.execute_reply.started":"2025-05-06T07:35:36.647701Z","shell.execute_reply":"2025-05-06T07:35:36.658489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s = pd.Series(role_data, name='role')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:50:17.517337Z","iopub.execute_input":"2025-05-04T16:50:17.517620Z","iopub.status.idle":"2025-05-04T16:50:17.521664Z","shell.execute_reply.started":"2025-05-04T16:50:17.517600Z","shell.execute_reply":"2025-05-04T16:50:17.520964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = pd.concat([a, s], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:50:36.146165Z","iopub.execute_input":"2025-05-04T16:50:36.146708Z","iopub.status.idle":"2025-05-04T16:50:36.166817Z","shell.execute_reply.started":"2025-05-04T16:50:36.146673Z","shell.execute_reply":"2025-05-04T16:50:36.166132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:50:37.445761Z","iopub.execute_input":"2025-05-04T16:50:37.446397Z","iopub.status.idle":"2025-05-04T16:50:37.459714Z","shell.execute_reply.started":"2025-05-04T16:50:37.446375Z","shell.execute_reply":"2025-05-04T16:50:37.459099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_an = aligned_df[['is_anomaly']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:53:24.445576Z","iopub.execute_input":"2025-05-04T16:53:24.446253Z","iopub.status.idle":"2025-05-04T16:53:24.452911Z","shell.execute_reply.started":"2025-05-04T16:53:24.446226Z","shell.execute_reply":"2025-05-04T16:53:24.452118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = pd.concat([a,is_an],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:53:55.780683Z","iopub.execute_input":"2025-05-04T16:53:55.781220Z","iopub.status.idle":"2025-05-04T16:53:55.806547Z","shell.execute_reply.started":"2025-05-04T16:53:55.781197Z","shell.execute_reply":"2025-05-04T16:53:55.806019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:53:59.165606Z","iopub.execute_input":"2025-05-04T16:53:59.166242Z","iopub.status.idle":"2025-05-04T16:53:59.179676Z","shell.execute_reply.started":"2025-05-04T16:53:59.166220Z","shell.execute_reply":"2025-05-04T16:53:59.179157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a['user_anomaly_rate'] = a.groupby('user')['is_anomaly'].transform(\n        lambda x: x.ewm(span=30).mean().shift(1).fillna(0.001))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:54:38.985711Z","iopub.execute_input":"2025-05-04T16:54:38.986135Z","iopub.status.idle":"2025-05-04T16:54:39.326164Z","shell.execute_reply.started":"2025-05-04T16:54:38.986113Z","shell.execute_reply":"2025-05-04T16:54:39.325291Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(a['user_anomaly_rate'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:55:01.886441Z","iopub.execute_input":"2025-05-04T16:55:01.886685Z","iopub.status.idle":"2025-05-04T16:55:01.893473Z","shell.execute_reply.started":"2025-05-04T16:55:01.886668Z","shell.execute_reply":"2025-05-04T16:55:01.892867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a['role_anomaly_rate'] = a.groupby('role')['is_anomaly'].transform(\n        lambda x: x.rolling(100, min_periods=1).mean().shift(1).fillna(0.005))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:55:18.007748Z","iopub.execute_input":"2025-05-04T16:55:18.008025Z","iopub.status.idle":"2025-05-04T16:55:18.069442Z","shell.execute_reply.started":"2025-05-04T16:55:18.008004Z","shell.execute_reply":"2025-05-04T16:55:18.068870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a['role_anomaly_rate'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T16:55:45.707034Z","iopub.execute_input":"2025-05-04T16:55:45.707701Z","iopub.status.idle":"2025-05-04T16:55:45.714402Z","shell.execute_reply.started":"2025-05-04T16:55:45.707677Z","shell.execute_reply":"2025-05-04T16:55:45.713856Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AdaptiveDQNAgent:\n    def __init__(self, state_dim):\n        self.state_dim = state_dim\n        self.model = self._build_model()\n        self.user_thresholds = defaultdict(lambda: 0.65)  # Default thresholds\n        self.role_thresholds = defaultdict(lambda: 0.55)\n        self.user_counts = defaultdict(int)\n        \n    def _build_model(self):\n        \"\"\"Build and compile the DQN model\"\"\"\n        model = tf.keras.Sequential([\n            tf.keras.layers.Dense(64, activation='relu', input_shape=(self.state_dim,)),\n            tf.keras.layers.Dense(32, activation='relu'),\n            tf.keras.layers.Dense(1, activation='sigmoid')  # Outputs anomaly probability\n        ])\n        model.compile(optimizer='adam', loss='binary_crossentropy')\n        return model\n    \n    def predict(self, state, user, role):\n        if not isinstance(state, np.ndarray):\n            state = np.array(state, dtype=np.float32)\n        \n        # Ensure correct shape (batch_size, state_dim)\n        if len(state.shape) == 1:\n            state = state[np.newaxis, :]\n        \n        prob = self.model.predict(state, verbose=0)[0][0]\n        \n        # Update user count\n        self.user_counts[user] += 1\n        \n        # Get thresholds\n        user_thresh = self.user_thresholds[user]\n        role_thresh = self.role_thresholds[role]\n        \n        # Weighted threshold (more user-specific with more data)\n        user_weight = min(0.7, 0.4 + 0.01 * self.user_counts[user])\n        combined_thresh = user_weight * user_thresh + (1-user_weight) * role_thresh\n        \n        return 1 if prob > combined_thresh else 0, prob\n\n    def update_thresholds(self, user, role, reward):\n        \"\"\"Adjust thresholds based on performance\"\"\"\n        # User thresholds adapt faster\n        adj = 0.02 if reward > 0 else -0.03\n        self.user_thresholds[user] = np.clip(\n            self.user_thresholds[user] + adj, 0.4, 0.8)\n        \n        # Role thresholds adapt slower\n        adj = 0.01 if reward > 0 else -0.02\n        self.role_thresholds[role] = np.clip(\n            self.role_thresholds[role] + adj, 0.5, 0.7)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:01:18.521256Z","iopub.execute_input":"2025-05-04T17:01:18.521950Z","iopub.status.idle":"2025-05-04T17:01:18.529730Z","shell.execute_reply.started":"2025-05-04T17:01:18.521926Z","shell.execute_reply":"2025-05-04T17:01:18.529030Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class InsiderThreatEnv:\n    def __init__(self, df):\n        self.df = df\n        self.current_idx = 0\n        self.state_columns = [col for col in df.columns \n                            if col not in ['user', 'date_only', 'is_anomaly', 'role']]\n        \n    def reset(self):\n        self.current_idx = np.random.randint(0, len(self.df))\n        return self._get_state()\n    \n    def _get_state(self):\n        return self.df.iloc[self.current_idx][self.state_columns].values.astype(np.float32)\n    \n    def step(self, action):\n        row = self.df.iloc[self.current_idx]\n        true_label = row['is_anomaly']\n        user = row['user']\n        role = row['role']\n        \n        # Calculate reward\n        if action == true_label:\n            reward = 10.0 if action == 1 else 1.0\n        else:\n            reward = -5.0 if action == 1 else -15.0\n        \n        # Move to next state\n        self.current_idx = (self.current_idx + 1) % len(self.df)\n        done = self.current_idx == 0\n        \n        return self._get_state(), reward, done, {'user': user, 'role': role}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:01:29.546328Z","iopub.execute_input":"2025-05-04T17:01:29.546594Z","iopub.status.idle":"2025-05-04T17:01:29.552741Z","shell.execute_reply.started":"2025-05-04T17:01:29.546573Z","shell.execute_reply":"2025-05-04T17:01:29.552123Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_adaptive_dqn(df, epochs=10):\n    env = InsiderThreatEnv(df)\n    agent = AdaptiveDQNAgent(state_dim=len(env.state_columns))\n    \n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        \n        while not done:\n            user = env.df.iloc[env.current_idx]['user']\n            role = env.df.iloc[env.current_idx]['role']\n            \n            # Get action\n            action, _ = agent.predict(state, user, role)\n            \n            # Take step\n            next_state, reward, done, info = env.step(action)\n            \n            # Convert to proper format\n            state_array = np.array(state, dtype=np.float32).reshape(1, -1)\n            next_state_array = np.array(next_state, dtype=np.float32).reshape(1, -1)\n            target = np.array([[1 if action == 1 else 0]], dtype=np.float32)\n            \n            # Train model\n            agent.model.train_on_batch(state_array, target)\n            \n            # Update thresholds\n            agent.update_thresholds(info['user'], info['role'], reward)\n            \n            state = next_state\n            total_reward += reward\n        \n        print(f\"Epoch {epoch+1}, Total Reward: {total_reward:.1f}\")\n    \n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:01:37.645615Z","iopub.execute_input":"2025-05-04T17:01:37.646198Z","iopub.status.idle":"2025-05-04T17:01:37.652543Z","shell.execute_reply.started":"2025-05-04T17:01:37.646173Z","shell.execute_reply":"2025-05-04T17:01:37.651743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent = train_adaptive_dqn(a, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:06:04.585815Z","iopub.execute_input":"2025-05-04T17:06:04.586187Z","iopub.status.idle":"2025-05-04T17:06:07.953682Z","shell.execute_reply.started":"2025-05-04T17:06:04.586164Z","shell.execute_reply":"2025-05-04T17:06:07.952484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:06:15.170793Z","iopub.execute_input":"2025-05-04T17:06:15.171529Z","iopub.status.idle":"2025-05-04T17:06:15.176511Z","shell.execute_reply.started":"2025-05-04T17:06:15.171498Z","shell.execute_reply":"2025-05-04T17:06:15.175835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:06:29.729770Z","iopub.execute_input":"2025-05-04T17:06:29.730356Z","iopub.status.idle":"2025-05-04T17:06:29.747236Z","shell.execute_reply.started":"2025-05-04T17:06:29.730335Z","shell.execute_reply":"2025-05-04T17:06:29.746543Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent.model.save('adaptive_dqn.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"logcal attempt","metadata":{}},{"cell_type":"code","source":"class InsiderThreatEnv:\n    def __init__(self, df, window_size=5):\n        self.df = df.sort_values(['user', 'date_only']).reset_index(drop=True)\n        self.window_size = window_size\n        self.state_columns = [col for col in df.columns if col not in ['user', 'date_only', 'is_anomaly', 'role']]\n        self.users = df['user'].unique()\n        self.user_data = {user: df[df['user'] == user].reset_index(drop=True) for user in self.users}\n        self.state_buffer = deque(maxlen=window_size)\n        self.current_user = None\n        self.current_idx = 0\n\n    def reset(self):\n        self.current_user = np.random.choice(self.users)\n        self.current_idx = 0\n        self.state_buffer.clear()\n        user_df = self.user_data[self.current_user]\n        \n        for i in range(min(self.window_size, len(user_df))):\n            self.state_buffer.append(user_df.iloc[i][self.state_columns].values.astype(np.float32))\n\n        return self._get_state()\n\n    def _get_state(self):\n        while len(self.state_buffer) < self.window_size:\n            self.state_buffer.appendleft(np.zeros(len(self.state_columns), dtype=np.float32))\n\n        user_df = self.user_data[self.current_user]\n        state = np.concatenate([x for x in self.state_buffer])\n        if self.current_idx < len(user_df):\n            user_rate = user_df.iloc[self.current_idx]['user_anomaly_rate']\n            role_rate = user_df.iloc[self.current_idx]['role_anomaly_rate']\n        else:\n            user_rate = role_rate = 0.0\n        return np.append(state, [user_rate, role_rate]).astype(np.float32)\n\n    def step(self, action):\n        user_df = self.user_data[self.current_user]\n        if self.current_idx >= len(user_df):\n            return self._get_state(), 0.0, True, {'user': self.current_user, 'role': 0}\n\n        row = user_df.iloc[self.current_idx]\n        user, role, true_label = row['user'], row['role'], row['is_anomaly']\n        \n        thresholds = [0.4, 0.6, 0.8]\n        threshold = thresholds[action]\n        prob = np.mean(row[self.state_columns])\n        prediction = 1 if prob > threshold else 0\n\n        if prediction == true_label:\n            reward = 10.0 if prediction == 1 else 1.0\n        else:\n            reward = -15.0 if true_label == 1 else -5.0\n\n        self.current_idx += 1\n        if self.current_idx < len(user_df):\n            self.state_buffer.append(user_df.iloc[self.current_idx][self.state_columns].values.astype(np.float32))\n        \n        done = self.current_idx >= len(user_df)\n        return self._get_state(), reward, done, {'user': user, 'role': role}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:12:57.787079Z","iopub.execute_input":"2025-05-04T17:12:57.787344Z","iopub.status.idle":"2025-05-04T17:12:57.798157Z","shell.execute_reply.started":"2025-05-04T17:12:57.787324Z","shell.execute_reply":"2025-05-04T17:12:57.797445Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AdaptiveDQNAgent:\n    def __init__(self, state_dim, action_dim=3, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.gamma = 0.95\n        self.memory = deque(maxlen=2000)\n        self.model = self._build_model()\n        self.target_model = self._build_model()\n        self.update_target_model()\n\n    def _build_model(self):\n        model = tf.keras.Sequential([\n            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_dim,)),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(self.action_dim, activation='linear')\n        ])\n        model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')\n        return model\n\n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n\n    def act(self, state):\n        if np.random.rand() < self.epsilon:\n            return np.random.randint(self.action_dim)\n        q_values = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n        return np.argmax(q_values)\n\n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n\n    def replay(self, batch_size=32):\n        if len(self.memory) < batch_size:\n            return\n        minibatch = np.random.choice(len(self.memory), batch_size, replace=False)\n        minibatch = [self.memory[i] for i in minibatch]\n        states = np.array([s[0] for s in minibatch])\n        actions = np.array([s[1] for s in minibatch])\n        rewards = np.array([s[2] for s in minibatch])\n        next_states = np.array([s[3] for s in minibatch])\n        dones = np.array([s[4] for s in minibatch])\n\n        targets = self.model.predict(states, verbose=0)\n        next_targets = self.target_model.predict(next_states, verbose=0)\n\n        for i in range(batch_size):\n            targets[i][actions[i]] = rewards[i] if dones[i] else rewards[i] + self.gamma * np.max(next_targets[i])\n\n        self.model.fit(states, targets, epochs=1, verbose=0)\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:13:16.122176Z","iopub.execute_input":"2025-05-04T17:13:16.122441Z","iopub.status.idle":"2025-05-04T17:13:16.132239Z","shell.execute_reply.started":"2025-05-04T17:13:16.122419Z","shell.execute_reply":"2025-05-04T17:13:16.131550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_adaptive_dqn(df, epochs=10, batch_size=32):\n    env = InsiderThreatEnv(df, window_size=5)\n    state_dim = len(env.state_columns) * env.window_size + 2\n    agent = AdaptiveDQNAgent(state_dim=state_dim)\n\n    reward_history = []\n    \n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        total_correct = 0\n        total_anomalies = 0\n        steps = 0\n        done = False\n\n        with trange(1_000, desc=f\"Epoch {epoch+1}\", leave=False) as t:\n            for _ in t:\n                action = agent.act(state)\n                next_state, reward, done, info = env.step(action)\n\n                # For tracking\n                user = info.get(\"user\")\n                true_label = env.user_data[user].iloc[env.current_idx - 1][\"is_anomaly\"] if env.current_idx > 0 else 0\n                pred_label = 1 if action == 2 else 0  # assume action 2 = high threshold = anomaly\n                if pred_label == true_label:\n                    total_correct += 1\n                if true_label == 1:\n                    total_anomalies += 1\n\n                agent.remember(state, action, reward, next_state, done)\n                agent.replay(batch_size)\n                state = next_state\n                total_reward += reward\n                steps += 1\n\n                if steps % 100 == 0:\n                    agent.update_target_model()\n                \n                if done:\n                    break\n\n                # Update tqdm description\n                t.set_postfix({\n                    'Reward': f\"{total_reward:.1f}\",\n                    'Steps': steps,\n                    'Epsilon': f\"{agent.epsilon:.3f}\"\n                })\n\n        reward_history.append(total_reward)\n        avg_reward = np.mean(reward_history[-5:])\n\n        print(f\"[Epoch {epoch+1}] Total Reward: {total_reward:.1f} | \"\n              f\"Avg Reward (last 5): {avg_reward:.1f} | \"\n              f\"Accuracy: {total_correct}/{steps} | \"\n              f\"Anomalies Seen: {total_anomalies} | Epsilon: {agent.epsilon:.3f}\")\n\n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:14:33.966643Z","iopub.execute_input":"2025-05-04T17:14:33.966920Z","iopub.status.idle":"2025-05-04T17:14:33.974669Z","shell.execute_reply.started":"2025-05-04T17:14:33.966899Z","shell.execute_reply":"2025-05-04T17:14:33.973920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import trange","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:31:10.877557Z","iopub.execute_input":"2025-05-06T07:31:10.878325Z","iopub.status.idle":"2025-05-06T07:31:10.882033Z","shell.execute_reply.started":"2025-05-06T07:31:10.878298Z","shell.execute_reply":"2025-05-06T07:31:10.881017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent = train_adaptive_dqn(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:19:03.130570Z","iopub.execute_input":"2025-05-04T17:19:03.130827Z","iopub.status.idle":"2025-05-04T17:31:11.455639Z","shell.execute_reply.started":"2025-05-04T17:19:03.130806Z","shell.execute_reply":"2025-05-04T17:31:11.454885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent.model.save('dqn_rolebased_1.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:35:11.485254Z","iopub.execute_input":"2025-05-04T17:35:11.485911Z","iopub.status.idle":"2025-05-04T17:35:11.508368Z","shell.execute_reply.started":"2025-05-04T17:35:11.485888Z","shell.execute_reply":"2025-05-04T17:35:11.507852Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"better reward and anomaly weighting","metadata":{}},{"cell_type":"code","source":"class InsiderThreatEnv:\n    def __init__(self, df, window_size=5):\n        # Preprocess data\n        self.df = self._preprocess_data(df)\n        self.window_size = window_size\n        \n        # Define features and targets\n        self.state_columns = [col for col in df.columns \n                            if col not in ['user', 'date_only', 'is_anomaly', 'role']]\n        self.scaler = StandardScaler()\n        self.scaler.fit(self.df[self.state_columns])\n        \n        # Group by user\n        self.users = self.df['user'].unique()\n        self.user_data = {user: self.df[self.df['user'] == user] \n                         for user in self.users}\n        \n        # Track episode stats\n        self.current_user = None\n        self.current_idx = 0\n        self.state_buffer = deque(maxlen=window_size)\n        self.anomaly_weight = len(self.df[self.df['is_anomaly']==0])/len(self.df[self.df['is_anomaly']==1])\n    \n    def _preprocess_data(self, df):\n        # Fill missing dates with zero activity\n        all_dates = pd.date_range(df['date_only'].min(), df['date_only'].max())\n        full_data = []\n        \n        for user in df['user'].unique():\n            user_df = df[df['user'] == user]\n            user_role = user_df['role'].iloc[0]\n            \n            for date in all_dates:\n                date_str = date.strftime('%Y-%m-%d')\n                if date_str in user_df['date_only'].values:\n                    row = user_df[user_df['date_only'] == date_str].iloc[0]\n                else:\n                    # Impute zeros for missing days\n                    row = pd.Series({\n                        'user': user, 'date_only': date_str, 'role': user_role,\n                        'is_anomaly': 0, 'user_anomaly_rate': user_df['user_anomaly_rate'].mean(),\n                        'role_anomaly_rate': user_df['role_anomaly_rate'].mean(),\n                        **{col: 0 for col in df.columns if col not in ['user', 'date_only', 'role', \n                                                                       'is_anomaly', 'user_anomaly_rate', \n                                                                       'role_anomaly_rate']}\n                    })\n                full_data.append(row)\n        \n        return pd.DataFrame(full_data).sort_values(['user', 'date_only'])\n    \n    def _get_state(self):\n        # Pad with zeros if needed\n        while len(self.state_buffer) < self.window_size:\n            self.state_buffer.appendleft(np.zeros(len(self.state_columns)))\n        \n        # Create stacked state with temporal features\n        window = np.stack(self.state_buffer)\n        recent = window.flatten()\n        stats = np.concatenate([\n            window.mean(axis=0),  # Mean\n            window.std(axis=0),   # Std dev\n            window[-1] - window[0]  # Trend\n        ])\n        \n        # Get user/role context\n        user_df = self.user_data[self.current_user]\n        if self.current_idx < len(user_df):\n            user_rate = user_df.iloc[self.current_idx]['user_anomaly_rate']\n            role_rate = user_df.iloc[self.current_idx]['role_anomaly_rate']\n        else:\n            user_rate, role_rate = 0.0, 0.0\n        \n        # Combine all features\n        state = np.concatenate([\n            self.scaler.transform([recent])[0],\n            stats,\n            [user_rate, role_rate]\n        ])\n        \n        return state.astype(np.float32)\n    \n    def reset(self):\n        self.current_user = np.random.choice(self.users)\n        user_df = self.user_data[self.current_user]\n        self.current_idx = 0\n        self.state_buffer.clear()\n        \n        # Initialize with first window_size states\n        for i in range(min(self.window_size, len(user_df))):\n            self.state_buffer.append(user_df.iloc[i][self.state_columns].values)\n        \n        return self._get_state()\n    \n    def step(self, action):\n        user_df = self.user_data[self.current_user]\n        if self.current_idx >= len(user_df):\n            return self._get_state(), 0.0, True, {}\n        \n        row = user_df.iloc[self.current_idx]\n        true_label = row['is_anomaly']\n        \n        # Threshold options (low, medium, high)\n        threshold = [0.4, 0.6, 0.8][action]\n        \n        # Simulate anomaly prediction\n        prob = np.mean(row[self.state_columns])  # Replace with actual model\n        prediction = 1 if prob > threshold else 0\n        \n        # Enhanced reward calculation\n        if prediction == true_label:\n            if true_label == 1:  # True positive\n                reward = 20.0 * (1 + threshold) * self.anomaly_weight\n            else:  # True negative\n                reward = 1.0\n        else:\n            if true_label == 1:  # False negative\n                reward = -30.0 * (2 - threshold) * self.anomaly_weight\n            else:  # False positive\n                reward = -10.0\n        \n        # Update position\n        self.current_idx += 1\n        if self.current_idx < len(user_df):\n            self.state_buffer.append(user_df.iloc[self.current_idx][self.state_columns].values)\n        \n        done = self.current_idx >= len(user_df)\n        info = {\n            'true_label': true_label,\n            'prediction': prediction,\n            'threshold': threshold\n        }\n        \n        return self._get_state(), reward, done, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:43:44.386939Z","iopub.execute_input":"2025-05-04T17:43:44.387646Z","iopub.status.idle":"2025-05-04T17:43:44.403990Z","shell.execute_reply.started":"2025-05-04T17:43:44.387622Z","shell.execute_reply":"2025-05-04T17:43:44.403252Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AdaptiveDQNAgent:\n    def __init__(self, state_dim, action_dim=3, epsilon=1.0, epsilon_min=0.1, \n                 epsilon_decay=0.98, gamma=0.95):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.epsilon = epsilon\n        self.epsilon_min = epsilon_min\n        self.epsilon_decay = epsilon_decay\n        self.gamma = gamma\n        self.memory = deque(maxlen=10000)\n        self.model = self._build_model()\n        self.target_model = self._build_model()\n        self.update_target_model()\n    \n    def _build_model(self):\n        model = tf.keras.Sequential([\n            tf.keras.layers.Dense(128, activation='relu', input_shape=(self.state_dim,)),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Dense(64, activation='relu'),\n            tf.keras.layers.Dense(self.action_dim, activation='linear')\n        ])\n        model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='mse')\n        return model\n    \n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n    \n    def remember(self, state, action, reward, next_state, done):\n        self.memory.append((state, action, reward, next_state, done))\n    \n    def act(self, state):\n        if np.random.rand() < self.epsilon:\n            return np.random.randint(self.action_dim)\n        q_values = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n        return np.argmax(q_values)\n    \n    def replay(self, batch_size=32):\n        if len(self.memory) < batch_size:\n            return\n        \n        minibatch = np.random.choice(len(self.memory), batch_size, replace=False)\n        states, actions, rewards, next_states, dones = zip(*[self.memory[i] for i in minibatch])\n        \n        states = np.array(states)\n        next_states = np.array(next_states)\n        \n        targets = self.model.predict(states, verbose=0)\n        target_next = self.target_model.predict(next_states, verbose=0)\n        \n        for i in range(batch_size):\n            if dones[i]:\n                targets[i][actions[i]] = rewards[i]\n            else:\n                targets[i][actions[i]] = rewards[i] + self.gamma * np.max(target_next[i])\n        \n        self.model.fit(states, targets, batch_size=batch_size, verbose=0)\n        \n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:43:54.641175Z","iopub.execute_input":"2025-05-04T17:43:54.641413Z","iopub.status.idle":"2025-05-04T17:43:54.651911Z","shell.execute_reply.started":"2025-05-04T17:43:54.641395Z","shell.execute_reply":"2025-05-04T17:43:54.651278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_agent(df, epochs=20, batch_size=64):\n    env = InsiderThreatEnv(df)\n    state_dim = (len(env.state_columns) * env.window_size) + (len(env.state_columns) * 3) + 2\n    agent = AdaptiveDQNAgent(state_dim)\n    \n    metrics = {\n        'epoch': [],\n        'total_reward': [],\n        'true_positives': [],\n        'false_negatives': [],\n        'precision': [],\n        'recall': [],\n        'f1': []\n    }\n    \n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        stats = defaultdict(int)\n        \n        while not done:\n            action = agent.act(state)\n            next_state, reward, done, info = env.step(action)\n            \n            agent.remember(state, action, reward, next_state, done)\n            agent.replay(batch_size)\n            \n            # Track predictions\n            if 'true_label' in info:\n                stats['total'] += 1\n                if info['true_label'] == 1:\n                    stats['actual_anomalies'] += 1\n                    if info['prediction'] == 1:\n                        stats['tp'] += 1\n                    else:\n                        stats['fn'] += 1\n                elif info['prediction'] == 1:\n                    stats['fp'] += 1\n            \n            state = next_state\n            total_reward += reward\n        \n        # Calculate metrics\n        precision = stats['tp'] / (stats['tp'] + stats['fp'] + 1e-10)\n        recall = stats['tp'] / (stats['tp'] + stats['fn'] + 1e-10)\n        f1 = 2 * precision * recall / (precision + recall + 1e-10)\n        \n        # Update metrics\n        metrics['epoch'].append(epoch+1)\n        metrics['total_reward'].append(total_reward)\n        metrics['true_positives'].append(stats['tp'])\n        metrics['false_negatives'].append(stats['fn'])\n        metrics['precision'].append(precision)\n        metrics['recall'].append(recall)\n        metrics['f1'].append(f1)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"  Reward: {total_reward:.1f} | ε: {agent.epsilon:.3f}\")\n        print(f\"  TP: {stats['tp']} | FN: {stats['fn']} | FP: {stats.get('fp',0)}\")\n        print(f\"  Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f}\")\n        \n        # Update target network every 5 epochs\n        if epoch % 5 == 0:\n            agent.update_target_model()\n    \n    return agent, pd.DataFrame(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:44:11.861111Z","iopub.execute_input":"2025-05-04T17:44:11.861704Z","iopub.status.idle":"2025-05-04T17:44:11.871157Z","shell.execute_reply.started":"2025-05-04T17:44:11.861682Z","shell.execute_reply":"2025-05-04T17:44:11.870468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trained_agent, metrics = train_agent(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T17:44:22.425644Z","iopub.execute_input":"2025-05-04T17:44:22.426219Z","iopub.status.idle":"2025-05-04T17:45:00.108414Z","shell.execute_reply.started":"2025-05-04T17:44:22.426196Z","shell.execute_reply":"2025-05-04T17:45:00.107313Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"isolation forest + rl","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nfrom typing import Dict, Tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T14:47:04.007453Z","iopub.execute_input":"2025-05-05T14:47:04.007778Z","iopub.status.idle":"2025-05-05T14:47:04.344705Z","shell.execute_reply.started":"2025-05-05T14:47:04.007757Z","shell.execute_reply":"2025-05-05T14:47:04.344136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:04:22.118936Z","iopub.execute_input":"2025-05-04T18:04:22.119248Z","iopub.status.idle":"2025-05-04T18:04:22.139206Z","shell.execute_reply.started":"2025-05-04T18:04:22.119224Z","shell.execute_reply":"2025-05-04T18:04:22.138488Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DataHandler:\n    def __init__(self):\n        self.feature_cols = [\n            'after_hours_logon_count', 'total_logon_count', 'device_connects',\n            'avg_content_word_count', 'text_files_accessed', 'files_accessed',\n            'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag',\n            'keyword_richness'\n        ]\n        self.context_cols = ['user_anomaly_rate', 'role_anomaly_rate', 'role']\n        \n    def preprocess(self, df: pd.DataFrame) -> Tuple[dict, dict]:\n        \"\"\"Returns: \n        - user_sequences: {user_id: (features, labels, contexts)}\n        - global_stats: (mean_anomaly_rate, role_weights)\n        \"\"\"\n        user_sequences = {}\n        \n        # Calculate global anomaly stats\n        global_anomaly_rate = df['is_anomaly'].mean()\n        role_weights = df.groupby('role')['is_anomaly'].mean().to_dict()\n        \n        for user, group in df.groupby('user'):\n            features = group[self.feature_cols].values\n            labels = group['is_anomaly'].values\n            contexts = group[self.context_cols].values\n            user_sequences[user] = (features, labels, contexts)\n            \n        return user_sequences, (global_anomaly_rate, role_weights)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:14:56.252818Z","iopub.execute_input":"2025-05-04T18:14:56.253177Z","iopub.status.idle":"2025-05-04T18:14:56.259073Z","shell.execute_reply.started":"2025-05-04T18:14:56.253152Z","shell.execute_reply":"2025-05-04T18:14:56.258455Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class IForestRLEnv:\n    def __init__(self, user_sequences: dict, global_stats: tuple, window_size: int = 5):\n        self.user_sequences = user_sequences\n        self.users = list(user_sequences.keys())\n        self.window_size = window_size\n        \n        # Isolation Forest model\n        self.iforest = IsolationForest(n_estimators=150, contamination='auto')\n        \n        # Class imbalance handling\n        self.global_anomaly_rate, self.role_weights = global_stats\n        self.anomaly_weight = 1 / (self.global_anomaly_rate + 1e-6)\n        \n        # State tracking\n        self.current_user = None\n        self.current_idx = 0\n        self.score_buffer = deque(maxlen=window_size)\n    \n    def reset(self) -> np.ndarray:\n        self.current_user = np.random.choice(self.users)\n        features, _, contexts = self.user_sequences[self.current_user]\n        self.current_idx = 0\n        \n        # Initialize buffer with IF scores\n        self.score_buffer.clear()\n        for i in range(min(self.window_size, len(features))):\n            score = self.iforest.decision_function([features[i]])[0]\n            self.score_buffer.append(score)\n            \n        return self._get_state(contexts[0])\n    \n    def _get_state(self, context: np.ndarray) -> np.ndarray:\n        \"\"\"State includes:\n        - Recent anomaly scores (window_size)\n        - User anomaly rate\n        - Role anomaly rate\n        - Role (one-hot encoded)\n        - Temporal stats of scores\n        \"\"\"\n        # Pad if needed\n        while len(self.score_buffer) < self.window_size:\n            self.score_buffer.appendleft(0.0)\n            \n        # One-hot encode role (assuming 12 roles based on your data)\n        role = int(context[2])  # role is at index 2\n        role_onehot = np.zeros(12)\n        role_onehot[role-1] = 1  # Assuming roles are 1-12\n        \n        state = np.concatenate([\n            np.array(self.score_buffer),               # Recent scores\n            [context[0]],                              # user_anomaly_rate\n            [context[1]],                              # role_anomaly_rate\n            role_onehot,                               # role encoding\n            [np.mean(self.score_buffer)],              # mean score\n            [np.std(self.score_buffer)],               # std score\n            [self.score_buffer[-1] - self.score_buffer[0]]  # trend\n        ])\n        \n        return state.astype(np.float32)\n    \n    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n        \"\"\"Action space:\n        0: Decrease threshold (more sensitive)\n        1: Maintain threshold\n        2: Increase threshold (more strict)\n        \"\"\"\n        features, labels, contexts = self.user_sequences[self.current_user]\n        if self.current_idx >= len(features):\n            return self._get_state(contexts[-1]), 0.0, True, {}\n        \n        # Get current observation\n        x = features[self.current_idx]\n        true_label = labels[self.current_idx]\n        context = contexts[self.current_idx]\n        role = int(context[2])\n        \n        # Adjust threshold based on action and role weight\n        threshold_adjustments = {0: -0.3, 1: 0.0, 2: 0.3}\n        role_weight = self.role_weights.get(role, 1.0)\n        adjusted_threshold = self.iforest.offset_ + (threshold_adjustments[action] * role_weight)\n        \n        # Make prediction\n        score = self.iforest.decision_function([x])[0]\n        pred_label = int(score < adjusted_threshold)\n        \n        # Reward calculation with class balancing\n        if pred_label == true_label:\n            reward = 15.0 if pred_label == 1 else 1.0\n            reward *= self.anomaly_weight if pred_label == 1 else 1.0\n        else:\n            reward = -25.0 if true_label == 1 else -3.0\n            reward *= self.anomaly_weight if true_label == 1 else 1.0\n        \n        # Update position\n        self.current_idx += 1\n        if self.current_idx < len(features):\n            new_score = self.iforest.decision_function([features[self.current_idx]])[0]\n            self.score_buffer.append(new_score)\n        \n        done = self.current_idx >= len(features)\n        info = {\n            'user': self.current_user,\n            'true': true_label,\n            'predicted': pred_label,\n            'threshold': adjusted_threshold,\n            'score': score\n        }\n        \n        return self._get_state(context), reward, done, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:01.066143Z","iopub.execute_input":"2025-05-04T18:16:01.066393Z","iopub.status.idle":"2025-05-04T18:16:01.079658Z","shell.execute_reply.started":"2025-05-04T18:16:01.066377Z","shell.execute_reply":"2025-05-04T18:16:01.078880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DQNAgent:\n    def __init__(self, state_dim: int):\n        self.state_dim = state_dim\n        self.action_dim = 3  # Decrease, Maintain, Increase threshold\n        self.memory = deque(maxlen=100000)\n        \n        # Hyperparameters\n        self.gamma = 0.95\n        self.epsilon = 1.0\n        self.epsilon_min = 0.1\n        self.epsilon_decay = 0.998\n        self.batch_size = 64\n        \n        # Model with dueling architecture\n        self.model = self._build_dueling_dqn()\n        self.target_model = self._build_dueling_dqn()\n        self.update_target_model()\n    \n    def _build_dueling_dqn(self) -> tf.keras.Model:\n        inputs = tf.keras.Input(shape=(self.state_dim,))\n        \n        # Shared feature layer\n        x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n        x = tf.keras.layers.LayerNormalization()(x)\n        x = tf.keras.layers.Dropout(0.3)(x)\n        \n        # Value stream\n        value = tf.keras.layers.Dense(64, activation='relu')(x)\n        value = tf.keras.layers.Dense(1)(value)\n        \n        # Advantage stream\n        advantage = tf.keras.layers.Dense(64, activation='relu')(x)\n        advantage = tf.keras.layers.Dense(self.action_dim)(advantage)\n        \n        # Combine streams\n        q_values = value + (advantage - tf.reduce_mean(advantage, axis=1, keepdims=True))\n        \n        return tf.keras.Model(inputs=inputs, outputs=q_values)\n    \n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n    \n    def remember(self, state, action, reward, next_state, done):\n        # Prioritize anomaly-related experiences\n        if abs(reward) > 20 or (reward < 0 and abs(reward) > 10):\n            self.memory.appendleft((state, action, reward, next_state, done))\n        else:\n            self.memory.append((state, action, reward, next_state, done))\n    \n    def act(self, state: np.ndarray) -> int:\n        if np.random.rand() <= self.epsilon:\n            return np.random.randint(self.action_dim)\n        q_values = self.model.predict(state[np.newaxis, :], verbose=0)[0]\n        return np.argmax(q_values)\n    \n    def replay(self):\n        if len(self.memory) < self.batch_size:\n            return\n        \n        # Create balanced batch\n        batch = []\n        anomaly_indices = [i for i, x in enumerate(self.memory) if x[2] > 15 or x[2] < -15]\n        \n        if len(anomaly_indices) > self.batch_size//3:\n            batch += np.random.choice(anomaly_indices, self.batch_size//3, replace=False).tolist()\n            remaining = np.random.choice(len(self.memory), self.batch_size - len(batch), replace=False)\n            batch += remaining.tolist()\n        else:\n            batch = np.random.choice(len(self.memory), self.batch_size, replace=False).tolist()\n        \n        states, actions, rewards, next_states, dones = zip(*[self.memory[i] for i in batch])\n        \n        # Convert to tensors\n        states = tf.convert_to_tensor(states, dtype=tf.float32)\n        next_states = tf.convert_to_tensor(next_states, dtype=tf.float32)\n        \n        # Compute target Q-values\n        target_q = rewards + (1 - np.array(dones)) * self.gamma * \\\n                  np.amax(self.target_model.predict(next_states, verbose=0), axis=1)\n        \n        # Train model\n        with tf.GradientTape() as tape:\n            q_values = tf.reduce_sum(\n                self.model(states) * tf.one_hot(actions, self.action_dim),\n                axis=1\n            )\n            loss = tf.keras.losses.Huber()(target_q, q_values)\n        \n        grads = tape.gradient(loss, self.model.trainable_variables)\n        tf.keras.optimizers.Adam(0.001).apply_gradients(zip(grads, self.model.trainable_variables))\n        \n        # Decay epsilon\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:17.146660Z","iopub.execute_input":"2025-05-04T18:16:17.146944Z","iopub.status.idle":"2025-05-04T18:16:17.161827Z","shell.execute_reply.started":"2025-05-04T18:16:17.146923Z","shell.execute_reply":"2025-05-04T18:16:17.161115Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_iforest_rl(df: pd.DataFrame, epochs: int = 30):\n    # 1. Prepare data\n    handler = DataHandler()\n    user_sequences, global_stats = handler.preprocess(df)\n    \n    # 2. Initialize environment\n    env = IForestRLEnv(user_sequences, global_stats)\n    \n    # 3. Train Isolation Forest on normal users\n    normal_users = [u for u in user_sequences if user_sequences[u][1].mean() < 0.05]\n    normal_data = np.concatenate([user_sequences[u][0] for u in normal_users])\n    env.iforest.fit(normal_data)\n    \n    # 4. Initialize agent\n    agent = DQNAgent(state_dim=env._get_state(user_sequences[env.users[0]][2][0]).shape[0])\n    \n    # 5. Training loop\n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        metrics = {'tp':0, 'fp':0, 'tn':0, 'fn':0}\n        \n        while not done:\n            action = agent.act(state)\n            next_state, reward, done, info = env.step(action)\n            \n            agent.remember(state, action, reward, next_state, done)\n            agent.replay()\n            \n            # Track performance\n            if 'true' in info:\n                true, pred = info['true'], info['predicted']\n                if true == 1 and pred == 1: metrics['tp'] += 1\n                elif true == 0 and pred == 1: metrics['fp'] += 1\n                elif true == 1 and pred == 0: metrics['fn'] += 1\n                else: metrics['tn'] += 1\n            \n            state = next_state\n            total_reward += reward\n        \n        # Calculate metrics\n        precision = metrics['tp'] / (metrics['tp'] + metrics['fp'] + 1e-10)\n        recall = metrics['tp'] / (metrics['tp'] + metrics['fn'] + 1e-10)\n        f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"  Reward: {total_reward:.1f} | ε: {agent.epsilon:.3f}\")\n        print(f\"  Anomalies: {metrics['tp'] + metrics['fn']} -> Detected: {metrics['tp']}\")\n        print(f\"  Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f}\")\n        \n        if (epoch + 1) % 10 == 0:\n            agent.update_target_model()\n    \n    return agent, env.iforest\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:32.643598Z","iopub.execute_input":"2025-05-04T18:16:32.644346Z","iopub.status.idle":"2025-05-04T18:16:32.653945Z","shell.execute_reply.started":"2025-05-04T18:16:32.644313Z","shell.execute_reply":"2025-05-04T18:16:32.653265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent, iforest = train_iforest_rl(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:16:41.950833Z","iopub.execute_input":"2025-05-04T18:16:41.951124Z","iopub.status.idle":"2025-05-04T18:16:43.637639Z","shell.execute_reply.started":"2025-05-04T18:16:41.951102Z","shell.execute_reply":"2025-05-04T18:16:43.636621Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"rl alone","metadata":{}},{"cell_type":"code","source":"class DataHandler:\n    def __init__(self, min_sequence_length: int = 3):\n        self.scaler = StandardScaler()\n        self.min_sequence_length = min_sequence_length\n        \n    def preprocess(self, ais: pd.DataFrame, mu_all: np.ndarray, user_col: str = 'user', \n                   feature_cols: list = None, date_col: str = 'date_only') -> Tuple[dict, dict]:\n        \"\"\"Returns: \n        - user_sequences: {user_id: (features, labels)}\n        - user_stats: {user_id: (mean_anomaly_rate, role)}\n        \"\"\"\n        # Validate inputs\n        if len(ais) != mu_all.shape[0]:\n            raise ValueError(f\"mu_all must have {len(ais)} rows, got {mu_all.shape[0]}\")\n        if mu_all.shape[1] != 8:\n            raise ValueError(f\"mu_all must have 8 columns, got {mu_all.shape[1]}\")\n        \n        # Create a copy of ais to avoid modifying the original\n        df = ais.copy()\n        \n        # Add latent vector columns from mu_all\n        latent_cols = [f'latent_{i}' for i in range(mu_all.shape[1])]\n        df[latent_cols] = mu_all\n        \n        # Combine feature columns\n        all_feature_cols = feature_cols + latent_cols\n        \n        # Handle missing values in feature columns\n        df[all_feature_cols] = df[all_feature_cols].fillna(0)\n        \n        # Normalize features\n        df[all_feature_cols] = self.scaler.fit_transform(df[all_feature_cols])\n        \n        # Ensure is_anomaly column exists\n        if 'is_anomaly' not in df.columns:\n            raise ValueError(\"Dataframe must contain 'is_anomaly' column\")\n        \n        # Group by user with temporal ordering\n        user_sequences = {}\n        user_stats = {}\n        \n        for user, group in df.groupby(user_col):\n            # Sort by date to maintain temporal order\n            group = group.sort_values(date_col)\n            if len(group) < self.min_sequence_length:\n                continue  # Skip users with too few observations\n            features = group[all_feature_cols].values\n            labels = group['is_anomaly'].values\n            user_sequences[user] = (features, labels)\n            \n            # Calculate user-level stats\n            anomaly_rate = labels.mean()\n            role = group['role'].mode()[0]\n            user_stats[user] = (anomaly_rate, role)\n            \n        if not user_sequences:\n            raise ValueError(\"No users have sufficient sequence length\")\n            \n        return user_sequences, user_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:58:17.926907Z","iopub.execute_input":"2025-05-04T18:58:17.927663Z","iopub.status.idle":"2025-05-04T18:58:17.936485Z","shell.execute_reply.started":"2025-05-04T18:58:17.927639Z","shell.execute_reply":"2025-05-04T18:58:17.935712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AnomalyRLEnv:\n    def __init__(self, user_sequences: dict, user_stats: dict, window_size: int = 3):\n        self.user_sequences = user_sequences\n        self.user_stats = user_stats\n        self.users = list(user_sequences.keys())\n        if not self.users:\n            raise ValueError(\"No valid users in user_sequences\")\n        self.window_size = window_size\n        \n        # Class imbalance handling\n        self.anomaly_weight = self._calculate_anomaly_weight()\n        \n        # State tracking\n        self.current_user = None\n        self.current_idx = 0\n        self.feature_dim = len(next(iter(user_sequences.values()))[0][0])  # 19 (11 + 8)\n        self.state_buffer = deque(maxlen=window_size)\n        \n        # Initialize state\n        self.reset()\n    \n    def _calculate_anomaly_weight(self) -> float:\n        \"\"\"Calculate weight for anomaly class\"\"\"\n        total_anomalies = sum(labels.sum() for _, labels in self.user_sequences.values())\n        total_normal = sum(len(labels) - labels.sum() for _, labels in self.user_sequences.values())\n        return total_normal / (total_anomalies + 1e-6)\n    \n    def reset(self) -> np.ndarray:\n        \"\"\"Returns initial state\"\"\"\n        self.current_user = np.random.choice(self.users)\n        features, _ = self.user_sequences[self.current_user]\n        if len(features) == 0:\n            raise ValueError(f\"Empty feature sequence for user {self.current_user}\")\n        self.current_idx = 0\n        self.state_buffer.clear()\n        \n        # Initialize buffer with zeros or available features\n        for i in range(min(self.window_size, len(features))):\n            self.state_buffer.append(features[i])\n        while len(self.state_buffer) < self.window_size:\n            self.state_buffer.appendleft(np.zeros(self.feature_dim))\n            \n        return self._get_state()\n    \n    def _get_state(self) -> np.ndarray:\n        \"\"\"Create state vector:\n        - Window of recent feature vectors (including latent components)\n        - User anomaly rate\n        - Role\n        \"\"\"\n        user_rate, role = self.user_stats[self.current_user]\n        features, _ = self.user_sequences[self.current_user]\n        \n        # Flatten the window of features\n        window_features = np.array(self.state_buffer).flatten()\n        \n        state = np.concatenate([\n            window_features,\n            [user_rate],\n            [role]\n        ])\n        \n        return state.astype(np.float32)\n    \n    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n        \"\"\"Action: 0 (normal), 1 (anomaly)\"\"\"\n        features, labels = self.user_sequences[self.current_user]\n        \n        # Check if sequence is exhausted\n        if self.current_idx >= len(features):\n            return self._get_state(), 0.0, True, {}\n        \n        # Get current observation\n        true_label = labels[self.current_idx]\n        \n        # Calculate reward\n        if action == true_label:\n            reward = 10.0 if action == 1 else 1.0\n            reward *= self.anomaly_weight if action == 1 else 1.0\n        else:\n            reward = -20.0 if true_label == 1 else -5.0\n            reward *= self.anomaly_weight if true_label == 1 else 1.0\n        \n        # Update position and buffer\n        self.current_idx += 1\n        if self.current_idx < len(features):\n            self.state_buffer.append(features[self.current_idx])\n        else:\n            self.state_buffer.append(np.zeros(self.feature_dim))\n        \n        done = self.current_idx >= len(features)\n        info = {\n            'user': self.current_user,\n            'true': true_label,\n            'predicted': action\n        }\n        \n        return self._get_state(), reward, done, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:58:46.887208Z","iopub.execute_input":"2025-05-04T18:58:46.887486Z","iopub.status.idle":"2025-05-04T18:58:46.900572Z","shell.execute_reply.started":"2025-05-04T18:58:46.887464Z","shell.execute_reply":"2025-05-04T18:58:46.899881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class DQNAgent:\n    def __init__(self, state_dim: int, action_dim: int = 2):\n        self.state_dim = state_dim\n        self.action_dim = action_dim\n        self.memory = deque(maxlen=100000)\n        \n        # Hyperparameters\n        self.gamma = 0.95\n        self.epsilon = 1.0\n        self.epsilon_min = 0.1\n        self.epsilon_decay = 0.995\n        self.batch_size = 64\n        \n        # Model\n        self.model = self._build_model()\n        self.target_model = self._build_model()\n        self.update_target_model()\n    \n    def _build_model(self) -> tf.keras.Model:\n        inputs = Input(shape=(self.state_dim,))\n        x = Dense(96, activation='relu')(inputs)\n        x = Dropout(0.2)(x)\n        x = Dense(48, activation='relu')(x)\n        outputs = Dense(self.action_dim, activation='linear')(x)\n        \n        model = Model(inputs, outputs)\n        model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='huber')\n        return model\n    \n    def update_target_model(self):\n        self.target_model.set_weights(self.model.get_weights())\n    \n    def remember(self, state, action, reward, next_state, done):\n        if abs(reward) > 15:  # Prioritize anomaly-related experiences\n            self.memory.appendleft((state, action, reward, next_state, done))\n        else:\n            self.memory.append((state, action, reward, next_state, done))\n    \n    def act(self, state: np.ndarray) -> int:\n        if np.random.rand() <= self.epsilon:\n            return np.random.randint(self.action_dim)\n        act_values = self.model.predict(state[np.newaxis, :], verbose=0)\n        return np.argmax(act_values[0])\n    \n    def replay(self):\n        if len(self.memory) < self.batch_size:\n            return\n        \n        # Oversample anomaly-related experiences\n        minibatch = []\n        high_impact_indices = [i for i, x in enumerate(self.memory) if abs(x[2]) > 15]\n        \n        if len(high_impact_indices) > self.batch_size//3:\n            minibatch += np.random.choice(high_impact_indices, self.batch_size//3, replace=False).tolist()\n            remaining = np.random.choice(len(self.memory), self.batch_size - len(minibatch), replace=False)\n            minibatch += remaining.tolist()\n        else:\n            minibatch = np.random.choice(len(self.memory), self.batch_size, replace=False).tolist()\n        \n        states, actions, rewards, next_states, dones = zip(*[self.memory[i] for i in minibatch])\n        \n        states = np.array(states)\n        next_states = np.array(next_states)\n        \n        targets = self.model.predict(states, verbose=0)\n        target_next = self.target_model.predict(next_states, verbose=0)\n        \n        for i in range(len(minibatch)):\n            if dones[i]:\n                targets[i][actions[i]] = rewards[i]\n            else:\n                targets[i][actions[i]] = rewards[i] + self.gamma * np.amax(target_next[i])\n        \n        self.model.fit(states, targets, batch_size=self.batch_size, verbose=0)\n        \n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:59:07.726771Z","iopub.execute_input":"2025-05-04T18:59:07.727530Z","iopub.status.idle":"2025-05-04T18:59:07.741174Z","shell.execute_reply.started":"2025-05-04T18:59:07.727497Z","shell.execute_reply":"2025-05-04T18:59:07.740479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_rl_anomaly_detector(ais: pd.DataFrame, mu_all: np.ndarray, \n                             epochs: int = 50, window_size: int = 3):\n    # 1. Prepare data\n    feature_cols = [\n        'after_hours_logon_count',\n        'total_logon_count',\n        'device_connects',\n        'avg_content_word_count',\n        'text_files_accessed',\n        'files_accessed',\n        'total_recipients',\n        'external_ratio',\n        'emails_sent',\n        'bcc_flag',\n        'keyword_richness'\n    ]\n    handler = DataHandler(min_sequence_length=window_size)\n    sequences, stats = handler.preprocess(ais, mu_all, feature_cols=feature_cols, \n                                        date_col='date_only')\n    \n    # 2. Initialize environment and agent\n    env = AnomalyRLEnv(sequences, stats, window_size=window_size)\n    agent = DQNAgent(state_dim=env._get_state().shape[0], action_dim=2)\n    \n    # 3. RL Training\n    for epoch in range(epochs):\n        state = env.reset()\n        total_reward = 0\n        done = False\n        metrics = {'tp':0, 'fp':0, 'tn':0, 'fn':0}\n        \n        while not done:\n            action = agent.act(state)\n            result = env.step(action)\n            if result is None:\n                print(f\"Warning: step returned None for user {env.current_user}, idx {env.current_idx}\")\n                break\n            next_state, reward, done, info = result\n            \n            agent.remember(state, action, reward, next_state, done)\n            agent.replay()\n            \n            # Track performance\n            if 'true' in info:\n                true, pred = info['true'], info['predicted']\n                if true == 1 and pred == 1: metrics['tp'] += 1\n                elif true == 0 and pred == 1: metrics['fp'] += 1\n                elif true == 1 and pred == 0: metrics['fn'] += 1\n                else: metrics['tn'] += 1\n            \n            state = next_state\n            total_reward += reward\n        \n        # Calculate metrics\n        precision = metrics['tp'] / (metrics['tp'] + metrics['fp'] + 1e-10)\n        recall = metrics['tp'] / (metrics['tp'] + metrics['fn'] + 1e-10)\n        f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n        \n        print(f\"Epoch {epoch+1}/{epochs}\")\n        print(f\"  Reward: {total_reward:.1f} | ε: {agent.epsilon:.3f}\")\n        print(f\"  TP: {metrics['tp']} | FP: {metrics['fp']} | FN: {metrics['fn']}\")\n        print(f\"  Precision: {precision:.2f} | Recall: {recall:.2f} | F1: {f1:.2f}\")\n        \n        if epoch % 5 == 0:\n            agent.update_target_model()\n    \n    return agent","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:59:21.707085Z","iopub.execute_input":"2025-05-04T18:59:21.707361Z","iopub.status.idle":"2025-05-04T18:59:21.717085Z","shell.execute_reply.started":"2025-05-04T18:59:21.707339Z","shell.execute_reply":"2025-05-04T18:59:21.716319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agent = train_rl_anomaly_detector(a, mu_all, epochs=20, window_size=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T18:59:42.246773Z","iopub.execute_input":"2025-05-04T18:59:42.247378Z","iopub.status.idle":"2025-05-04T19:10:08.641593Z","shell.execute_reply.started":"2025-05-04T18:59:42.247354Z","shell.execute_reply":"2025-05-04T19:10:08.640562Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ppo","metadata":{}},{"cell_type":"code","source":"a['role'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T19:44:13.926183Z","iopub.execute_input":"2025-05-04T19:44:13.926754Z","iopub.status.idle":"2025-05-04T19:44:13.934441Z","shell.execute_reply.started":"2025-05-04T19:44:13.926731Z","shell.execute_reply":"2025-05-04T19:44:13.933673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nfrom typing import Dict, Any","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:14:56.884155Z","iopub.status.idle":"2025-05-21T15:14:56.886175Z","shell.execute_reply.started":"2025-05-21T15:14:56.885822Z","shell.execute_reply":"2025-05-21T15:14:56.885842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gym\nimport numpy as np\nimport pandas as pd\nimport torch\n\n\n# ----------------------------\n# 1. Custom RL Environment\n# ----------------------------\nclass AdaptiveThresholdEnv(gym.Env):\n    def __init__(self, \n                 anomaly_scores: np.ndarray,  # Precomputed anomaly scores (user-day)\n                 role_bits: np.ndarray,       # Role-bit vectors (user-day, 4 bits)\n                 features: np.ndarray,        # 11 features (user-day)\n                 labels: np.ndarray = None,   # Ground truth (1=anomaly, 0=normal)\n                 window_size: int = 7         # Rolling window for stats\n                ):\n        super(AdaptiveThresholdEnv, self).__init__()\n        \n        self.anomaly_scores = anomaly_scores\n        self.role_bits = role_bits\n        self.features = features\n        self.labels = labels\n        self.window_size = window_size\n        \n        # Action space: [0=decrease, 1=keep, 2=increase]\n        self.action_space = gym.spaces.Discrete(3)\n        \n        # State space: [score, rolling_mean, rolling_std, role_bits (4), features (2 key)]\n        self.observation_space = gym.spaces.Box(\n            low=0, high=1, shape=(9,), dtype=np.float32\n        )\n        \n        self.current_step = 0\n        self.threshold = 0.5  # Initial threshold\n        self.n_users = anomaly_scores.shape[0]\n        \n    def _get_state(self, user_idx: int) -> np.ndarray:\n        \"\"\"Build state vector for the current user-day.\"\"\"\n        # Get rolling stats of anomaly scores\n        start_idx = max(0, self.current_step - self.window_size)\n        rolling_mean = np.mean(self.anomaly_scores[user_idx, start_idx:self.current_step])\n        rolling_std = np.std(self.anomaly_scores[user_idx, start_idx:self.current_step])\n        \n        # Normalize to [0,1]\n        rolling_mean_norm = (rolling_mean - np.min(self.anomaly_scores)) / (\n            np.max(self.anomaly_scores) - np.min(self.anomaly_scores) + 1e-8\n        )\n        rolling_std_norm = rolling_std / (np.max(self.anomaly_scores) + 1e-8)\n        \n        # Get role bits and key features (e.g., first 2 features)\n        role = self.role_bits[user_idx, self.current_step]\n        features = self.features[user_idx, self.current_step, :2]  # Example: 2 key features\n        \n        # Concatenate into state vector\n        state = np.concatenate([\n            [self.anomaly_scores[user_idx, self.current_step]],\n            [rolling_mean_norm, rolling_std_norm],\n            role,\n            features\n        ]).astype(np.float32)\n        \n        return state\n    \n    def step(self, action: int) -> tuple:\n        user_idx = self.current_step % self.n_users  # Simulate user rotation\n        \n        # Adjust threshold based on action\n        delta = 0.05 * (action - 1)  # [-0.05, 0, +0.05]\n        self.threshold = np.clip(self.threshold + delta, 0.1, 0.9)\n        \n        # Get predicted anomaly (0/1)\n        pred = 1 if self.anomaly_scores[user_idx, self.current_step] > self.threshold else 0\n        \n        # Compute reward (use pseudo-labels if no ground truth)\n        if self.labels is not None:\n            true_label = self.labels[user_idx, self.current_step]\n        else:\n            # Fallback: Use static threshold baseline as pseudo-label\n            true_label = 1 if self.anomaly_scores[user_idx, self.current_step] > 0.5 else 0\n        \n        # Reward function (tune weights as needed)\n        reward = 0\n        if pred == true_label:\n            reward += 1.0  # Correct prediction\n        else:\n            if pred == 1:  # False positive\n                reward -= 0.5\n            else:          # False negative\n                reward -= 1.5  # Higher penalty for missing threats\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= self.anomaly_scores.shape[1]  # End of episode\n        \n        return self._get_state(user_idx), reward, done, {}\n    \n    def reset(self) -> np.ndarray:\n        self.current_step = 0\n        self.threshold = 0.5  # Reset to initial threshold\n        return self._get_state(0)  # Return initial state\n\n\n# Dummy data (replace with your arrays)\nanomaly_scores = np.random.rand(n_users, n_days)  # Shape: (users, days)\nrole_bits = np.random.randint(0, 2, (n_users, n_days, 4))  # Shape: (users, days, 4)\nfeatures = np.random.rand(n_users, n_days, 11)    # Shape: (users, days, 11)\n\n# ----------------------------\n# 3. Train PPO Agent\n# ----------------------------\nenv = DummyVecEnv([lambda: AdaptiveThresholdEnv(\n    anomaly_scores, role_bits, features\n)])\n\nmodel = PPO(\n    \"MlpPolicy\", \n    env, \n    verbose=1,\n    policy_kwargs=dict(net_arch=[64, 64]),  # Neural network architecture\n    learning_rate=3e-4,\n    gamma=0.99,\n    ent_coef=0.01,\n    n_steps=1024,\n    batch_size=64,\n)\n\nmodel.learn(total_timesteps=50_000)\n\n# ----------------------------\n# 4. Evaluate Adaptive Thresholds\n# ----------------------------\n# Compare F1-score with static threshold\nfrom sklearn.metrics import f1_score\n\n# Static threshold baseline\nstatic_preds = (anomaly_scores > 0.5).astype(int)\nstatic_f1 = f1_score(labels.flatten(), static_preds.flatten())  # Replace `labels`\n\n# RL adaptive threshold\nadaptive_preds = []\nfor user_idx in range(n_users):\n    obs = env.reset()\n    for day in range(n_days):\n        action, _ = model.predict(obs)\n        obs, _, done, _ = env.step(action)\n        adaptive_preds.append(1 if anomaly_scores[user_idx, day] > env.envs[0].threshold else 0)\n\nadaptive_f1 = f1_score(labels.flatten(), adaptive_preds)  # Replace `labels`\n\nprint(f\"Static F1: {static_f1:.3f}, Adaptive F1: {adaptive_f1:.3f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#features\ninfo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:03:56.305726Z","iopub.execute_input":"2025-05-05T15:03:56.306390Z","iopub.status.idle":"2025-05-05T15:03:56.439904Z","shell.execute_reply.started":"2025-05-05T15:03:56.306364Z","shell.execute_reply":"2025-05-05T15:03:56.439203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\ninfo.iloc[:,2:] = scaler.fit_transform(info.iloc[:,2:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:13.361877Z","iopub.execute_input":"2025-05-05T15:08:13.362189Z","iopub.status.idle":"2025-05-05T15:08:13.656607Z","shell.execute_reply.started":"2025-05-05T15:08:13.362165Z","shell.execute_reply":"2025-05-05T15:08:13.655851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols = ['after_hours_logon_count', 'total_logon_count','device_connects','avg_content_word_count', 'text_files_accessed', 'files_accessed', 'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag','keyword_richness' ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:17.519534Z","iopub.execute_input":"2025-05-05T15:08:17.520011Z","iopub.status.idle":"2025-05-05T15:08:17.523525Z","shell.execute_reply.started":"2025-05-05T15:08:17.519991Z","shell.execute_reply":"2025-05-05T15:08:17.522807Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a = info[ ['user','date_only'] + feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:19.019324Z","iopub.execute_input":"2025-05-05T15:08:19.019792Z","iopub.status.idle":"2025-05-05T15:08:19.038868Z","shell.execute_reply.started":"2025-05-05T15:08:19.019769Z","shell.execute_reply":"2025-05-05T15:08:19.038003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:20.839443Z","iopub.execute_input":"2025-05-05T15:08:20.839717Z","iopub.status.idle":"2025-05-05T15:08:20.853340Z","shell.execute_reply.started":"2025-05-05T15:08:20.839696Z","shell.execute_reply":"2025-05-05T15:08:20.852752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:32.479733Z","iopub.execute_input":"2025-05-05T15:08:32.480406Z","iopub.status.idle":"2025-05-05T15:08:32.485019Z","shell.execute_reply.started":"2025-05-05T15:08:32.480376Z","shell.execute_reply":"2025-05-05T15:08:32.484524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"a.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:08:35.599544Z","iopub.execute_input":"2025-05-05T15:08:35.600075Z","iopub.status.idle":"2025-05-05T15:08:35.604326Z","shell.execute_reply.started":"2025-05-05T15:08:35.600047Z","shell.execute_reply":"2025-05-05T15:08:35.603723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:09:10.859616Z","iopub.execute_input":"2025-05-05T15:09:10.860140Z","iopub.status.idle":"2025-05-05T15:09:10.868413Z","shell.execute_reply.started":"2025-05-05T15:09:10.860117Z","shell.execute_reply":"2025-05-05T15:09:10.867822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all = np.load('/kaggle/working/mu_all.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:11:43.520201Z","iopub.execute_input":"2025-05-05T15:11:43.520486Z","iopub.status.idle":"2025-05-05T15:11:43.607203Z","shell.execute_reply.started":"2025-05-05T15:11:43.520466Z","shell.execute_reply":"2025-05-05T15:11:43.606304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:11:46.659541Z","iopub.execute_input":"2025-05-05T15:11:46.659795Z","iopub.status.idle":"2025-05-05T15:11:46.664995Z","shell.execute_reply.started":"2025-05-05T15:11:46.659775Z","shell.execute_reply":"2025-05-05T15:11:46.664484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:11:50.744626Z","iopub.execute_input":"2025-05-05T15:11:50.744892Z","iopub.status.idle":"2025-05-05T15:11:50.749733Z","shell.execute_reply.started":"2025-05-05T15:11:50.744872Z","shell.execute_reply":"2025-05-05T15:11:50.749065Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features = a\nroles_df = roles","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:37:21.449556Z","iopub.execute_input":"2025-05-06T07:37:21.450334Z","iopub.status.idle":"2025-05-06T07:37:21.453519Z","shell.execute_reply.started":"2025-05-06T07:37:21.450301Z","shell.execute_reply":"2025-05-06T07:37:21.452787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:37:45.232473Z","iopub.execute_input":"2025-05-06T07:37:45.232708Z","iopub.status.idle":"2025-05-06T07:37:45.242134Z","shell.execute_reply.started":"2025-05-06T07:37:45.232693Z","shell.execute_reply":"2025-05-06T07:37:45.241371Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df_features.merge(roles_df, on=\"user\", how=\"left\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:19.599757Z","iopub.execute_input":"2025-05-05T15:22:19.600315Z","iopub.status.idle":"2025-05-05T15:22:19.692241Z","shell.execute_reply.started":"2025-05-05T15:22:19.600293Z","shell.execute_reply":"2025-05-05T15:22:19.691443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:26.182676Z","iopub.execute_input":"2025-05-05T15:22:26.183177Z","iopub.status.idle":"2025-05-05T15:22:26.198439Z","shell.execute_reply.started":"2025-05-05T15:22:26.183153Z","shell.execute_reply":"2025-05-05T15:22:26.197703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = np.concatenate([\n    df.drop([\"user\", \"date_only\"], axis=1).values,\n    mu_all\n], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:30.159868Z","iopub.execute_input":"2025-05-05T15:22:30.160172Z","iopub.status.idle":"2025-05-05T15:22:30.219069Z","shell.execute_reply.started":"2025-05-05T15:22:30.160149Z","shell.execute_reply":"2025-05-05T15:22:30.218283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:31.459706Z","iopub.execute_input":"2025-05-05T15:22:31.459969Z","iopub.status.idle":"2025-05-05T15:22:31.464742Z","shell.execute_reply.started":"2025-05-05T15:22:31.459950Z","shell.execute_reply":"2025-05-05T15:22:31.464074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf = IsolationForest(contamination=0.01, random_state=42)  # Adjust contamination\nclf.fit(X)\nanomaly_scores = -clf.decision_function(X)  # Higher = more anomalous\nanomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())  # [0, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:22:43.639916Z","iopub.execute_input":"2025-05-05T15:22:43.640558Z","iopub.status.idle":"2025-05-05T15:22:58.391278Z","shell.execute_reply.started":"2025-05-05T15:22:43.640533Z","shell.execute_reply":"2025-05-05T15:22:58.390649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Histogram of Anomaly Scores (Check Separation)\nplt.hist(anomaly_scores, bins=50)\nplt.xlabel(\"Anomaly Score\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Anomaly Scores\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:23:54.319985Z","iopub.execute_input":"2025-05-05T15:23:54.320294Z","iopub.status.idle":"2025-05-05T15:23:54.583257Z","shell.execute_reply.started":"2025-05-05T15:23:54.320273Z","shell.execute_reply":"2025-05-05T15:23:54.582548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:24:26.082405Z","iopub.execute_input":"2025-05-05T15:24:26.082932Z","iopub.status.idle":"2025-05-05T15:24:26.087391Z","shell.execute_reply.started":"2025-05-05T15:24:26.082909Z","shell.execute_reply":"2025-05-05T15:24:26.086629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:25:09.659908Z","iopub.execute_input":"2025-05-05T15:25:09.660501Z","iopub.status.idle":"2025-05-05T15:25:09.663788Z","shell.execute_reply.started":"2025-05-05T15:25:09.660476Z","shell.execute_reply":"2025-05-05T15:25:09.663014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. \"Pseudo-ROC\" (if you had labels, replace pseudo_labels with real ones)\nlabels = is_anomaly  # Top 1% as anomalies\nfpr, tpr, _ = roc_curve(labels, anomaly_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:25:18.460088Z","iopub.execute_input":"2025-05-05T15:25:18.460365Z","iopub.status.idle":"2025-05-05T15:25:18.658924Z","shell.execute_reply.started":"2025-05-05T15:25:18.460346Z","shell.execute_reply":"2025-05-05T15:25:18.658075Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"IF with rolling_mean and avg","metadata":{}},{"cell_type":"code","source":"df_features['date_only'] = pd.to_datetime(df_features['date_only'])\ndf_features = df_features.sort_values(['user', 'date_only'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:26:52.939620Z","iopub.execute_input":"2025-05-05T15:26:52.939892Z","iopub.status.idle":"2025-05-05T15:26:53.018454Z","shell.execute_reply.started":"2025-05-05T15:26:52.939872Z","shell.execute_reply":"2025-05-05T15:26:53.017689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:27:06.645515Z","iopub.execute_input":"2025-05-05T15:27:06.646229Z","iopub.status.idle":"2025-05-05T15:27:06.661295Z","shell.execute_reply.started":"2025-05-05T15:27:06.646207Z","shell.execute_reply":"2025-05-05T15:27:06.660550Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rolling_features = []\nfor feature in df_features.columns[2:13]:  # Assuming columns 2-12 are your 11 features\n    df_features[f'{feature}_rolling_mean'] = df_features.groupby('user')[feature].transform(\n        lambda x: x.rolling(7, min_periods=1).mean()\n    )\n    df_features[f'{feature}_rolling_std'] = df_features.groupby('user')[feature].transform(\n        lambda x: x.rolling(7, min_periods=1).std().fillna(0)\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:27:46.159416Z","iopub.execute_input":"2025-05-05T15:27:46.160079Z","iopub.status.idle":"2025-05-05T15:27:52.248103Z","shell.execute_reply.started":"2025-05-05T15:27:46.160045Z","shell.execute_reply":"2025-05-05T15:27:52.247525Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:28:47.341047Z","iopub.execute_input":"2025-05-05T15:28:47.341598Z","iopub.status.idle":"2025-05-05T15:28:47.559792Z","shell.execute_reply.started":"2025-05-05T15:28:47.341577Z","shell.execute_reply":"2025-05-05T15:28:47.559081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_static = df_features.drop(['user', 'date_only'], axis=1).values  # Original 11 + 14 rolling = 25 features\nX_static.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:36:37.970554Z","iopub.execute_input":"2025-05-05T15:36:37.970825Z","iopub.status.idle":"2025-05-05T15:36:38.080993Z","shell.execute_reply.started":"2025-05-05T15:36:37.970805Z","shell.execute_reply":"2025-05-05T15:36:38.080239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_combined = np.concatenate([X_static, mu_all], axis=1)  # +8 latent = 33 total features\nX_combined.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:37:31.911483Z","iopub.execute_input":"2025-05-05T15:37:31.911754Z","iopub.status.idle":"2025-05-05T15:37:31.985285Z","shell.execute_reply.started":"2025-05-05T15:37:31.911735Z","shell.execute_reply":"2025-05-05T15:37:31.984624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train IF (now with temporal context)\nclf = IsolationForest(\n    contamination=0.01,  # Adjust based on expected anomaly rate\n    random_state=42,\n    n_jobs=-1\n)\nclf.fit(X_combined)\nanomaly_scores = -clf.decision_function(X_combined)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:38:27.735989Z","iopub.execute_input":"2025-05-05T15:38:27.736305Z","iopub.status.idle":"2025-05-05T15:38:44.178205Z","shell.execute_reply.started":"2025-05-05T15:38:27.736283Z","shell.execute_reply":"2025-05-05T15:38:44.177427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.hist(anomaly_scores, bins=50)\nplt.xlabel(\"Anomaly Score\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Distribution of Anomaly Scores\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:42:36.170379Z","iopub.execute_input":"2025-05-05T15:42:36.171149Z","iopub.status.idle":"2025-05-05T15:42:36.378734Z","shell.execute_reply.started":"2025-05-05T15:42:36.171120Z","shell.execute_reply":"2025-05-05T15:42:36.377948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fpr, tpr, _ = roc_curve(labels, anomaly_scores)\nroc_auc = auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label=f\"ROC (AUC = {roc_auc:.2f})\")\nplt.plot([0, 1], [0, 1], linestyle=\"--\")\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:42:49.239553Z","iopub.execute_input":"2025-05-05T15:42:49.239819Z","iopub.status.idle":"2025-05-05T15:42:49.455952Z","shell.execute_reply.started":"2025-05-05T15:42:49.239799Z","shell.execute_reply":"2025-05-05T15:42:49.455216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gym\nfrom gym import spaces","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:08:12.071232Z","iopub.execute_input":"2025-05-06T12:08:12.071946Z","iopub.status.idle":"2025-05-06T12:08:12.075338Z","shell.execute_reply.started":"2025-05-06T12:08:12.071920Z","shell.execute_reply":"2025-05-06T12:08:12.074546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AdaptiveThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles, users, window_size=7):\n        super().__init__()\n        self.anomaly_scores = anomaly_scores  # Shape: (n_samples,)\n        self.roles = roles                    # Shape: (n_samples, 4)\n        self.users = users                    # Array of user IDs\n        self.window_size = window_size\n        \n        # Action space: 0=decrease, 1=keep, 2=increase\n        self.action_space = spaces.Discrete(3)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_0, ..., role_3]\n        self.observation_space = spaces.Box(low=0, high=1, shape=(7,), dtype=np.float32)\n        \n        # Trackers\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_steps = {user: 0 for user in np.unique(users)}  # Per-user step counter\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        user_mask = (self.users == user)\n        user_scores = self.anomaly_scores[user_mask]\n        \n        # Rolling stats for the current user\n        start_idx = max(0, self.user_steps[user] - self.window_size)\n        rolling_scores = user_scores[start_idx:self.user_steps[user]]\n        rolling_mean = np.mean(rolling_scores) if len(rolling_scores) > 0 else 0\n        rolling_std = np.std(rolling_scores) if len(rolling_scores) > 0 else 0\n        \n        # Current role bits\n        role = self.roles[self.current_step]\n        \n        return np.array([\n            self.anomaly_scores[self.current_step],\n            rolling_mean,\n            rolling_std,\n            *role\n        ], dtype=np.float32)\n\n    def step(self, action):\n        # Adjust threshold\n        delta = 0.05 * (action - 1)  # [-0.05, 0, +0.05]\n        self.threshold = np.clip(self.threshold + delta, 0.1, 0.9)\n        \n        # Pseudo-label (1 if anomaly, 0 otherwise)\n        pseudo_label = 1 if self.anomaly_scores[self.current_step] > 0.5 else 0  # Static baseline\n        \n        # Cost-sensitive reward (adjust weights based on imbalance)\n        true_positive_reward = 1.0\n        false_negative_penalty = -5.0  # Heavy penalty for missing anomalies\n        false_positive_penalty = -0.5\n        true_negative_reward = 0.1\n        \n        pred = 1 if self.anomaly_scores[self.current_step] > self.threshold else 0\n        \n        if pred == pseudo_label:\n            reward = true_positive_reward if pred == 1 else true_negative_reward\n        else:\n            reward = false_negative_penalty if pred == 0 else false_positive_penalty\n        \n        # Update trackers\n        self.user_steps[self.users[self.current_step]] += 1\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {}\n\n    def reset(self):\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_steps = {user: 0 for user in np.unique(self.users)}\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:46:49.819093Z","iopub.execute_input":"2025-05-05T15:46:49.819683Z","iopub.status.idle":"2025-05-05T15:46:49.829767Z","shell.execute_reply.started":"2025-05-05T15:46:49.819663Z","shell.execute_reply":"2025-05-05T15:46:49.828967Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\n\n# Create environment\nenv = make_vec_env(\n    lambda: AdaptiveThresholdEnv(anomaly_scores, roles_df[[\"role_0\", \"role_1\", \"role_2\", \"role_3\"]].values, df[\"user\"].values),\n    n_envs=4\n)\n\n# Train PPO with class-weighted rewards\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(net_arch=[64, 64]),\n    learning_rate=3e-4,\n    gamma=0.99,\n    ent_coef=0.01,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:46:59.459254Z","iopub.execute_input":"2025-05-05T15:46:59.459520Z","iopub.status.idle":"2025-05-05T15:47:29.746949Z","shell.execute_reply.started":"2025-05-05T15:46:59.459502Z","shell.execute_reply":"2025-05-05T15:47:29.745968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:49:09.750246Z","iopub.execute_input":"2025-05-05T15:49:09.750926Z","iopub.status.idle":"2025-05-05T15:49:09.755320Z","shell.execute_reply.started":"2025-05-05T15:49:09.750907Z","shell.execute_reply":"2025-05-05T15:49:09.754717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:49:32.060122Z","iopub.execute_input":"2025-05-05T15:49:32.060402Z","iopub.status.idle":"2025-05-05T15:49:32.065600Z","shell.execute_reply.started":"2025-05-05T15:49:32.060382Z","shell.execute_reply":"2025-05-05T15:49:32.064893Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_merged = df_features.merge(roles_df, on='user', how='left')\n\n# Now roles are aligned with user-days\nroles_expanded = df_merged[['role_0', 'role_1', 'role_2', 'role_3']].values  # Shape: (330285, 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:38:19.310610Z","iopub.execute_input":"2025-05-06T07:38:19.311115Z","iopub.status.idle":"2025-05-06T07:38:19.412339Z","shell.execute_reply.started":"2025-05-06T07:38:19.311091Z","shell.execute_reply":"2025-05-06T07:38:19.411734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles_expanded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:38:20.667202Z","iopub.execute_input":"2025-05-06T07:38:20.667668Z","iopub.status.idle":"2025-05-06T07:38:20.672379Z","shell.execute_reply.started":"2025-05-06T07:38:20.667644Z","shell.execute_reply":"2025-05-06T07:38:20.671852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_rows = np.unique(roles_expanded, axis=0)\nprint(unique_rows)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:39:01.287429Z","iopub.execute_input":"2025-05-06T07:39:01.288074Z","iopub.status.idle":"2025-05-06T07:39:01.827146Z","shell.execute_reply.started":"2025-05-06T07:39:01.288047Z","shell.execute_reply":"2025-05-06T07:39:01.826477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_rows, inverse_indices = np.unique(roles_expanded, axis=0, return_inverse=True)\n\n# Map each row to an integer label starting from 1\nroles_labeled = inverse_indices + 1\n\nprint(\"Transformed roles_expanded:\")\nprint(roles_labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:40:17.452397Z","iopub.execute_input":"2025-05-06T07:40:17.452655Z","iopub.status.idle":"2025-05-06T07:40:18.010118Z","shell.execute_reply.started":"2025-05-06T07:40:17.452637Z","shell.execute_reply":"2025-05-06T07:40:18.009365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles_labeled.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:41:13.133231Z","iopub.execute_input":"2025-05-06T07:41:13.133931Z","iopub.status.idle":"2025-05-06T07:41:13.138589Z","shell.execute_reply.started":"2025-05-06T07:41:13.133904Z","shell.execute_reply":"2025-05-06T07:41:13.137854Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.unique(roles_labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:40:44.007984Z","iopub.execute_input":"2025-05-06T07:40:44.008267Z","iopub.status.idle":"2025-05-06T07:40:44.016929Z","shell.execute_reply.started":"2025-05-06T07:40:44.008247Z","shell.execute_reply":"2025-05-06T07:40:44.016175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AdaptiveThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, window_size=7):\n        self.anomaly_scores = anomaly_scores  # Shape: (330285,)\n        self.roles = roles_expanded          # Shape: (330285, 4)\n        self.users = users                  # Shape: (330285,) user IDs\n        self.window_size = window_size\n        \n        # Action space: 0=decrease, 1=keep, 2=increase\n        self.action_space = spaces.Discrete(3)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_0, ..., role_3]\n        self.observation_space = spaces.Box(low=0, high=1, shape=(7,), dtype=np.float32)\n        \n        # Trackers\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_history = {}  # Track rolling stats per user\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        \n        # Initialize user history if not exists\n        if user not in self.user_history:\n            self.user_history[user] = {'scores': []}\n        \n        # Update rolling window\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > self.window_size:\n            self.user_history[user]['scores'].pop(0)\n        \n        # Compute stats\n        scores = self.user_history[user]['scores']\n        rolling_mean = np.mean(scores) if scores else 0\n        rolling_std = np.std(scores) if scores else 0\n        \n        # Get role for current step\n        role = self.roles[self.current_step]  # Now safe (roles_expanded matches anomaly_scores)\n        \n        return np.array([\n            self.anomaly_scores[self.current_step],\n            rolling_mean,\n            rolling_std,\n            *role\n        ], dtype=np.float32)\n\n    def step(self, action):\n        # Adjust threshold\n        delta = 0.05 * (action - 1)  # [-0.05, 0, +0.05]\n        self.threshold = np.clip(self.threshold + delta, 0.1, 0.9)\n        \n        # Pseudo-reward (replace with your actual labels if available)\n        pred_anomaly = self.anomaly_scores[self.current_step] > self.threshold\n        reward = 1.0 if pred_anomaly else 0.1  # Simplified example\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {}\n\n    def reset(self):\n        self.current_step = 0\n        self.threshold = 0.5\n        self.user_history = {}\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:51:23.359623Z","iopub.execute_input":"2025-05-05T15:51:23.360123Z","iopub.status.idle":"2025-05-05T15:51:23.371205Z","shell.execute_reply.started":"2025-05-05T15:51:23.360098Z","shell.execute_reply":"2025-05-05T15:51:23.370281Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create environment\nenv = DummyVecEnv([\n    lambda: AdaptiveThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_expanded=roles_expanded,\n        users=df_merged['user'].values\n    )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:51:54.240475Z","iopub.execute_input":"2025-05-05T15:51:54.241007Z","iopub.status.idle":"2025-05-05T15:51:54.245830Z","shell.execute_reply.started":"2025-05-05T15:51:54.240984Z","shell.execute_reply":"2025-05-05T15:51:54.245056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train PPO\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(net_arch=[64, 64]),\n    learning_rate=3e-4,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T15:52:01.004827Z","iopub.execute_input":"2025-05-05T15:52:01.005157Z","iopub.status.idle":"2025-05-05T15:55:22.095286Z","shell.execute_reply.started":"2025-05-05T15:52:01.005131Z","shell.execute_reply":"2025-05-05T15:55:22.094571Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_global_model(model, anomaly_scores, roles_expanded, users, true_labels):\n    \"\"\"Index-safe evaluation with proper step handling.\"\"\"\n    # Validate inputs\n    assert isinstance(users, np.ndarray), \"Users must be a NumPy array\"\n    assert len(anomaly_scores) == len(roles_expanded) == len(users), \\\n        \"Input arrays must have the same length\"\n    \n    env = AdaptiveThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_expanded=roles_expanded,\n        users=users\n    )\n    obs = env.reset()\n    preds, scores = [], []\n    \n    # Process all steps\n    while env.current_step < len(anomaly_scores):\n        # Get current score and threshold before stepping\n        current_score = anomaly_scores[env.current_step]\n        current_threshold = env.threshold\n        \n        # Store prediction (score > threshold)\n        preds.append(1 if current_score > current_threshold else 0)\n        scores.append(current_score)\n        \n        # Predict action and step (only if not at the end)\n        if env.current_step < len(anomaly_scores) - 1:\n            action, _ = model.predict(obs, deterministic=True)\n            obs, _, done, _ = env.step(action)\n            if done:\n                break\n        else:\n            # At the final step, don't step further\n            break\n    \n    # Ensure preds and true_labels align\n    preds = np.array(preds)\n    # Flatten true_labels if 2D (shape (n, 1) -> (n,))\n    true_labels = true_labels.flatten() if true_labels.ndim > 1 else true_labels\n    true_labels = true_labels[:len(preds)]  # Truncate to match preds length\n    \n    # Calculate metrics\n    metrics = {\n        \"precision\": precision_score(true_labels, preds, zero_division=0),\n        \"recall\": recall_score(true_labels, preds, zero_division=0),\n        \"f1\": f1_score(true_labels, preds, zero_division=0),\n        \"auc_roc\": roc_auc_score(true_labels, preds) if len(np.unique(true_labels)) > 1 else 0,\n        \"final_threshold\": env.threshold\n    }\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:59:49.786463Z","iopub.execute_input":"2025-05-05T16:59:49.786735Z","iopub.status.idle":"2025-05-05T16:59:49.794003Z","shell.execute_reply.started":"2025-05-05T16:59:49.786715Z","shell.execute_reply":"2025-05-05T16:59:49.793220Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n    cm = confusion_matrix(y_true, y_pred)\n    labels = [\"Normal\", \"Anomaly\"]\n\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n    plt.xlabel(\"Predicted Label\")\n    plt.ylabel(\"True Label\")\n    plt.title(title)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:59:51.823534Z","iopub.execute_input":"2025-05-05T16:59:51.823765Z","iopub.status.idle":"2025-05-05T16:59:51.828686Z","shell.execute_reply.started":"2025-05-05T16:59:51.823750Z","shell.execute_reply":"2025-05-05T16:59:51.827874Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"users=df_merged['user'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:58:13.724318Z","iopub.execute_input":"2025-05-05T16:58:13.724979Z","iopub.status.idle":"2025-05-05T16:58:13.728194Z","shell.execute_reply.started":"2025-05-05T16:58:13.724958Z","shell.execute_reply":"2025-05-05T16:58:13.727469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"anomaly_scores.shape, roles_expanded.shape, is_anomaly.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:54:09.288987Z","iopub.execute_input":"2025-05-05T16:54:09.289475Z","iopub.status.idle":"2025-05-05T16:54:09.294114Z","shell.execute_reply.started":"2025-05-05T16:54:09.289452Z","shell.execute_reply":"2025-05-05T16:54:09.293424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"users","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:57:50.882992Z","iopub.execute_input":"2025-05-05T16:57:50.883873Z","iopub.status.idle":"2025-05-05T16:57:50.888305Z","shell.execute_reply.started":"2025-05-05T16:57:50.883846Z","shell.execute_reply":"2025-05-05T16:57:50.887735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"users","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:58:05.983882Z","iopub.execute_input":"2025-05-05T16:58:05.984192Z","iopub.status.idle":"2025-05-05T16:58:05.988828Z","shell.execute_reply.started":"2025-05-05T16:58:05.984168Z","shell.execute_reply":"2025-05-05T16:58:05.988299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test with a small subset\nsmall_scores = anomaly_scores[:100]\nsmall_roles = roles_expanded[:100]\nsmall_users = users[:100]\nsmall_labels = is_anomaly[:100]\n\nmetrics = evaluate_global_model(model, small_scores, small_roles, small_users, small_labels)\nprint(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T16:59:54.782995Z","iopub.execute_input":"2025-05-05T16:59:54.783585Z","iopub.status.idle":"2025-05-05T16:59:54.873292Z","shell.execute_reply.started":"2025-05-05T16:59:54.783562Z","shell.execute_reply":"2025-05-05T16:59:54.872533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After training:\nresults = evaluate_global_model(\n    model=model,\n    anomaly_scores=anomaly_scores,      \n    roles_expanded=roles_expanded,     \n    users=users,    \n    true_labels=is_anomaly             \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:00:24.724466Z","iopub.execute_input":"2025-05-05T17:00:24.725246Z","iopub.status.idle":"2025-05-05T17:04:46.011140Z","shell.execute_reply.started":"2025-05-05T17:00:24.725221Z","shell.execute_reply":"2025-05-05T17:04:46.010186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:06:16.463966Z","iopub.execute_input":"2025-05-05T17:06:16.464515Z","iopub.status.idle":"2025-05-05T17:06:16.468417Z","shell.execute_reply.started":"2025-05-05T17:06:16.464492Z","shell.execute_reply":"2025-05-05T17:06:16.467674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"\"\"\nFinal Threshold: {results['final_threshold']:.3f}\nPrecision: {results['metrics']['precision']:.3f}\nRecall: {results['metrics']['recall']:.3f}\nF1-Score: {results['metrics']['f1']:.3f}\nAUC-ROC: {results['metrics']['auc_roc']:.3f}\nMCC: {results['metrics']['mcc']:.3f}\n\"\"\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('ppo_globalthres.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:06:39.468286Z","iopub.execute_input":"2025-05-05T17:06:39.468576Z","iopub.status.idle":"2025-05-05T17:06:39.482630Z","shell.execute_reply.started":"2025-05-05T17:06:39.468555Z","shell.execute_reply":"2025-05-05T17:06:39.482076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_confusion_matrix(is_anomaly, results[\"predictions\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_global_model(model, anomaly_scores, roles_expanded, users, true_labels):\n    \"\"\"Index-safe evaluation with proper step handling.\"\"\"\n    # Validate inputs\n    assert isinstance(users, np.ndarray), \"Users must be a NumPy array\"\n    assert len(anomaly_scores) == len(roles_expanded) == len(users), \\\n        \"Input arrays must have the same length\"\n    \n    env = AdaptiveThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_expanded=roles_expanded,\n        users=users\n    )\n    obs = env.reset()\n    preds, scores = [], []\n    \n    # Process all steps\n    while env.current_step < len(anomaly_scores):\n        current_score = anomaly_scores[env.current_step]\n        current_threshold = env.threshold\n        preds.append(1 if current_score > current_threshold else 0)\n        scores.append(current_score)\n        \n        if env.current_step < len(anomaly_scores) - 1:\n            action, _ = model.predict(obs, deterministic=True)\n            obs, _, done, _ = env.step(action)\n            if done:\n                break\n        else:\n            break\n    \n    # Ensure preds and true_labels align\n    preds = np.array(preds)\n    true_labels = true_labels.flatten() if true_labels.ndim > 1 else true_labels\n    true_labels = true_labels[:len(preds)]  # Truncate to match preds length\n    \n    # Calculate metrics\n    metrics = {\n        \"precision\": precision_score(true_labels, preds, zero_division=0),\n        \"recall\": recall_score(true_labels, preds, zero_division=0),\n        \"f1\": f1_score(true_labels, preds, zero_division=0),\n        \"auc_roc\": roc_auc_score(true_labels, preds) if len(np.unique(true_labels)) > 1 else 0,\n        \"final_threshold\": env.threshold\n    }\n    \n    return metrics, preds, true_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:08:47.759223Z","iopub.execute_input":"2025-05-05T17:08:47.759517Z","iopub.status.idle":"2025-05-05T17:08:47.766981Z","shell.execute_reply.started":"2025-05-05T17:08:47.759499Z","shell.execute_reply":"2025-05-05T17:08:47.766264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test with a small subset\nsmall_scores = anomaly_scores[:100]\nsmall_roles = roles_expanded[:100]\nsmall_users = users[:100]\nsmall_labels = is_anomaly[:100]\n\nmetrics = evaluate_global_model(model, small_scores, small_roles, small_users, small_labels)\nprint(metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:09:41.550794Z","iopub.execute_input":"2025-05-05T17:09:41.551080Z","iopub.status.idle":"2025-05-05T17:09:41.640708Z","shell.execute_reply.started":"2025-05-05T17:09:41.551059Z","shell.execute_reply":"2025-05-05T17:09:41.640189Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metrics, preds, true_labels = evaluate_global_model(\n    model, anomaly_scores, roles_expanded, users, is_anomaly\n)\nprint(\"Metrics:\", metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:12:20.548965Z","iopub.execute_input":"2025-05-05T17:12:20.549543Z","iopub.status.idle":"2025-05-05T17:16:39.725980Z","shell.execute_reply.started":"2025-05-05T17:12:20.549520Z","shell.execute_reply":"2025-05-05T17:16:39.724968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:16:45.689853Z","iopub.execute_input":"2025-05-05T17:16:45.690551Z","iopub.status.idle":"2025-05-05T17:16:45.693804Z","shell.execute_reply.started":"2025-05-05T17:16:45.690528Z","shell.execute_reply":"2025-05-05T17:16:45.693058Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(true_labels, preds)\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal (0)', 'Anomaly (1)'],\n            yticklabels=['Normal (0)', 'Anomaly (1)'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:16:46.969258Z","iopub.execute_input":"2025-05-05T17:16:46.969734Z","iopub.status.idle":"2025-05-05T17:16:47.214149Z","shell.execute_reply.started":"2025-05-05T17:16:46.969712Z","shell.execute_reply":"2025-05-05T17:16:47.213461Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class RoleAdaptiveThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, n_roles=10):\n        self.anomaly_scores = anomaly_scores  # Shape: (330285,)\n        self.role_ids = np.argmax(roles_expanded, axis=1) \n        self.users = users                    \n        self.n_roles = n_roles\n        \n        # Initialize separate thresholds per role\n        self.role_thresholds = np.linspace(0.3, 0.7, n_roles)\n        \n        # Action: Delta to adjust threshold ∈ [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # State: [current_score, rolling_mean, rolling_std, one_hot_role]\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,)),\n            \"role\": spaces.Discrete(n_roles)\n        })\n        \n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_id\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role_id] = np.clip(\n            self.role_thresholds[role_id] + action[0], \n            0.1, 0.9  # Hard bounds\n        )\n        \n        # Get prediction\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_id])\n        \n        # Reward (heavier penalties for high-risk roles)\n        reward = self._calculate_reward(pred, role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_id]\n        }\n\n    def _calculate_reward(self, pred, role_id):\n        # Define risk weights per role (e.g., role_0=highest risk)\n        role_weights = [2.0, 1.8, 1.5, 1.2, 1.0]  # Extend to n_roles\n        weight = role_weights[role_id % len(role_weights)]\n        \n        # Simplified reward (replace with your actual labels if available)\n        return weight * (10 if pred else -1)  # Customize based on FP/FN costs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert role bits to IDs (0-9)\nrole_ids = np.argmax(roles_expanded, axis=1)\n\n# Calculate anomaly frequency per role\nrole_anomaly_rates = pd.DataFrame({\n    'role_id': role_ids,\n    'is_anomaly': is_anomaly\n}).groupby('role_id')['is_anomaly'].mean()\n\nprint(\"Anomaly Rates per Role:\")\nprint(role_anomaly_rates.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:29:35.545092Z","iopub.execute_input":"2025-05-05T17:29:35.546000Z","iopub.status.idle":"2025-05-05T17:29:35.589073Z","shell.execute_reply.started":"2025-05-05T17:29:35.545965Z","shell.execute_reply":"2025-05-05T17:29:35.588087Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming roles_expanded is a (330285, 4) numpy array\nrole_ids = np.zeros(len(roles_expanded), dtype=int)\nfor i in range(4):  # For each bit\n    role_ids += (roles_expanded[:, i] * (2 ** i)).astype(int)\n\n# Verify unique roles\nprint(\"Unique Role IDs:\", np.unique(role_ids)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:32:27.059317Z","iopub.execute_input":"2025-05-05T17:32:27.059786Z","iopub.status.idle":"2025-05-05T17:32:27.074258Z","shell.execute_reply.started":"2025-05-05T17:32:27.059765Z","shell.execute_reply":"2025-05-05T17:32:27.073677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly = is_anomaly.reshape(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:34:07.148827Z","iopub.execute_input":"2025-05-05T17:34:07.149528Z","iopub.status.idle":"2025-05-05T17:34:07.152828Z","shell.execute_reply.started":"2025-05-05T17:34:07.149502Z","shell.execute_reply":"2025-05-05T17:34:07.152008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nrole_df = pd.DataFrame({\n    'role_id': role_ids,\n    'is_anomaly': is_anomaly  # Your anomaly labels (330285,)\n})\n\n# Calculate anomaly frequency per role\nrole_anomaly_rates = role_df.groupby('role_id')['is_anomaly'].mean()\nprint(\"Anomaly Rates per Role:\")\nprint(role_anomaly_rates.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:34:11.057946Z","iopub.execute_input":"2025-05-05T17:34:11.058490Z","iopub.status.idle":"2025-05-05T17:34:11.077484Z","shell.execute_reply.started":"2025-05-05T17:34:11.058467Z","shell.execute_reply":"2025-05-05T17:34:11.076746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Normalize weights between [0.5, 2.0] based on anomaly rates\nmin_rate = role_anomaly_rates.min()\nmax_rate = role_anomaly_rates.max()\nrole_weights = (role_anomaly_rates - min_rate) / (max_rate - min_rate + 1e-8) * 1.5 + 0.5\nrole_weights = role_weights.to_dict()  # {role_id: weight}\n\nprint(\"Role Weights:\")\nprint(role_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:34:24.269990Z","iopub.execute_input":"2025-05-05T17:34:24.270696Z","iopub.status.idle":"2025-05-05T17:34:24.275799Z","shell.execute_reply.started":"2025-05-05T17:34:24.270672Z","shell.execute_reply":"2025-05-05T17:34:24.275223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RoleWeightedThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, is_anomaly):\n        # Convert bit-encoded roles to IDs\n        self.role_ids = np.sum(roles_expanded * (2 ** np.arange(4)), axis=1)  # Shape: (330285,)\n        \n        # Calculate role weights\n        self.role_weights = self._calculate_role_weights(self.role_ids, is_anomaly)\n        \n        # Initialize thresholds per role\n        self.role_thresholds = np.ones(len(role_weights)) * 0.5  # Default threshold=0.5\n        \n        # Action space: threshold delta ∈ [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_id_one_hot]\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,)),\n            \"role\": spaces.Discrete(len(role_weights))\n        })\n        \n        # Trackers\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _calculate_role_weights(self, role_ids, is_anomaly):\n        \"\"\"Compute weights based on anomaly frequency per role.\"\"\"\n        df = pd.DataFrame({'role': role_ids, 'is_anomaly': is_anomaly})\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        return (anomaly_rates / anomaly_rates.max() * 2.0).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_id\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role_id] = np.clip(\n            self.role_thresholds[role_id] + action[0], \n            0.1, 0.9\n        )\n        \n        # Get prediction and reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_id])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_id]\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        \"\"\"Weighted reward based on role risk.\"\"\"\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label == 1:  # Anomaly\n            return 50.0 * weight if pred == 1 else -100.0 * weight  # Heavy FN penalty\n        else:                # Normal\n            return 0.1 if pred == 0 else -2.0 / weight  # Smaller FP penalty","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:39:06.469959Z","iopub.execute_input":"2025-05-05T17:39:06.470537Z","iopub.status.idle":"2025-05-05T17:39:06.481741Z","shell.execute_reply.started":"2025-05-05T17:39:06.470512Z","shell.execute_reply":"2025-05-05T17:39:06.481213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from stable_baselines3 import PPO\nfrom stable_baselines3.common.policies import MultiInputPolicy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:48:41.767763Z","iopub.execute_input":"2025-05-05T17:48:41.768084Z","iopub.status.idle":"2025-05-05T17:48:41.787049Z","shell.execute_reply.started":"2025-05-05T17:48:41.768062Z","shell.execute_reply":"2025-05-05T17:48:41.786138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(\n        net_arch=[dict(pi=[64, 64], vf=[64, 64])]  # Separate policy/value networks\n    ),\n    learning_rate=3e-4,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:47:08.728303Z","iopub.execute_input":"2025-05-05T17:47:08.728946Z","iopub.status.idle":"2025-05-05T17:47:08.751828Z","shell.execute_reply.started":"2025-05-05T17:47:08.728922Z","shell.execute_reply":"2025-05-05T17:47:08.750796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:42:02.829472Z","iopub.execute_input":"2025-05-05T17:42:02.830316Z","iopub.status.idle":"2025-05-05T17:42:02.851508Z","shell.execute_reply.started":"2025-05-05T17:42:02.830287Z","shell.execute_reply":"2025-05-05T17:42:02.850501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from stable_baselines3.common.env_util import make_vec_env\n\n# Create and vectorize the environment\nenv = make_vec_env(\n    lambda: RoleWeightedThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly),\n    n_envs=1\n)\n\n# Train PPO with MultiInputPolicy\nmodel = PPO(\n    \"MultiInputPolicy\",\n    env,\n    policy_kwargs=dict(\n        net_arch=[dict(pi=[64, 64], vf=[64, 64])]  # Separate policy/value networks\n    ),\n    learning_rate=3e-4,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:51:08.088294Z","iopub.execute_input":"2025-05-05T17:51:08.088835Z","iopub.status.idle":"2025-05-05T17:51:08.133104Z","shell.execute_reply.started":"2025-05-05T17:51:08.088816Z","shell.execute_reply":"2025-05-05T17:51:08.131947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class VecEnvResetWrapper(gym.Wrapper):\n    def __init__(self, env):\n        super().__init__(env)\n        self.info_buffer = [{}] * self.env.num_envs if hasattr(self.env, \"num_envs\") else [{}]\n\n    def reset(self, **kwargs):\n        obs, info = self.env.reset(**kwargs)\n        self.info_buffer = info if isinstance(info, list) else [info]\n        return obs\n\n    def step(self, action):\n        obs, reward, done, info = self.env.step(action)\n        self.info_buffer = info if isinstance(info, list) else [info]\n        return obs, reward, done, info\n\nclass RoleWeightedThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, is_anomaly):\n        # Normalize anomaly scores to [0, 1]\n        anomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())\n        self.anomaly_scores = anomaly_scores  # Shape: (330285,)\n        self.users = users                    # Shape: (330285,)\n        self.is_anomaly = is_anomaly.flatten()  # Shape: (330285,)\n        self.roles_expanded = roles_expanded  # Shape: (330285, 4)\n        \n        # Convert bit-encoded roles to IDs\n        self.role_ids = np.sum(roles_expanded * (2 ** np.arange(4)), axis=1)  # Shape: (330285,)\n        \n        # Calculate role weights\n        self.role_weights = self._calculate_role_weights(self.role_ids, self.is_anomaly)\n        \n        # Initialize thresholds per role\n        self.role_thresholds = np.ones(len(self.role_weights)) * 0.5  # Default threshold=0.5\n        \n        # Action space: threshold delta ∈ [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # State space: [current_score, rolling_mean, rolling_std, role_id]\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32),\n            \"role\": spaces.Discrete(len(self.role_weights))\n        })\n        \n        # Trackers\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _calculate_role_weights(self, role_ids, is_anomaly):\n        \"\"\"Compute weights based on anomaly frequency per role.\"\"\"\n        df = pd.DataFrame({'role': role_ids, 'is_anomaly': is_anomaly})\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        return (anomaly_rates / anomaly_rates.max() * 2.0).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"scores\": np.zeros(3, dtype=np.float32),\n                \"role\": 0\n            }\n        \n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_id\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role_id] = np.clip(\n            self.role_thresholds[role_id] + action[0], \n            0.1, 0.9\n        )\n        \n        # Get prediction and reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_id])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_id]\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        \"\"\"Weighted reward based on role risk.\"\"\"\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label == 1:  # Anomaly\n            return 50.0 * weight if pred == 1 else -100.0 * weight  # Heavy FN penalty\n        else:                # Normal\n            return 0.1 if pred == 0 else -2.0 / weight  # Smaller FP penalty\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n        self.role_thresholds = np.ones(len(self.role_weights)) * 0.5  # Reset thresholds\n        return self._get_state(), {}  # Return observation and info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:54:06.969014Z","iopub.execute_input":"2025-05-05T17:54:06.969368Z","iopub.status.idle":"2025-05-05T17:54:06.983759Z","shell.execute_reply.started":"2025-05-05T17:54:06.969345Z","shell.execute_reply":"2025-05-05T17:54:06.982931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = make_vec_env(\n    lambda: RoleWeightedThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly),\n    n_envs=1\n)\nenv = VecEnvResetWrapper(env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:54:26.608397Z","iopub.execute_input":"2025-05-05T17:54:26.608655Z","iopub.status.idle":"2025-05-05T17:54:26.636245Z","shell.execute_reply.started":"2025-05-05T17:54:26.608635Z","shell.execute_reply":"2025-05-05T17:54:26.635502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PPO(\n    \"MultiInputPolicy\",\n    env,\n    policy_kwargs=dict(\n        net_arch=dict(pi=[64, 64], vf=[64, 64])\n    ),\n    learning_rate=3e-4,\n    verbose=1\n)\nmodel.learn(total_timesteps=100_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T17:54:35.269129Z","iopub.execute_input":"2025-05-05T17:54:35.269761Z","iopub.status.idle":"2025-05-05T17:54:35.295729Z","shell.execute_reply.started":"2025-05-05T17:54:35.269740Z","shell.execute_reply":"2025-05-05T17:54:35.294801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SimpleRoleThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, n_roles=10):\n        self.anomaly_scores = anomaly_scores\n        self.roles = np.argmax(roles_expanded, axis=1)  # Convert to role IDs 0-9\n        self.users = users\n        self.n_roles = n_roles\n        \n        # Initialize thresholds per role\n        self.role_thresholds = np.ones(n_roles) * 0.5\n        \n        # Action space: threshold adjustment [-0.1, 0.1]\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # Simplified observation: [current_score, rolling_mean, rolling_std, role_id_normalized]\n        self.observation_space = spaces.Box(\n            low=np.array([0, 0, 0, 0]),\n            high=np.array([1, 1, 1, 1]),\n            dtype=np.float32\n        )\n        \n        self.current_step = 0\n        self.user_history = {}\n\n    def _get_rolling_stats(self, user):\n        if user not in self.user_history:\n            self.user_history[user] = []\n        \n        scores = self.user_history[user]\n        if len(scores) > 7:\n            scores.pop(0)\n        \n        mean = np.mean(scores) if scores else 0\n        std = np.std(scores) if scores else 0\n        return mean, std\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = {}\n        return self._get_state()\n\n    def _get_state(self):\n        user = self.users[self.current_step]\n        role = self.roles[self.current_step]\n        \n        # Update rolling stats\n        current_score = self.anomaly_scores[self.current_step]\n        if user in self.user_history:\n            self.user_history[user].append(current_score)\n        else:\n            self.user_history[user] = [current_score]\n        \n        mean, std = self._get_rolling_stats(user)\n        \n        # Normalize role ID to [0,1]\n        normalized_role = role / (self.n_roles - 1)\n        \n        return np.array([\n            current_score,\n            mean,\n            std,\n            normalized_role\n        ], dtype=np.float32)\n\n    def step(self, action):\n        role = self.roles[self.current_step]\n        \n        # Update role-specific threshold\n        self.role_thresholds[role] = np.clip(\n            self.role_thresholds[role] + action[0],\n            0.1, 0.9\n        )\n        \n        # Get prediction\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role])\n        \n        # Simple reward\n        reward = 10 if pred else -1\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {}\n\n# Initialize and train\nenv = SimpleRoleThresholdEnv(\n    anomaly_scores=anomaly_scores,\n    roles_expanded=roles_expanded,\n    users=users\n)\n\n# Wrap for Stable Baselines3\nfrom stable_baselines3.common.vec_env import DummyVecEnv\nenv = DummyVecEnv([lambda: env])\n\n# Train with MlpPolicy (now compatible)\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs=dict(net_arch=[64, 64]),\n    verbose=1\n)\nmodel.learn(total_timesteps=100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:00:01.868997Z","iopub.execute_input":"2025-05-05T18:00:01.869763Z","iopub.status.idle":"2025-05-05T18:03:02.267070Z","shell.execute_reply.started":"2025-05-05T18:00:01.869737Z","shell.execute_reply":"2025-05-05T18:03:02.266349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(env.envs[0].role_thresholds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:03:18.448070Z","iopub.execute_input":"2025-05-05T18:03:18.448347Z","iopub.status.idle":"2025-05-05T18:03:18.452796Z","shell.execute_reply.started":"2025-05-05T18:03:18.448326Z","shell.execute_reply":"2025-05-05T18:03:18.451971Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(env.envs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:22:45.928759Z","iopub.execute_input":"2025-05-05T18:22:45.929167Z","iopub.status.idle":"2025-05-05T18:22:45.933954Z","shell.execute_reply.started":"2025-05-05T18:22:45.929138Z","shell.execute_reply":"2025-05-05T18:22:45.933050Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(env.envs[0].unwrapped)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:24:04.288749Z","iopub.execute_input":"2025-05-05T18:24:04.289092Z","iopub.status.idle":"2025-05-05T18:24:04.293706Z","shell.execute_reply.started":"2025-05-05T18:24:04.289016Z","shell.execute_reply":"2025-05-05T18:24:04.292883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(env.envs[0].unwrapped.__dict__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:24:50.953409Z","iopub.execute_input":"2025-05-05T18:24:50.953678Z","iopub.status.idle":"2025-05-05T18:24:50.957934Z","shell.execute_reply.started":"2025-05-05T18:24:50.953658Z","shell.execute_reply":"2025-05-05T18:24:50.957167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ppo ","metadata":{}},{"cell_type":"code","source":"class RoleWeightedThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_expanded, users, is_anomaly):\n        # Normalize and store data\n        self.anomaly_scores = (anomaly_scores - anomaly_scores.min()) / (anomaly_scores.max() - anomaly_scores.min())\n        self.users = users\n        self.is_anomaly = is_anomaly.flatten()\n        self.roles_expanded = roles_expanded\n\n        # Convert roles to integer IDs\n        self.role_ids = np.sum(roles_expanded * (2 ** np.arange(4)), axis=1)\n        unique_roles = np.unique(self.role_ids)\n        self.num_roles = len(unique_roles)\n        self.role_to_idx = {role: idx for idx, role in enumerate(unique_roles)}\n        \n        # Calculate role weights\n        self.role_weights = self._calculate_role_weights()\n        \n        # Initialize thresholds\n        self.role_thresholds = np.ones(self.num_roles) * 0.5\n        \n        # Action space\n        self.action_space = spaces.Box(low=-0.1, high=0.1, shape=(1,), dtype=np.float32)\n        \n        # Observation space\n        self.observation_space = spaces.Dict({\n            \"scores\": spaces.Box(low=0, high=1, shape=(3,), dtype=np.float32),\n            \"role\": spaces.Box(low=0, high=1, shape=(self.num_roles,), dtype=np.float32)\n        })\n        \n        # Trackers\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n\n    def _calculate_role_weights(self):\n        df = pd.DataFrame({'role': self.role_ids, 'is_anomaly': self.is_anomaly})\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        return (anomaly_rates / anomaly_rates.max() * 2.0).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"scores\": np.zeros(3, dtype=np.float32),\n                \"role\": np.zeros(self.num_roles, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        role_id = self.role_ids[self.current_step]\n        \n        # Update rolling stats\n        self.user_history[user]['scores'].append(self.anomaly_scores[self.current_step])\n        if len(self.user_history[user]['scores']) > 7:\n            self.user_history[user]['scores'].pop(0)\n        \n        scores = self.user_history[user]['scores']\n        \n        # One-hot encode role\n        role_one_hot = np.zeros(self.num_roles, dtype=np.float32)\n        role_one_hot[self.role_to_idx[role_id]] = 1.0\n        \n        return {\n            \"scores\": np.array([\n                self.anomaly_scores[self.current_step],\n                np.mean(scores) if scores else 0,\n                np.std(scores) if scores else 0\n            ], dtype=np.float32),\n            \"role\": role_one_hot\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        role_idx = self.role_to_idx[role_id]\n        \n        # Update threshold\n        self.role_thresholds[role_idx] = np.clip(\n            self.role_thresholds[role_idx] + action[0], \n            0.1, 0.9\n        )\n        \n        # Get prediction and reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_idx])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_idx]\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label == 1:  # Anomaly\n            return 50.0 * weight if pred == 1 else -100.0 * weight\n        else:                # Normal\n            return 0.1 if pred == 0 else -2.0 / weight\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': []})\n        self.role_thresholds = np.ones(self.num_roles) * 0.5\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:49:54.289906Z","iopub.execute_input":"2025-05-05T18:49:54.290271Z","iopub.status.idle":"2025-05-05T18:49:54.413083Z","shell.execute_reply.started":"2025-05-05T18:49:54.290246Z","shell.execute_reply":"2025-05-05T18:49:54.412272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = RoleWeightedThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly)\nenv = make_vec_env(lambda: env, n_envs=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:50:06.191167Z","iopub.execute_input":"2025-05-05T18:50:06.191738Z","iopub.status.idle":"2025-05-05T18:50:06.220633Z","shell.execute_reply.started":"2025-05-05T18:50:06.191715Z","shell.execute_reply":"2025-05-05T18:50:06.219858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PPO(\n    \"MultiInputPolicy\",\n    env,\n    verbose=1,\n    learning_rate=3e-4,\n    n_steps=1024,\n    batch_size=64,\n    n_epochs=10,\n    gamma=0.99,\n    policy_kwargs={\n        \"net_arch\": {\n            \"pi\": [64, 64],\n            \"vf\": [64, 64]\n        }\n    }\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:50:17.014575Z","iopub.execute_input":"2025-05-05T18:50:17.015175Z","iopub.status.idle":"2025-05-05T18:50:17.024433Z","shell.execute_reply.started":"2025-05-05T18:50:17.015154Z","shell.execute_reply":"2025-05-05T18:50:17.023773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.learn(total_timesteps=10_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:50:30.329790Z","iopub.execute_input":"2025-05-05T18:50:30.330530Z","iopub.status.idle":"2025-05-05T18:50:49.634111Z","shell.execute_reply.started":"2025-05-05T18:50:30.330505Z","shell.execute_reply":"2025-05-05T18:50:49.633519Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('ppo_rolebased.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:03:18.346660Z","iopub.execute_input":"2025-05-05T19:03:18.347259Z","iopub.status.idle":"2025-05-05T19:03:18.359493Z","shell.execute_reply.started":"2025-05-05T19:03:18.347237Z","shell.execute_reply":"2025-05-05T19:03:18.358928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"obs = env.reset()\nfor _ in range(1000):\n    action, _ = model.predict(obs, deterministic=True)\n    obs, reward, done, info = env.step(action)\n    print(f\"Step {_}: Role={info[0]['role']}, Threshold={info[0]['threshold']:.3f}, Reward={reward[0]:.1f}\")\n    if done:\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T18:54:07.979673Z","iopub.execute_input":"2025-05-05T18:54:07.979937Z","iopub.status.idle":"2025-05-05T18:54:08.869619Z","shell.execute_reply.started":"2025-05-05T18:54:07.979921Z","shell.execute_reply":"2025-05-05T18:54:08.869037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"improved trial","metadata":{}},{"cell_type":"code","source":"class BitRoleThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_bit_encoded, users, is_anomaly):\n        # Data normalization with epsilon handling\n        self.anomaly_scores = self._normalize_scores(anomaly_scores)\n        self.users = users\n        self.is_anomaly = is_anomaly.flatten()\n        \n        # Store original 4-bit role encoding\n        self.roles_bit_encoded = roles_bit_encoded.astype(np.float32)  # (n_samples, 4)\n        \n        # Convert 4-bit roles to integer IDs (your exact method)\n        self.role_ids = np.sum(roles_bit_encoded * (2 ** np.arange(4)), axis=1)\n        self.unique_roles = np.unique(self.role_ids)\n        self.num_roles = len(self.unique_roles)\n        self.role_to_idx = {role: idx for idx, role in enumerate(self.unique_roles)}\n        \n        # Enhanced role weighting\n        self.role_weights = self._calculate_role_weights()\n        \n        # Initialize thresholds with role-wise variation\n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles)\n        \n        # Action space with smaller steps\n        self.action_space = spaces.Box(low=-0.05, high=0.05, shape=(1,), dtype=np.float32)\n        \n        # Observation space using raw bits\n        self.observation_space = spaces.Dict({\n            \"current_score\": spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n            \"user_stats\": spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32),\n            \"role_bits\": spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)  # Raw 4 bits\n        })\n        \n        # Tracking\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n\n    def _normalize_scores(self, scores):\n        \"\"\"Robust normalization handling edge cases\"\"\"\n        min_score, max_score = scores.min(), scores.max()\n        range_score = max_score - min_score\n        if range_score < 1e-6:  # Handle constant scores\n            return np.zeros_like(scores)\n        return (scores - min_score) / range_score\n\n    def _calculate_role_weights(self):\n        \"\"\"Enhanced weight calculation considering both anomaly rate and population size\"\"\"\n        df = pd.DataFrame({\n            'role': self.role_ids,\n            'is_anomaly': self.is_anomaly,\n            'user': self.users\n        })\n        \n        # Calculate anomaly prevalence and user count per role\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        user_counts = df.groupby('role')['user'].nunique()\n        \n        # Combine factors with logarithmic scaling\n        weights = anomaly_rates * np.log(user_counts + 1)\n        return (weights / weights.max()).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"current_score\": np.array([0], dtype=np.float32),\n                \"user_stats\": np.array([0, 0], dtype=np.float32),\n                \"role_bits\": np.zeros(4, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        current_score = self.anomaly_scores[self.current_step]\n        \n        # Update user history\n        hist = self.user_history[user]\n        hist['scores'].append(current_score)\n        if len(hist['scores']) > 7:  # 1-week window\n            hist['scores'].pop(0)\n        \n        # Track anomalies\n        if self.is_anomaly[self.current_step]:\n            hist['last_anomaly'] = self.current_step\n            self.global_last_anomaly = self.current_step\n        \n        # Get the 4 role bits exactly as they were input\n        role_bits = self.roles_bit_encoded[self.current_step]\n        \n        return {\n            \"current_score\": np.array([current_score], dtype=np.float32),\n            \"user_stats\": np.array([\n                np.mean(hist['scores']) if hist['scores'] else 0,\n                np.std(hist['scores']) if len(hist['scores']) > 1 else 0\n            ], dtype=np.float32),\n            \"role_bits\": role_bits\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        role_idx = self.role_to_idx[role_id]\n        \n        # Role-weighted threshold adjustment\n        learning_rate = 0.05 * self.role_weights.get(role_id, 1.0)\n        self.role_thresholds[role_idx] = np.clip(\n            self.role_thresholds[role_idx] + action[0] * learning_rate,\n            0.1, 0.9\n        )\n        \n        # Get prediction and balanced reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_idx])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_idx],\n            \"true_label\": self.is_anomaly[self.current_step - 1],\n            \"prediction\": pred\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        \"\"\"Balanced reward function optimized for F1 score\"\"\"\n        weight = self.role_weights.get(role_id, 1.0)\n        \n        if true_label and pred:   # True positive\n            return 15.0 * weight\n        elif true_label and not pred:  # False negative\n            return -20.0 * weight\n        elif not true_label and pred:  # False positive\n            return -3.0 / weight\n        else:  # True negative\n            return 1.0 / weight\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n        # Initialize thresholds with small random variation\n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles) * np.random.uniform(0.95, 1.05, self.num_roles)\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:31:00.305707Z","iopub.execute_input":"2025-05-05T19:31:00.306349Z","iopub.status.idle":"2025-05-05T19:31:00.321762Z","shell.execute_reply.started":"2025-05-05T19:31:00.306322Z","shell.execute_reply":"2025-05-05T19:31:00.321079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = BitRoleThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_bit_encoded=roles_expanded,\n        users=users,\n        is_anomaly=is_anomaly\n    )\n    \n    # Wrap for vectorization (single env)\nenv = DummyVecEnv([lambda: env])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:34:56.425468Z","iopub.execute_input":"2025-05-05T19:34:56.426156Z","iopub.status.idle":"2025-05-05T19:34:56.506380Z","shell.execute_reply.started":"2025-05-05T19:34:56.426132Z","shell.execute_reply":"2025-05-05T19:34:56.505584Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PPO(\n        \"MultiInputPolicy\",  # Changed from \"MlpPolicy\"\n        env,\n        learning_rate=3e-4,\n        n_steps=1024,\n        batch_size=64,\n        n_epochs=10,\n        gamma=0.95,\n        verbose=1,\n        policy_kwargs={\n            \"net_arch\": [dict(pi=[64, 64], vf=[64, 64])]  # Optional custom network\n        }\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:36:13.665746Z","iopub.execute_input":"2025-05-05T19:36:13.666431Z","iopub.status.idle":"2025-05-05T19:36:13.710740Z","shell.execute_reply.started":"2025-05-05T19:36:13.666409Z","shell.execute_reply":"2025-05-05T19:36:13.710057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.learn(total_timesteps=50_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:36:35.390591Z","iopub.execute_input":"2025-05-05T19:36:35.391099Z","iopub.status.idle":"2025-05-05T19:38:12.961419Z","shell.execute_reply.started":"2025-05-05T19:36:35.391069Z","shell.execute_reply":"2025-05-05T19:38:12.960763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"ppo_role2.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:39:18.777019Z","iopub.execute_input":"2025-05-05T19:39:18.777348Z","iopub.status.idle":"2025-05-05T19:39:18.790993Z","shell.execute_reply.started":"2025-05-05T19:39:18.777326Z","shell.execute_reply":"2025-05-05T19:39:18.790240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, env, n_eval_episodes=1):\n    \"\"\"\n    Evaluate the trained model with proper observation handling\n    \"\"\"\n    all_predictions = []\n    all_labels = []\n    all_scores = []\n    \n    for _ in range(n_eval_episodes):\n        obs = env.reset()\n        done = [False]\n        while not all(done):\n            action, _ = model.predict(obs, deterministic=True)\n            obs, _, done, info = env.step(action)\n            \n            # Properly handle vectorized env observations\n            if isinstance(obs, dict):\n                # Single environment case\n                current_score = obs['current_score'][0][0]\n                pred = info[0]['prediction']\n                true_label = info[0]['true_label']\n            else:\n                # Vectorized environment case\n                current_score = obs[0]['current_score'][0][0]\n                pred = info[0]['prediction']\n                true_label = info[0]['true_label']\n            \n            all_predictions.append(pred)\n            all_labels.append(true_label)\n            all_scores.append(current_score)\n    \n    y_true = np.array(all_labels)\n    y_pred = np.array(all_predictions)\n    y_scores = np.array(all_scores)\n    \n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred, zero_division=0),\n        'recall': recall_score(y_true, y_pred, zero_division=0),\n        'f1': f1_score(y_true, y_pred, zero_division=0),\n        'roc_auc': roc_auc_score(y_true, y_scores) if len(np.unique(y_true)) > 1 else 0.5,\n        'pr_auc': average_precision_score(y_true, y_scores),\n        'confusion_matrix': confusion_matrix(y_true, y_pred)\n    }\n    \n    return metrics, y_pred, y_true","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:40:35.865899Z","iopub.execute_input":"2025-05-05T19:40:35.866521Z","iopub.status.idle":"2025-05-05T19:40:35.873836Z","shell.execute_reply.started":"2025-05-05T19:40:35.866496Z","shell.execute_reply":"2025-05-05T19:40:35.873096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = BitRoleThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly)\nenv = DummyVecEnv([lambda: env])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n                            f1_score, roc_auc_score, confusion_matrix, \n                            precision_recall_curve, average_precision_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:46:41.890388Z","iopub.execute_input":"2025-05-05T19:46:41.890666Z","iopub.status.idle":"2025-05-05T19:46:41.894501Z","shell.execute_reply.started":"2025-05-05T19:46:41.890645Z","shell.execute_reply":"2025-05-05T19:46:41.893730Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmetrics, predictions, labels = evaluate_model(model, env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:46:45.349462Z","iopub.execute_input":"2025-05-05T19:46:45.350174Z","iopub.status.idle":"2025-05-05T19:51:41.359473Z","shell.execute_reply.started":"2025-05-05T19:46:45.350149Z","shell.execute_reply":"2025-05-05T19:51:41.358858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print results\nprint(f\"Accuracy: {metrics['accuracy']:.4f}\")\nprint(f\"Precision: {metrics['precision']:.4f}\")\nprint(f\"Recall: {metrics['recall']:.4f}\")\nprint(f\"F1 Score: {metrics['f1']:.4f}\")\nprint(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(metrics['confusion_matrix'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:52:50.529759Z","iopub.execute_input":"2025-05-05T19:52:50.530467Z","iopub.status.idle":"2025-05-05T19:52:50.535260Z","shell.execute_reply.started":"2025-05-05T19:52:50.530441Z","shell.execute_reply":"2025-05-05T19:52:50.534510Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"improved attempt","metadata":{}},{"cell_type":"code","source":"class BitRoleThresholdEnv(gym.Env):\n    def __init__(self, anomaly_scores, roles_bit_encoded, users, is_anomaly):\n\n        self.anomaly_scores = self._normalize_scores(anomaly_scores)\n        self.users = users\n        self.is_anomaly = is_anomaly.flatten()\n        \n        self.roles_bit_encoded = roles_bit_encoded.astype(np.float32)  # (n_samples, 4)\n        \n        self.role_ids = np.sum(roles_bit_encoded * (2 ** np.arange(4)), axis=1)\n        self.unique_roles = np.unique(self.role_ids)\n        self.num_roles = len(self.unique_roles)\n        self.role_to_idx = {role: idx for idx, role in enumerate(self.unique_roles)}\n        \n        self.role_weights = self._calculate_role_weights()\n        \n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles)\n        \n        self.action_space = spaces.Box(low=-0.05, high=0.05, shape=(1,), dtype=np.float32)\n        \n        self.observation_space = spaces.Dict({\n            \"current_score\": spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n            \"user_stats\": spaces.Box(low=0, high=1, shape=(2,), dtype=np.float32),\n            \"role_bits\": spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)  # Raw 4 bits\n        })\n       \n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n\n    def _normalize_scores(self, scores):\n        min_score, max_score = scores.min(), scores.max()\n        range_score = max_score - min_score\n        if range_score < 1e-6:  # Handle constant scores\n            return np.zeros_like(scores)\n        return (scores - min_score) / range_score\n\n    def _calculate_role_weights(self):\n        df = pd.DataFrame({\n            'role': self.role_ids,\n            'is_anomaly': self.is_anomaly,\n            'user': self.users\n        })\n        \n        # Calculate anomaly prevalence and user count per role\n        anomaly_rates = df.groupby('role')['is_anomaly'].mean()\n        user_counts = df.groupby('role')['user'].nunique()\n        \n        # Combine factors with logarithmic scaling\n        weights = anomaly_rates * np.log(user_counts + 1)\n        return (weights / weights.max()).clip(0.5, 2.0).to_dict()\n\n    def _get_state(self):\n        if self.current_step >= len(self.anomaly_scores):\n            return {\n                \"current_score\": np.array([0], dtype=np.float32),\n                \"user_stats\": np.array([0, 0], dtype=np.float32),\n                \"role_bits\": np.zeros(4, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        current_score = self.anomaly_scores[self.current_step]\n        \n        hist = self.user_history[user]\n        hist['scores'].append(current_score)\n        if len(hist['scores']) > 7:  # 1-week window\n            hist['scores'].pop(0)\n        \n        # Track anomalies\n        if self.is_anomaly[self.current_step]:\n            hist['last_anomaly'] = self.current_step\n            self.global_last_anomaly = self.current_step\n        \n        role_bits = self.roles_bit_encoded[self.current_step]\n        \n        return {\n            \"current_score\": np.array([current_score], dtype=np.float32),\n            \"user_stats\": np.array([\n                np.mean(hist['scores']) if hist['scores'] else 0,\n                np.std(hist['scores']) if len(hist['scores']) > 1 else 0\n            ], dtype=np.float32),\n            \"role_bits\": role_bits\n        }\n\n    def step(self, action):\n        role_id = self.role_ids[self.current_step]\n        role_idx = self.role_to_idx[role_id]\n        \n        # Role-weighted threshold adjustment\n        learning_rate = 0.05 * self.role_weights.get(role_id, 1.0)\n        self.role_thresholds[role_idx] = np.clip(\n            self.role_thresholds[role_idx] + action[0] * learning_rate,\n            0.1, 0.9\n        )\n        \n        # Get prediction and balanced reward\n        current_score = self.anomaly_scores[self.current_step]\n        pred = int(current_score > self.role_thresholds[role_idx])\n        reward = self._calculate_reward(pred, self.is_anomaly[self.current_step], role_id)\n        \n        # Update step\n        self.current_step += 1\n        done = self.current_step >= len(self.anomaly_scores)\n        \n        return self._get_state(), reward, done, {\n            \"role\": role_id,\n            \"threshold\": self.role_thresholds[role_idx],\n            \"true_label\": self.is_anomaly[self.current_step - 1],\n            \"prediction\": pred\n        }\n\n    def _calculate_reward(self, pred, true_label, role_id):\n        weight = self.role_weights.get(role_id, 1.0)\n        if true_label and pred:   # True positive\n            return 25.0 * weight  # Increased from 15\n        elif true_label and not pred:  # False negative\n            return -30.0 * weight  # Increased penalty\n        elif not true_label and pred:  # False positive\n            return -5.0 / weight  # Reduced penalty\n        else:  # True negative\n            return 0.5 / weight\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(lambda: {'scores': [], 'last_anomaly': -np.inf})\n        self.global_last_anomaly = -np.inf\n        # Initialize thresholds with small random variation\n        self.role_thresholds = np.linspace(0.4, 0.6, num=self.num_roles) * np.random.uniform(0.95, 1.05, self.num_roles)\n        return self._get_state()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:57:25.828848Z","iopub.execute_input":"2025-05-05T19:57:25.829721Z","iopub.status.idle":"2025-05-05T19:57:25.844837Z","shell.execute_reply.started":"2025-05-05T19:57:25.829695Z","shell.execute_reply":"2025-05-05T19:57:25.844167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = BitRoleThresholdEnv(\n        anomaly_scores=anomaly_scores,\n        roles_bit_encoded=roles_expanded,\n        users=users,\n        is_anomaly=is_anomaly\n    )\n    \n    # Wrap for vectorization (single env)\nenv = DummyVecEnv([lambda: env])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:58:32.269668Z","iopub.execute_input":"2025-05-05T19:58:32.270253Z","iopub.status.idle":"2025-05-05T19:58:32.327742Z","shell.execute_reply.started":"2025-05-05T19:58:32.270231Z","shell.execute_reply":"2025-05-05T19:58:32.326861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = PPO(\n        \"MultiInputPolicy\",  # Changed from \"MlpPolicy\"\n        env,\n        learning_rate=3e-4,\n        n_steps=1024,\n        batch_size=64,\n        n_epochs=10,\n        gamma=0.95,\n        verbose=1\n    )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:58:41.968438Z","iopub.execute_input":"2025-05-05T19:58:41.968910Z","iopub.status.idle":"2025-05-05T19:58:41.979137Z","shell.execute_reply.started":"2025-05-05T19:58:41.968889Z","shell.execute_reply":"2025-05-05T19:58:41.978396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.learn(total_timesteps=50_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T19:58:47.212650Z","iopub.execute_input":"2025-05-05T19:58:47.213399Z","iopub.status.idle":"2025-05-05T20:00:25.105381Z","shell.execute_reply.started":"2025-05-05T19:58:47.213376Z","shell.execute_reply":"2025-05-05T20:00:25.104724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"ppo_role2.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:00:50.947701Z","iopub.execute_input":"2025-05-05T20:00:50.948276Z","iopub.status.idle":"2025-05-05T20:00:50.959593Z","shell.execute_reply.started":"2025-05-05T20:00:50.948253Z","shell.execute_reply":"2025-05-05T20:00:50.959056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = BitRoleThresholdEnv(anomaly_scores, roles_expanded, users, is_anomaly)\nenv = DummyVecEnv([lambda: env])\n\n\nmetrics, predictions, labels = evaluate_model(model, env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:00:58.548117Z","iopub.execute_input":"2025-05-05T20:00:58.548844Z","iopub.status.idle":"2025-05-05T20:05:49.703792Z","shell.execute_reply.started":"2025-05-05T20:00:58.548816Z","shell.execute_reply":"2025-05-05T20:05:49.703221Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print results\nprint(f\"Accuracy: {metrics['accuracy']:.4f}\")\nprint(f\"Precision: {metrics['precision']:.4f}\")\nprint(f\"Recall: {metrics['recall']:.4f}\")\nprint(f\"F1 Score: {metrics['f1']:.4f}\")\nprint(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\nprint(\"Confusion Matrix:\")\nprint(metrics['confusion_matrix'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:05:49.704802Z","iopub.execute_input":"2025-05-05T20:05:49.705013Z","iopub.status.idle":"2025-05-05T20:05:49.710335Z","shell.execute_reply.started":"2025-05-05T20:05:49.704996Z","shell.execute_reply":"2025-05-05T20:05:49.709527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"end-end rl model trial","metadata":{}},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:13:04.528419Z","iopub.execute_input":"2025-05-05T20:13:04.528937Z","iopub.status.idle":"2025-05-05T20:13:04.543366Z","shell.execute_reply.started":"2025-05-05T20:13:04.528914Z","shell.execute_reply":"2025-05-05T20:13:04.542701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"roles_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:13:08.157592Z","iopub.execute_input":"2025-05-05T20:13:08.157858Z","iopub.status.idle":"2025-05-05T20:13:08.167423Z","shell.execute_reply.started":"2025-05-05T20:13:08.157837Z","shell.execute_reply":"2025-05-05T20:13:08.166718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:13:11.387997Z","iopub.execute_input":"2025-05-05T20:13:11.388675Z","iopub.status.idle":"2025-05-05T20:13:11.393088Z","shell.execute_reply.started":"2025-05-05T20:13:11.388653Z","shell.execute_reply":"2025-05-05T20:13:11.392536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class InsiderThreatEnv(gym.Env):\n    def __init__(self, df_features, roles_df, is_anomaly):\n        # Data\n        self.features = df_features.iloc[:, 2:].values  # Exclude user/date, shape: (330285, 11)\n        self.roles = roles_df.iloc[:, 1:].values  # Exclude user column, shape: (330285, 4)\n        self.users = df_features['user'].values\n        self.labels = is_anomaly\n        \n        # Spaces\n        self.action_space = spaces.Box(-1, 1, (1,))  # Single continuous action\n        self.observation_space = spaces.Dict({\n            \"features\": spaces.Box(-5, 5, (11,)),  # Shape: 11\n            \"role_bits\": spaces.Box(0, 1, (4,)),\n            \"user_avg\": spaces.Box(-5, 5, (11,))   # Shape: 11\n        })\n        \n        # Tracking\n        self.current_step = 0\n        self.user_history = defaultdict(list)\n\n    def reset(self):\n        self.current_step = 0\n        self.user_history = defaultdict(list)\n        return self._get_obs(), {}  # Return (obs, info) for gymnasium API\n\n    def _get_obs(self):\n        if self.current_step >= len(self.features):\n            return {\n                \"features\": np.zeros(11, dtype=np.float32),\n                \"role_bits\": np.zeros(4, dtype=np.float32),\n                \"user_avg\": np.zeros(11, dtype=np.float32)\n            }\n        \n        user = self.users[self.current_step]\n        user_avg = np.mean(self.user_history[user], axis=0) if self.user_history[user] else np.zeros(11)\n        \n        return {\n            \"features\": self.features[self.current_step],\n            \"role_bits\": self.roles[self.current_step],\n            \"user_avg\": user_avg\n        }\n\n    def step(self, action):\n        user = self.users[self.current_step]\n        obs = self._get_obs()\n        \n        # Store current features\n        self.user_history[user].append(self.features[self.current_step])\n        if len(self.user_history[user]) > 7:  # Keep last 7 days\n            self.user_history[user].pop(0)\n        \n        # Simple threshold decision\n        threshold = 0.5 + action[0] * 0.2  # Map action to [0.3, 0.7]\n        pred = int(np.sum(obs[\"features\"][:5]) > threshold)  # Use first 5 features for anomaly score\n        \n        # Reward calculation\n        reward = self._calculate_reward(pred, self.labels[self.current_step], obs[\"role_bits\"])\n        \n        self.current_step += 1\n        terminated = self.current_step >= len(self.features)\n        truncated = False\n        \n        info = {\"prediction\": pred, \"true_label\": self.labels[self.current_step-1]}\n        \n        return obs, reward, terminated, truncated, info  # Return 5 elements for gymnasium API\n\n    def _calculate_reward(self, pred, true_label, role_bits):\n        # Simple role-aware reward\n        role_weight = 0.5 + np.sum(role_bits)  # Higher weight for roles with more bits set\n        if true_label:\n            return 10 * role_weight if pred else -15 * role_weight\n        else:\n            return 0.1 if not pred else -2 / role_weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:33:33.637187Z","iopub.execute_input":"2025-05-05T20:33:33.637770Z","iopub.status.idle":"2025-05-05T20:33:33.648183Z","shell.execute_reply.started":"2025-05-05T20:33:33.637749Z","shell.execute_reply":"2025-05-05T20:33:33.647378Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_simple_model(df_features, roles_df, is_anomaly):\n    env = InsiderThreatEnv(df_features, roles_df, is_anomaly)  # Single environment\n    \n    # Correct policy configuration\n    policy_kwargs = {\n        \"net_arch\": dict(pi=[64, 32], vf=[64, 32])\n    }\n    \n    model = PPO(\n        \"MultiInputPolicy\",\n        env,\n        learning_rate=3e-4,\n        n_steps=1024,  # Suitable for a single environment\n        batch_size=64,\n        verbose=1,\n        policy_kwargs=policy_kwargs,\n        tensorboard_log=\"./logs\"\n    )\n    \n    model.learn(total_timesteps=100_000)\n    return model\n\ndef evaluate_simple(model, df_features, roles_df, is_anomaly):\n    env = InsiderThreatEnv(df_features, roles_df, is_anomaly)\n    obs, _ = env.reset()\n    \n    y_true, y_pred = [], []\n    while True:\n        action, _ = model.predict(obs, deterministic=True)\n        obs, _, terminated, truncated, info = env.step(action)\n        y_true.append(info[\"true_label\"])\n        y_pred.append(info[\"prediction\"])\n        if terminated or truncated:\n            break\n    \n    from sklearn.metrics import classification_report\n    print(classification_report(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:33:46.986515Z","iopub.execute_input":"2025-05-05T20:33:46.986777Z","iopub.status.idle":"2025-05-05T20:33:46.992929Z","shell.execute_reply.started":"2025-05-05T20:33:46.986757Z","shell.execute_reply":"2025-05-05T20:33:46.992214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run it\nmodel = train_simple_model(df_features, roles_df, is_anomaly)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-05T20:33:48.064894Z","iopub.execute_input":"2025-05-05T20:33:48.065444Z","iopub.status.idle":"2025-05-05T20:33:48.104040Z","shell.execute_reply.started":"2025-05-05T20:33:48.065418Z","shell.execute_reply":"2025-05-05T20:33:48.103088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_simple(model, df_features, roles_df, is_anomaly)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def infer_high_risk_roles(roles_df, is_anomaly):\n\n    # Create a DataFrame with role numbers and anomalies\n    anomaly_df = pd.DataFrame({\n        'role_number': roles_df,\n        'is_anomaly': is_anomaly\n    })\n    \n    # Group by role to compute anomaly counts and total user-days\n    role_stats = anomaly_df.groupby('role_number').agg(\n        total_days=('is_anomaly', 'count'),\n        anomalies=('is_anomaly', 'sum')\n    )\n    \n    # Calculate anomaly rate\n    role_stats['anomaly_rate'] = role_stats['anomalies'] / role_stats['total_days']\n    \n    # Define high-risk roles (e.g., anomaly rate > 70th percentile)\n    threshold = role_stats['anomaly_rate'].quantile(0.7)\n    high_risk_roles = role_stats[role_stats['anomaly_rate'] >= threshold].index.tolist()\n    \n    print(\"Role Statistics:\")\n    print(role_stats)\n    print(f\"\\nHigh-Risk Roles (anomaly rate >= {threshold:.4f}): {high_risk_roles}\")\n    \n    return high_risk_roles\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:48:41.058028Z","iopub.execute_input":"2025-05-06T07:48:41.058302Z","iopub.status.idle":"2025-05-06T07:48:41.063563Z","shell.execute_reply.started":"2025-05-06T07:48:41.058280Z","shell.execute_reply":"2025-05-06T07:48:41.062714Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nfrom sklearn.metrics import precision_recall_curve, auc, matthews_corrcoef, balanced_accuracy_score\nfrom sklearn.metrics import confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:08:33.516374Z","iopub.execute_input":"2025-05-06T12:08:33.517000Z","iopub.status.idle":"2025-05-06T12:08:33.520630Z","shell.execute_reply.started":"2025-05-06T12:08:33.516977Z","shell.execute_reply":"2025-05-06T12:08:33.519897Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:48:43.128165Z","iopub.execute_input":"2025-05-06T07:48:43.128773Z","iopub.status.idle":"2025-05-06T07:48:43.157495Z","shell.execute_reply.started":"2025-05-06T07:48:43.128734Z","shell.execute_reply":"2025-05-06T07:48:43.156936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nfrom gymnasium import Env, spaces\nfrom stable_baselines3 import PPO\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nimport uuid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:56:24.790510Z","iopub.execute_input":"2025-05-06T07:56:24.790792Z","iopub.status.idle":"2025-05-06T07:56:24.794953Z","shell.execute_reply.started":"2025-05-06T07:56:24.790759Z","shell.execute_reply":"2025-05-06T07:56:24.794261Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Role weights (roles 1-10)\nROLE_WEIGHTS = {\n    1: 0.6666364519334633,\n    2: 1.503301351626301,\n    3: 1.0,  # Default for missing role\n    4: 1.1658889718506966,\n    5: 0.5,\n    6: 1.4732138828974453,\n    7: 1.4732138828974453,  # Matches role 6 (high-risk)\n    8: 0.5,\n    9: 0.7872542782243186,\n    10: 1.2289515996962965\n}\n\n# High-risk roles from anomaly rates\nHIGH_RISK_ROLES = [4, 6, 7]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:56:25.971450Z","iopub.execute_input":"2025-05-06T07:56:25.971711Z","iopub.status.idle":"2025-05-06T07:56:25.975896Z","shell.execute_reply.started":"2025-05-06T07:56:25.971693Z","shell.execute_reply":"2025-05-06T07:56:25.975204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort by date_only and user for consistency\ndata = df_features.copy()\ndata['roles_labeled'] = roles_labeled\ndata['mu_all'] = [row for row in mu_all]\ndata['is_anomaly'] = is_anomaly\ndata = data.sort_values(['date_only', 'user']).reset_index(drop=True)\n    \n# Split by time (80% earliest, 20% latest)\nsplit_idx = int(0.8 * len(data))\ntrain_data = data.iloc[:split_idx]\ntest_data = data.iloc[split_idx:]\n    \n# Extract splits\ndf_train = train_data.drop(columns=['roles_labeled', 'mu_all', 'is_anomaly'])\nroles_train = train_data['roles_labeled'].values\nmu_train = np.array([row for row in train_data['mu_all']])\nanomaly_train = train_data['is_anomaly'].values\ndf_test = test_data.drop(columns=['roles_labeled', 'mu_all', 'is_anomaly'])\nroles_test = test_data['roles_labeled'].values\nmu_test = np.array([row for row in test_data['mu_all']])\nanomaly_test = test_data['is_anomaly'].values    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:09:54.091224Z","iopub.execute_input":"2025-05-06T09:09:54.091912Z","iopub.status.idle":"2025-05-06T09:09:54.721991Z","shell.execute_reply.started":"2025-05-06T09:09:54.091888Z","shell.execute_reply":"2025-05-06T09:09:54.721207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train Set Statistics:\")\nprint(f\"Total samples: {len(df_train)}\")\nprint(f\"Anomalies: {np.sum(anomaly_train)} ({np.sum(anomaly_train)/len(anomaly_train)*100:.2f}%)\")\nhigh_risk_mask_train = np.isin(roles_train, HIGH_RISK_ROLES)\nprint(f\"High-risk role anomalies: {np.sum(anomaly_train[high_risk_mask_train])} ({np.sum(anomaly_train[high_risk_mask_train])/np.sum(high_risk_mask_train)*100:.2f}%)\")\n    \nprint(\"\\nTest Set Statistics:\")\nprint(f\"Total samples: {len(df_test)}\")\nprint(f\"Anomalies: {np.sum(anomaly_test)} ({np.sum(anomaly_test)/len(anomaly_test)*100:.2f}%)\")\nhigh_risk_mask_test = np.isin(roles_test, HIGH_RISK_ROLES)\nprint(f\"High-risk role anomalies: {np.sum(anomaly_test[high_risk_mask_test])} ({np.sum(anomaly_test[high_risk_mask_test])/np.sum(high_risk_mask_test)*100:.2f}%)\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T09:09:58.170416Z","iopub.execute_input":"2025-05-06T09:09:58.170949Z","iopub.status.idle":"2025-05-06T09:09:58.184914Z","shell.execute_reply.started":"2025-05-06T09:09:58.170924Z","shell.execute_reply":"2025-05-06T09:09:58.184134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all = np.load('/kaggle/working/mu_all.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:57:00.712237Z","iopub.execute_input":"2025-05-06T07:57:00.712522Z","iopub.status.idle":"2025-05-06T07:57:00.719987Z","shell.execute_reply.started":"2025-05-06T07:57:00.712502Z","shell.execute_reply":"2025-05-06T07:57:00.719336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_all.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T07:57:07.592427Z","iopub.execute_input":"2025-05-06T07:57:07.592981Z","iopub.status.idle":"2025-05-06T07:57:07.597485Z","shell.execute_reply.started":"2025-05-06T07:57:07.592956Z","shell.execute_reply":"2025-05-06T07:57:07.596835Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"basic RL","metadata":{}},{"cell_type":"code","source":"class BasicInsiderEnv(Env):\n    def __init__(self, features, roles, labels):\n        \"\"\"\n        features: Normalized feature matrix (n_samples x n_features)\n        roles: Array of role numbers (1-10)\n        labels: Binary anomaly labels\n        \"\"\"\n        self.features = features\n        self.roles = roles\n        self.labels = labels\n        self.n_samples = len(features)\n        \n        # Action space: 0 (normal), 1 (anomaly)\n        self.action_space = spaces.Discrete(2)  \n        \n        # Observation space: features + role\n        self.observation_space = spaces.Dict({\n            \"features\": spaces.Box(-5, 5, (features.shape[1],), dtype=np.float32),\n            \"role\": spaces.Discrete(10)  # Roles 1-10 (will subtract 1 internally)\n        })\n        \n        self.current_step = 0\n\n    def reset(self):\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        return {\n            \"features\": self.features[self.current_step],\n            \"role\": self.roles[self.current_step] - 1  # Convert to 0-9\n        }\n\n    def step(self, action):\n        reward = self._calculate_reward(action, self.labels[self.current_step], \n                                      self.roles[self.current_step])\n        \n        self.current_step += 1\n        done = self.current_step >= self.n_samples\n        \n        return self._get_obs(), reward, done, False, {}\n\n    def _calculate_reward(self, pred, true_label, role):\n        if pred == true_label:\n            return 1.0 if true_label == 1 else 0.1  # Higher reward for correct anomaly\n        else:\n            return -10.0 if (true_label == 1 and pred == 0) else -1.0  # Heavy FN penalty","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:08:40.411434Z","iopub.execute_input":"2025-05-06T10:08:40.412201Z","iopub.status.idle":"2025-05-06T10:08:40.420522Z","shell.execute_reply.started":"2025-05-06T10:08:40.412174Z","shell.execute_reply":"2025-05-06T10:08:40.419845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = DummyVecEnv([lambda: BasicInsiderEnv(df_features , roles_labeled, is_anomaly)])\nmodel = PPO(\"MultiInputPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=50_000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:10:01.696119Z","iopub.execute_input":"2025-05-06T10:10:01.696400Z","iopub.status.idle":"2025-05-06T10:10:01.734724Z","shell.execute_reply.started":"2025-05-06T10:10:01.696378Z","shell.execute_reply":"2025-05-06T10:10:01.733825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features.to_csv('df_features.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:41:11.191430Z","iopub.execute_input":"2025-05-06T10:41:11.191691Z","iopub.status.idle":"2025-05-06T10:41:16.598790Z","shell.execute_reply.started":"2025-05-06T10:41:11.191674Z","shell.execute_reply":"2025-05-06T10:41:16.598018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('roles_expanded.npy', roles_expanded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:41:34.591160Z","iopub.execute_input":"2025-05-06T10:41:34.591421Z","iopub.status.idle":"2025-05-06T10:41:34.603574Z","shell.execute_reply.started":"2025-05-06T10:41:34.591402Z","shell.execute_reply":"2025-05-06T10:41:34.602863Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('is_anomaly.npy', is_anomaly)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:41:51.475967Z","iopub.execute_input":"2025-05-06T10:41:51.476206Z","iopub.status.idle":"2025-05-06T10:41:51.482410Z","shell.execute_reply.started":"2025-05-06T10:41:51.476190Z","shell.execute_reply":"2025-05-06T10:41:51.481850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.save('roles_labeled.npy', roles_labeled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:42:30.733090Z","iopub.execute_input":"2025-05-06T10:42:30.733360Z","iopub.status.idle":"2025-05-06T10:42:30.738933Z","shell.execute_reply.started":"2025-05-06T10:42:30.733339Z","shell.execute_reply":"2025-05-06T10:42:30.738314Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#mu_all has alr been saved","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T10:42:44.370911Z","iopub.execute_input":"2025-05-06T10:42:44.371160Z","iopub.status.idle":"2025-05-06T10:42:44.374367Z","shell.execute_reply.started":"2025-05-06T10:42:44.371143Z","shell.execute_reply":"2025-05-06T10:42:44.373629Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#importing reqd files\nis_anomaly = np.load('/kaggle/working/is_anomaly.npy')\ndf_features = pd.read_csv('/kaggle/working/df_features.csv')\nmu_all = np.load('/kaggle/working/mu_all.npy')\nroles_labeled = np.load('/kaggle/working/roles_labeled.npy')\nroles_expanded = np.load('/kaggle/working/roles_expanded.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:26.466712Z","iopub.execute_input":"2025-05-21T16:39:26.467091Z","iopub.status.idle":"2025-05-21T16:39:27.245864Z","shell.execute_reply.started":"2025-05-21T16:39:26.467062Z","shell.execute_reply":"2025-05-21T16:39:27.240968Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"#better role representation - embeddings\ndf_features = df_features.drop(columns = 'Unnamed: 0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:29.341695Z","iopub.execute_input":"2025-05-21T16:39:29.342055Z","iopub.status.idle":"2025-05-21T16:39:29.364731Z","shell.execute_reply.started":"2025-05-21T16:39:29.342026Z","shell.execute_reply":"2025-05-21T16:39:29.359940Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T12:44:47.892426Z","iopub.execute_input":"2025-05-06T12:44:47.892716Z","iopub.status.idle":"2025-05-06T12:44:47.907311Z","shell.execute_reply.started":"2025-05-06T12:44:47.892696Z","shell.execute_reply":"2025-05-06T12:44:47.906554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:38:23.942768Z","iopub.execute_input":"2025-05-06T15:38:23.943343Z","iopub.status.idle":"2025-05-06T15:38:23.967967Z","shell.execute_reply.started":"2025-05-06T15:38:23.943320Z","shell.execute_reply":"2025-05-06T15:38:23.967395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/df-with-pca/df_with_pca.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:31.216481Z","iopub.execute_input":"2025-05-21T16:39:31.216839Z","iopub.status.idle":"2025-05-21T16:39:35.636411Z","shell.execute_reply.started":"2025-05-21T16:39:31.216812Z","shell.execute_reply":"2025-05-21T16:39:35.630599Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"df = df.drop(columns = {'Unnamed: 0'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:35.637153Z","iopub.execute_input":"2025-05-21T16:39:35.637382Z","iopub.status.idle":"2025-05-21T16:39:35.711042Z","shell.execute_reply.started":"2025-05-21T16:39:35.637362Z","shell.execute_reply":"2025-05-21T16:39:35.706690Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:45:14.231701Z","iopub.execute_input":"2025-05-06T15:45:14.232412Z","iopub.status.idle":"2025-05-06T15:45:14.302158Z","shell.execute_reply.started":"2025-05-06T15:45:14.232386Z","shell.execute_reply":"2025-05-06T15:45:14.301375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_cols = ['after_hours_logon_count', 'total_logon_count', 'device_connects',\n       'avg_content_word_count', 'text_files_accessed', 'files_accessed',\n       'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag',\n       'keyword_richness']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:40.501654Z","iopub.execute_input":"2025-05-21T16:39:40.501931Z","iopub.status.idle":"2025-05-21T16:39:40.511840Z","shell.execute_reply.started":"2025-05-21T16:39:40.501908Z","shell.execute_reply":"2025-05-21T16:39:40.507160Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# Compute cluster behavioral profiles\nbehavioral_features = [col for col in feature_cols]  # 11 features\ncluster_stats = df.groupby('cluster')[behavioral_features].agg(['mean', 'std']).reset_index()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:40.981110Z","iopub.execute_input":"2025-05-21T16:39:40.981423Z","iopub.status.idle":"2025-05-21T16:39:41.073060Z","shell.execute_reply.started":"2025-05-21T16:39:40.981398Z","shell.execute_reply":"2025-05-21T16:39:41.068056Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"cluster_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:46:58.534930Z","iopub.execute_input":"2025-05-06T15:46:58.535548Z","iopub.status.idle":"2025-05-06T15:46:58.565149Z","shell.execute_reply.started":"2025-05-06T15:46:58.535525Z","shell.execute_reply":"2025-05-06T15:46:58.564298Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute historical baselines with proper handling of NaN values\ndf['rolling_avg_logon'] = df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=1).mean()\n)\ndf['rolling_std_logon'] = df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=2).std()\n)\n\n# Fill NaN values in rolling_std_logon (e.g., when there's only 1 data point)\ndf['rolling_std_logon'] = df['rolling_std_logon'].fillna(0)\n\n# Compute Z-score, avoiding division by zero\ndf['z_score_logon'] = (\n    (df['total_logon_count'] - df['rolling_avg_logon']) / \n    df['rolling_std_logon'].replace(0, 1)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:42.761627Z","iopub.execute_input":"2025-05-21T16:39:42.761932Z","iopub.status.idle":"2025-05-21T16:39:43.284347Z","shell.execute_reply.started":"2025-05-21T16:39:42.761908Z","shell.execute_reply":"2025-05-21T16:39:43.279195Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:49:28.041764Z","iopub.execute_input":"2025-05-06T15:49:28.042212Z","iopub.status.idle":"2025-05-06T15:49:28.141351Z","shell.execute_reply.started":"2025-05-06T15:49:28.042188Z","shell.execute_reply":"2025-05-06T15:49:28.140593Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:49:29.594221Z","iopub.execute_input":"2025-05-06T15:49:29.594792Z","iopub.status.idle":"2025-05-06T15:49:29.800049Z","shell.execute_reply.started":"2025-05-06T15:49:29.594769Z","shell.execute_reply":"2025-05-06T15:49:29.799376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"high_level_roles = {'President', 'VicePresident', 'Manager'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:01.022322Z","iopub.execute_input":"2025-05-21T16:39:01.022647Z","iopub.status.idle":"2025-05-21T16:39:01.031334Z","shell.execute_reply.started":"2025-05-21T16:39:01.022621Z","shell.execute_reply":"2025-05-21T16:39:01.027557Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df['role'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:51:02.443826Z","iopub.execute_input":"2025-05-06T15:51:02.444127Z","iopub.status.idle":"2025-05-06T15:51:02.464084Z","shell.execute_reply.started":"2025-05-06T15:51:02.444106Z","shell.execute_reply":"2025-05-06T15:51:02.463255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:41:21.040106Z","iopub.execute_input":"2025-05-21T15:41:21.040487Z","iopub.status.idle":"2025-05-21T15:41:21.059796Z","shell.execute_reply.started":"2025-05-21T15:41:21.040455Z","shell.execute_reply":"2025-05-21T15:41:21.054773Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, ..., 0, 0, 0])"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"df = pd.concat([df, pd.DataFrame(is_anomaly)], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:47.306611Z","iopub.execute_input":"2025-05-21T16:39:47.306927Z","iopub.status.idle":"2025-05-21T16:39:47.487288Z","shell.execute_reply.started":"2025-05-21T16:39:47.306900Z","shell.execute_reply":"2025-05-21T16:39:47.481554Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"df.rename(columns = {0:'is_anomaly'}, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:47.565880Z","iopub.execute_input":"2025-05-21T16:39:47.566168Z","iopub.status.idle":"2025-05-21T16:39:47.578734Z","shell.execute_reply.started":"2025-05-21T16:39:47.566143Z","shell.execute_reply":"2025-05-21T16:39:47.572638Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:27.302600Z","iopub.execute_input":"2025-05-06T15:54:27.302882Z","iopub.status.idle":"2025-05-06T15:54:27.308946Z","shell.execute_reply.started":"2025-05-06T15:54:27.302859Z","shell.execute_reply":"2025-05-06T15:54:27.308187Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['is_anomaly'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:44.268003Z","iopub.execute_input":"2025-05-06T15:54:44.268288Z","iopub.status.idle":"2025-05-06T15:54:44.276423Z","shell.execute_reply.started":"2025-05-06T15:54:44.268268Z","shell.execute_reply":"2025-05-06T15:54:44.275801Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"role_anomaly_rates = df.groupby('role')['is_anomaly'].mean().to_dict()\ndf['role_anomaly_rate'] = df['role'].map(role_anomaly_rates)\ndf['role_sensitivity'] = df['role'].apply(lambda x: 1.5 if x in high_level_roles else 1.0)\ndf['adaptive_threshold'] = df.apply(\n    lambda row: max(0.5, min(0.95, 0.9 - row['role_anomaly_rate'] * 10)) * row['role_sensitivity'],\n    axis=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:50.080891Z","iopub.execute_input":"2025-05-21T16:39:50.081197Z","iopub.status.idle":"2025-05-21T16:39:54.601051Z","shell.execute_reply.started":"2025-05-21T16:39:50.081172Z","shell.execute_reply":"2025-05-21T16:39:54.595355Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"role_anomaly_rates","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:54:54.464958Z","iopub.execute_input":"2025-05-06T15:54:54.465526Z","iopub.status.idle":"2025-05-06T15:54:54.470307Z","shell.execute_reply.started":"2025-05-06T15:54:54.465505Z","shell.execute_reply":"2025-05-06T15:54:54.469619Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Assuming mu_all has shape (n_samples, 8)\nlatent_cols = [f'latent_{i}' for i in range(8)]\nmu_df = pd.DataFrame(mu_all, columns=latent_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:54.603009Z","iopub.execute_input":"2025-05-21T16:39:54.603457Z","iopub.status.idle":"2025-05-21T16:39:54.613521Z","shell.execute_reply.started":"2025-05-21T16:39:54.603434Z","shell.execute_reply":"2025-05-21T16:39:54.607885Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"latent_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:59:51.515484Z","iopub.execute_input":"2025-05-06T15:59:51.516156Z","iopub.status.idle":"2025-05-06T15:59:51.520362Z","shell.execute_reply.started":"2025-05-06T15:59:51.516135Z","shell.execute_reply":"2025-05-06T15:59:51.519752Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:59:54.109602Z","iopub.execute_input":"2025-05-06T15:59:54.109869Z","iopub.status.idle":"2025-05-06T15:59:54.121983Z","shell.execute_reply.started":"2025-05-06T15:59:54.109848Z","shell.execute_reply":"2025-05-06T15:59:54.121304Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:57:45.699475Z","iopub.execute_input":"2025-05-06T15:57:45.699747Z","iopub.status.idle":"2025-05-06T15:57:45.704971Z","shell.execute_reply.started":"2025-05-06T15:57:45.699726Z","shell.execute_reply":"2025-05-06T15:57:45.704143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embedding_cols = [f'role_emb_pca_{i}' for i in range(50)] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:54.741159Z","iopub.execute_input":"2025-05-21T16:39:54.741423Z","iopub.status.idle":"2025-05-21T16:39:54.750641Z","shell.execute_reply.started":"2025-05-21T16:39:54.741401Z","shell.execute_reply":"2025-05-21T16:39:54.746197Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"history_cols = ['z_score_logon']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:55.661268Z","iopub.execute_input":"2025-05-21T16:39:55.661561Z","iopub.status.idle":"2025-05-21T16:39:55.669773Z","shell.execute_reply.started":"2025-05-21T16:39:55.661538Z","shell.execute_reply":"2025-05-21T16:39:55.666239Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"feature_cols","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T15:58:45.520405Z","iopub.execute_input":"2025-05-06T15:58:45.520662Z","iopub.status.idle":"2025-05-06T15:58:45.525495Z","shell.execute_reply.started":"2025-05-06T15:58:45.520642Z","shell.execute_reply":"2025-05-06T15:58:45.524924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[feature_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:00:37.228573Z","iopub.execute_input":"2025-05-06T16:00:37.229100Z","iopub.status.idle":"2025-05-06T16:00:37.248950Z","shell.execute_reply.started":"2025-05-06T16:00:37.229075Z","shell.execute_reply":"2025-05-06T16:00:37.248255Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_features = pd.concat(\n    [df[['user','date_only']], df[feature_cols], mu_df[latent_cols], df[embedding_cols + history_cols]],\n    axis=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:39:58.737497Z","iopub.execute_input":"2025-05-21T16:39:58.737812Z","iopub.status.idle":"2025-05-21T16:39:58.873985Z","shell.execute_reply.started":"2025-05-21T16:39:58.737784Z","shell.execute_reply":"2025-05-21T16:39:58.869130Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"all_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:18:43.420209Z","iopub.execute_input":"2025-05-06T16:18:43.420475Z","iopub.status.idle":"2025-05-06T16:18:43.515327Z","shell.execute_reply.started":"2025-05-06T16:18:43.420453Z","shell.execute_reply":"2025-05-06T16:18:43.514644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:16:01.688986Z","iopub.execute_input":"2025-05-06T16:16:01.689694Z","iopub.status.idle":"2025-05-06T16:16:01.694240Z","shell.execute_reply.started":"2025-05-06T16:16:01.689670Z","shell.execute_reply":"2025-05-06T16:16:01.693453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_features['z_score_logon'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:17:31.514744Z","iopub.execute_input":"2025-05-06T16:17:31.515244Z","iopub.status.idle":"2025-05-06T16:17:31.523655Z","shell.execute_reply.started":"2025-05-06T16:17:31.515221Z","shell.execute_reply":"2025-05-06T16:17:31.523054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:19:02.112568Z","iopub.execute_input":"2025-05-06T16:19:02.113149Z","iopub.status.idle":"2025-05-06T16:19:02.118006Z","shell.execute_reply.started":"2025-05-06T16:19:02.113126Z","shell.execute_reply":"2025-05-06T16:19:02.117273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_features = all_features.sort_values(['user', 'date_only']).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:04.281214Z","iopub.execute_input":"2025-05-21T16:40:04.281546Z","iopub.status.idle":"2025-05-21T16:40:04.570950Z","shell.execute_reply.started":"2025-05-21T16:40:04.281520Z","shell.execute_reply":"2025-05-21T16:40:04.565221Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/df-with-pca/df_with_pca.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:06.421646Z","iopub.execute_input":"2025-05-21T16:40:06.421922Z","iopub.status.idle":"2025-05-21T16:40:10.581975Z","shell.execute_reply.started":"2025-05-21T16:40:06.421900Z","shell.execute_reply":"2025-05-21T16:40:10.578362Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"df = df.drop(columns = 'Unnamed: 0')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:10.584587Z","iopub.execute_input":"2025-05-21T16:40:10.584802Z","iopub.status.idle":"2025-05-21T16:40:10.656734Z","shell.execute_reply.started":"2025-05-21T16:40:10.584781Z","shell.execute_reply":"2025-05-21T16:40:10.653347Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"new_df = df.sort_values(['user', 'date_only'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:10.659522Z","iopub.execute_input":"2025-05-21T16:40:10.659778Z","iopub.status.idle":"2025-05-21T16:40:10.789420Z","shell.execute_reply.started":"2025-05-21T16:40:10.659754Z","shell.execute_reply":"2025-05-21T16:40:10.784923Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:20.181739Z","iopub.execute_input":"2025-05-07T05:10:20.182104Z","iopub.status.idle":"2025-05-07T05:10:20.187609Z","shell.execute_reply.started":"2025-05-07T05:10:20.182081Z","shell.execute_reply":"2025-05-07T05:10:20.186857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df['user_day_seq'] = df.groupby('user').cumcount()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:10.792342Z","iopub.execute_input":"2025-05-21T16:40:10.792584Z","iopub.status.idle":"2025-05-21T16:40:10.835705Z","shell.execute_reply.started":"2025-05-21T16:40:10.792562Z","shell.execute_reply":"2025-05-21T16:40:10.830528Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"new_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:27.791399Z","iopub.execute_input":"2025-05-07T05:10:27.792073Z","iopub.status.idle":"2025-05-07T05:10:27.871804Z","shell.execute_reply.started":"2025-05-07T05:10:27.792048Z","shell.execute_reply":"2025-05-07T05:10:27.871059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:10:39.102022Z","iopub.execute_input":"2025-05-07T05:10:39.102290Z","iopub.status.idle":"2025-05-07T05:10:39.107208Z","shell.execute_reply.started":"2025-05-07T05:10:39.102271Z","shell.execute_reply":"2025-05-07T05:10:39.106452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mu_df = np.load('/kaggle/working/mu_all.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:13.901369Z","iopub.execute_input":"2025-05-21T16:40:13.901644Z","iopub.status.idle":"2025-05-21T16:40:13.917948Z","shell.execute_reply.started":"2025-05-21T16:40:13.901621Z","shell.execute_reply":"2025-05-21T16:40:13.911942Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"behavioral_features = [\n    'after_hours_logon_count', 'total_logon_count', 'device_connects',\n    'avg_content_word_count', 'text_files_accessed', 'files_accessed',\n    'total_recipients', 'external_ratio', 'emails_sent', 'bcc_flag',\n    'keyword_richness', 'z_score_logon'\n]\n\nlatent_features = [f'latent_{i}' for i in range(8)]\nrole_features = [f'role_emb_pca_{i}' for i in range(50)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:14.128239Z","iopub.execute_input":"2025-05-21T16:40:14.128558Z","iopub.status.idle":"2025-05-21T16:40:14.140325Z","shell.execute_reply.started":"2025-05-21T16:40:14.128535Z","shell.execute_reply":"2025-05-21T16:40:14.134502Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"mu_df = pd.DataFrame(mu_df, columns=latent_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:16.382412Z","iopub.execute_input":"2025-05-21T16:40:16.382688Z","iopub.status.idle":"2025-05-21T16:40:16.393115Z","shell.execute_reply.started":"2025-05-21T16:40:16.382665Z","shell.execute_reply":"2025-05-21T16:40:16.387697Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"mu_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:02.941869Z","iopub.execute_input":"2025-05-07T05:13:02.942208Z","iopub.status.idle":"2025-05-07T05:13:02.954977Z","shell.execute_reply.started":"2025-05-07T05:13:02.942185Z","shell.execute_reply":"2025-05-07T05:13:02.954206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = pd.concat([\n    new_df, mu_df\n], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:18.861191Z","iopub.execute_input":"2025-05-21T16:40:18.861517Z","iopub.status.idle":"2025-05-21T16:40:18.980034Z","shell.execute_reply.started":"2025-05-21T16:40:18.861491Z","shell.execute_reply":"2025-05-21T16:40:18.974214Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T16:55:22.842798Z","iopub.execute_input":"2025-05-06T16:55:22.843496Z","iopub.status.idle":"2025-05-06T16:55:22.848291Z","shell.execute_reply.started":"2025-05-06T16:55:22.843474Z","shell.execute_reply":"2025-05-06T16:55:22.847513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute historical baselines with proper handling of NaN values\nnew_df['rolling_avg_logon'] = new_df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=1).mean()\n)\nnew_df['rolling_std_logon'] = new_df.groupby('user')['total_logon_count'].transform(\n    lambda x: x.rolling(window=7, min_periods=2).std()\n)\n\n# Fill NaN values in rolling_std_logon (e.g., when there's only 1 data point)\nnew_df['rolling_std_logon'] = new_df['rolling_std_logon'].fillna(0)\n\n# Compute Z-score, avoiding division by zero\nnew_df['z_score_logon'] = (\n    (new_df['total_logon_count'] - new_df['rolling_avg_logon']) / \n    new_df['rolling_std_logon'].replace(0, 1)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:20.542731Z","iopub.execute_input":"2025-05-21T16:40:20.543031Z","iopub.status.idle":"2025-05-21T16:40:21.033611Z","shell.execute_reply.started":"2025-05-21T16:40:20.543006Z","shell.execute_reply":"2025-05-21T16:40:21.028073Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"scaler = StandardScaler()\nnew_df[behavioral_features + latent_features + role_features] = scaler.fit_transform(\n    new_df[behavioral_features + latent_features + role_features]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:23.542347Z","iopub.execute_input":"2025-05-21T16:40:23.542650Z","iopub.status.idle":"2025-05-21T16:40:24.069516Z","shell.execute_reply.started":"2025-05-21T16:40:23.542624Z","shell.execute_reply":"2025-05-21T16:40:24.064553Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# Create temporal features from existing data\ndef add_temporal_features(group):\n    # Use z_score_logon as base for temporal patterns\n    group['logon_trend'] = group['z_score_logon'].rolling(7, min_periods=1).mean()\n    group['logon_volatility'] = group['z_score_logon'].rolling(7, min_periods=1).std()\n    return group\n\nnew_df = new_df.groupby('user').apply(add_temporal_features).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:29.261532Z","iopub.execute_input":"2025-05-21T16:40:29.261860Z","iopub.status.idle":"2025-05-21T16:40:32.607843Z","shell.execute_reply.started":"2025-05-21T16:40:29.261832Z","shell.execute_reply":"2025-05-21T16:40:32.603512Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_10/3699887942.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  new_df = new_df.groupby('user').apply(add_temporal_features).reset_index(drop=True)\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"new_df.fillna(0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:32.609790Z","iopub.execute_input":"2025-05-21T16:40:32.610099Z","iopub.status.idle":"2025-05-21T16:40:33.210232Z","shell.execute_reply.started":"2025-05-21T16:40:32.610074Z","shell.execute_reply":"2025-05-21T16:40:33.204286Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"new_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:34.601342Z","iopub.execute_input":"2025-05-21T16:40:34.601655Z","iopub.status.idle":"2025-05-21T16:40:34.788615Z","shell.execute_reply.started":"2025-05-21T16:40:34.601629Z","shell.execute_reply":"2025-05-21T16:40:34.783134Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"user                       0\ndate_only                  0\nafter_hours_logon_count    0\ntotal_logon_count          0\ndevice_connects            0\n                          ..\nrolling_avg_logon          0\nrolling_std_logon          0\nz_score_logon              0\nlogon_trend                0\nlogon_volatility           0\nLength: 87, dtype: int64"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"new_df.fillna(0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:44:09.160541Z","iopub.execute_input":"2025-05-21T15:44:09.160893Z","iopub.status.idle":"2025-05-21T15:44:09.359921Z","shell.execute_reply.started":"2025-05-21T15:44:09.160863Z","shell.execute_reply":"2025-05-21T15:44:09.353953Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"new_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:13:49.222161Z","iopub.execute_input":"2025-05-07T05:13:49.222569Z","iopub.status.idle":"2025-05-07T05:13:49.227743Z","shell.execute_reply.started":"2025-05-07T05:13:49.222546Z","shell.execute_reply":"2025-05-07T05:13:49.227004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"is_anomaly = np.load('/kaggle/working/is_anomaly.npy')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:44:11.221614Z","iopub.execute_input":"2025-05-21T15:44:11.221936Z","iopub.status.idle":"2025-05-21T15:44:11.234581Z","shell.execute_reply.started":"2025-05-21T15:44:11.221905Z","shell.execute_reply":"2025-05-21T15:44:11.228859Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"df_features = new_df.copy()\ndf_features['role'] = df_features['role']  # Ensure this column exists\ndf_features['has_left'] = df_features['has_left']\ndf_features['is_anomaly'] = is_anomaly\nis_anomaly = df_features['is_anomaly'].values\n\nrole_anomaly_rates = df_features.groupby('role')['is_anomaly'].mean().to_dict()\ndf_features['role_anomaly_rate'] = df_features['role'].map(role_anomaly_rates)\ndf_features['role_sensitivity'] = df_features['role'].apply(lambda x: 1.5 if x in high_level_roles else 1.0)\ndf_features['adaptive_threshold'] = df_features.apply(\n    lambda row: max(0.5, min(0.95, 0.9 - row['role_anomaly_rate'] * 10)) * row['role_sensitivity'],\n    axis=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:40:59.521224Z","iopub.execute_input":"2025-05-21T16:40:59.521531Z","iopub.status.idle":"2025-05-21T16:41:04.157267Z","shell.execute_reply.started":"2025-05-21T16:40:59.521508Z","shell.execute_reply":"2025-05-21T16:41:04.151285Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:15:56.501825Z","iopub.execute_input":"2025-05-07T05:15:56.502438Z","iopub.status.idle":"2025-05-07T05:15:56.604123Z","shell.execute_reply.started":"2025-05-07T05:15:56.502412Z","shell.execute_reply":"2025-05-07T05:15:56.603212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:03:43.813968Z","iopub.execute_input":"2025-05-06T17:03:43.814664Z","iopub.status.idle":"2025-05-06T17:03:43.819513Z","shell.execute_reply.started":"2025-05-06T17:03:43.814634Z","shell.execute_reply":"2025-05-06T17:03:43.818788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nclass UserDayEnv(gym.Env):\n    def __init__(self, user_data):\n        super().__init__()  # Modern super() initialization\n        \n        # Maintain exact observation shape\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(behavioral_features) + len(latent_features) + len(role_features) + 2),  # 72D\n            dtype=np.float32\n        )\n        \n        # Maintain same action space\n        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n        \n        # Enhanced reward parameters\n        self.anomaly_weight = 50  # Base weight for true positives\n        self.normal_weight = 1     # Base weight for true negatives\n        self.has_left_bonus = 2.0  # Multiplier for departed users\n        self.fp_count = 0          # False positive counter\n        self.total_preds = 0       # Total predictions counter\n        \n        # Temporal tracking\n        self.last_5_scores = []    # Track recent scores for trend analysis\n        self.user_data = user_data.sort_values('date_only').copy()\n        \n        # Calculate class weights for imbalance handling\n        self.pos_weight = len(user_data) / (2 * max(1, user_data['is_anomaly'].sum()))\n        self.neg_weight = len(user_data) / (2 * max(1, (~user_data['is_anomaly']).sum()))\n\n    def reset(self, seed=None, options=None):\n        \"\"\"Maintains exact reset signature and functionality\"\"\"\n        self.current_step = 0\n        self.fp_count = 0\n        self.total_preds = 0\n        self.last_5_scores = []\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        \"\"\"Maintains exact observation structure\"\"\"\n        row = self.user_data.iloc[self.current_step]\n        obs = np.concatenate([\n            row[behavioral_features].values.astype(np.float32),\n            row[latent_features].values.astype(np.float32),\n            row[role_features].values.astype(np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        return obs\n\n    def step(self, action):\n        \"\"\"Maintains exact step signature with enhanced rewards\"\"\"\n        reward = self._calculate_reward(action)\n        row = self.user_data.iloc[self.current_step]\n        info = {\n            'final_action': 1 if action[0] >= row['adaptive_threshold'] else 0,\n            'true_label': row['is_anomaly']\n        }\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n            \n        return obs, reward, done, False, info\n\n    def _calculate_reward(self, action):\n        \"\"\"Enhanced reward logic while maintaining original structure\"\"\"\n        row = self.user_data.iloc[self.current_step]\n        true_label = row['is_anomaly']\n        threshold = row['adaptive_threshold']\n        self.total_preds += 1\n        \n        # Maintain original action thresholding\n        anomaly_score = action[0]\n        final_action = 1 if anomaly_score >= threshold else 0\n        \n        # Track recent scores for temporal consistency\n        self.last_5_scores.append(anomaly_score)\n        if len(self.last_5_scores) > 5:\n            self.last_5_scores.pop(0)\n        \n        # Dynamic FP rate adjustment (original logic)\n        fp_rate = self.fp_count / max(1, self.total_preds)\n        if fp_rate > 0.05:\n            self.anomaly_weight = max(20, self.anomaly_weight * 0.9)\n        \n        # Enhanced reward calculation\n        has_left_bonus = self.has_left_bonus if row['has_left'] == 1 else 1.0\n        \n        if final_action == true_label:\n            if true_label == 1:  # True Positive\n                # Add temporal consistency bonus\n                trend_bonus = 1.5 if len(self.last_5_scores) >= 3 and np.polyfit(\n                    range(len(self.last_5_scores)), self.last_5_scores, 1)[0] > 0.1 else 1.0\n                \n                reward = (self.anomaly_weight * has_left_bonus * trend_bonus * self.pos_weight)\n            else:  # True Negative\n                reward = self.normal_weight * self.neg_weight\n        else:\n            if final_action == 1:  # False Positive\n                reward = -10 * (1 + (1 - row['role_anomaly_rate']))  # Cluster-aware penalty\n                self.fp_count += 1\n            else:  # False Negative\n                reward = -15 * (1 + row['role_anomaly_rate'])  # Higher penalty for high-risk roles\n        \n        return float(reward)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:06:34.004935Z","iopub.execute_input":"2025-05-06T19:06:34.005240Z","iopub.status.idle":"2025-05-06T19:06:34.017698Z","shell.execute_reply.started":"2025-05-06T19:06:34.005217Z","shell.execute_reply":"2025-05-06T19:06:34.016837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_clusters = df_features.groupby('user')['cluster'].first()\ncluster_users = defaultdict(list)\nfor user, cluster in user_clusters.items():\n    cluster_users[cluster].append(user)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:10:20.399578Z","iopub.execute_input":"2025-05-06T17:10:20.399860Z","iopub.status.idle":"2025-05-06T17:10:20.421980Z","shell.execute_reply.started":"2025-05-06T17:10:20.399841Z","shell.execute_reply":"2025-05-06T17:10:20.421033Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_clusters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:10:20.897772Z","iopub.execute_input":"2025-05-06T17:10:20.898074Z","iopub.status.idle":"2025-05-06T17:10:20.904045Z","shell.execute_reply.started":"2025-05-06T17:10:20.898049Z","shell.execute_reply":"2025-05-06T17:10:20.903485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cluster_policies = {}\nfor cluster, users in cluster_users.items():\n    cluster_data = df_features[df_features['user'].isin(users)]\n    env = UserDayEnv(cluster_data)\n    model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, n_steps=2048, batch_size=64, n_epochs=10)\n    model.learn(total_timesteps=10000)\n    cluster_policies[cluster] = model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:10:34.398890Z","iopub.execute_input":"2025-05-06T17:10:34.399608Z","iopub.status.idle":"2025-05-06T17:24:11.047243Z","shell.execute_reply.started":"2025-05-06T17:10:34.399583Z","shell.execute_reply":"2025-05-06T17:24:11.046701Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cluster_policies","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:28:39.878665Z","iopub.execute_input":"2025-05-06T17:28:39.879183Z","iopub.status.idle":"2025-05-06T17:28:39.884468Z","shell.execute_reply.started":"2025-05-06T17:28:39.879159Z","shell.execute_reply":"2025-05-06T17:28:39.883751Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type(cluster_policies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:30:07.958298Z","iopub.execute_input":"2025-05-06T17:30:07.958983Z","iopub.status.idle":"2025-05-06T17:30:07.963357Z","shell.execute_reply.started":"2025-05-06T17:30:07.958958Z","shell.execute_reply":"2025-05-06T17:30:07.962633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(\"cluster_policies\", exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:34:21.188245Z","iopub.execute_input":"2025-05-06T17:34:21.189005Z","iopub.status.idle":"2025-05-06T17:34:21.192861Z","shell.execute_reply.started":"2025-05-06T17:34:21.188973Z","shell.execute_reply":"2025-05-06T17:34:21.192079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save each cluster policy\nfor cluster_id, model in cluster_policies.items():\n        if not isinstance(model, PPO):\n            print(f\"Warning: Model for cluster {cluster_id} is not a PPO model. Skipping.\")\n            continue\n        model_path = os.path.join(\"cluster_policies\", f\"ppo_cluster_{cluster_id}.zip\")\n        model.save(model_path)\n        print(f\"Saved cluster policy for cluster {cluster_id} to {model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:34:46.778939Z","iopub.execute_input":"2025-05-06T17:34:46.779490Z","iopub.status.idle":"2025-05-06T17:34:47.013974Z","shell.execute_reply.started":"2025-05-06T17:34:46.779467Z","shell.execute_reply":"2025-05-06T17:34:47.013374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check dtypes for role_features\nprint(df_features[role_features].dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:51:05.826287Z","iopub.execute_input":"2025-05-06T17:51:05.826564Z","iopub.status.idle":"2025-05-06T17:51:05.921900Z","shell.execute_reply.started":"2025-05-06T17:51:05.826543Z","shell.execute_reply":"2025-05-06T17:51:05.921175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MetaControllerEnv(gym.Env):\n    def __init__(self, df, cluster_policies):\n        super().__init__()  # Key fix: use modern super() syntax\n        \n        # Define action space first\n        self.action_space = spaces.Discrete(len(cluster_policies))\n        \n        # Define observation space\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(role_features),),\n            dtype=np.float32\n        )\n\n        # Initialize other attributes\n        self.df = df\n        self.cluster_policies = cluster_policies\n        self.current_user = None\n        self.user_data = None\n        self.current_step = 0\n\n    def reset(self, seed=None, options=None):\n        self.current_user = np.random.choice(self.df['user'].unique())\n        self.user_data = self.df[self.df['user'] == self.current_user]\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        return self.user_data.iloc[self.current_step][role_features].values.astype(np.float32)\n\n    def step(self, action):\n        chosen_cluster = list(self.cluster_policies.keys())[action]\n        policy = self.cluster_policies[chosen_cluster]\n        \n        obs = self._get_obs().astype(np.float32)  # Ensure float32\n        anomaly_score = policy.predict(obs, deterministic=True)[0]\n        \n        true_cluster = self.user_data.iloc[self.current_step]['cluster']\n        reward = 1.0 if chosen_cluster == true_cluster else -0.5\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n        \n        return self._get_obs(), reward, done, False, {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:56:51.719338Z","iopub.execute_input":"2025-05-06T17:56:51.719763Z","iopub.status.idle":"2025-05-06T17:56:51.727435Z","shell.execute_reply.started":"2025-05-06T17:56:51.719737Z","shell.execute_reply":"2025-05-06T17:56:51.726735Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure all features are float32\nrole_features = [f'role_emb_pca_{i}' for i in range(50)]\ndf_features[role_features] = df_features[role_features].astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:56:00.929117Z","iopub.execute_input":"2025-05-06T17:56:00.929802Z","iopub.status.idle":"2025-05-06T17:56:01.007022Z","shell.execute_reply.started":"2025-05-06T17:56:00.929779Z","shell.execute_reply":"2025-05-06T17:56:01.006460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# First ensure all cluster policies use proper dtype\nfor cluster, policy in cluster_policies.items():\n    policy.policy.obs_to_tensor = lambda x: (th.as_tensor(x.astype(np.float32), False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:07:29.744898Z","iopub.execute_input":"2025-05-06T18:07:29.745371Z","iopub.status.idle":"2025-05-06T18:07:29.749343Z","shell.execute_reply.started":"2025-05-06T18:07:29.745347Z","shell.execute_reply":"2025-05-06T18:07:29.748554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MetaControllerEnv(gym.Env):\n    def __init__(self, df, cluster_policies):\n        super().__init__()\n        \n        # Subset df to include necessary columns\n        self.df = df[\n            ['user', 'cluster'] + \n            behavioral_features + latent_features + role_features + \n            ['logon_trend', 'logon_volatility']\n        ]\n        \n        # Check for NaN values in numeric columns\n        numeric_cols = behavioral_features + latent_features + role_features + ['logon_trend', 'logon_volatility']\n        if self.df[numeric_cols].isna().any().any():\n            raise ValueError(\"NaN values found in numeric columns\")\n        \n        # Ensure numeric columns are float32\n        for col in numeric_cols:\n            self.df[col] = self.df[col].astype(np.float32)\n        \n        # Define action and observation spaces\n        self.action_space = spaces.Discrete(len(cluster_policies))\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(role_features),),\n            dtype=np.float32\n        )\n        \n        self.cluster_policies = cluster_policies\n        self.current_user = None\n        self.user_data = None\n        self.current_step = 0\n\n    def reset(self, seed=None, options=None):\n        self.current_user = np.random.choice(self.df['user'].unique())\n        self.user_data = self.df[self.df['user'] == self.current_user]\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        obs = self.user_data.iloc[self.current_step][role_features].to_numpy(dtype=np.float32)\n        return obs\n\n    def step(self, action):\n        chosen_cluster = list(self.cluster_policies.keys())[action]\n        policy = self.cluster_policies[chosen_cluster]\n        \n        # Construct the full observation for the cluster policy (72 features)\n        row = self.user_data.iloc[self.current_step]\n        cluster_obs = np.concatenate([\n            row[behavioral_features].to_numpy(dtype=np.float32),\n            row[latent_features].to_numpy(dtype=np.float32),\n            row[role_features].to_numpy(dtype=np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        \n        # Ensure cluster_obs is numeric\n        if not np.issubdtype(cluster_obs.dtype, np.floating):\n            raise ValueError(f\"Cluster observation contains non-numeric data: {cluster_obs.dtype}\")\n        \n        # Predict using the cluster policy\n        anomaly_score, _ = policy.predict(cluster_obs, deterministic=True)\n        \n        true_cluster = self.user_data.iloc[self.current_step]['cluster']\n        reward = 1.0 if chosen_cluster == true_cluster else -0.5\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n\n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n        return self._get_obs(), reward, done, False, {}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:18:08.566533Z","iopub.execute_input":"2025-05-06T18:18:08.567119Z","iopub.status.idle":"2025-05-06T18:18:08.576786Z","shell.execute_reply.started":"2025-05-06T18:18:08.567094Z","shell.execute_reply":"2025-05-06T18:18:08.575938Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch as th","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:38:46.642928Z","iopub.execute_input":"2025-05-21T16:38:46.643476Z","iopub.status.idle":"2025-05-21T16:38:46.653003Z","shell.execute_reply.started":"2025-05-21T16:38:46.643447Z","shell.execute_reply":"2025-05-21T16:38:46.648288Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"meta_env = MetaControllerEnv(\n    df_features[df_features['cluster'].isin(cluster_policies.keys())],\n    cluster_policies\n)\n\nmeta_policy = PPO(\n    \"MlpPolicy\",\n    meta_env,\n    verbose=1,\n    learning_rate=1e-4,\n    n_steps=512,\n    batch_size=32\n)\n\nmeta_policy.learn(total_timesteps=20000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:18:12.124969Z","iopub.execute_input":"2025-05-06T18:18:12.125675Z","iopub.status.idle":"2025-05-06T18:19:58.686449Z","shell.execute_reply.started":"2025-05-06T18:18:12.125651Z","shell.execute_reply":"2025-05-06T18:19:58.685905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:02:46.694974Z","iopub.execute_input":"2025-05-06T18:02:46.695757Z","iopub.status.idle":"2025-05-06T18:02:46.700077Z","shell.execute_reply.started":"2025-05-06T18:02:46.695733Z","shell.execute_reply":"2025-05-06T18:02:46.699401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Behavioral features dtypes:\", df_features[behavioral_features].dtypes)\nprint(\"Latent features dtypes:\", df_features[latent_features].dtypes)\nprint(\"Role features dtypes:\", df_features[role_features].dtypes)\nprint(\"Logon trend dtype:\", df_features['logon_trend'].dtype)\nprint(\"Logon volatility dtype:\", df_features['logon_volatility'].dtype)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T17:36:24.203926Z","iopub.execute_input":"2025-05-06T17:36:24.204788Z","iopub.status.idle":"2025-05-06T17:36:24.270603Z","shell.execute_reply.started":"2025-05-06T17:36:24.204759Z","shell.execute_reply":"2025-05-06T17:36:24.269827Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_anomaly(user_day_data):\n    cluster_idx, _ = meta_policy.predict(user_day_data[role_features].to_numpy(dtype=np.float32))\n    chosen_cluster = list(cluster_policies.keys())[cluster_idx]\n    \n    policy = cluster_policies[chosen_cluster]\n    obs = np.concatenate([\n        user_day_data[behavioral_features].to_numpy(dtype=np.float32),\n        user_day_data[latent_features].to_numpy(dtype=np.float32),\n        user_day_data[role_features].to_numpy(dtype=np.float32),\n        np.array([user_day_data['logon_trend'], user_day_data['logon_volatility']], dtype=np.float32)\n    ])\n    anomaly_score, _ = policy.predict(obs)\n    threshold = user_day_data['adaptive_threshold']\n    return 1 if anomaly_score >= threshold else 0\n\n# Run inference\npredictions = np.zeros(len(df))\nfor i in range(len(df)):\n    predictions[i] = predict_anomaly(df_features.iloc[i])\n\ndf_features['final_prediction'] = predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:21:43.987622Z","iopub.execute_input":"2025-05-06T18:21:43.988333Z","iopub.status.idle":"2025-05-06T18:37:01.122112Z","shell.execute_reply.started":"2025-05-06T18:21:43.988307Z","shell.execute_reply":"2025-05-06T18:37:01.121545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features['final_prediction'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:41:02.260032Z","iopub.execute_input":"2025-05-06T18:41:02.260307Z","iopub.status.idle":"2025-05-06T18:41:02.269936Z","shell.execute_reply.started":"2025-05-06T18:41:02.260286Z","shell.execute_reply":"2025-05-06T18:41:02.269240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:41:49.000301Z","iopub.execute_input":"2025-05-06T18:41:49.000567Z","iopub.status.idle":"2025-05-06T18:41:49.004264Z","shell.execute_reply.started":"2025-05-06T18:41:49.000544Z","shell.execute_reply":"2025-05-06T18:41:49.003653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision, recall, f1, _ = precision_recall_fscore_support(\n    df_features['is_anomaly'], df_features['final_prediction'], average='binary'\n)\nauc_roc = roc_auc_score(df_features['is_anomaly'], df_features['final_prediction'])\n\nprint(\"Performance of Temporal-Aware HRL with Custom Reward Logic:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\nprint(f\"AUC-ROC: {auc_roc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:41:50.624034Z","iopub.execute_input":"2025-05-06T18:41:50.624586Z","iopub.status.idle":"2025-05-06T18:41:50.960971Z","shell.execute_reply.started":"2025-05-06T18:41:50.624565Z","shell.execute_reply":"2025-05-06T18:41:50.960154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:41:17.783259Z","iopub.execute_input":"2025-05-21T16:41:17.783557Z","iopub.status.idle":"2025-05-21T16:41:17.795014Z","shell.execute_reply.started":"2025-05-21T16:41:17.783533Z","shell.execute_reply":"2025-05-21T16:41:17.788672Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"cm = confusion_matrix(df_features['is_anomaly'], df_features['final_prediction'])\n\n# Create a new figure\nplt.figure(figsize=(8, 6))\n# Plot the confusion matrix using seaborn heatmap\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal', 'Anomaly'], \n            yticklabels=['Normal', 'Anomaly'])\nplt.title('Confusion Matrix for Anomaly Detection')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:44:29.344551Z","iopub.execute_input":"2025-05-06T18:44:29.344813Z","iopub.status.idle":"2025-05-06T18:44:29.651767Z","shell.execute_reply.started":"2025-05-06T18:44:29.344791Z","shell.execute_reply":"2025-05-06T18:44:29.651068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_policy.save(\"meta_policy.zip\")\nprint(\"Meta-policy model saved to meta_policy.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:50:18.965183Z","iopub.execute_input":"2025-05-06T18:50:18.965431Z","iopub.status.idle":"2025-05-06T18:50:18.980610Z","shell.execute_reply.started":"2025-05-06T18:50:18.965413Z","shell.execute_reply":"2025-05-06T18:50:18.980022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correct_selections = 0\ntotal_selections = 0\nfor i in range(100):  # Test on 100 steps\n    obs, _ = meta_env.reset()\n    action, _ = meta_policy.predict(obs)\n    chosen_cluster = list(cluster_policies.keys())[action]\n    true_cluster = meta_env.user_data.iloc[meta_env.current_step]['cluster']\n    if chosen_cluster == true_cluster:\n        correct_selections += 1\n    total_selections += 1\n    meta_env.step(action)\n\naccuracy = correct_selections / total_selections\nprint(f\"Meta-Controller Cluster Selection Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T18:54:23.925395Z","iopub.execute_input":"2025-05-06T18:54:23.925928Z","iopub.status.idle":"2025-05-06T18:54:27.837353Z","shell.execute_reply.started":"2025-05-06T18:54:23.925905Z","shell.execute_reply":"2025-05-06T18:54:27.836587Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"imporving the HRL","metadata":{}},{"cell_type":"code","source":"class UserDayEnv(gym.Env):\n    def __init__(self, user_data):\n        super().__init__()\n        self.user_data = user_data[\n            behavioral_features + latent_features + role_features + \n            ['logon_trend', 'logon_volatility', 'is_anomaly', 'adaptive_threshold', 'has_left']\n        ]\n        self.current_step = 0\n        \n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(behavioral_features) + len(latent_features) + len(role_features) + 2,),\n            dtype=np.float32\n        )\n        \n        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n        \n        self.anomaly_weight = 200  # Increased to prioritize anomalies\n        self.normal_weight = 1\n        self.has_left_bonus = 2.0\n        self.fp_count = 0\n        self.total_preds = 0\n\n    def reset(self, seed=None, options=None):\n        self.current_step = 0\n        self.fp_count = 0\n        self.total_preds = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        row = self.user_data.iloc[self.current_step]\n        obs = np.concatenate([\n            row[behavioral_features].to_numpy(dtype=np.float32),\n            row[latent_features].to_numpy(dtype=np.float32),\n            row[role_features].to_numpy(dtype=np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        return obs\n\n    def step(self, action):\n        reward = self._calculate_reward(action)\n        row = self.user_data.iloc[self.current_step]\n        info = {'final_action': 1 if action[0] >= row['adaptive_threshold'] else 0}\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n            \n        return obs, reward, done, False, info\n\n    def _calculate_reward(self, action):\n        row = self.user_data.iloc[self.current_step]\n        true_label = row['is_anomaly']\n        threshold = row['adaptive_threshold']\n        self.total_preds += 1\n        \n        anomaly_score = action[0]\n        final_action = 1 if anomaly_score >= threshold else 0\n        \n        fp_rate = self.fp_count / max(1, self.total_preds)\n        if fp_rate > 0.1:  # Relaxed FP rate threshold\n            self.anomaly_weight = max(100, self.anomaly_weight * 0.95)  # Slower decrease\n        \n        has_left_bonus = self.has_left_bonus if row['has_left'] == 1 else 1.0\n        if final_action == true_label:\n            reward = self.anomaly_weight * has_left_bonus if true_label == 1 else self.normal_weight\n        else:\n            reward = -10 if final_action == 1 else -15  # Increased penalty for FNs\n        \n        if final_action == 1 and true_label == 0:\n            self.fp_count += 1\n        \n        return reward","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:17:09.299171Z","iopub.execute_input":"2025-05-06T19:17:09.299756Z","iopub.status.idle":"2025-05-06T19:17:09.309790Z","shell.execute_reply.started":"2025-05-06T19:17:09.299733Z","shell.execute_reply":"2025-05-06T19:17:09.308983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:17:14.358974Z","iopub.execute_input":"2025-05-06T19:17:14.359746Z","iopub.status.idle":"2025-05-06T19:17:14.453447Z","shell.execute_reply.started":"2025-05-06T19:17:14.359714Z","shell.execute_reply":"2025-05-06T19:17:14.452617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cluster_policies = {}\nfor cluster, users in cluster_users.items():\n    cluster_data = df_features[df_features['user'].isin(users)]\n    env = UserDayEnv(cluster_data)\n    model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, n_steps=2048, batch_size=64, n_epochs=10)\n    model.learn(total_timesteps=10000)\n    cluster_policies[cluster] = model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:17:15.503839Z","iopub.execute_input":"2025-05-06T19:17:15.504114Z","iopub.status.idle":"2025-05-06T19:31:18.522287Z","shell.execute_reply.started":"2025-05-06T19:17:15.504092Z","shell.execute_reply":"2025-05-06T19:31:18.521473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MetaControllerEnv(gym.Env):\n    def __init__(self, df, cluster_policies):\n        super().__init__()\n        \n        self.df = df[\n            ['user', 'cluster'] + \n            behavioral_features + latent_features + role_features + \n            ['logon_trend', 'logon_volatility', 'is_anomaly', 'adaptive_threshold']\n        ]\n        \n        self.action_space = spaces.Discrete(len(cluster_policies))\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(role_features),),\n            dtype=np.float32\n        )\n        \n        self.cluster_policies = cluster_policies\n        self.current_user = None\n        self.user_data = None\n        self.current_step = 0\n        # For tracking selection accuracy\n        self.correct_selections = 0\n        self.total_selections = 0\n\n    def reset(self, seed=None, options=None):\n        while True:  # Ensure user_data is not empty\n            self.current_user = np.random.choice(self.df['user'].unique())\n            self.user_data = self.df[self.df['user'] == self.current_user]\n            if len(self.user_data) > 0:\n                break\n        self.current_step = 0\n        return self._get_obs(), {}\n\n    def _get_obs(self):\n        obs = self.user_data.iloc[self.current_step][role_features].to_numpy(dtype=np.float32)\n        return obs\n\n    def step(self, action):\n        chosen_cluster = list(self.cluster_policies.keys())[action]\n        policy = self.cluster_policies[chosen_cluster]\n        \n        # Construct the full observation for the cluster policy (72 features)\n        row = self.user_data.iloc[self.current_step]\n        cluster_obs = np.concatenate([\n            row[behavioral_features].to_numpy(dtype=np.float32),\n            row[latent_features].to_numpy(dtype=np.float32),\n            row[role_features].to_numpy(dtype=np.float32),\n            np.array([row['logon_trend'], row['logon_volatility']], dtype=np.float32)\n        ])\n        \n        anomaly_score, _ = policy.predict(cluster_obs, deterministic=True)\n        \n        # Compute reward based on anomaly detection performance\n        true_label = row['is_anomaly']\n        threshold = row['adaptive_threshold']\n        final_action = 1 if anomaly_score >= threshold else 0\n        \n        if final_action == true_label:\n            reward = 200 if true_label == 1 else 1  # High reward for detecting anomalies\n        else:\n            reward = -10 if final_action == 1 else -15\n        \n        # Track cluster selection accuracy for debugging\n        true_cluster = self.user_data.iloc[self.current_step]['cluster']\n        if chosen_cluster == true_cluster:\n            self.correct_selections += 1\n        self.total_selections += 1\n        if self.total_selections % 100 == 0:  # Print every 100 steps\n            print(f\"Meta-Controller Selection Accuracy: {self.correct_selections / self.total_selections:.4f}\")\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.user_data)\n\n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self._get_obs()\n        return obs, reward, done, False, {}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:32:41.449655Z","iopub.execute_input":"2025-05-06T19:32:41.450370Z","iopub.status.idle":"2025-05-06T19:32:41.460803Z","shell.execute_reply.started":"2025-05-06T19:32:41.450349Z","shell.execute_reply":"2025-05-06T19:32:41.460061Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"meta_env = MetaControllerEnv(\n    df_features[df_features['cluster'].isin(cluster_policies.keys())],\n    cluster_policies\n)\n\nmeta_policy = PPO(\n    \"MlpPolicy\",\n    meta_env,\n    verbose=1,\n    learning_rate=1e-4,\n    n_steps=512,\n    batch_size=32\n)\n\nmeta_policy.learn(total_timesteps=20000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:32:47.389323Z","iopub.execute_input":"2025-05-06T19:32:47.389583Z","iopub.status.idle":"2025-05-06T19:34:24.855799Z","shell.execute_reply.started":"2025-05-06T19:32:47.389564Z","shell.execute_reply":"2025-05-06T19:34:24.854934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_anomaly(user_day_data):\n    cluster_idx, _ = meta_policy.predict(user_day_data[role_features].to_numpy(dtype=np.float32))\n    chosen_cluster = list(cluster_policies.keys())[cluster_idx]\n    \n    policy = cluster_policies[chosen_cluster]\n    obs = np.concatenate([\n        user_day_data[behavioral_features].to_numpy(dtype=np.float32),\n        user_day_data[latent_features].to_numpy(dtype=np.float32),\n        user_day_data[role_features].to_numpy(dtype=np.float32),\n        np.array([user_day_data['logon_trend'], user_day_data['logon_volatility']], dtype=np.float32)\n    ])\n    anomaly_score, _ = policy.predict(obs)\n    threshold = user_day_data['adaptive_threshold']\n    user_day_data['anomaly_score'] = anomaly_score\n    return 1 if anomaly_score >= threshold else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T19:36:28.968479Z","iopub.execute_input":"2025-05-06T19:36:28.969248Z","iopub.status.idle":"2025-05-06T19:36:28.974360Z","shell.execute_reply.started":"2025-05-06T19:36:28.969218Z","shell.execute_reply":"2025-05-06T19:36:28.973667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = np.zeros(len(df_features))\nanomaly_scores = np.zeros(len(df_features))\nfor i in range(len(df_features)):\n    row = df_features.iloc[i].copy()\n    predictions[i] = predict_anomaly(row)\n    anomaly_scores[i] = row['anomaly_score'] if 'anomaly_score' in row else 0\n\ndf['final_prediction'] = predictions\ndf['anomaly_score'] = anomaly_scores","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precision, recall, f1, _ = precision_recall_fscore_support(\n    df_features['is_anomaly'], df_features['final_prediction'], average='binary'\n)\nprint(\"Performance of Temporal-Aware HRL with Custom Reward Logic:\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:06:27.835999Z","iopub.execute_input":"2025-05-06T20:06:27.836573Z","iopub.status.idle":"2025-05-06T20:06:28.055725Z","shell.execute_reply.started":"2025-05-06T20:06:27.836549Z","shell.execute_reply":"2025-05-06T20:06:28.054932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cm = confusion_matrix(df_features['is_anomaly'], df_features['final_prediction'])\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['Normal', 'Anomaly'], \n            yticklabels=['Normal', 'Anomaly'])\nplt.title('Confusion Matrix for Anomaly Detection')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:03:48.276785Z","iopub.execute_input":"2025-05-06T20:03:48.277506Z","iopub.status.idle":"2025-05-06T20:03:48.533679Z","shell.execute_reply.started":"2025-05-06T20:03:48.277481Z","shell.execute_reply":"2025-05-06T20:03:48.533049Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save each cluster policy\nfor cluster_id, model in cluster_policies.items():\n        if not isinstance(model, PPO):\n            print(f\"Warning: Model for cluster {cluster_id} is not a PPO model. Skipping.\")\n            continue\n        model_path = os.path.join(\"cluster_policies_2\", f\"ppo_cluster_{cluster_id}.zip\")\n        model.save(model_path)\n        print(f\"Saved cluster policy for cluster {cluster_id} to {model_path}\")\n\nmeta_policy.save(\"meta_policy_2.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T20:04:46.615809Z","iopub.execute_input":"2025-05-06T20:04:46.616497Z","iopub.status.idle":"2025-05-06T20:04:46.856655Z","shell.execute_reply.started":"2025-05-06T20:04:46.616472Z","shell.execute_reply":"2025-05-06T20:04:46.855987Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix, roc_curve, auc, precision_recall_curve","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:45:39.109605Z","iopub.execute_input":"2025-05-21T16:45:39.109937Z","iopub.status.idle":"2025-05-21T16:45:39.121711Z","shell.execute_reply.started":"2025-05-21T16:45:39.109910Z","shell.execute_reply":"2025-05-21T16:45:39.115733Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"RL with ppo guided reward","metadata":{}},{"cell_type":"code","source":"df_features = df_features.sort_values(['user', 'date_only'])\ngrouped_data = df_features.groupby('user')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:45:44.028060Z","iopub.execute_input":"2025-05-21T16:45:44.028382Z","iopub.status.idle":"2025-05-21T16:45:44.430768Z","shell.execute_reply.started":"2025-05-21T16:45:44.028355Z","shell.execute_reply":"2025-05-21T16:45:44.425123Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"temporal_features = ['logon_trend', 'logon_volatility']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:45:44.867970Z","iopub.execute_input":"2025-05-21T16:45:44.868263Z","iopub.status.idle":"2025-05-21T16:45:44.882602Z","shell.execute_reply.started":"2025-05-21T16:45:44.868239Z","shell.execute_reply":"2025-05-21T16:45:44.874687Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"all_features = behavioral_features + latent_features + role_features + temporal_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:45:45.270215Z","iopub.execute_input":"2025-05-21T16:45:45.270550Z","iopub.status.idle":"2025-05-21T16:45:45.287712Z","shell.execute_reply.started":"2025-05-21T16:45:45.270523Z","shell.execute_reply":"2025-05-21T16:45:45.280354Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"grouped_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T15:37:38.660378Z","iopub.execute_input":"2025-05-21T15:37:38.660753Z","iopub.status.idle":"2025-05-21T15:37:38.710558Z","shell.execute_reply.started":"2025-05-21T15:37:38.660720Z","shell.execute_reply":"2025-05-21T15:37:38.705427Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"           user   date_only  after_hours_logon_count  total_logon_count  \\\n0       AAE0190  2010-01-04                -0.737332           -0.53406   \n1       AAE0190  2010-01-05                -0.737332           -0.53406   \n2       AAE0190  2010-01-06                -0.737332           -0.53406   \n3       AAE0190  2010-01-07                -0.737332           -0.53406   \n4       AAE0190  2010-01-08                -0.737332           -0.53406   \n...         ...         ...                      ...                ...   \n329939  ZSL0305  2010-01-04                -0.737332           -0.53406   \n329940  ZSL0305  2010-01-05                -0.737332           -0.53406   \n329941  ZSL0305  2010-01-06                -0.737332           -0.53406   \n329942  ZSL0305  2010-01-07                -0.737332           -0.53406   \n329943  ZSL0305  2010-01-08                -0.737332           -0.53406   \n\n        device_connects  avg_content_word_count  text_files_accessed  \\\n0             -0.331274               -0.396378            -0.285834   \n1             -0.331274               -0.396378            -0.285834   \n2             -0.331274               -0.396378            -0.285834   \n3             -0.331274               -0.396378            -0.285834   \n4             -0.331274               -0.396378            -0.285834   \n...                 ...                     ...                  ...   \n329939        -0.331274               -0.396378            -0.285834   \n329940        -0.331274               -0.396378            -0.285834   \n329941        -0.331274               -0.396378            -0.285834   \n329942        -0.331274               -0.396378            -0.285834   \n329943        -0.331274               -0.396378            -0.285834   \n\n        files_accessed  total_recipients  external_ratio  emails_sent  \\\n0            -0.287121          0.930009       -0.759447     1.141349   \n1            -0.287121          0.711501       -0.233484     0.952298   \n2            -0.287121          0.766128       -0.064106     1.141349   \n3            -0.287121          0.875382       -0.179997     1.141349   \n4            -0.287121          0.766128       -0.607898     0.952298   \n...                ...               ...             ...          ...   \n329939       -0.287121         -1.255072        0.515344    -1.316319   \n329940       -0.287121         -1.255072        0.515344    -1.316319   \n329941       -0.287121         -1.145818       -1.107117    -1.316319   \n329942       -0.287121         -1.309699        0.515344    -1.316319   \n329943       -0.287121         -1.418953       -1.107117    -1.505370   \n\n        bcc_flag  keyword_richness  \n0      -0.583959          0.386906  \n1      -0.583959          0.374986  \n2      -0.583959          1.463670  \n3      -0.583959          0.323333  \n4      -0.583959          0.001496  \n...          ...               ...  \n329939 -0.583959         -1.265986  \n329940 -0.583959         -1.281879  \n329941 -0.583959         -1.258040  \n329942 -0.583959         -1.222280  \n329943 -0.583959         -1.480544  \n\n[5000 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>date_only</th>\n      <th>after_hours_logon_count</th>\n      <th>total_logon_count</th>\n      <th>device_connects</th>\n      <th>avg_content_word_count</th>\n      <th>text_files_accessed</th>\n      <th>files_accessed</th>\n      <th>total_recipients</th>\n      <th>external_ratio</th>\n      <th>emails_sent</th>\n      <th>bcc_flag</th>\n      <th>keyword_richness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAE0190</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.930009</td>\n      <td>-0.759447</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.386906</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAE0190</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.711501</td>\n      <td>-0.233484</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.374986</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAE0190</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.064106</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>1.463670</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAE0190</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.875382</td>\n      <td>-0.179997</td>\n      <td>1.141349</td>\n      <td>-0.583959</td>\n      <td>0.323333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAE0190</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>0.766128</td>\n      <td>-0.607898</td>\n      <td>0.952298</td>\n      <td>-0.583959</td>\n      <td>0.001496</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>329939</th>\n      <td>ZSL0305</td>\n      <td>2010-01-04</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.255072</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.265986</td>\n    </tr>\n    <tr>\n      <th>329940</th>\n      <td>ZSL0305</td>\n      <td>2010-01-05</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.255072</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.281879</td>\n    </tr>\n    <tr>\n      <th>329941</th>\n      <td>ZSL0305</td>\n      <td>2010-01-06</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.145818</td>\n      <td>-1.107117</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.258040</td>\n    </tr>\n    <tr>\n      <th>329942</th>\n      <td>ZSL0305</td>\n      <td>2010-01-07</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.309699</td>\n      <td>0.515344</td>\n      <td>-1.316319</td>\n      <td>-0.583959</td>\n      <td>-1.222280</td>\n    </tr>\n    <tr>\n      <th>329943</th>\n      <td>ZSL0305</td>\n      <td>2010-01-08</td>\n      <td>-0.737332</td>\n      <td>-0.53406</td>\n      <td>-0.331274</td>\n      <td>-0.396378</td>\n      <td>-0.285834</td>\n      <td>-0.287121</td>\n      <td>-1.418953</td>\n      <td>-1.107117</td>\n      <td>-1.505370</td>\n      <td>-0.583959</td>\n      <td>-1.480544</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"user_data_dict = {}\nfor user, group in grouped_data:\n    user_data_dict[user] = {\n        'X': group[all_features].to_numpy().astype(np.float32),\n        'y': group['is_anomaly'].to_numpy(),\n        'thresholds': group['adaptive_threshold'].to_numpy(),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:51:40.547921Z","iopub.execute_input":"2025-05-21T16:51:40.548234Z","iopub.status.idle":"2025-05-21T16:51:41.256968Z","shell.execute_reply.started":"2025-05-21T16:51:40.548203Z","shell.execute_reply":"2025-05-21T16:51:41.251362Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"X_all = df_features[all_features].to_numpy()\ny_all = df_features['is_anomaly'].to_numpy()\nuser_ids_all = df_features['user'].to_numpy()\nadaptive_thresholds_all = df_features['adaptive_threshold'].to_numpy()\n\nX_mean = X_all.mean(axis=0)\nX_std = X_all.std(axis=0) + 1e-8\nX_normalized = (X_all - X_mean) / X_std","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:51:45.248467Z","iopub.execute_input":"2025-05-21T16:51:45.248805Z","iopub.status.idle":"2025-05-21T16:51:45.499610Z","shell.execute_reply.started":"2025-05-21T16:51:45.248773Z","shell.execute_reply":"2025-05-21T16:51:45.494020Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"for user in user_data_dict:\n    user_data_dict[user]['X'] = (user_data_dict[user]['X'] - X_mean) / X_std\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:51:47.687863Z","iopub.execute_input":"2025-05-21T16:51:47.688188Z","iopub.status.idle":"2025-05-21T16:51:47.779711Z","shell.execute_reply.started":"2025-05-21T16:51:47.688162Z","shell.execute_reply":"2025-05-21T16:51:47.775525Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"!pip install xgboost\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:45:02.668342Z","iopub.execute_input":"2025-05-21T16:45:02.668647Z","iopub.status.idle":"2025-05-21T16:45:12.821074Z","shell.execute_reply.started":"2025-05-21T16:45:02.668622Z","shell.execute_reply":"2025-05-21T16:45:12.817424Z"}},"outputs":[{"name":"stdout","text":"Collecting xgboost\n  Downloading xgboost-3.0.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from xgboost) (2.0.2)\nRequirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/site-packages (from xgboost) (2.21.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/site-packages (from xgboost) (1.15.2)\nDownloading xgboost-3.0.1-py3-none-manylinux_2_28_x86_64.whl (253.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.9/253.9 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: xgboost\nSuccessfully installed xgboost-3.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import xgboost as xgb\nprint(\"Training XGBoost for reward model...\")\nxgb_model = xgb.XGBClassifier(\n    objective=\"binary:logistic\",\n    scale_pos_weight=(len(y_all) - sum(y_all)) / sum(y_all),  # Handle class imbalance\n    max_depth=4,\n    n_estimators=50,\n    learning_rate=0.1,\n    random_state=42\n)\nxgb_model.fit(X_normalized, y_all)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:50:24.968146Z","iopub.execute_input":"2025-05-21T16:50:24.968476Z","iopub.status.idle":"2025-05-21T16:50:25.484486Z","shell.execute_reply.started":"2025-05-21T16:50:24.968451Z","shell.execute_reply":"2025-05-21T16:50:25.479990Z"}},"outputs":[{"name":"stdout","text":"Training XGBoost for reward model...\n","output_type":"stream"},{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              feature_weights=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=50,\n              n_jobs=None, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-1 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              feature_weights=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=50,\n              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              feature_weights=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=50,\n              n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"class AnomalyDetectionEnv(gym.Env):\n    def __init__(self, user_data_dict, xgb_model, oversample_ratio=0.3):\n        super().__init__()\n        self.user_data_dict = user_data_dict\n        self.xgb_model = xgb_model\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(all_features),),  # 72 features\n            dtype=np.float32\n        )\n        self.action_space = spaces.Box(\n            low=0,\n            high=1,\n            shape=(1,),\n            dtype=np.float32\n        )\n        # For balanced sampling\n        self.all_users = list(user_data_dict.keys())\n        self.anomaly_users = [\n            user for user, data in user_data_dict.items()\n            if np.any(data['y'] == 1)\n        ]\n        self.oversample_ratio = oversample_ratio\n        self.current_user = None\n        self.current_data = None\n        self.current_step = 0\n\n    def reset(self, seed=None, options=None):\n        if seed is not None:\n            np.random.seed(seed)\n        # Ignore options for now (can be used for future customization)\n        _ = options  # Unused but required by Gymnasium API\n        \n        # Balanced sampling: 50% chance to sample a user with anomalies\n        if self.anomaly_users and np.random.random() < self.oversample_ratio:\n            self.current_user = np.random.choice(self.anomaly_users)\n        else:\n            self.current_user = np.random.choice(self.all_users)\n        \n        self.current_data = self.user_data_dict[self.current_user]\n        self.current_step = 0\n        return self.current_data['X'][self.current_step], {}\n\n    def step(self, action):\n        true_label = self.current_data['y'][self.current_step]\n        threshold = self.current_data['thresholds'][self.current_step]\n        \n        # Convert action (anomaly_score) to binary prediction\n        pred = 1 if action[0] >= threshold else 0\n        \n        # Get XGBoost probability for anomaly\n        xgb_proba = self.xgb_model.predict_proba(\n            self.current_data['X'][self.current_step].reshape(1, -1)\n        )[0, 1]\n        \n        # Reward structure inspired by provided code\n        if pred == true_label:\n            reward = (\n                100.0 * xgb_proba if true_label == 1 else 1.0 * (1 - xgb_proba)\n            )\n        else:\n            reward = (\n                -10.0 * (1 - xgb_proba) if pred == 1 else -5.0 * xgb_proba\n            )\n        \n        reward = float(reward)  # Ensure reward is a float\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.current_data['X'])\n        truncated = False\n        info = {\"user_id\": self.current_user}\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self.current_data['X'][self.current_step]\n        \n        return obs, reward, done, truncated, info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:25:52.781160Z","iopub.execute_input":"2025-05-07T05:25:52.781398Z","iopub.status.idle":"2025-05-07T05:25:52.790872Z","shell.execute_reply.started":"2025-05-07T05:25:52.781381Z","shell.execute_reply":"2025-05-07T05:25:52.790159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = AnomalyDetectionEnv(\n    user_data_dict,\n    xgb_model,\n    oversample_ratio=0.3\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:26:03.544636Z","iopub.execute_input":"2025-05-07T05:26:03.544911Z","iopub.status.idle":"2025-05-07T05:26:03.554690Z","shell.execute_reply.started":"2025-05-07T05:26:03.544892Z","shell.execute_reply":"2025-05-07T05:26:03.553906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training PPO...\")\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs={\"net_arch\": [64, 64]},\n    learning_rate=3e-4,\n    n_steps=2048,\n    batch_size=64,\n    n_epochs=10,\n    gamma=0.99,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:26:12.399812Z","iopub.execute_input":"2025-05-07T05:26:12.400098Z","iopub.status.idle":"2025-05-07T05:26:12.411342Z","shell.execute_reply.started":"2025-05-07T05:26:12.400077Z","shell.execute_reply":"2025-05-07T05:26:12.410618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.learn(total_timesteps=100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:26:18.029297Z","iopub.execute_input":"2025-05-07T05:26:18.029565Z","iopub.status.idle":"2025-05-07T05:29:47.002326Z","shell.execute_reply.started":"2025-05-07T05:26:18.029543Z","shell.execute_reply":"2025-05-07T05:29:47.001661Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"ppo_anomaly_detector_xgb.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:34:54.039900Z","iopub.execute_input":"2025-05-07T05:34:54.040205Z","iopub.status.idle":"2025-05-07T05:34:54.054424Z","shell.execute_reply.started":"2025-05-07T05:34:54.040184Z","shell.execute_reply":"2025-05-07T05:34:54.053717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, user_data_dict, n_samples=1000):\n    true_labels = []\n    predictions = []\n    anomaly_scores = []\n    \n    # Randomly select users to evaluate\n    users_to_evaluate = np.random.choice(\n        list(user_data_dict.keys()), \n        size=min(n_samples, len(user_data_dict)), \n        replace=False\n    )\n    \n    # Evaluate each selected user\n    for user in users_to_evaluate:\n        data = user_data_dict[user]\n        for i in range(len(data['X'])):\n            obs = data['X'][i]\n            action, _ = model.predict(obs, deterministic=True)\n            \n            # Store results\n            true_labels.append(data['y'][i])\n            predictions.append(1 if action[0] >= data['thresholds'][i] else 0)\n            anomaly_scores.append(float(action[0]))\n    \n    precision = precision_score(true_labels, predictions, zero_division=0)\n    recall = recall_score(true_labels, predictions, zero_division=0)\n    f1 = f1_score(true_labels, predictions, zero_division=0)\n    \n    print(\"\\nSimple Evaluation Results:\")\n    print(f\"Evaluated {len(predictions)} samples\")\n    print(f\"Anomaly rate: {np.mean(true_labels):.2%}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    \n    if sum(true_labels) > 0:\n        fpr, tpr, _ = roc_curve(true_labels, anomaly_scores)\n        plt.plot(fpr, tpr)\n        plt.plot([0, 1], [0, 1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.show()\n    else:\n        print(\"No anomalies found in evaluation set - cannot plot ROC curve\")\n\n# Run the simple evaluation\nevaluate_model(model, user_data_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:35:07.559860Z","iopub.execute_input":"2025-05-07T05:35:07.560155Z","iopub.status.idle":"2025-05-07T05:38:17.915199Z","shell.execute_reply.started":"2025-05-07T05:35:07.560135Z","shell.execute_reply":"2025-05-07T05:38:17.914338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"improving using hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"feature_importances = xgb_model.feature_importances_\nfeature_importance_weights = feature_importances / feature_importances.sum() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:51:32.608039Z","iopub.execute_input":"2025-05-21T16:51:32.608372Z","iopub.status.idle":"2025-05-21T16:51:32.621658Z","shell.execute_reply.started":"2025-05-21T16:51:32.608347Z","shell.execute_reply":"2025-05-21T16:51:32.615419Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"class AnomalyDetectionEnv(gym.Env):\n    def __init__(self, user_data_dict, xgb_model, feature_weights, oversample_ratio=0.5):\n        super().__init__()\n        self.user_data_dict = user_data_dict\n        self.xgb_model = xgb_model\n        self.feature_weights = feature_weights\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(all_features),),\n            dtype=np.float32\n        )\n        self.action_space = spaces.Box(\n            low=0,\n            high=1,\n            shape=(1,),\n            dtype=np.float32\n        )\n        self.all_users = list(user_data_dict.keys())\n        self.anomaly_users = [\n            user for user, data in user_data_dict.items()\n            if np.any(data['y'] == 1)\n        ]\n        self.oversample_ratio = oversample_ratio\n        self.current_user = None\n        self.current_data = None\n        self.current_step = 0\n        self.fp_count = 0\n        self.total_preds = 0\n\n    def reset(self, seed=None, options=None):\n        if seed is not None:\n            np.random.seed(seed)\n        _ = options\n        \n        if self.anomaly_users and np.random.random() < self.oversample_ratio:\n            self.current_user = np.random.choice(self.anomaly_users)\n        else:\n            self.current_user = np.random.choice(self.all_users)\n        \n        self.current_data = self.user_data_dict[self.current_user]\n        self.current_step = 0\n        return self.current_data['X'][self.current_step], {}\n\n    def step(self, action):\n        true_label = self.current_data['y'][self.current_step]\n        threshold = self.current_data['thresholds'][self.current_step]\n        obs = self.current_data['X'][self.current_step]\n        \n        pred = 1 if action[0] >= threshold else 0\n        \n        # Get XGBoost probability for anomaly\n        xgb_proba = self.xgb_model.predict_proba(obs.reshape(1, -1))[0, 1]\n        \n        # Compute feature contribution to reward (weighted by importance)\n        feature_contrib = np.abs(obs) * self.feature_weights\n        feature_score = feature_contrib.sum()\n        \n        # Updated reward function\n        if pred == true_label:\n            reward = (\n                150.0 * xgb_proba * (1 + 0.1 * feature_score) if true_label == 1 else\n                2.0 * (1 - xgb_proba) * (1 + 0.05 * feature_score)\n            )\n        else:\n            reward = (\n                -15.0 * (1 - xgb_proba) * (1 + 0.1 * feature_score) if pred == 1 else\n                -8.0 * xgb_proba * (1 + 0.1 * feature_score)\n            )\n        \n        reward = float(reward)\n        \n        # Track FP rate for threshold adjustment\n        if pred == 1 and true_label == 0:\n            self.fp_count += 1\n        self.total_preds += 1\n        \n        self.current_step += 1\n        done = self.current_step >= len(self.current_data['X'])\n        truncated = False\n        info = {\"user_id\": self.current_user}\n        \n        if done:\n            obs, _ = self.reset()\n        else:\n            obs = self.current_data['X'][self.current_step]\n        \n        return obs, reward, done, truncated, info\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:45:56.319459Z","iopub.execute_input":"2025-05-07T05:45:56.319723Z","iopub.status.idle":"2025-05-07T05:45:56.330134Z","shell.execute_reply.started":"2025-05-07T05:45:56.319703Z","shell.execute_reply":"2025-05-07T05:45:56.329341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"env = AnomalyDetectionEnv(\n    user_data_dict,\n    xgb_model,\n    feature_importance_weights,\n    oversample_ratio=0.4\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:46:05.439670Z","iopub.execute_input":"2025-05-07T05:46:05.440205Z","iopub.status.idle":"2025-05-07T05:46:05.449839Z","shell.execute_reply.started":"2025-05-07T05:46:05.440184Z","shell.execute_reply":"2025-05-07T05:46:05.449130Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training PPO...\")\nmodel = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs={\"net_arch\": [128, 128]},\n    learning_rate=1e-4,\n    n_steps=4096,\n    batch_size=128,\n    n_epochs=10,\n    gamma=0.99,\n    verbose=1\n)\nmodel.learn(total_timesteps=200000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T05:46:16.068421Z","iopub.execute_input":"2025-05-07T05:46:16.068977Z","iopub.status.idle":"2025-05-07T05:52:10.678764Z","shell.execute_reply.started":"2025-05-07T05:46:16.068956Z","shell.execute_reply":"2025-05-07T05:52:10.678026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model_curves(model, user_data_dict, n_eval_samples=10000):\n    predictions = []\n    true_labels = []\n    anomaly_scores = []\n    \n    # Sample users for evaluation\n    sampled_users = np.random.choice(\n        list(user_data_dict.keys()),\n        size=min(len(user_data_dict), n_eval_samples // 10),\n        replace=False\n    )\n    \n    for user in sampled_users:\n        data = user_data_dict[user]\n        for i in range(len(data['X'])):\n            obs = data['X'][i]\n            action, _ = model.predict(obs, deterministic=True)\n            true_label = data['y'][i]\n            threshold = data['thresholds'][i]\n            \n            pred = 1 if action[0] >= threshold else 0\n            \n            predictions.append(pred)\n            true_labels.append(true_label)\n            anomaly_scores.append(action[0])\n\n    # Metrics\n    precision = precision_score(true_labels, predictions, zero_division=0)\n    recall = recall_score(true_labels, predictions, zero_division=0)\n    f1 = f1_score(true_labels, predictions, zero_division=0)\n    auc_score = roc_auc_score(true_labels, anomaly_scores) if len(np.unique(true_labels)) > 1 else 0.0\n\n    # Compute FPR using confusion matrix\n    cm = confusion_matrix(true_labels, predictions)\n    tn, fp, fn, tp = cm.ravel()\n    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n\n    # Confusion matrix plot\n    plt.figure(figsize=(6, 4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n                xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # ROC curve\n    fpr_roc, tpr, _ = roc_curve(true_labels, anomaly_scores)\n    roc_auc = auc(fpr_roc, tpr)\n    plt.figure()\n    plt.plot(fpr_roc, tpr, label=f\"ROC curve (AUC = {roc_auc:.4f})\")\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curve\")\n    plt.legend(loc=\"best\")\n    plt.show()\n\n    # PR curve\n    precision_pr, recall_pr, _ = precision_recall_curve(true_labels, anomaly_scores)\n    plt.figure()\n    plt.plot(recall_pr, precision_pr, label=\"Precision-Recall curve\")\n    plt.xlabel(\"Recall\")\n    plt.ylabel(\"Precision\")\n    plt.title(\"Precision-Recall Curve\")\n    plt.legend(loc=\"best\")\n    plt.show()\n\n    # Print results\n    print(f\"Class balance: {np.mean(true_labels):.4f} anomalies\")\n    print(f\"Evaluation Metrics (n={len(predictions)} samples):\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"FPR: {fpr:.4f}\")\n    print(f\"AUC-ROC: {auc_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T06:08:53.656329Z","iopub.execute_input":"2025-05-07T06:08:53.657059Z","iopub.status.idle":"2025-05-07T06:08:53.668225Z","shell.execute_reply.started":"2025-05-07T06:08:53.657034Z","shell.execute_reply":"2025-05-07T06:08:53.667486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model_curves(model, user_data_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T06:08:59.647772Z","iopub.execute_input":"2025-05-07T06:08:59.648084Z","iopub.status.idle":"2025-05-07T06:12:10.845758Z","shell.execute_reply.started":"2025-05-07T06:08:59.648061Z","shell.execute_reply":"2025-05-07T06:12:10.844986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('xgboost-guided-ppo-improved')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T06:15:02.804613Z","iopub.execute_input":"2025-05-07T06:15:02.805215Z","iopub.status.idle":"2025-05-07T06:15:02.820839Z","shell.execute_reply.started":"2025-05-07T06:15:02.805189Z","shell.execute_reply":"2025-05-07T06:15:02.820254Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"improvement\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport gymnasium as gym\nfrom gymnasium import spaces\nfrom collections import defaultdict\n\nclass AnomalyDetectionEnv(gym.Env):\n    def __init__(self, user_data_dict, xgb_model, feature_weights, oversample_ratio=0.5):\n        super().__init__()\n        self.user_data_dict = user_data_dict\n        self.xgb_model = xgb_model\n        self.feature_weights = feature_weights\n        \n        # Observation space remains the same\n        self.observation_space = spaces.Box(\n            low=-np.inf,\n            high=np.inf,\n            shape=(len(feature_weights),),  # Use feature_weights length instead of all_features\n            dtype=np.float32\n        )\n        \n        self.action_space = spaces.Box(\n            low=0,\n            high=1,\n            shape=(1,),\n            dtype=np.float32\n        )\n        \n        # User management\n        self.all_users = list(user_data_dict.keys())\n        self.anomaly_users = [\n            user for user, data in user_data_dict.items()\n            if np.any(data['y'] == 1)\n        ]\n        self.oversample_ratio = oversample_ratio\n        \n        # Tracking state\n        self.current_user = None\n        self.current_data = None\n        self.current_step = 0\n        \n        # Adaptive threshold parameters\n        self.fp_count = 0\n        self.total_preds = 0\n        self.fp_tolerance = 0.05  # Target FP rate\n        self.threshold_adjustment_rate = 0.01  # How much to adjust thresholds\n        \n        # Reward hyperparameters\n        self.reward_weights = {\n            'tp': 150.0,    # True positive\n            'tn': 2.0,      # True negative\n            'fp': -15.0,    # False positive\n            'fn': -8.0      # False negative\n        }\n        \n        # Feature contribution scaling\n        self.feature_scale_anomaly = 0.1   # For anomaly rewards\n        self.feature_scale_normal = 0.05   # For normal rewards\n\n    def reset(self, seed=None, options=None):\n        if seed is not None:\n            np.random.seed(seed)\n        _ = options\n        \n        if self.anomaly_users and np.random.random() < self.oversample_ratio:\n            self.current_user = np.random.choice(self.anomaly_users)\n        else:\n            self.current_user = np.random.choice(self.all_users)\n        \n        self.current_data = self.user_data_dict[self.current_user]\n        self.current_step = 0\n        \n        # Initialize adaptive threshold if not present\n        if 'adaptive_threshold' not in self.current_data:\n            self.current_data['adaptive_threshold'] = np.mean(self.current_data['thresholds'])\n        \n        return self.current_data['X'][self.current_step], {}\n\n    def _calculate_reward(self, pred, true_label, xgb_proba, features):\n        \"\"\"Enhanced reward calculation with feature importance\"\"\"\n        feature_contrib = np.abs(features) * self.feature_weights\n        feature_score = feature_contrib.sum()\n        \n        if pred == true_label:\n            if true_label == 1:  # True positive\n                reward = (self.reward_weights['tp'] * xgb_proba * \n                         (1 + self.feature_scale_anomaly * feature_score))\n            else:  # True negative\n                reward = (self.reward_weights['tn'] * (1 - xgb_proba) * \n                         (1 + self.feature_scale_normal * feature_score))\n        else:\n            if pred == 1:  # False positive\n                reward = (self.reward_weights['fp'] * (1 - xgb_proba) * \n                         (1 + self.feature_scale_anomaly * feature_score))\n            else:  # False negative\n                reward = (self.reward_weights['fn'] * xgb_proba * \n                         (1 + self.feature_scale_anomaly * feature_score))\n        \n        return float(reward)\n\n    def _update_threshold(self):\n        \"\"\"Adaptively adjust threshold based on FP rate\"\"\"\n        if self.total_preds == 0:\n            return\n            \n        current_fp_rate = self.fp_count / self.total_preds\n        \n        if current_fp_rate > self.fp_tolerance:\n            # Too many FPs, increase threshold to be more conservative\n            self.current_data['adaptive_threshold'] += self.threshold_adjustment_rate\n            self.current_data['adaptive_threshold'] = min(self.current_data['adaptive_threshold'], 0.9)\n        else:\n            # Few FPs, can afford to be more sensitive\n            self.current_data['adaptive_threshold'] -= self.threshold_adjustment_rate * 0.5\n            self.current_data['adaptive_threshold'] = max(self.current_data['adaptive_threshold'], 0.1)\n        \n        # Reset counters\n        self.fp_count = 0\n        self.total_preds = 0\n\n    def step(self, action):\n        true_label = self.current_data['y'][self.current_step]\n        obs = self.current_data['X'][self.current_step]\n        \n        # Use adaptive threshold instead of fixed one\n        threshold = self.current_data['adaptive_threshold']\n        pred = 1 if action[0] >= threshold else 0\n        \n        # Get XGBoost probability\n        xgb_proba = self.xgb_model.predict_proba(obs.reshape(1, -1))[0, 1]\n        \n        # Calculate reward\n        reward = self._calculate_reward(pred, true_label, xgb_proba, obs)\n        \n        # Update FP tracking\n        if pred == 1 and true_label == 0:\n            self.fp_count += 1\n        self.total_preds += 1\n        \n        # Move to next step\n        self.current_step += 1\n        done = self.current_step >= len(self.current_data['X'])\n        truncated = False\n        \n        # Prepare info dict\n        info = {\n            \"user_id\": self.current_user,\n            \"threshold\": threshold,\n            \"prediction\": pred,\n            \"true_label\": true_label,\n            \"xgb_proba\": xgb_proba\n        }\n        \n        if done:\n            # Update threshold before next episode\n            self._update_threshold()\n            obs, _ = self.reset()\n        else:\n            obs = self.current_data['X'][self.current_step]\n        \n        return obs, reward, done, truncated, info\n\n    def get_current_threshold(self):\n        \"\"\"Get the current adaptive threshold\"\"\"\n        return self.current_data.get('adaptive_threshold', 0.5) if self.current_data else 0.5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:50:43.290601Z","iopub.execute_input":"2025-05-21T16:50:43.290911Z","iopub.status.idle":"2025-05-21T16:50:43.319104Z","shell.execute_reply.started":"2025-05-21T16:50:43.290887Z","shell.execute_reply":"2025-05-21T16:50:43.313007Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"import gym","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:50:45.587986Z","iopub.execute_input":"2025-05-21T16:50:45.588351Z","iopub.status.idle":"2025-05-21T16:50:45.598093Z","shell.execute_reply.started":"2025-05-21T16:50:45.588303Z","shell.execute_reply":"2025-05-21T16:50:45.593237Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# Example of creating the environment with custom hyperparameters\nenv = AnomalyDetectionEnv(\n    user_data_dict=user_data_dict,\n    xgb_model=xgb_model,\n    feature_weights=feature_importances,\n    oversample_ratio=0.4\n)\n\n# You can access and modify hyperparameters after creation:\nenv.fp_tolerance = 0.03  # Lower FP target\nenv.threshold_adjustment_rate = 0.02  # Faster adaptation\nenv.reward_weights = {\n    'tp': 200.0,  # Higher reward for true positives\n    'tn': 1.0,\n    'fp': -20.0,  # Stronger penalty for false positives\n    'fn': -10.0\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:52:35.169831Z","iopub.execute_input":"2025-05-21T16:52:35.170209Z","iopub.status.idle":"2025-05-21T16:52:35.189212Z","shell.execute_reply.started":"2025-05-21T16:52:35.170182Z","shell.execute_reply":"2025-05-21T16:52:35.184344Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model = PPO(\n    \"MlpPolicy\",\n    env,\n    policy_kwargs={\"net_arch\": [128, 128]},\n    learning_rate=1e-4,\n    n_steps=4096,\n    batch_size=128,\n    n_epochs=10,\n    gamma=0.99,\n    verbose=1\n)\nmodel.learn(total_timesteps=200000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T16:52:44.507809Z","iopub.execute_input":"2025-05-21T16:52:44.508109Z","iopub.status.idle":"2025-05-21T17:19:14.686746Z","shell.execute_reply.started":"2025-05-21T16:52:44.508085Z","shell.execute_reply":"2025-05-21T17:19:14.680933Z"}},"outputs":[{"name":"stdout","text":"Using cpu device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 291      |\n|    ep_rew_mean     | -447     |\n| time/              |          |\n|    fps             | 139      |\n|    iterations      | 1        |\n|    time_elapsed    | 29       |\n|    total_timesteps | 4096     |\n---------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 282         |\n|    ep_rew_mean          | -460        |\n| time/                   |             |\n|    fps                  | 132         |\n|    iterations           | 2           |\n|    time_elapsed         | 62          |\n|    total_timesteps      | 8192        |\n| train/                  |             |\n|    approx_kl            | 0.004413357 |\n|    clip_fraction        | 0.0193      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.41       |\n|    explained_variance   | -0.00136    |\n|    learning_rate        | 0.0001      |\n|    loss                 | 7.19e+03    |\n|    n_updates            | 10          |\n|    policy_gradient_loss | -0.0049     |\n|    std                  | 0.988       |\n|    value_loss           | 1.1e+04     |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 288          |\n|    ep_rew_mean          | -535         |\n| time/                   |              |\n|    fps                  | 130          |\n|    iterations           | 3            |\n|    time_elapsed         | 94           |\n|    total_timesteps      | 12288        |\n| train/                  |              |\n|    approx_kl            | 0.0049702255 |\n|    clip_fraction        | 0.0174       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.4         |\n|    explained_variance   | 0.0185       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 885          |\n|    n_updates            | 20           |\n|    policy_gradient_loss | -0.00475     |\n|    std                  | 0.977        |\n|    value_loss           | 5.59e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 288          |\n|    ep_rew_mean          | -521         |\n| time/                   |              |\n|    fps                  | 129          |\n|    iterations           | 4            |\n|    time_elapsed         | 126          |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0067050457 |\n|    clip_fraction        | 0.0389       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.39        |\n|    explained_variance   | 0.00197      |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.62e+03     |\n|    n_updates            | 30           |\n|    policy_gradient_loss | -0.00615     |\n|    std                  | 0.966        |\n|    value_loss           | 5.18e+03     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 287         |\n|    ep_rew_mean          | -466        |\n| time/                   |             |\n|    fps                  | 129         |\n|    iterations           | 5           |\n|    time_elapsed         | 158         |\n|    total_timesteps      | 20480       |\n| train/                  |             |\n|    approx_kl            | 0.005733438 |\n|    clip_fraction        | 0.0282      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.38       |\n|    explained_variance   | 0.0276      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.62e+03    |\n|    n_updates            | 40          |\n|    policy_gradient_loss | -0.00565    |\n|    std                  | 0.953       |\n|    value_loss           | 4.68e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 288          |\n|    ep_rew_mean          | -479         |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 6            |\n|    time_elapsed         | 190          |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0038756807 |\n|    clip_fraction        | 0.00977      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.37        |\n|    explained_variance   | 0.0601       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.84e+03     |\n|    n_updates            | 50           |\n|    policy_gradient_loss | -0.00453     |\n|    std                  | 0.945        |\n|    value_loss           | 1.28e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | -460         |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 7            |\n|    time_elapsed         | 223          |\n|    total_timesteps      | 28672        |\n| train/                  |              |\n|    approx_kl            | 0.0092047285 |\n|    clip_fraction        | 0.0704       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.35        |\n|    explained_variance   | 0.0486       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 532          |\n|    n_updates            | 60           |\n|    policy_gradient_loss | -0.0127      |\n|    std                  | 0.926        |\n|    value_loss           | 1.42e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | -413         |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 8            |\n|    time_elapsed         | 255          |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0054380847 |\n|    clip_fraction        | 0.0172       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.34        |\n|    explained_variance   | 0.0532       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.98e+03     |\n|    n_updates            | 70           |\n|    policy_gradient_loss | -0.00326     |\n|    std                  | 0.922        |\n|    value_loss           | 1.28e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 298          |\n|    ep_rew_mean          | -351         |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 9            |\n|    time_elapsed         | 287          |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0063589145 |\n|    clip_fraction        | 0.0435       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.33        |\n|    explained_variance   | 0.182        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.18e+03     |\n|    n_updates            | 80           |\n|    policy_gradient_loss | -0.00646     |\n|    std                  | 0.908        |\n|    value_loss           | 8.49e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | -218         |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 10           |\n|    time_elapsed         | 319          |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0024021883 |\n|    clip_fraction        | 0.00625      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.32        |\n|    explained_variance   | 0.123        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.8e+03      |\n|    n_updates            | 90           |\n|    policy_gradient_loss | -0.002       |\n|    std                  | 0.907        |\n|    value_loss           | 1.02e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | -199         |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 11           |\n|    time_elapsed         | 352          |\n|    total_timesteps      | 45056        |\n| train/                  |              |\n|    approx_kl            | 0.0016332678 |\n|    clip_fraction        | 0.00435      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.32        |\n|    explained_variance   | 0.104        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.62e+03     |\n|    n_updates            | 100          |\n|    policy_gradient_loss | -0.00269     |\n|    std                  | 0.903        |\n|    value_loss           | 1.9e+04      |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 294         |\n|    ep_rew_mean          | -137        |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 12          |\n|    time_elapsed         | 384         |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.008688366 |\n|    clip_fraction        | 0.05        |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.3        |\n|    explained_variance   | 0.0372      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.01e+03    |\n|    n_updates            | 110         |\n|    policy_gradient_loss | -0.00774    |\n|    std                  | 0.877       |\n|    value_loss           | 4.44e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | -58.7        |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 13           |\n|    time_elapsed         | 416          |\n|    total_timesteps      | 53248        |\n| train/                  |              |\n|    approx_kl            | 0.0012292636 |\n|    clip_fraction        | 0.00132      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.29        |\n|    explained_variance   | 0.122        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.84e+03     |\n|    n_updates            | 120          |\n|    policy_gradient_loss | -0.0013      |\n|    std                  | 0.874        |\n|    value_loss           | 1.08e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 290          |\n|    ep_rew_mean          | 2.66         |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 14           |\n|    time_elapsed         | 449          |\n|    total_timesteps      | 57344        |\n| train/                  |              |\n|    approx_kl            | 0.0020548431 |\n|    clip_fraction        | 0.00691      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.28        |\n|    explained_variance   | 0.21         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.65e+03     |\n|    n_updates            | 130          |\n|    policy_gradient_loss | -0.00463     |\n|    std                  | 0.867        |\n|    value_loss           | 1.19e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 287         |\n|    ep_rew_mean          | 35.9        |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 15          |\n|    time_elapsed         | 480         |\n|    total_timesteps      | 61440       |\n| train/                  |             |\n|    approx_kl            | 0.001685078 |\n|    clip_fraction        | 0.00437     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.27       |\n|    explained_variance   | 0.0274      |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.18e+03    |\n|    n_updates            | 140         |\n|    policy_gradient_loss | -0.00391    |\n|    std                  | 0.859       |\n|    value_loss           | 1.96e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 280         |\n|    ep_rew_mean          | -27.2       |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 16          |\n|    time_elapsed         | 513         |\n|    total_timesteps      | 65536       |\n| train/                  |             |\n|    approx_kl            | 0.006176506 |\n|    clip_fraction        | 0.0417      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.26       |\n|    explained_variance   | 0.269       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.1e+03     |\n|    n_updates            | 150         |\n|    policy_gradient_loss | -0.00705    |\n|    std                  | 0.85        |\n|    value_loss           | 6.1e+03     |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 285         |\n|    ep_rew_mean          | -44.7       |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 17          |\n|    time_elapsed         | 545         |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.006233193 |\n|    clip_fraction        | 0.0395      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.25       |\n|    explained_variance   | 0.141       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 581         |\n|    n_updates            | 160         |\n|    policy_gradient_loss | -0.00611    |\n|    std                  | 0.845       |\n|    value_loss           | 4.85e+03    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 284          |\n|    ep_rew_mean          | 37.9         |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 18           |\n|    time_elapsed         | 577          |\n|    total_timesteps      | 73728        |\n| train/                  |              |\n|    approx_kl            | 0.0040731225 |\n|    clip_fraction        | 0.0131       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.25        |\n|    explained_variance   | 0.15         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 9.51e+03     |\n|    n_updates            | 170          |\n|    policy_gradient_loss | -0.00186     |\n|    std                  | 0.841        |\n|    value_loss           | 2.33e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 286         |\n|    ep_rew_mean          | 20.9        |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 19          |\n|    time_elapsed         | 610         |\n|    total_timesteps      | 77824       |\n| train/                  |             |\n|    approx_kl            | 0.004578167 |\n|    clip_fraction        | 0.0277      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.24       |\n|    explained_variance   | 0.219       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.03e+04    |\n|    n_updates            | 180         |\n|    policy_gradient_loss | -0.0027     |\n|    std                  | 0.83        |\n|    value_loss           | 1.72e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 290          |\n|    ep_rew_mean          | 27           |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 20           |\n|    time_elapsed         | 642          |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0059836507 |\n|    clip_fraction        | 0.032        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.23        |\n|    explained_variance   | 0.252        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 951          |\n|    n_updates            | 190          |\n|    policy_gradient_loss | -0.00763     |\n|    std                  | 0.823        |\n|    value_loss           | 3.66e+03     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 85.4         |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 21           |\n|    time_elapsed         | 674          |\n|    total_timesteps      | 86016        |\n| train/                  |              |\n|    approx_kl            | 0.0034831194 |\n|    clip_fraction        | 0.015        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.22        |\n|    explained_variance   | 0.169        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.92e+03     |\n|    n_updates            | 200          |\n|    policy_gradient_loss | -0.00286     |\n|    std                  | 0.817        |\n|    value_loss           | 1.27e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 286          |\n|    ep_rew_mean          | 182          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 22           |\n|    time_elapsed         | 707          |\n|    total_timesteps      | 90112        |\n| train/                  |              |\n|    approx_kl            | 0.0030447645 |\n|    clip_fraction        | 0.00828      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.21        |\n|    explained_variance   | 0.142        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.91e+04     |\n|    n_updates            | 210          |\n|    policy_gradient_loss | -0.00318     |\n|    std                  | 0.81         |\n|    value_loss           | 4.12e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 287          |\n|    ep_rew_mean          | 341          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 23           |\n|    time_elapsed         | 739          |\n|    total_timesteps      | 94208        |\n| train/                  |              |\n|    approx_kl            | 0.0025917133 |\n|    clip_fraction        | 0.0101       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.21        |\n|    explained_variance   | 0.154        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.17e+04     |\n|    n_updates            | 220          |\n|    policy_gradient_loss | -0.00431     |\n|    std                  | 0.809        |\n|    value_loss           | 5.57e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 286          |\n|    ep_rew_mean          | 410          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 24           |\n|    time_elapsed         | 771          |\n|    total_timesteps      | 98304        |\n| train/                  |              |\n|    approx_kl            | 0.0016297124 |\n|    clip_fraction        | 0.00708      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.178        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.33e+03     |\n|    n_updates            | 230          |\n|    policy_gradient_loss | -0.00324     |\n|    std                  | 0.802        |\n|    value_loss           | 6.42e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 279          |\n|    ep_rew_mean          | 536          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 25           |\n|    time_elapsed         | 804          |\n|    total_timesteps      | 102400       |\n| train/                  |              |\n|    approx_kl            | 0.0012960136 |\n|    clip_fraction        | 0.00288      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.203        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.11e+04     |\n|    n_updates            | 240          |\n|    policy_gradient_loss | -0.00107     |\n|    std                  | 0.803        |\n|    value_loss           | 2.82e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 276          |\n|    ep_rew_mean          | 641          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 26           |\n|    time_elapsed         | 836          |\n|    total_timesteps      | 106496       |\n| train/                  |              |\n|    approx_kl            | 0.0021612938 |\n|    clip_fraction        | 0.00723      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.178        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.63e+04     |\n|    n_updates            | 250          |\n|    policy_gradient_loss | -0.0027      |\n|    std                  | 0.801        |\n|    value_loss           | 4.03e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 274          |\n|    ep_rew_mean          | 738          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 27           |\n|    time_elapsed         | 868          |\n|    total_timesteps      | 110592       |\n| train/                  |              |\n|    approx_kl            | 0.0012906794 |\n|    clip_fraction        | 0.00281      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.206        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.68e+04     |\n|    n_updates            | 260          |\n|    policy_gradient_loss | -0.00134     |\n|    std                  | 0.801        |\n|    value_loss           | 4.78e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 269          |\n|    ep_rew_mean          | 757          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 28           |\n|    time_elapsed         | 901          |\n|    total_timesteps      | 114688       |\n| train/                  |              |\n|    approx_kl            | 0.0012992265 |\n|    clip_fraction        | 0.00173      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.2         |\n|    explained_variance   | 0.174        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.71e+04     |\n|    n_updates            | 270          |\n|    policy_gradient_loss | -0.00114     |\n|    std                  | 0.801        |\n|    value_loss           | 5.74e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 278          |\n|    ep_rew_mean          | 631          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 29           |\n|    time_elapsed         | 933          |\n|    total_timesteps      | 118784       |\n| train/                  |              |\n|    approx_kl            | 0.0027161585 |\n|    clip_fraction        | 0.00676      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.19        |\n|    explained_variance   | 0.165        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.67e+04     |\n|    n_updates            | 280          |\n|    policy_gradient_loss | -0.00303     |\n|    std                  | 0.793        |\n|    value_loss           | 2.8e+04      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 281          |\n|    ep_rew_mean          | 578          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 30           |\n|    time_elapsed         | 965          |\n|    total_timesteps      | 122880       |\n| train/                  |              |\n|    approx_kl            | 0.0056332694 |\n|    clip_fraction        | 0.0302       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.18        |\n|    explained_variance   | 0.227        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.16e+04     |\n|    n_updates            | 290          |\n|    policy_gradient_loss | -0.00471     |\n|    std                  | 0.782        |\n|    value_loss           | 3.64e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 279          |\n|    ep_rew_mean          | 488          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 31           |\n|    time_elapsed         | 998          |\n|    total_timesteps      | 126976       |\n| train/                  |              |\n|    approx_kl            | 0.0042517125 |\n|    clip_fraction        | 0.0106       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.16        |\n|    explained_variance   | 0.475        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.83e+03     |\n|    n_updates            | 300          |\n|    policy_gradient_loss | -0.00249     |\n|    std                  | 0.769        |\n|    value_loss           | 6.4e+03      |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 283         |\n|    ep_rew_mean          | 465         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 32          |\n|    time_elapsed         | 1030        |\n|    total_timesteps      | 131072      |\n| train/                  |             |\n|    approx_kl            | 0.003058236 |\n|    clip_fraction        | 0.0221      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.15       |\n|    explained_variance   | 0.212       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 9.2e+03     |\n|    n_updates            | 310         |\n|    policy_gradient_loss | -0.00205    |\n|    std                  | 0.764       |\n|    value_loss           | 1.94e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 283          |\n|    ep_rew_mean          | 491          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 33           |\n|    time_elapsed         | 1062         |\n|    total_timesteps      | 135168       |\n| train/                  |              |\n|    approx_kl            | 0.0021142305 |\n|    clip_fraction        | 0.00923      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.15        |\n|    explained_variance   | 0.212        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.74e+04     |\n|    n_updates            | 320          |\n|    policy_gradient_loss | -0.00329     |\n|    std                  | 0.759        |\n|    value_loss           | 3.95e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 285         |\n|    ep_rew_mean          | 406         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 34          |\n|    time_elapsed         | 1094        |\n|    total_timesteps      | 139264      |\n| train/                  |             |\n|    approx_kl            | 0.002072078 |\n|    clip_fraction        | 0.00422     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.14       |\n|    explained_variance   | 0.184       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 3.76e+04    |\n|    n_updates            | 330         |\n|    policy_gradient_loss | -0.00176    |\n|    std                  | 0.76        |\n|    value_loss           | 4.59e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 285          |\n|    ep_rew_mean          | 431          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 35           |\n|    time_elapsed         | 1127         |\n|    total_timesteps      | 143360       |\n| train/                  |              |\n|    approx_kl            | 0.0021170548 |\n|    clip_fraction        | 0.0107       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 0.294        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.34e+03     |\n|    n_updates            | 340          |\n|    policy_gradient_loss | -0.00305     |\n|    std                  | 0.755        |\n|    value_loss           | 1.4e+04      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 281          |\n|    ep_rew_mean          | 492          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 36           |\n|    time_elapsed         | 1159         |\n|    total_timesteps      | 147456       |\n| train/                  |              |\n|    approx_kl            | 0.0020958385 |\n|    clip_fraction        | 0.0131       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 0.218        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.84e+04     |\n|    n_updates            | 350          |\n|    policy_gradient_loss | -0.0033      |\n|    std                  | 0.754        |\n|    value_loss           | 4.1e+04      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 282          |\n|    ep_rew_mean          | 684          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 37           |\n|    time_elapsed         | 1191         |\n|    total_timesteps      | 151552       |\n| train/                  |              |\n|    approx_kl            | 0.0012703517 |\n|    clip_fraction        | 0.00352      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.14        |\n|    explained_variance   | 0.0972       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.23e+05     |\n|    n_updates            | 360          |\n|    policy_gradient_loss | -0.00219     |\n|    std                  | 0.751        |\n|    value_loss           | 7.25e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 284          |\n|    ep_rew_mean          | 748          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 38           |\n|    time_elapsed         | 1224         |\n|    total_timesteps      | 155648       |\n| train/                  |              |\n|    approx_kl            | 0.0028711355 |\n|    clip_fraction        | 0.012        |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.13        |\n|    explained_variance   | 0.205        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.03e+04     |\n|    n_updates            | 370          |\n|    policy_gradient_loss | -0.004       |\n|    std                  | 0.75         |\n|    value_loss           | 9.63e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 287         |\n|    ep_rew_mean          | 670         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 39          |\n|    time_elapsed         | 1256        |\n|    total_timesteps      | 159744      |\n| train/                  |             |\n|    approx_kl            | 0.003372737 |\n|    clip_fraction        | 0.0194      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.13       |\n|    explained_variance   | 0.297       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.41e+04    |\n|    n_updates            | 380         |\n|    policy_gradient_loss | -0.00468    |\n|    std                  | 0.739       |\n|    value_loss           | 2.49e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 581          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 40           |\n|    time_elapsed         | 1288         |\n|    total_timesteps      | 163840       |\n| train/                  |              |\n|    approx_kl            | 0.0041928682 |\n|    clip_fraction        | 0.0196       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.12        |\n|    explained_variance   | 0.201        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.01e+03     |\n|    n_updates            | 390          |\n|    policy_gradient_loss | -0.00304     |\n|    std                  | 0.739        |\n|    value_loss           | 1.52e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 290         |\n|    ep_rew_mean          | 560         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 41          |\n|    time_elapsed         | 1321        |\n|    total_timesteps      | 167936      |\n| train/                  |             |\n|    approx_kl            | 0.005409422 |\n|    clip_fraction        | 0.0276      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.11       |\n|    explained_variance   | 0.185       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.49e+04    |\n|    n_updates            | 400         |\n|    policy_gradient_loss | -0.00294    |\n|    std                  | 0.733       |\n|    value_loss           | 3.1e+04     |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 292         |\n|    ep_rew_mean          | 582         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 42          |\n|    time_elapsed         | 1353        |\n|    total_timesteps      | 172032      |\n| train/                  |             |\n|    approx_kl            | 0.003533212 |\n|    clip_fraction        | 0.0212      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.1        |\n|    explained_variance   | 0.643       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 237         |\n|    n_updates            | 410         |\n|    policy_gradient_loss | -0.00375    |\n|    std                  | 0.722       |\n|    value_loss           | 1.77e+03    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 294         |\n|    ep_rew_mean          | 594         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 43          |\n|    time_elapsed         | 1385        |\n|    total_timesteps      | 176128      |\n| train/                  |             |\n|    approx_kl            | 0.002979906 |\n|    clip_fraction        | 0.0149      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.09       |\n|    explained_variance   | 0.277       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 2.2e+04     |\n|    n_updates            | 420         |\n|    policy_gradient_loss | -0.00284    |\n|    std                  | 0.717       |\n|    value_loss           | 4.27e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 288         |\n|    ep_rew_mean          | 499         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 44          |\n|    time_elapsed         | 1418        |\n|    total_timesteps      | 180224      |\n| train/                  |             |\n|    approx_kl            | 0.003128124 |\n|    clip_fraction        | 0.00942     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.08       |\n|    explained_variance   | 0.304       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 6.41e+03    |\n|    n_updates            | 430         |\n|    policy_gradient_loss | -0.00203    |\n|    std                  | 0.708       |\n|    value_loss           | 2.92e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 285          |\n|    ep_rew_mean          | 498          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 45           |\n|    time_elapsed         | 1450         |\n|    total_timesteps      | 184320       |\n| train/                  |              |\n|    approx_kl            | 0.0009596038 |\n|    clip_fraction        | 0.00588      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.07        |\n|    explained_variance   | 0.168        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 7.73e+03     |\n|    n_updates            | 440          |\n|    policy_gradient_loss | -0.0035      |\n|    std                  | 0.703        |\n|    value_loss           | 8.04e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 293         |\n|    ep_rew_mean          | 557         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 46          |\n|    time_elapsed         | 1482        |\n|    total_timesteps      | 188416      |\n| train/                  |             |\n|    approx_kl            | 0.003768248 |\n|    clip_fraction        | 0.0178      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 0.108       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.13e+04    |\n|    n_updates            | 450         |\n|    policy_gradient_loss | -0.00279    |\n|    std                  | 0.699       |\n|    value_loss           | 3.11e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 289         |\n|    ep_rew_mean          | 582         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 47          |\n|    time_elapsed         | 1514        |\n|    total_timesteps      | 192512      |\n| train/                  |             |\n|    approx_kl            | 0.005066273 |\n|    clip_fraction        | 0.0297      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.06       |\n|    explained_variance   | 0.213       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.86e+04    |\n|    n_updates            | 460         |\n|    policy_gradient_loss | -0.00343    |\n|    std                  | 0.695       |\n|    value_loss           | 3.66e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 290          |\n|    ep_rew_mean          | 821          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 48           |\n|    time_elapsed         | 1547         |\n|    total_timesteps      | 196608       |\n| train/                  |              |\n|    approx_kl            | 0.0026485915 |\n|    clip_fraction        | 0.0104       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.05        |\n|    explained_variance   | 0.271        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.15e+04     |\n|    n_updates            | 470          |\n|    policy_gradient_loss | -0.00204     |\n|    std                  | 0.694        |\n|    value_loss           | 3.23e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 286          |\n|    ep_rew_mean          | 828          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 49           |\n|    time_elapsed         | 1579         |\n|    total_timesteps      | 200704       |\n| train/                  |              |\n|    approx_kl            | 0.0017536171 |\n|    clip_fraction        | 0.00527      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.05        |\n|    explained_variance   | 0.2          |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.4e+04      |\n|    n_updates            | 480          |\n|    policy_gradient_loss | -0.00271     |\n|    std                  | 0.692        |\n|    value_loss           | 1.07e+05     |\n------------------------------------------\n","output_type":"stream"},{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7aa5e5f3e2c0>"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"model.save(\"ppo_anomaly_detector_xgb_role2.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:23:57.225129Z","iopub.execute_input":"2025-05-21T17:23:57.225857Z","iopub.status.idle":"2025-05-21T17:23:57.250331Z","shell.execute_reply.started":"2025-05-21T17:23:57.225828Z","shell.execute_reply":"2025-05-21T17:23:57.244569Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"# Check final threshold\nprint(\"Final threshold:\", env.get_current_threshold())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:24:04.273547Z","iopub.execute_input":"2025-05-21T17:24:04.273842Z","iopub.status.idle":"2025-05-21T17:24:04.282984Z","shell.execute_reply.started":"2025-05-21T17:24:04.273818Z","shell.execute_reply":"2025-05-21T17:24:04.278117Z"}},"outputs":[{"name":"stdout","text":"Final threshold: 0.9\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"def evaluate_model(model, env, n_episodes=100):\n    \"\"\"\n    Simplified evaluation function for your anomaly detection model\n    \n    Args:\n        model: Your trained PPO model\n        env: Your AnomalyDetectionEnv instance\n        n_episodes: Number of evaluation episodes\n    \"\"\"\n    true_labels = []\n    predictions = []\n    anomaly_scores = []\n    \n    for _ in range(n_episodes):\n        obs, _ = env.reset()\n        done = False\n        \n        while not done:\n            action, _ = model.predict(obs, deterministic=True)\n            \n            # Get the current adaptive threshold\n            current_threshold = env.get_current_threshold()\n            \n            # Store predictions and labels\n            true_label = env.current_data['y'][env.current_step]\n            pred = 1 if action[0] >= current_threshold else 0\n            \n            true_labels.append(true_label)\n            predictions.append(pred)\n            anomaly_scores.append(action[0])\n            \n            # Step through environment\n            obs, _, done, _, _ = env.step(action)\n    \n    # Calculate metrics\n    precision = precision_score(true_labels, predictions, zero_division=0)\n    recall = recall_score(true_labels, predictions, zero_division=0)\n    f1 = f1_score(true_labels, predictions, zero_division=0)\n    \n    # Confusion Matrix with numbers\n    cm = confusion_matrix(true_labels, predictions)\n    plt.figure(figsize=(6,4))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n                xticklabels=['Normal', 'Anomaly'], \n                yticklabels=['Normal', 'Anomaly'])\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.show()\n    \n    # ROC Curve (if anomalies exist)\n    if sum(true_labels) > 0:\n        fpr, tpr, _ = roc_curve(true_labels, anomaly_scores)\n        roc_auc = auc(fpr, tpr)\n        \n        plt.figure()\n        plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc:.2f})')\n        plt.plot([0,1], [0,1], 'k--')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('ROC Curve')\n        plt.legend()\n        plt.show()\n    \n    print(\"\\nEvaluation Results:\")\n    print(f\"Total samples: {len(true_labels)}\")\n    print(f\"Anomaly rate: {np.mean(true_labels):.2%}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:36:50.404902Z","iopub.execute_input":"2025-05-21T17:36:50.405269Z","iopub.status.idle":"2025-05-21T17:36:50.424527Z","shell.execute_reply.started":"2025-05-21T17:36:50.405241Z","shell.execute_reply":"2025-05-21T17:36:50.418462Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"evaluate_model(model, env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:36:51.319583Z","iopub.execute_input":"2025-05-21T17:36:51.319926Z","iopub.status.idle":"2025-05-21T17:39:58.328442Z","shell.execute_reply.started":"2025-05-21T17:36:51.319897Z","shell.execute_reply":"2025-05-21T17:39:58.323163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nEvaluation Results:\nTotal samples: 28720\nAnomaly rate: 3.35%\nPrecision: 0.5764\nRecall: 0.5489\nF1 Score: 0.5623\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"model.learn(total_timesteps=100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:41:53.718203Z","iopub.execute_input":"2025-05-21T17:41:53.718602Z","iopub.status.idle":"2025-05-21T17:55:20.912509Z","shell.execute_reply.started":"2025-05-21T17:41:53.718572Z","shell.execute_reply":"2025-05-21T17:55:20.908264Z"}},"outputs":[{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 287      |\n|    ep_rew_mean     | 1.87e+03 |\n| time/              |          |\n|    fps             | 142      |\n|    iterations      | 1        |\n|    time_elapsed    | 28       |\n|    total_timesteps | 4096     |\n---------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 283           |\n|    ep_rew_mean          | 1.21e+03      |\n| time/                   |               |\n|    fps                  | 133           |\n|    iterations           | 2             |\n|    time_elapsed         | 61            |\n|    total_timesteps      | 8192          |\n| train/                  |               |\n|    approx_kl            | 0.00060938287 |\n|    clip_fraction        | 9.77e-05      |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -1.04         |\n|    explained_variance   | 0.135         |\n|    learning_rate        | 0.0001        |\n|    loss                 | 1.43e+05      |\n|    n_updates            | 500           |\n|    policy_gradient_loss | -0.000848     |\n|    std                  | 0.687         |\n|    value_loss           | 1.32e+05      |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | 881          |\n| time/                   |              |\n|    fps                  | 131          |\n|    iterations           | 3            |\n|    time_elapsed         | 93           |\n|    total_timesteps      | 12288        |\n| train/                  |              |\n|    approx_kl            | 0.0026557061 |\n|    clip_fraction        | 0.00989      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.04        |\n|    explained_variance   | 0.308        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 9.85e+03     |\n|    n_updates            | 510          |\n|    policy_gradient_loss | -0.003       |\n|    std                  | 0.682        |\n|    value_loss           | 4.18e+04     |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 296        |\n|    ep_rew_mean          | 929        |\n| time/                   |            |\n|    fps                  | 130        |\n|    iterations           | 4          |\n|    time_elapsed         | 125        |\n|    total_timesteps      | 16384      |\n| train/                  |            |\n|    approx_kl            | 0.00405591 |\n|    clip_fraction        | 0.0322     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -1.03      |\n|    explained_variance   | 0.816      |\n|    learning_rate        | 0.0001     |\n|    loss                 | 178        |\n|    n_updates            | 520        |\n|    policy_gradient_loss | -0.00605   |\n|    std                  | 0.677      |\n|    value_loss           | 631        |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 822          |\n| time/                   |              |\n|    fps                  | 129          |\n|    iterations           | 5            |\n|    time_elapsed         | 158          |\n|    total_timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0018609515 |\n|    clip_fraction        | 0.00657      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.03        |\n|    explained_variance   | 0.258        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5e+04        |\n|    n_updates            | 530          |\n|    policy_gradient_loss | -0.00266     |\n|    std                  | 0.674        |\n|    value_loss           | 6.8e+04      |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 287          |\n|    ep_rew_mean          | 946          |\n| time/                   |              |\n|    fps                  | 129          |\n|    iterations           | 6            |\n|    time_elapsed         | 190          |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0022397167 |\n|    clip_fraction        | 0.00654      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.03        |\n|    explained_variance   | 0.262        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.23e+04     |\n|    n_updates            | 540          |\n|    policy_gradient_loss | -0.00191     |\n|    std                  | 0.675        |\n|    value_loss           | 2.27e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 282          |\n|    ep_rew_mean          | 967          |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 7            |\n|    time_elapsed         | 222          |\n|    total_timesteps      | 28672        |\n| train/                  |              |\n|    approx_kl            | 0.0009499581 |\n|    clip_fraction        | 0.000684     |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.02        |\n|    explained_variance   | 0.179        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.77e+04     |\n|    n_updates            | 550          |\n|    policy_gradient_loss | -0.000797    |\n|    std                  | 0.672        |\n|    value_loss           | 1.06e+05     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 283          |\n|    ep_rew_mean          | 882          |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 8            |\n|    time_elapsed         | 255          |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0013491695 |\n|    clip_fraction        | 0.00281      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.02        |\n|    explained_variance   | 0.193        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.07e+04     |\n|    n_updates            | 560          |\n|    policy_gradient_loss | -0.00183     |\n|    std                  | 0.666        |\n|    value_loss           | 8.27e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 288          |\n|    ep_rew_mean          | 872          |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 9            |\n|    time_elapsed         | 287          |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0023051854 |\n|    clip_fraction        | 0.00793      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.01        |\n|    explained_variance   | 0.215        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.1e+04      |\n|    n_updates            | 570          |\n|    policy_gradient_loss | -0.00213     |\n|    std                  | 0.665        |\n|    value_loss           | 6.75e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 283          |\n|    ep_rew_mean          | 1e+03        |\n| time/                   |              |\n|    fps                  | 128          |\n|    iterations           | 10           |\n|    time_elapsed         | 319          |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0047461223 |\n|    clip_fraction        | 0.0259       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -1.01        |\n|    explained_variance   | 0.415        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 846          |\n|    n_updates            | 580          |\n|    policy_gradient_loss | -0.00339     |\n|    std                  | 0.664        |\n|    value_loss           | 2.01e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 287         |\n|    ep_rew_mean          | 914         |\n| time/                   |             |\n|    fps                  | 128         |\n|    iterations           | 11          |\n|    time_elapsed         | 351         |\n|    total_timesteps      | 45056       |\n| train/                  |             |\n|    approx_kl            | 0.002105214 |\n|    clip_fraction        | 0.00715     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1.01       |\n|    explained_variance   | 0.177       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.07e+04    |\n|    n_updates            | 590         |\n|    policy_gradient_loss | -0.00158    |\n|    std                  | 0.66        |\n|    value_loss           | 7.6e+04     |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 287         |\n|    ep_rew_mean          | 1.01e+03    |\n| time/                   |             |\n|    fps                  | 128         |\n|    iterations           | 12          |\n|    time_elapsed         | 383         |\n|    total_timesteps      | 49152       |\n| train/                  |             |\n|    approx_kl            | 0.002837205 |\n|    clip_fraction        | 0.00774     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -1          |\n|    explained_variance   | 0.206       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.43e+04    |\n|    n_updates            | 600         |\n|    policy_gradient_loss | -0.00138    |\n|    std                  | 0.657       |\n|    value_loss           | 2.64e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 290         |\n|    ep_rew_mean          | 919         |\n| time/                   |             |\n|    fps                  | 128         |\n|    iterations           | 13          |\n|    time_elapsed         | 415         |\n|    total_timesteps      | 53248       |\n| train/                  |             |\n|    approx_kl            | 0.002028081 |\n|    clip_fraction        | 0.0083      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.999      |\n|    explained_variance   | 0.164       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.84e+04    |\n|    n_updates            | 610         |\n|    policy_gradient_loss | -0.00177    |\n|    std                  | 0.656       |\n|    value_loss           | 4.19e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | 797          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 14           |\n|    time_elapsed         | 448          |\n|    total_timesteps      | 57344        |\n| train/                  |              |\n|    approx_kl            | 0.0024897922 |\n|    clip_fraction        | 0.00659      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.994       |\n|    explained_variance   | 0.267        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.36e+04     |\n|    n_updates            | 620          |\n|    policy_gradient_loss | -0.00149     |\n|    std                  | 0.651        |\n|    value_loss           | 4.23e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 296         |\n|    ep_rew_mean          | 712         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 15          |\n|    time_elapsed         | 480         |\n|    total_timesteps      | 61440       |\n| train/                  |             |\n|    approx_kl            | 0.002627816 |\n|    clip_fraction        | 0.00918     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.988      |\n|    explained_variance   | 0.428       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.17e+04    |\n|    n_updates            | 630         |\n|    policy_gradient_loss | -0.00282    |\n|    std                  | 0.647       |\n|    value_loss           | 1.6e+04     |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 727          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 16           |\n|    time_elapsed         | 512          |\n|    total_timesteps      | 65536        |\n| train/                  |              |\n|    approx_kl            | 0.0040345476 |\n|    clip_fraction        | 0.0222       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.982       |\n|    explained_variance   | 0.487        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.46e+03     |\n|    n_updates            | 640          |\n|    policy_gradient_loss | -0.00322     |\n|    std                  | 0.644        |\n|    value_loss           | 1.35e+04     |\n------------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 294        |\n|    ep_rew_mean          | 711        |\n| time/                   |            |\n|    fps                  | 127        |\n|    iterations           | 17         |\n|    time_elapsed         | 545        |\n|    total_timesteps      | 69632      |\n| train/                  |            |\n|    approx_kl            | 0.00438089 |\n|    clip_fraction        | 0.0233     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.978     |\n|    explained_variance   | 0.276      |\n|    learning_rate        | 0.0001     |\n|    loss                 | 7.15e+03   |\n|    n_updates            | 650        |\n|    policy_gradient_loss | -0.00409   |\n|    std                  | 0.642      |\n|    value_loss           | 2.08e+04   |\n----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 291          |\n|    ep_rew_mean          | 752          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 18           |\n|    time_elapsed         | 578          |\n|    total_timesteps      | 73728        |\n| train/                  |              |\n|    approx_kl            | 0.0022900095 |\n|    clip_fraction        | 0.00767      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.975       |\n|    explained_variance   | 0.164        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.99e+04     |\n|    n_updates            | 660          |\n|    policy_gradient_loss | -0.0023      |\n|    std                  | 0.64         |\n|    value_loss           | 4.32e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 285          |\n|    ep_rew_mean          | 760          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 19           |\n|    time_elapsed         | 610          |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0023425051 |\n|    clip_fraction        | 0.00859      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.972       |\n|    explained_variance   | 0.187        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.95e+03     |\n|    n_updates            | 670          |\n|    policy_gradient_loss | -0.00373     |\n|    std                  | 0.636        |\n|    value_loss           | 5e+04        |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 288         |\n|    ep_rew_mean          | 707         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 20          |\n|    time_elapsed         | 642         |\n|    total_timesteps      | 81920       |\n| train/                  |             |\n|    approx_kl            | 0.001970572 |\n|    clip_fraction        | 0.00603     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.965      |\n|    explained_variance   | 0.232       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 4.79e+04    |\n|    n_updates            | 680         |\n|    policy_gradient_loss | -0.00283    |\n|    std                  | 0.633       |\n|    value_loss           | 5.87e+04    |\n-----------------------------------------\n----------------------------------------\n| rollout/                |            |\n|    ep_len_mean          | 290        |\n|    ep_rew_mean          | 775        |\n| time/                   |            |\n|    fps                  | 127        |\n|    iterations           | 21         |\n|    time_elapsed         | 674        |\n|    total_timesteps      | 86016      |\n| train/                  |            |\n|    approx_kl            | 0.00248218 |\n|    clip_fraction        | 0.0105     |\n|    clip_range           | 0.2        |\n|    entropy_loss         | -0.958     |\n|    explained_variance   | 0.422      |\n|    learning_rate        | 0.0001     |\n|    loss                 | 1.22e+04   |\n|    n_updates            | 690        |\n|    policy_gradient_loss | -0.00207   |\n|    std                  | 0.629      |\n|    value_loss           | 1.09e+04   |\n----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 287         |\n|    ep_rew_mean          | 916         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 22          |\n|    time_elapsed         | 707         |\n|    total_timesteps      | 90112       |\n| train/                  |             |\n|    approx_kl            | 0.001881194 |\n|    clip_fraction        | 0.00461     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.955      |\n|    explained_variance   | 0.193       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.04e+05    |\n|    n_updates            | 700         |\n|    policy_gradient_loss | -0.00203    |\n|    std                  | 0.629       |\n|    value_loss           | 7.25e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 290          |\n|    ep_rew_mean          | 915          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 23           |\n|    time_elapsed         | 739          |\n|    total_timesteps      | 94208        |\n| train/                  |              |\n|    approx_kl            | 0.0011580926 |\n|    clip_fraction        | 0.0042       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.953       |\n|    explained_variance   | 0.18         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.41e+04     |\n|    n_updates            | 710          |\n|    policy_gradient_loss | -0.00118     |\n|    std                  | 0.625        |\n|    value_loss           | 8.68e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 296         |\n|    ep_rew_mean          | 897         |\n| time/                   |             |\n|    fps                  | 127         |\n|    iterations           | 24          |\n|    time_elapsed         | 771         |\n|    total_timesteps      | 98304       |\n| train/                  |             |\n|    approx_kl            | 0.003529659 |\n|    clip_fraction        | 0.0161      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.945      |\n|    explained_variance   | 0.324       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.43e+04    |\n|    n_updates            | 720         |\n|    policy_gradient_loss | -0.00532    |\n|    std                  | 0.619       |\n|    value_loss           | 2.95e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 947          |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 25           |\n|    time_elapsed         | 803          |\n|    total_timesteps      | 102400       |\n| train/                  |              |\n|    approx_kl            | 0.0021590956 |\n|    clip_fraction        | 0.00813      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.935       |\n|    explained_variance   | 0.282        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 341          |\n|    n_updates            | 730          |\n|    policy_gradient_loss | -0.00171     |\n|    std                  | 0.613        |\n|    value_loss           | 3.4e+04      |\n------------------------------------------\n","output_type":"stream"},{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7aa5e5f3e2c0>"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"model.save(\"ppo_anomaly_detector_xgb_role2_300000steps.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:58:37.423585Z","iopub.execute_input":"2025-05-21T17:58:37.423876Z","iopub.status.idle":"2025-05-21T17:58:37.445278Z","shell.execute_reply.started":"2025-05-21T17:58:37.423851Z","shell.execute_reply":"2025-05-21T17:58:37.440529Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"evaluate_model(model,env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T17:58:55.974286Z","iopub.execute_input":"2025-05-21T17:58:55.974580Z","iopub.status.idle":"2025-05-21T18:01:58.620354Z","shell.execute_reply.started":"2025-05-21T17:58:55.974556Z","shell.execute_reply":"2025-05-21T18:01:58.616998Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 600x400 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nEvaluation Results:\nTotal samples: 27944\nAnomaly rate: 2.82%\nPrecision: 0.3920\nRecall: 0.6717\nF1 Score: 0.4951\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"model.learn(total_timesteps=100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:16:54.487964Z","iopub.execute_input":"2025-05-21T18:16:54.488325Z","iopub.status.idle":"2025-05-21T18:31:12.026557Z","shell.execute_reply.started":"2025-05-21T18:16:54.488280Z","shell.execute_reply":"2025-05-21T18:31:12.022119Z"}},"outputs":[{"name":"stdout","text":"---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 235      |\n|    ep_rew_mean     | 1.39e+03 |\n| time/              |          |\n|    fps             | 140      |\n|    iterations      | 1        |\n|    time_elapsed    | 29       |\n|    total_timesteps | 4096     |\n---------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 271          |\n|    ep_rew_mean          | 1.18e+03     |\n| time/                   |              |\n|    fps                  | 130          |\n|    iterations           | 2            |\n|    time_elapsed         | 62           |\n|    total_timesteps      | 8192         |\n| train/                  |              |\n|    approx_kl            | 0.0014150897 |\n|    clip_fraction        | 0.00754      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.925       |\n|    explained_variance   | 0.151        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.44e+04     |\n|    n_updates            | 750          |\n|    policy_gradient_loss | -0.00407     |\n|    std                  | 0.609        |\n|    value_loss           | 1.13e+05     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 272          |\n|    ep_rew_mean          | 1.11e+03     |\n| time/                   |              |\n|    fps                  | 127          |\n|    iterations           | 3            |\n|    time_elapsed         | 96           |\n|    total_timesteps      | 12288        |\n| train/                  |              |\n|    approx_kl            | 0.0013334947 |\n|    clip_fraction        | 0.00398      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.923       |\n|    explained_variance   | 0.222        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.1e+03      |\n|    n_updates            | 760          |\n|    policy_gradient_loss | -0.00101     |\n|    std                  | 0.609        |\n|    value_loss           | 4.79e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 275          |\n|    ep_rew_mean          | 1.13e+03     |\n| time/                   |              |\n|    fps                  | 124          |\n|    iterations           | 4            |\n|    time_elapsed         | 131          |\n|    total_timesteps      | 16384        |\n| train/                  |              |\n|    approx_kl            | 0.0024490603 |\n|    clip_fraction        | 0.00437      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.92        |\n|    explained_variance   | 0.296        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 4.49e+04     |\n|    n_updates            | 770          |\n|    policy_gradient_loss | -0.0015      |\n|    std                  | 0.605        |\n|    value_loss           | 3.92e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 276          |\n|    ep_rew_mean          | 996          |\n| time/                   |              |\n|    fps                  | 123          |\n|    iterations           | 5            |\n|    time_elapsed         | 165          |\n|    total_timesteps      | 20480        |\n| train/                  |              |\n|    approx_kl            | 0.0016843963 |\n|    clip_fraction        | 0.00325      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.917       |\n|    explained_variance   | 0.174        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 8.84e+04     |\n|    n_updates            | 780          |\n|    policy_gradient_loss | -0.00222     |\n|    std                  | 0.604        |\n|    value_loss           | 8.74e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 282          |\n|    ep_rew_mean          | 909          |\n| time/                   |              |\n|    fps                  | 123          |\n|    iterations           | 6            |\n|    time_elapsed         | 199          |\n|    total_timesteps      | 24576        |\n| train/                  |              |\n|    approx_kl            | 0.0022466925 |\n|    clip_fraction        | 0.00632      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.912       |\n|    explained_variance   | 0.386        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 7.82e+03     |\n|    n_updates            | 790          |\n|    policy_gradient_loss | -0.00173     |\n|    std                  | 0.6          |\n|    value_loss           | 1.82e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 282         |\n|    ep_rew_mean          | 1.05e+03    |\n| time/                   |             |\n|    fps                  | 122         |\n|    iterations           | 7           |\n|    time_elapsed         | 234         |\n|    total_timesteps      | 28672       |\n| train/                  |             |\n|    approx_kl            | 0.004532134 |\n|    clip_fraction        | 0.0275      |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.907      |\n|    explained_variance   | 0.431       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.08e+04    |\n|    n_updates            | 800         |\n|    policy_gradient_loss | -0.0026     |\n|    std                  | 0.597       |\n|    value_loss           | 2.13e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 1.05e+03     |\n| time/                   |              |\n|    fps                  | 121          |\n|    iterations           | 8            |\n|    time_elapsed         | 268          |\n|    total_timesteps      | 32768        |\n| train/                  |              |\n|    approx_kl            | 0.0035197358 |\n|    clip_fraction        | 0.0132       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.903       |\n|    explained_variance   | 0.23         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.05e+05     |\n|    n_updates            | 810          |\n|    policy_gradient_loss | -0.00226     |\n|    std                  | 0.597        |\n|    value_loss           | 1.57e+05     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 295          |\n|    ep_rew_mean          | 1.01e+03     |\n| time/                   |              |\n|    fps                  | 121          |\n|    iterations           | 9            |\n|    time_elapsed         | 303          |\n|    total_timesteps      | 36864        |\n| train/                  |              |\n|    approx_kl            | 0.0034596892 |\n|    clip_fraction        | 0.0191       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.899       |\n|    explained_variance   | 0.251        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3e+04        |\n|    n_updates            | 820          |\n|    policy_gradient_loss | -0.00355     |\n|    std                  | 0.593        |\n|    value_loss           | 5.95e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 297          |\n|    ep_rew_mean          | 1.01e+03     |\n| time/                   |              |\n|    fps                  | 121          |\n|    iterations           | 10           |\n|    time_elapsed         | 338          |\n|    total_timesteps      | 40960        |\n| train/                  |              |\n|    approx_kl            | 0.0031984355 |\n|    clip_fraction        | 0.0164       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.894       |\n|    explained_variance   | 0.369        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.13e+04     |\n|    n_updates            | 830          |\n|    policy_gradient_loss | -0.00363     |\n|    std                  | 0.589        |\n|    value_loss           | 2.14e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 298          |\n|    ep_rew_mean          | 1.02e+03     |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 11           |\n|    time_elapsed         | 372          |\n|    total_timesteps      | 45056        |\n| train/                  |              |\n|    approx_kl            | 0.0022961064 |\n|    clip_fraction        | 0.00933      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.885       |\n|    explained_variance   | 0.273        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.2e+04      |\n|    n_updates            | 840          |\n|    policy_gradient_loss | -0.00268     |\n|    std                  | 0.583        |\n|    value_loss           | 6.66e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 301          |\n|    ep_rew_mean          | 1.1e+03      |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 12           |\n|    time_elapsed         | 407          |\n|    total_timesteps      | 49152        |\n| train/                  |              |\n|    approx_kl            | 0.0015620748 |\n|    clip_fraction        | 0.00618      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.877       |\n|    explained_variance   | 0.0963       |\n|    learning_rate        | 0.0001       |\n|    loss                 | 5.88e+04     |\n|    n_updates            | 850          |\n|    policy_gradient_loss | -0.00189     |\n|    std                  | 0.579        |\n|    value_loss           | 1.02e+05     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 292          |\n|    ep_rew_mean          | 1.22e+03     |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 13           |\n|    time_elapsed         | 441          |\n|    total_timesteps      | 53248        |\n| train/                  |              |\n|    approx_kl            | 0.0031038553 |\n|    clip_fraction        | 0.00847      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.87        |\n|    explained_variance   | 0.326        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 3.45e+04     |\n|    n_updates            | 860          |\n|    policy_gradient_loss | -0.0031      |\n|    std                  | 0.576        |\n|    value_loss           | 5.49e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 301          |\n|    ep_rew_mean          | 1.02e+03     |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 14           |\n|    time_elapsed         | 475          |\n|    total_timesteps      | 57344        |\n| train/                  |              |\n|    approx_kl            | 0.0026546041 |\n|    clip_fraction        | 0.00798      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.863       |\n|    explained_variance   | 0.203        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 9.26e+04     |\n|    n_updates            | 870          |\n|    policy_gradient_loss | -0.00203     |\n|    std                  | 0.57         |\n|    value_loss           | 8.31e+04     |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 297         |\n|    ep_rew_mean          | 870         |\n| time/                   |             |\n|    fps                  | 120         |\n|    iterations           | 15          |\n|    time_elapsed         | 509         |\n|    total_timesteps      | 61440       |\n| train/                  |             |\n|    approx_kl            | 0.003407325 |\n|    clip_fraction        | 0.011       |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.855      |\n|    explained_variance   | 0.483       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 1.26e+04    |\n|    n_updates            | 880         |\n|    policy_gradient_loss | -0.00214    |\n|    std                  | 0.567       |\n|    value_loss           | 1.62e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 294          |\n|    ep_rew_mean          | 927          |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 16           |\n|    time_elapsed         | 544          |\n|    total_timesteps      | 65536        |\n| train/                  |              |\n|    approx_kl            | 0.0031634397 |\n|    clip_fraction        | 0.0151       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.851       |\n|    explained_variance   | 0.564        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.31e+03     |\n|    n_updates            | 890          |\n|    policy_gradient_loss | -0.00267     |\n|    std                  | 0.567        |\n|    value_loss           | 6.9e+03      |\n------------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 291         |\n|    ep_rew_mean          | 1.02e+03    |\n| time/                   |             |\n|    fps                  | 120         |\n|    iterations           | 17          |\n|    time_elapsed         | 578         |\n|    total_timesteps      | 69632       |\n| train/                  |             |\n|    approx_kl            | 0.001309034 |\n|    clip_fraction        | 0.00366     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.85       |\n|    explained_variance   | 0.307       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 5.11e+03    |\n|    n_updates            | 900         |\n|    policy_gradient_loss | -0.00148    |\n|    std                  | 0.565       |\n|    value_loss           | 4.17e+04    |\n-----------------------------------------\n-----------------------------------------\n| rollout/                |             |\n|    ep_len_mean          | 292         |\n|    ep_rew_mean          | 947         |\n| time/                   |             |\n|    fps                  | 120         |\n|    iterations           | 18          |\n|    time_elapsed         | 613         |\n|    total_timesteps      | 73728       |\n| train/                  |             |\n|    approx_kl            | 0.002054818 |\n|    clip_fraction        | 0.00784     |\n|    clip_range           | 0.2         |\n|    entropy_loss         | -0.844      |\n|    explained_variance   | 0.338       |\n|    learning_rate        | 0.0001      |\n|    loss                 | 8.62e+03    |\n|    n_updates            | 910         |\n|    policy_gradient_loss | -0.00161    |\n|    std                  | 0.561       |\n|    value_loss           | 5.18e+04    |\n-----------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 904          |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 19           |\n|    time_elapsed         | 647          |\n|    total_timesteps      | 77824        |\n| train/                  |              |\n|    approx_kl            | 0.0029435116 |\n|    clip_fraction        | 0.0179       |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.838       |\n|    explained_variance   | 0.31         |\n|    learning_rate        | 0.0001       |\n|    loss                 | 8.55e+03     |\n|    n_updates            | 920          |\n|    policy_gradient_loss | -0.00369     |\n|    std                  | 0.557        |\n|    value_loss           | 6.95e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 296          |\n|    ep_rew_mean          | 892          |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 20           |\n|    time_elapsed         | 682          |\n|    total_timesteps      | 81920        |\n| train/                  |              |\n|    approx_kl            | 0.0016176786 |\n|    clip_fraction        | 0.00354      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.833       |\n|    explained_variance   | 0.242        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 6.05e+04     |\n|    n_updates            | 930          |\n|    policy_gradient_loss | -0.00177     |\n|    std                  | 0.556        |\n|    value_loss           | 7.96e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 1.02e+03     |\n| time/                   |              |\n|    fps                  | 120          |\n|    iterations           | 21           |\n|    time_elapsed         | 716          |\n|    total_timesteps      | 86016        |\n| train/                  |              |\n|    approx_kl            | 0.0019491796 |\n|    clip_fraction        | 0.00732      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.831       |\n|    explained_variance   | 0.152        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 2.64e+04     |\n|    n_updates            | 940          |\n|    policy_gradient_loss | -0.00217     |\n|    std                  | 0.554        |\n|    value_loss           | 1.01e+05     |\n------------------------------------------\n-------------------------------------------\n| rollout/                |               |\n|    ep_len_mean          | 292           |\n|    ep_rew_mean          | 1.21e+03      |\n| time/                   |               |\n|    fps                  | 120           |\n|    iterations           | 22            |\n|    time_elapsed         | 750           |\n|    total_timesteps      | 90112         |\n| train/                  |               |\n|    approx_kl            | 0.00092242355 |\n|    clip_fraction        | 0.00181       |\n|    clip_range           | 0.2           |\n|    entropy_loss         | -0.828        |\n|    explained_variance   | 0.157         |\n|    learning_rate        | 0.0001        |\n|    loss                 | 7.25e+04      |\n|    n_updates            | 950           |\n|    policy_gradient_loss | -0.00128      |\n|    std                  | 0.553         |\n|    value_loss           | 9.32e+04      |\n-------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 291          |\n|    ep_rew_mean          | 1.15e+03     |\n| time/                   |              |\n|    fps                  | 119          |\n|    iterations           | 23           |\n|    time_elapsed         | 785          |\n|    total_timesteps      | 94208        |\n| train/                  |              |\n|    approx_kl            | 0.0019368045 |\n|    clip_fraction        | 0.00586      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.824       |\n|    explained_variance   | 0.203        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 1.99e+05     |\n|    n_updates            | 960          |\n|    policy_gradient_loss | -0.00189     |\n|    std                  | 0.548        |\n|    value_loss           | 1.47e+05     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 293          |\n|    ep_rew_mean          | 1.22e+03     |\n| time/                   |              |\n|    fps                  | 119          |\n|    iterations           | 24           |\n|    time_elapsed         | 819          |\n|    total_timesteps      | 98304        |\n| train/                  |              |\n|    approx_kl            | 0.0012514587 |\n|    clip_fraction        | 0.00452      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.816       |\n|    explained_variance   | 0.3          |\n|    learning_rate        | 0.0001       |\n|    loss                 | 9.38e+03     |\n|    n_updates            | 970          |\n|    policy_gradient_loss | -0.00153     |\n|    std                  | 0.546        |\n|    value_loss           | 2.21e+04     |\n------------------------------------------\n------------------------------------------\n| rollout/                |              |\n|    ep_len_mean          | 297          |\n|    ep_rew_mean          | 1.17e+03     |\n| time/                   |              |\n|    fps                  | 119          |\n|    iterations           | 25           |\n|    time_elapsed         | 854          |\n|    total_timesteps      | 102400       |\n| train/                  |              |\n|    approx_kl            | 0.0014171402 |\n|    clip_fraction        | 0.00366      |\n|    clip_range           | 0.2          |\n|    entropy_loss         | -0.812       |\n|    explained_variance   | 0.207        |\n|    learning_rate        | 0.0001       |\n|    loss                 | 8.95e+04     |\n|    n_updates            | 980          |\n|    policy_gradient_loss | -0.00232     |\n|    std                  | 0.544        |\n|    value_loss           | 1.02e+05     |\n------------------------------------------\n","output_type":"stream"},{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"<stable_baselines3.ppo.ppo.PPO at 0x7aa5e5f3e2c0>"},"metadata":{}}],"execution_count":89},{"cell_type":"code","source":"model.save(\"ppo_anomaly_detector_xgb_role2_400000.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:34:20.577050Z","iopub.status.idle":"2025-05-21T18:34:20.577631Z","shell.execute_reply.started":"2025-05-21T18:34:20.577358Z","shell.execute_reply":"2025-05-21T18:34:20.577374Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_model(model,env)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:31:14.771317Z","iopub.status.idle":"2025-05-21T18:31:14.771816Z","shell.execute_reply.started":"2025-05-21T18:31:14.771458Z","shell.execute_reply":"2025-05-21T18:31:14.771471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}